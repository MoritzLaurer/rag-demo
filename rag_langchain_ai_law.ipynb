{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoritzLaurer/rag-demo/blob/master/rag_langchain_ai_law.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating a RAG pipeline with LangChain and Hugging Face Endpoints or OpenAI"
      ],
      "metadata": {
        "id": "53l_qbyq4LPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook provides a quick demo for creating and evaluating a Retrieval Augmented Generation (RAG) pipeline with LangChain and Hugging Face Endpoints or OpenAI.\n",
        "\n",
        "The demo has the following main steps:\n",
        "1. Create an example vector database: The demo downloads 440 position paper PDFs which stakeholders had submitted to the EU public consultation on the EU White Paper on AI in 2020. These PDFs are processed and ingested in a vector database.\n",
        "2. We then automatically generate test questions about a sample of the texts with an LLM\n",
        "3. Then we create a RAG pipeline and feed the generated test questions into the RAG pipeline as user queries\n",
        "4. RAG evaluation:\n",
        "  - Retriever quality: If we ask a generated question to the RAG pipeline, does the pipeline's retriever retrieve the same original text which was used to generated the question? This provides an indication of retriever (and reranker) quality. Note that this indicator is imperfect, as the retriever could also retrieve other texts that help the RAG pipeline generate good answers beyond only the original text used for generating the test question.\n",
        "  - Answer quality: We also use an LLM to evaluate answer quality more broadly. This is particularly important for RAG systems, as RAG outputs are unstructured text and these are hard to evaluate with standard metrics like ROUGE, BERTScore etc. Standard metrics require a reference \"gold\" answer, which is expensive to create at scale.\n"
      ],
      "metadata": {
        "id": "PsYcqBav4VfY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tocCqFNnQqgo"
      },
      "source": [
        "## Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myUZd_CK4zeL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5f4d29-3224-4b93-c254-5cf3f8a933d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain~=0.1.0 in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain~=0.1.0) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain~=0.1.0) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain~=0.1.0) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain~=0.1.0) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain~=0.1.0) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain~=0.1.0) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from langchain~=0.1.0) (0.0.11)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from langchain~=0.1.0) (0.1.10)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.77 in /usr/local/lib/python3.10/dist-packages (from langchain~=0.1.0) (0.0.80)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain~=0.1.0) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain~=0.1.0) (2.5.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain~=0.1.0) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain~=0.1.0) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain~=0.1.0) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain~=0.1.0) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain~=0.1.0) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain~=0.1.0) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain~=0.1.0) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain~=0.1.0) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain~=0.1.0) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain~=0.1.0) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain~=0.1.0) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain~=0.1.0) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain~=0.1.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain~=0.1.0) (2.14.6)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain~=0.1.0) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain~=0.1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain~=0.1.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain~=0.1.0) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain~=0.1.0) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain~=0.1.0) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain~=0.1.0) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain~=0.1.0) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain~=0.1.0) (1.0.0)\n",
            "Requirement already satisfied: langchain_mistralai in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1 in /usr/local/lib/python3.10/dist-packages (from langchain_mistralai) (0.1.10)\n",
            "Collecting mistralai<0.0.9,>=0.0.8 (from langchain_mistralai)\n",
            "  Using cached mistralai-0.0.8-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_mistralai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_mistralai) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_mistralai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_mistralai) (0.0.80)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_mistralai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_mistralai) (2.5.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_mistralai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_mistralai) (8.2.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from mistralai<0.0.9,>=0.0.8->langchain_mistralai) (3.9.1)\n",
            "Requirement already satisfied: backoff<3.0.0,>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from mistralai<0.0.9,>=0.0.8->langchain_mistralai) (2.2.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.10 in /usr/local/lib/python3.10/dist-packages (from mistralai<0.0.9,>=0.0.8->langchain_mistralai) (3.9.10)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->mistralai<0.0.9,>=0.0.8->langchain_mistralai) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->mistralai<0.0.9,>=0.0.8->langchain_mistralai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->mistralai<0.0.9,>=0.0.8->langchain_mistralai) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->mistralai<0.0.9,>=0.0.8->langchain_mistralai) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->mistralai<0.0.9,>=0.0.8->langchain_mistralai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->mistralai<0.0.9,>=0.0.8->langchain_mistralai) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain_mistralai) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain_mistralai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain_mistralai) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain_mistralai) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain_mistralai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain_mistralai) (2.14.6)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain_mistralai) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain_mistralai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain_mistralai) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain_mistralai) (2023.11.17)\n",
            "Using cached mistralai-0.0.8-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: mistralai\n",
            "  Attempting uninstall: mistralai\n",
            "    Found existing installation: mistralai 0.0.1\n",
            "    Uninstalling mistralai-0.0.1:\n",
            "      Successfully uninstalled mistralai-0.0.1\n",
            "Successfully installed mistralai-0.0.8\n",
            "Requirement already satisfied: langchainhub~=0.1.14 in /usr/local/lib/python3.10/dist-packages (0.1.14)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchainhub~=0.1.14) (2.31.0)\n",
            "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub~=0.1.14) (2.31.0.20240106)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub~=0.1.14) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub~=0.1.14) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub~=0.1.14) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub~=0.1.14) (2023.11.17)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchainhub~=0.1.14)\n",
            "  Using cached urllib3-2.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Using cached urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
            "Installing collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.18\n",
            "    Uninstalling urllib3-1.26.18:\n",
            "      Successfully uninstalled urllib3-1.26.18\n",
            "Successfully installed urllib3-2.1.0\n",
            "Requirement already satisfied: openai~=1.6.0 in /usr/local/lib/python3.10/dist-packages (1.6.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai~=1.6.0) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai~=1.6.0) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai~=1.6.0) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai~=1.6.0) (2.5.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai~=1.6.0) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai~=1.6.0) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai~=1.6.0) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai~=1.6.0) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai~=1.6.0) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai~=1.6.0) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai~=1.6.0) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai~=1.6.0) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai~=1.6.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai~=1.6.0) (2.14.6)\n",
            "Requirement already satisfied: tiktoken~=0.5.2 in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken~=0.5.2) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken~=0.5.2) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken~=0.5.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken~=0.5.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken~=0.5.2) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken~=0.5.2) (2023.11.17)\n",
            "Requirement already satisfied: huggingface_hub~=0.20.1 in /usr/local/lib/python3.10/dist-packages (0.20.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub~=0.20.1) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub~=0.20.1) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub~=0.20.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub~=0.20.1) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub~=0.20.1) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub~=0.20.1) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub~=0.20.1) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub~=0.20.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub~=0.20.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub~=0.20.1) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub~=0.20.1) (2023.11.17)\n",
            "Requirement already satisfied: sentence_transformers~=2.2.2 in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers~=2.2.2) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers~=2.2.2) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers~=2.2.2) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers~=2.2.2) (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers~=2.2.2) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers~=2.2.2) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers~=2.2.2) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers~=2.2.2) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers~=2.2.2) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers~=2.2.2) (0.20.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers~=2.2.2) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers~=2.2.2) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers~=2.2.2) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers~=2.2.2) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers~=2.2.2) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers~=2.2.2) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers~=2.2.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers~=2.2.2) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers~=2.2.2) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers~=2.2.2) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers~=2.2.2) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers~=2.2.2) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers~=2.2.2) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers~=2.2.2) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers~=2.2.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers~=2.2.2) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers~=2.2.2) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers~=2.2.2) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers~=2.2.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers~=2.2.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers~=2.2.2) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers~=2.2.2) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers~=2.2.2) (1.3.0)\n",
            "Requirement already satisfied: qdrant-client~=1.7.0 in /usr/local/lib/python3.10/dist-packages (1.7.0)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client~=1.7.0) (1.60.0)\n",
            "Requirement already satisfied: grpcio-tools>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client~=1.7.0) (1.60.0)\n",
            "Requirement already satisfied: httpx>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.14.0->qdrant-client~=1.7.0) (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from qdrant-client~=1.7.0) (1.23.5)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client~=1.7.0) (2.8.2)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from qdrant-client~=1.7.0) (2.5.3)\n",
            "Collecting urllib3<2.0.0,>=1.26.14 (from qdrant-client~=1.7.0)\n",
            "  Using cached urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
            "Requirement already satisfied: protobuf<5.0dev,>=4.21.6 in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client~=1.7.0) (4.25.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client~=1.7.0) (67.7.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant-client~=1.7.0) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant-client~=1.7.0) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant-client~=1.7.0) (1.0.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant-client~=1.7.0) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant-client~=1.7.0) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant-client~=1.7.0) (0.14.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.14.0->qdrant-client~=1.7.0) (4.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client~=1.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client~=1.7.0) (2.14.6)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client~=1.7.0) (4.9.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant-client~=1.7.0) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant-client~=1.7.0) (4.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant-client~=1.7.0) (1.2.0)\n",
            "Using cached urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "Installing collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.1.0\n",
            "    Uninstalling urllib3-2.1.0:\n",
            "      Successfully uninstalled urllib3-2.1.0\n",
            "Successfully installed urllib3-1.26.18\n",
            "Requirement already satisfied: PyMuPDF~=1.23.7 in /usr/local/lib/python3.10/dist-packages (1.23.11)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.9 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF~=1.23.7) (1.23.9)\n",
            "Collecting git+https://github.com/mistralai/client-python\n",
            "  Cloning https://github.com/mistralai/client-python to /tmp/pip-req-build-q8g314su\n",
            "  Resolved https://github.com/mistralai/client-python to commit a503d3212a1389536794972da24f7ed27569eda0\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: httpx<0.26.0,>=0.25.2 in /usr/local/lib/python3.10/dist-packages (from mistralai==0.0.1) (0.25.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.10 in /usr/local/lib/python3.10/dist-packages (from mistralai==0.0.1) (3.9.10)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from mistralai==0.0.1) (2.5.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai==0.0.1) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai==0.0.1) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai==0.0.1) (1.0.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai==0.0.1) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai==0.0.1) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.26.0,>=0.25.2->mistralai==0.0.1) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->mistralai==0.0.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->mistralai==0.0.1) (2.14.6)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->mistralai==0.0.1) (4.9.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.26.0,>=0.25.2->mistralai==0.0.1) (1.2.0)\n",
            "Building wheels for collected packages: mistralai\n",
            "  Building wheel for mistralai (pyproject.toml): started\n",
            "  Building wheel for mistralai (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for mistralai: filename=mistralai-0.0.1-py3-none-any.whl size=14353 sha256=e7862a0ba76b63781cee38b0e3e48a1106cb7c276c715a560dae22f0270bda4c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i6o02v_5/wheels/97/82/15/4e2e5d6c8bf0190068fe36637d8b4b21bee9ec45ce75d1864c\n",
            "Successfully built mistralai\n",
            "Installing collected packages: mistralai\n",
            "  Attempting uninstall: mistralai\n",
            "    Found existing installation: mistralai 0.0.8\n",
            "    Uninstalling mistralai-0.0.8:\n",
            "      Successfully uninstalled mistralai-0.0.8\n",
            "Successfully installed mistralai-0.0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "qdrant-client 1.7.0 requires urllib3<2.0.0,>=1.26.14, but you have urllib3 2.1.0 which is incompatible.\n",
            "tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 4.25.2 which is incompatible.\n",
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 4.25.2 which is incompatible.\n",
            "types-requests 2.31.0.20240106 requires urllib3>=2, but you have urllib3 1.26.18 which is incompatible.\n",
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/mistralai/client-python /tmp/pip-req-build-q8g314su\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-mistralai 0.0.2 requires mistralai<0.0.9,>=0.0.8, but you have mistralai 0.0.1 which is incompatible.\n",
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pip install --upgrade pip -q\n",
        "pip install langchain~=0.1.0\n",
        "pip install langchain_mistralai\n",
        "pip install langchainhub~=0.1.14\n",
        "pip install openai~=1.6.0\n",
        "pip install tiktoken~=0.5.2\n",
        "pip install transformers>=4.35.2\n",
        "pip install huggingface_hub~=0.20.1\n",
        "pip install sentence_transformers~=2.2.2\n",
        "pip install qdrant-client~=1.7.0\n",
        "pip install PyMuPDF~=1.23.7\n",
        "\n",
        "pip install git+https://github.com/mistralai/client-python\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "\n",
        "# for using hugging face models\n",
        "login(token=userdata.get('HF_TOKEN'))\n",
        "\n",
        "# for using OAI models\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_KEY')"
      ],
      "metadata": {
        "id": "z-DBbhcmqdal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20a9d9be-eecc-4ed4-a8ff-db7440946007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE9Aj1bcQnMN"
      },
      "source": [
        "## Prepare example data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download PDF data"
      ],
      "metadata": {
        "id": "GKSJzyg9tinB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## download PDF data\n",
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# URL of the zip file in your GitHub repo (make sure it's the raw file URL)\n",
        "zip_url = 'https://github.com/MoritzLaurer/rag-demo/blob/master/data/position-papers-pdfs.zip?raw=true'\n",
        "\n",
        "# Download the zip file\n",
        "print(\"Downloading zip file...\")\n",
        "response = requests.get(zip_url)\n",
        "zip_content = BytesIO(response.content)\n",
        "\n",
        "# Define the extraction path\n",
        "extract_path = '/content/data'\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "if not os.path.exists(extract_path):\n",
        "    os.makedirs(extract_path)\n",
        "\n",
        "# Extract the zip file\n",
        "print(\"Extracting zip file...\")\n",
        "with zipfile.ZipFile(zip_content, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Extraction completed.\")\n",
        "\n",
        "file_paths = [f for f in os.listdir(extract_path) if os.path.isfile(os.path.join(extract_path, f))]\n",
        "print(f\"{len(file_paths)} PDF files downloaded.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa-86eodrEez",
        "outputId": "35321066-09bd-43d4-8636-f49bc90f7794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading zip file...\n",
            "Extracting zip file...\n",
            "Extraction completed.\n",
            "440 PDF files downloaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-mL7xkUf3F6"
      },
      "source": [
        "### Process data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parse the raw PDFs into machine-readable docs\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "directory = \"./data\"\n",
        "\n",
        "docs = []\n",
        "for pdf_path in tqdm(os.listdir(directory)):\n",
        "  try:\n",
        "    docs.append(PyMuPDFLoader(os.path.join(directory, pdf_path)).load())\n",
        "  except Exception as e:\n",
        "    print(\"Exception: \", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "83ec21e9f690429ea09a9ce4f04ad7f2",
            "3e24e5a0d37a4ee3b8f519a454862c6e",
            "27c8a1be1d8540e69145cfcf07725fd1",
            "2d856a03851d45449144c85974c4147d",
            "eee0f381993b43178d6d53dab74d6749",
            "93046f607bd1445a9a591aff4cdfcfc8",
            "041c17a8fbf8450a9a58c812fdfc131f",
            "98c887a6a4a5482491e7b2d66880a271",
            "9c30b006237e4878ab3df0acd0ce59d0",
            "1a2c1eecf3ed46aca857805690e721a7",
            "3b6f0f396b8446e78de4e364a80d8b74"
          ]
        },
        "id": "_bjaESlGec45",
        "outputId": "faea344d-6ba0-49ec-e274-aec57a4101a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/440 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83ec21e9f690429ea09a9ce4f04ad7f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception:  cannot open broken document\n",
            "Exception:  cannot open broken document\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the docs into shorter chunks that fit into LLM context windows\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# text splitter based on the tokenizer of a model of your choosing\n",
        "# to make texts fit exactly a transformer's context window size\n",
        "# langchain text splitters: https://python.langchain.com/docs/modules/data_connection/document_transformers/\n",
        "chunk_size = 256\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
        "        AutoTokenizer.from_pretrained(\"BAAI/bge-small-en-v1.5\"),\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=int(chunk_size / 10),\n",
        "        add_start_index=True,\n",
        "        strip_whitespace=True,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
        ")\n",
        "\n",
        "\n",
        "docs_processed = [text_splitter.split_documents(doc) for doc in docs]\n",
        "docs_processed = [item for sublist in docs_processed for item in sublist]\n",
        "\n",
        "print(len(docs_processed))\n",
        "\n",
        "docs_processed[:1]"
      ],
      "metadata": {
        "id": "T1wNg46flg68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95de0618-1e80-4f55-ed9b-c7b60b64492b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14785\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='1 the role of artificial intelligence within in silico medicine vph institute – avicenna alliance white paper provisional executive summary june 12th 2020 contributions liesbet geris, phd – university of liege & ku leuven ; vph institute ; avicenna alliance cecile f. rousseau, phd - voisin consulting life sciences ; avicenna alliance marco viceconti, phd – alma mater studiorum - university of bologna ; vph institute ; avicenna alliance alfons g. hoekstra, phd – university of amsterdam ; vph institute ; avicenna alliance emmanuelle m. voisin, phd – voisin consulting life sciences ; avicenna alliance markus reiterer, phd – medtronic, plc ; avicenna alliance martha de cunha - burgman, msc – medtronic, plc ; avicenna alliance michael auffret, msc – voisin consulting life sciences ; avicenna alliance payman afshari, phd – johnson and johnson ; avicenna alliance wen - yang chu, msc – virtonomy. io ; avicenna alliance thierry marchal, mecheng, mba – ansys ; avicenna alliance alicia waterkeyn, llm - rpp group', metadata={'source': './data/F530172-Avicenna_Alliance_Final_Provisional_Executive_Summary_AI_White_Paper_12.06.2020.pdf', 'file_path': './data/F530172-Avicenna_Alliance_Final_Provisional_Executive_Summary_AI_White_Paper_12.06.2020.pdf', 'page': 0, 'total_pages': 5, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''})]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sample data to reduce embedding and generation costs"
      ],
      "metadata": {
        "id": "XBcPIqYjMWu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "# sample corpus for embedding\n",
        "n_sample_texts = 100\n",
        "index_random = random.sample(range(len(docs_processed)), 100)\n",
        "docs_samp = [docs_processed[i] for i in index_random]\n",
        "\n",
        "# sample a smaller set of texts to generate questions from\n",
        "n_questions = 5\n",
        "docs_for_q_generation = docs_samp[:n_questions]\n",
        "docs_for_q_generation = [doc.page_content for doc in docs_for_q_generation]\n"
      ],
      "metadata": {
        "id": "hUIhFQoc6GtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automatic question generation for evaluation\n",
        "\n",
        "This section generates questions which users could ask about a specific text in the database. This allows us to assess:  \n",
        "- If we ask a generated question to the RAG pipeline, does the pipeline's retriever retrieve the same text which was used to generated the question? This provides an indication of retriever (and reranker) quality.\n",
        "- Beyond the original text used for generating the question, the retriever might retrieve other texts that are also help the RAG pipeline generate good answers. We therefore also use an LLM to evaluate answer quality more broadly."
      ],
      "metadata": {
        "id": "tKOmYhRe7vxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create an huggingface inference endpoint to run any LLM\n",
        "# intro: https://www.philschmid.de/inference-endpoints-iac\n",
        "# docs: https://huggingface.co/docs/huggingface_hub/v0.20.1/en/package_reference/hf_api#huggingface_hub.HfApi.create_inference_endpoint\n",
        "from huggingface_hub import create_inference_endpoint\n",
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "\n",
        "create_new_endpoint = False\n",
        "model_for_endpoint = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"  #\"mistralai/Mixtral-8x7B-Instruct-v0.1\",  #\"HuggingFaceH4/zephyr-7b-beta\",\n",
        "endpoint_name = \"mixtral-8x7b-instruct-v0-1-test\"\n",
        "\n",
        "if create_new_endpoint:\n",
        "  # define TGI as custom image\n",
        "  custom_image = {\n",
        "      \"health_route\": \"/health\",  # Health route for TGI\n",
        "      \"env\": {\n",
        "          \"MAX_BATCH_PREFILL_TOKENS\": \"2048\", # can be adjusted to your needs\n",
        "          \"MAX_INPUT_LENGTH\": \"1024\", # can be adjusted to your needs\n",
        "          \"MAX_TOTAL_TOKENS\": \"1512\", # can be adjusted to your needs\n",
        "          \"MODEL_ID\": \"/repository\",  # IE will save the model in /repository\n",
        "      },\n",
        "      \"url\": \"ghcr.io/huggingface/text-generation-inference:1.3.3\",\n",
        "  }\n",
        "\n",
        "  # Create Inference Endpoint to run Zephyr 7B\n",
        "  print(\"Creating Inference Endpoint\")\n",
        "  hf_endpoint = create_inference_endpoint(\n",
        "      name=endpoint_name,\n",
        "      repository=model_for_endpoint,\n",
        "      framework=\"pytorch\",\n",
        "      task=\"text-generation\",\n",
        "      vendor=\"aws\",\n",
        "      region=\"us-east-1\",\n",
        "      type=\"protected\",\n",
        "      instance_size=\"2xlarge\",  #\"medium\",\n",
        "      instance_type=\"p4de\",  #\"g5.2xlarge\",  # A10G GPU. Pricing: https://huggingface.co/pricing#endpoints\n",
        "      accelerator=\"gpu\",\n",
        "      namespace=\"HF-test-lab\",  # your user or organisation name on the HF hub\n",
        "      custom_image=custom_image,\n",
        "  )\n",
        "  #curl https://api.endpoints.huggingface.cloud/v2/endpoint/MoritzLaurer \\ -X POST \\ -d '{\"compute\":{\"accelerator\":\"gpu\",\"instanceSize\":\"2xlarge\",\"instanceType\":\"p4de\",\"scaling\":{\"maxReplica\":1,\"minReplica\":0}},\"model\":{\"framework\":\"pytorch\",\"image\":{\"custom\":{\"health_route\":\"/health\",\"env\":{\"MAX_BATCH_PREFILL_TOKENS\":\"2048\",\"MAX_INPUT_LENGTH\":\"1024\",\"MAX_TOTAL_TOKENS\":\"1512\",\"QUANTIZE\":\"bitsandbytes\",\"MODEL_ID\":\"/repository\"},\"url\":\"ghcr.io/huggingface/text-generation-inference:1.3.4\"}},\"repository\":\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\"task\":\"text-generation\"},\"name\":\"aws-mixtral-8x7b-instruct-v0-1\",\"provider\":{\"region\":\"us-east-1\",\"vendor\":\"aws\"},\"type\":\"protected\"}' \\ -H \"Content-Type: application/json\" \\ -H \"Authorization: Bearer XXXXX\"\n",
        "  print(\"Waiting for endpoint to be deployed\")\n",
        "  hf_endpoint.wait()\n",
        "\n",
        "  print(\"Endpoint ready\")\n",
        "\n",
        "\n",
        "else:\n",
        "  print(\"Waiting for endpoint to be resumed\")\n",
        "  hf_endpoint = api.get_inference_endpoint(name=endpoint_name, namespace=\"HF-test-lab\")\n",
        "  hf_endpoint.resume()  # resume only works if endpoint was explicitly paused. If endpoint scaled to 0, need to send a request to wake it up\n",
        "  hf_endpoint.wait()\n",
        "  print(\"Endpoint ready\")\n",
        "\n",
        "  # to manage an existing endpoint, use:\n",
        "  #hf_endpoint.resume()\n",
        "  #hf_endpoint.pause()\n",
        "  #hf_endpoint.delete()\n",
        "  # Endpoints should automatically scale to 0 after 15 minutes to avoid unnecessary costs\n",
        "  # But you can delete it manually just to be save"
      ],
      "metadata": {
        "id": "5Ciu9hbwyFNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import HuggingFaceEndpoint\n",
        "from langchain_mistralai.chat_models import ChatMistralAI\n",
        "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "\n",
        "provider_for_question_generation = \"MISTRAL\"\n",
        "\n",
        "\n",
        "if provider_for_question_generation == \"HF\":\n",
        "  chat_model = HuggingFaceEndpoint(\n",
        "    endpoint_url=hf_endpoint.url,  #\"https://ytjpei7t003tedav.us-east-1.aws.endpoints.huggingface.cloud\",\n",
        "    task=\"text-generation\",\n",
        "    huggingfacehub_api_token=userdata.get('HF_TOKEN'),\n",
        "    model_kwargs={}\n",
        "  )\n",
        "\n",
        "elif provider_for_question_generation == \"OAI\":\n",
        "  # https://platform.openai.com/docs/api-reference/chat\n",
        "  chat_model = ChatOpenAI(\n",
        "      model=\"gpt-3.5-turbo-1106\",  #\"gpt-3.5-turbo-1106\",  # \"gpt-4-1106-preview\"\n",
        "      temperature=0.2, max_tokens=1024,\n",
        "      n=1, top_p=0.95,\n",
        "      frequency_penalty=0.0,  # Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\n",
        "      presence_penalty=0.0,  # Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.\n",
        "      #response_format={ \"type\": \"json_object\" },\n",
        "      seed=42,\n",
        "  )\n",
        "\n",
        "elif provider_for_question_generation == \"MISTRAL\":\n",
        "  # source: https://github.com/langchain-ai/langchain/blob/9b3962fc2521ec0d6ef2ea7c0a40b9c32977671a/libs/partners/mistralai/langchain_mistralai/chat_models.py#L156C6-L156C6\n",
        "  # docs: https://docs.mistral.ai/platform/client/  or https://python.langchain.com/docs/integrations/chat/mistralai\n",
        "  chat_model = ChatMistralAI(\n",
        "      mistral_api_key=userdata.get('MISTRAL_KEY'),\n",
        "      max_retries=5,\n",
        "      timeout=60,\n",
        "      max_concurrent_requests=2,\n",
        "      model=\"mistral-small\",\n",
        "      temperature=0.2,\n",
        "      max_tokens=1024,\n",
        "      top_p=0.95,  #Decode using nucleus sampling: consider the smallest set of tokens whose probability sum is at least top_p. Must be in the closed interval [0.0, 1.0].\n",
        "      random_seed=42,\n",
        "      safe_mode=False,\n",
        "  )\n",
        "\n"
      ],
      "metadata": {
        "id": "mO2OTlAX7xzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import numpy as np\n",
        "\n",
        "# we generate both a question and answer\n",
        "# having an answer which according to the LLM follows from the question makes it easier to judge the quality of the question\n",
        "instruction_qa_gen = \"\"\"\\\n",
        "Your task is to write a factoid question and an answer given a context.\n",
        "\n",
        "Your factoid question should be answerable with a specific, concise piece of factual information from the context.\n",
        "Your factoid question should be formulated in the same style as questions users could ask in a search engine. \\\n",
        "This means that your factoid question MUST NOT mention something like \"according to the passage\" or \"context\".\n",
        "\n",
        "After writing the factoid question, also write the corresponding answer that is clearly grounded in the context.\n",
        "\n",
        "Always answer in this JSON response format: {{\"question\": \"...\", \"answer\": \"...\"}}\n",
        "\n",
        "context: {context}\\n\n",
        "JSON response: \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "prompt_question_gen = ChatPromptTemplate.from_template(instruction_qa_gen)\n",
        "\n",
        "chain_question_gen = prompt_question_gen | chat_model\n",
        "\n",
        "question_answer_dic_lst = []\n",
        "for context in docs_for_q_generation:\n",
        "  print(\"Context:\\n\", context)\n",
        "\n",
        "  output_question_dic = chain_question_gen.invoke({\"context\": context})\n",
        "\n",
        "  if provider_for_question_generation in [\"OAI\", \"MISTRAL\"]:\n",
        "    output_question_dic = output_question_dic.content\n",
        "\n",
        "  try:\n",
        "    output_question_judge_dic = ast.literal_eval(output_question_dic)\n",
        "  except:\n",
        "    output_question_judge_dic = {\"question\": np.nan, \"answer\": np.nan}\n",
        "\n",
        "  question_answer_dic_lst.append(output_question_judge_dic)\n",
        "  print(\"\\nGenerated question with answer:\\n\", output_question_judge_dic, \"\\n\")\n",
        "\n",
        "question_lst = [dic[\"question\"] for dic in question_answer_dic_lst]\n",
        "answer_lst = [dic[\"answer\"] for dic in question_answer_dic_lst]\n"
      ],
      "metadata": {
        "id": "Fsg4SXAT7xzR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a4799b-b3d4-48b5-bea1-00fe7db3916d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context:\n",
            " framework to assess the potential benefits. such opportunities include but are not 14 limited to : improvements to fairness, health, privacy, equity or efficiency. 15 3. the framework could assess the risk of tasks instead of sectors. the framework proposes to assess risks based on the industry sector. we suggest that an alternative basis should be considered and we suggest “ tasks ” as such an alternative. the 16 motivation to assess the risks of tasks instead of sectors is that sectors differ greatly internally with respect to the risk that ai tools pose. for example, although the health care sector appears to exhibit greater risks than municipal garbage collection, this need not be the case. as municipal garbage collection transitions to autonomous vehicle technology, very mundane driving decisions, such as whether the vehicles should avoid left turns, can have a significant negative impact on population safety in the aggregate. 17 likewise, accounting may as a whole appear to be a low risk sector, but individual tasks and practices that individual accountants engage in might carry significant risks. additionally, a household appliance manufacturer that uses a simple ai classifier in customer support to score inbound requests by urgency may, in practice, discriminate by race, gender or socio - economic status. hence, alternative frameworks should be considered that allow for a more fine -\n",
            "\n",
            "Generated question with answer:\n",
            " {'question': 'How does the framework suggest assessing AI risks differently?', 'answer': 'The framework suggests assessing AI risks based on tasks instead of sectors. This is because sectors can differ greatly internally with respect to the risk that AI tools pose. For example, tasks in municipal garbage collection or accounting, which may appear to be low risk, can carry significant risks. Additionally, AI tools used in seemingly safe sectors like customer support can lead to discrimination.'} \n",
            "\n",
            "Context:\n",
            " zivilgesellschaft eingebunden werden sollen und zugang zu den innovationszentren erhalten sollen. daruber hinaus ware auch eine verankerung von weitergehenden transparenz - und informationspflichten gegenuber der offentlichkeit zu verankern. so konnte ein direkter dialog mit betroffenen in der arbeitswelt und ein „ bottom - up - ansatz “ von beginn an im sinne eines „ menschenzentrierten ansatzes “ gewahrleistet werden. in maßnahme 3 ( aufbau und unterstutzung von netzen fuhrender universitaten und hochschuleinrichtungen ) wird die einbeziehung der sozialpartner als „ entscheidend “ bezeichnet und explizit von einem menschenzentrierten ansatz gesprochen, dies ist zu begrußen und sollte auch bei maßnahme 2 der fall sein. zusatzlich ist anzumerken, dass sich\n",
            "\n",
            "Generated question with answer:\n",
            " {'question': 'Which approach to innovations centers is considered crucial in measure 3?', 'answer': 'Measure 3 emphasizes the crucial role of including social partners in the establishment and support of networks of leading universities and higher education institutions, with a focus on a human-centered approach.'} \n",
            "\n",
            "Context:\n",
            " cnil, for permission to use a facial recognition system for managing entry at ampere high school in marseille. this “ trial ” was intended to be a year - long experiment and was also being carried out at another school in the region ( the lycee les eucalyptus in nice ) and was said to be held on the basis of students ’ and parents ’ consent. 79 the intention of the system was to facilitate the job of the schools ’ security agents, helping them to spot identity theft and to prevent access of unauthorised persons to the school. this was designed to increase the security of students and staff and to speed up the time it took for students to enter the school premises. edri ’ s analysis : • objective : as indicated by the cnil, we agree that the system aims to achieve a legitimate public au - thority objective of managing entry into a school, to ensure that the right people could enter and the wrong people could not. • necessity and proportionality : as the cnil emphasised, a school facial recognition system is not necessary when there is the less intrusive alternative of using identity badges. furthermore, this use of facial recognition is disproportionate as it brings in a large - scale, intrusive data surveillance\n",
            "\n",
            "Generated question with answer:\n",
            " {'question': \"What is EDRI's stance on the necessity and proportionality of using facial recognition systems in schools as opposed to identity badges?\", 'answer': 'EDRI argues that using facial recognition systems in schools is not necessary when there is a less intrusive alternative of using identity badges, and that this use is disproportionate as it brings in large-scale, intrusive data surveillance.'} \n",
            "\n",
            "Context:\n",
            " le domaine de l ’ ia pourrait etre a meme de stimuler et concentrer la recherche dans les centres de recherche des etats membres, tout en incitant a la cooperation.\n",
            "\n",
            "Generated question with answer:\n",
            " {'question': 'How can artificial intelligence impact research in EU member states?', 'answer': \"Artificial intelligence has the potential to stimulate and focus research within the EU member states' research centers, while also encouraging cooperation.\"} \n",
            "\n",
            "Context:\n",
            " i. e., which data was influential ), and to facilitate effective claims that a decision was made on the basis of inaccurate data and contest it. c. explanations to alter future decisions from the view of the data subject, alongside understanding and contesting decisions, explanations can also be useful to indicate what could be changed to receive a desired result in the future. this pur - pose does not necessarily relate to the right to contest. accurate deci - sions can produce unfavourable results for the data subject. the chances of successfully challenging the decision will also be low in some cases, or the costs and effort required too high. in these situa - 199. regulation 2016 / 679, gdpr, art. 22 ( 3 ), 2016 o. j. ( l 119 ) 46 ( eu ). 200. see article 29 data protection working party, supra note 85, at 25, 27.\n",
            "\n",
            "Generated question with answer:\n",
            " {'question': \"What article in GDPR outlines the data subject's right to demand human intervention and explanation in decisions based on automated data processing?\", 'answer': 'Article 22(3) of GDPR, 2016/679, gives the data subject the right to demand human intervention and explanation in decisions based on automated data processing.'} \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# good alternativ critique prompts: https://github.com/A-Roucher/RAG_cookbook/blob/master/retrieval_augmented_generation.ipynb\n",
        "\n",
        "instruction_question_judge = \"\"\"\\\n",
        "Your task is to score the quality of a question that has been written based on a specific context.\n",
        "\n",
        "Your scoring criteria for assessing the question are:\n",
        "- ambiguity: Can the question be clearly, unambiguously answered with the given context?\n",
        "- form and verbosity: Is the question formulated like a question that a user could ask to a search engine? The question should not be accompanied by an answer or other text that users would not ask in a search query\n",
        "\n",
        "Your quality score should be in the range of 0 to 100.\\\n",
        "100 means a very good question, 0 means a very bad question, 50 means a mediocre question.\n",
        "\n",
        "First briefly reason step-by-step to assess the extent to which the question fulfills these criteria. Your reasoning should be short.\n",
        "Then return the quality score.\n",
        "\n",
        "Always answer in this JSON evaluation format: {{\"reason\": \"...\", \"score\": \"...\"}}\n",
        "\n",
        "context: \"{context}\"\\n\n",
        "question: \"{question}\"\\n\n",
        "JSON evaluation: \"\"\"\n",
        "\n",
        "\n",
        "prompt_question_judge = ChatPromptTemplate.from_template(instruction_question_judge)\n",
        "\n",
        "chain = prompt_question_judge | chat_model\n",
        "\n",
        "question_judgement_lst = []\n",
        "for qa_dic, context in zip(question_answer_dic_lst, docs_for_q_generation):\n",
        "  print(\"Question:\", qa_dic[\"question\"])\n",
        "  print(\"Context:\", context)\n",
        "\n",
        "  output_question_judgement = chain.invoke({\"question\": qa_dic[\"question\"].strip().replace(\"\\n\", \" \"), \"context\": context.strip()})\n",
        "\n",
        "  if provider_for_question_generation == \"OAI\":\n",
        "    output_question_judgement = output_question_judgement.content\n",
        "\n",
        "  question_judgement_lst.append(output_question_judgement)\n",
        "  print(\"\\nJudgement:\\n\", output_question_judgement, \"\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WpAUC2A8fSv6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "004b9ab2-cb6d-40a7-f62a-bfcbf6164e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does the framework suggest assessing AI risks differently?\n",
            "Context: framework to assess the potential benefits. such opportunities include but are not 14 limited to : improvements to fairness, health, privacy, equity or efficiency. 15 3. the framework could assess the risk of tasks instead of sectors. the framework proposes to assess risks based on the industry sector. we suggest that an alternative basis should be considered and we suggest “ tasks ” as such an alternative. the 16 motivation to assess the risks of tasks instead of sectors is that sectors differ greatly internally with respect to the risk that ai tools pose. for example, although the health care sector appears to exhibit greater risks than municipal garbage collection, this need not be the case. as municipal garbage collection transitions to autonomous vehicle technology, very mundane driving decisions, such as whether the vehicles should avoid left turns, can have a significant negative impact on population safety in the aggregate. 17 likewise, accounting may as a whole appear to be a low risk sector, but individual tasks and practices that individual accountants engage in might carry significant risks. additionally, a household appliance manufacturer that uses a simple ai classifier in customer support to score inbound requests by urgency may, in practice, discriminate by race, gender or socio - economic status. hence, alternative frameworks should be considered that allow for a more fine -\n",
            "\n",
            "Judgement:\n",
            " content='{\"reason\": \"The question is clear and unambiguous, and it directly relates to the context provided. However, the question could be improved by specifying which framework is being referred to, as there are two different frameworks mentioned in the context. Despite this, the question is still specific enough to be answered. The form of the question is also appropriate for a search engine query. The score is slightly reduced due to the ambiguity regarding which framework is being referred to.\", \"score\": \"85\"}' \n",
            "\n",
            "Question: Which approach to innovations centers is considered crucial in measure 3?\n",
            "Context: zivilgesellschaft eingebunden werden sollen und zugang zu den innovationszentren erhalten sollen. daruber hinaus ware auch eine verankerung von weitergehenden transparenz - und informationspflichten gegenuber der offentlichkeit zu verankern. so konnte ein direkter dialog mit betroffenen in der arbeitswelt und ein „ bottom - up - ansatz “ von beginn an im sinne eines „ menschenzentrierten ansatzes “ gewahrleistet werden. in maßnahme 3 ( aufbau und unterstutzung von netzen fuhrender universitaten und hochschuleinrichtungen ) wird die einbeziehung der sozialpartner als „ entscheidend “ bezeichnet und explizit von einem menschenzentrierten ansatz gesprochen, dies ist zu begrußen und sollte auch bei maßnahme 2 der fall sein. zusatzlich ist anzumerken, dass sich\n",
            "\n",
            "Judgement:\n",
            " content='{\"reason\": \"The question is formulated clearly and unambiguously, using proper grammar and verb structure. It refers specifically to \\'measure 3\\' and asks about the \\'approach to innovations centers\\' which is mentioned in the context. The question does not contain any ambiguity and is formulated like a question that a user could ask to a search engine. Therefore, it fulfills the criteria well.\", \"score\": \"90\"}' \n",
            "\n",
            "Question: What is EDRI's stance on the necessity and proportionality of using facial recognition systems in schools as opposed to identity badges?\n",
            "Context: cnil, for permission to use a facial recognition system for managing entry at ampere high school in marseille. this “ trial ” was intended to be a year - long experiment and was also being carried out at another school in the region ( the lycee les eucalyptus in nice ) and was said to be held on the basis of students ’ and parents ’ consent. 79 the intention of the system was to facilitate the job of the schools ’ security agents, helping them to spot identity theft and to prevent access of unauthorised persons to the school. this was designed to increase the security of students and staff and to speed up the time it took for students to enter the school premises. edri ’ s analysis : • objective : as indicated by the cnil, we agree that the system aims to achieve a legitimate public au - thority objective of managing entry into a school, to ensure that the right people could enter and the wrong people could not. • necessity and proportionality : as the cnil emphasised, a school facial recognition system is not necessary when there is the less intrusive alternative of using identity badges. furthermore, this use of facial recognition is disproportionate as it brings in a large - scale, intrusive data surveillance\n",
            "\n",
            "Judgement:\n",
            " content='{\"reason\": \"The question is clear, concise, and directly addresses the issue of necessity and proportionality of facial recognition systems in schools as compared to identity badges, as discussed in the context. The question is formulated in a way that a user could ask to a search engine.\", \"score\": \"100\"}' \n",
            "\n",
            "Question: How can artificial intelligence impact research in EU member states?\n",
            "Context: le domaine de l ’ ia pourrait etre a meme de stimuler et concentrer la recherche dans les centres de recherche des etats membres, tout en incitant a la cooperation.\n",
            "\n",
            "Judgement:\n",
            " content='{\"reason\": \"The question is formulated clearly and unambiguously, and it is the type of question a user might ask in a search engine. The question directly relates to the context provided, focusing on how artificial intelligence can impact research in EU member states. The context suggests that AI could stimulate and concentrate research in EU member states and encourage cooperation, which aligns with the question\\'s focus.\", \"score\": \"95\"}' \n",
            "\n",
            "Question: What article in GDPR outlines the data subject's right to demand human intervention and explanation in decisions based on automated data processing?\n",
            "Context: i. e., which data was influential ), and to facilitate effective claims that a decision was made on the basis of inaccurate data and contest it. c. explanations to alter future decisions from the view of the data subject, alongside understanding and contesting decisions, explanations can also be useful to indicate what could be changed to receive a desired result in the future. this pur - pose does not necessarily relate to the right to contest. accurate deci - sions can produce unfavourable results for the data subject. the chances of successfully challenging the decision will also be low in some cases, or the costs and effort required too high. in these situa - 199. regulation 2016 / 679, gdpr, art. 22 ( 3 ), 2016 o. j. ( l 119 ) 46 ( eu ). 200. see article 29 data protection working party, supra note 85, at 25, 27.\n",
            "\n",
            "Judgement:\n",
            " content='{\"reason\": \"The question is formulated clearly and unambiguously, asking about a specific right of the data subject in the context of GDPR and automated data processing. The question is also formulated in a way that a user could ask to a search engine. There is no ambiguity in the question and it is not accompanied by any additional text that users would not include in a search query. The question demonstrates a good understanding of the context and asks for specific information that can be found in the provided text.\", \"score\": \"95\"}' \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parsing the JSON output can lead to errors\n",
        "# with open-source models, which don't enforce JSON as well as OAI\n",
        "import ast\n",
        "import numpy as np\n",
        "\n",
        "#output_question_judge_dic = []\n",
        "output_question_score = []\n",
        "output_question_reason = []\n",
        "for output in question_judgement_lst:\n",
        "  try:\n",
        "    output_question_judge_dic = ast.literal_eval(output)\n",
        "    output_question_score.append(int(output_question_judge_dic[\"score\"]))\n",
        "    output_question_reason.append(output_question_judge_dic[\"reason\"])\n",
        "\n",
        "  except:\n",
        "    print(\"This JSON output could not be parsed: \", output)\n",
        "    #output_question_judge_dic.append(np.nan)\n",
        "    output_question_score.append(np.nan)\n",
        "    output_question_reason.append(np.nan)\n",
        "\n"
      ],
      "metadata": {
        "id": "iOg2Q4lQLIcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9c22d96-56bc-4d36-ecc2-c561ea22d7dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This JSON output could not be parsed:  content='{\"reason\": \"The question is clear and unambiguous, and it directly relates to the context provided. However, the question could be improved by specifying which framework is being referred to, as there are two different frameworks mentioned in the context. Despite this, the question is still specific enough to be answered. The form of the question is also appropriate for a search engine query. The score is slightly reduced due to the ambiguity regarding which framework is being referred to.\", \"score\": \"85\"}'\n",
            "This JSON output could not be parsed:  content='{\"reason\": \"The question is formulated clearly and unambiguously, using proper grammar and verb structure. It refers specifically to \\'measure 3\\' and asks about the \\'approach to innovations centers\\' which is mentioned in the context. The question does not contain any ambiguity and is formulated like a question that a user could ask to a search engine. Therefore, it fulfills the criteria well.\", \"score\": \"90\"}'\n",
            "This JSON output could not be parsed:  content='{\"reason\": \"The question is clear, concise, and directly addresses the issue of necessity and proportionality of facial recognition systems in schools as compared to identity badges, as discussed in the context. The question is formulated in a way that a user could ask to a search engine.\", \"score\": \"100\"}'\n",
            "This JSON output could not be parsed:  content='{\"reason\": \"The question is formulated clearly and unambiguously, and it is the type of question a user might ask in a search engine. The question directly relates to the context provided, focusing on how artificial intelligence can impact research in EU member states. The context suggests that AI could stimulate and concentrate research in EU member states and encourage cooperation, which aligns with the question\\'s focus.\", \"score\": \"95\"}'\n",
            "This JSON output could not be parsed:  content='{\"reason\": \"The question is formulated clearly and unambiguously, asking about a specific right of the data subject in the context of GDPR and automated data processing. The question is also formulated in a way that a user could ask to a search engine. There is no ambiguity in the question and it is not accompanied by any additional text that users would not include in a search query. The question demonstrates a good understanding of the context and asks for specific information that can be found in the provided text.\", \"score\": \"95\"}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_questions = pd.DataFrame({\n",
        "  \"question\": question_lst,\n",
        "  \"answer\": answer_lst,\n",
        "  \"score_question\": output_question_score,\n",
        "  \"score_reason\": output_question_reason,\n",
        "  \"context\": docs_for_q_generation,\n",
        "})\n",
        "\n",
        "df_questions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZymdLlpaPSYy",
        "outputId": "6d1f1092-86c3-46ed-aae4-db3df6a20242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  How does the framework suggest assessing AI ri...   \n",
              "1  Which approach to innovations centers is consi...   \n",
              "2  What is EDRI's stance on the necessity and pro...   \n",
              "3  How can artificial intelligence impact researc...   \n",
              "4  What article in GDPR outlines the data subject...   \n",
              "\n",
              "                                              answer  score_question  \\\n",
              "0  The framework suggests assessing AI risks base...             NaN   \n",
              "1  Measure 3 emphasizes the crucial role of inclu...             NaN   \n",
              "2  EDRI argues that using facial recognition syst...             NaN   \n",
              "3  Artificial intelligence has the potential to s...             NaN   \n",
              "4  Article 22(3) of GDPR, 2016/679, gives the dat...             NaN   \n",
              "\n",
              "   score_reason                                            context  \n",
              "0           NaN  framework to assess the potential benefits. su...  \n",
              "1           NaN  zivilgesellschaft eingebunden werden sollen un...  \n",
              "2           NaN  cnil, for permission to use a facial recogniti...  \n",
              "3           NaN  le domaine de l ’ ia pourrait etre a meme de s...  \n",
              "4           NaN  i. e., which data was influential ), and to fa...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9562f502-87fa-49ab-8f7e-22fb9d4cb795\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>score_question</th>\n",
              "      <th>score_reason</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How does the framework suggest assessing AI ri...</td>\n",
              "      <td>The framework suggests assessing AI risks base...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>framework to assess the potential benefits. su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Which approach to innovations centers is consi...</td>\n",
              "      <td>Measure 3 emphasizes the crucial role of inclu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>zivilgesellschaft eingebunden werden sollen un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is EDRI's stance on the necessity and pro...</td>\n",
              "      <td>EDRI argues that using facial recognition syst...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cnil, for permission to use a facial recogniti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How can artificial intelligence impact researc...</td>\n",
              "      <td>Artificial intelligence has the potential to s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>le domaine de l ’ ia pourrait etre a meme de s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What article in GDPR outlines the data subject...</td>\n",
              "      <td>Article 22(3) of GDPR, 2016/679, gives the dat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>i. e., which data was influential ), and to fa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9562f502-87fa-49ab-8f7e-22fb9d4cb795')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9562f502-87fa-49ab-8f7e-22fb9d4cb795 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9562f502-87fa-49ab-8f7e-22fb9d4cb795');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-55706c5a-0a9e-4c16-bff8-1cc250bb34fc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-55706c5a-0a9e-4c16-bff8-1cc250bb34fc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-55706c5a-0a9e-4c16-bff8-1cc250bb34fc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run critique prompt and save question with context etc.\n",
        "# to csv file that can be loaded downstream"
      ],
      "metadata": {
        "id": "qEJHJASFhh-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG pipeline"
      ],
      "metadata": {
        "id": "EY0NxZbt5uMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrival\n",
        "\n",
        "Optimization potential: different retrievers, different rerankers, multi-retrievers"
      ],
      "metadata": {
        "id": "a5bjM8nLnyUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# detailed RAG docs: https://python.langchain.com/docs/use_cases/question_answering/\n",
        "# FAISS cookbook: https://python.langchain.com/docs/expression_language/cookbook/retrieval\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceEmbeddings, HuggingFaceInferenceAPIEmbeddings\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma, Qdrant\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import Distance, VectorParams\n"
      ],
      "metadata": {
        "id": "yQucSUUF5seT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! issue: langchain vector store wrappers don't seem to allow adjustment to dimensions, only accept OAI default 1.5k\n",
        "# using qdrant directly instead of langchain wrapper\n",
        "\n",
        "provider_retrieval_model = \"HF\"\n",
        "\n",
        "client_path = f\"./vectorstore\"\n",
        "collection_name = f\"collection\"\n",
        "\n",
        "if provider_retrieval_model == \"HF\":\n",
        "  qdrantClient = QdrantClient(path=client_path, prefer_grpc=True)\n",
        "\n",
        "  embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
        "      api_key=userdata.get('HF_TOKEN'), model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n",
        "  )\n",
        "\n",
        "  dim = 384\n",
        "\n",
        "elif provider_retrieval_model == \"OAI\":\n",
        "\n",
        "  qdrantClient = QdrantClient(path=client_path, prefer_grpc=True)\n",
        "\n",
        "  embeddings = OpenAIEmbeddings(\n",
        "          model=\"text-embedding-ada-002\",\n",
        "          openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "  )\n",
        "\n",
        "  dim = 1536\n",
        "\n",
        "\n",
        "qdrantClient.create_collection(\n",
        "    collection_name=collection_name,\n",
        "    vectors_config=VectorParams(size=dim, distance=Distance.COSINE),\n",
        ")\n",
        "\n",
        "vectorstore = Qdrant(\n",
        "    client=qdrantClient,\n",
        "    collection_name=collection_name,\n",
        "    embeddings=embeddings,\n",
        ")\n",
        "\n",
        "vectorstore.add_documents(docs_samp)"
      ],
      "metadata": {
        "id": "iEJozhRA-4mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "context_retrieved_lst = []\n",
        "for question in question_lst:\n",
        "  retriever = vectorstore.as_retriever(\n",
        "      search_type=\"similarity\",\n",
        "      search_kwargs={\"k\": 1}\n",
        "  )\n",
        "\n",
        "  context_retrieved = retriever.get_relevant_documents(\n",
        "      question\n",
        "  )\n",
        "\n",
        "  def format_docs(docs):\n",
        "      return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "  context_retrieved = format_docs(context_retrieved)\n",
        "\n",
        "  context_retrieved_lst.append(context_retrieved)\n",
        "  #print(context_retrieved)\n"
      ],
      "metadata": {
        "id": "1qGMOP0gQ8iB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if retrieved context for question is same as context used for generating the question\n",
        "# note that this is an imperfect measure, because the retriever might\n",
        "# retrieve other texts that are equally relevant as the text used for generating the question\n",
        "context_for_q_generation = [doc for doc in docs_for_q_generation]\n",
        "correct_context_retrieved = [a == b for a, b in zip(context_for_q_generation, context_retrieved_lst)]\n",
        "\n",
        "retrieval_accuracy = sum(correct_context_retrieved) / len(correct_context_retrieved)\n",
        "print(retrieval_accuracy)\n"
      ],
      "metadata": {
        "id": "Y3n3hP_3G2Pk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba28bd2-0466-4217-ebf7-99c55a3a59fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add reranking step\n",
        "# challenge: reranking with HF models not implemented in langchain\n",
        "# only cohere reranker seems implemented: https://python.langchain.com/docs/integrations/retrievers/cohere-reranker\n",
        "\n",
        "\"\"\"import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-base')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('BAAI/bge-reranker-base')\n",
        "model.eval()\n",
        "\n",
        "context_question_pairs_lst = []\n",
        "for question in question_lst:\n",
        "  context_question_pairs_lst.append([[question, context] for context in context_retrieved_lst])\n",
        "\n",
        "#pairs = [['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']]\n",
        "\n",
        "for context_question_pair in context_question_pairs_lst:\n",
        "  with torch.no_grad():\n",
        "      inputs = tokenizer(context_question_pair, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
        "      scores = model(**inputs, return_dict=True).logits.view(-1, ).float()\n",
        "      print(scores)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "afrC3UwIXsSZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e919440a-d0aa-4406-c2bb-f06b57fc7aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"import torch\\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-base')\\nmodel = AutoModelForSequenceClassification.from_pretrained('BAAI/bge-reranker-base')\\nmodel.eval()\\n\\ncontext_question_pairs_lst = []\\nfor question in question_lst:\\n  context_question_pairs_lst.append([[question, context] for context in context_retrieved_lst])\\n\\n#pairs = [['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']]\\n\\nfor context_question_pair in context_question_pairs_lst:\\n  with torch.no_grad():\\n      inputs = tokenizer(context_question_pair, padding=True, truncation=True, return_tensors='pt', max_length=512)\\n      scores = model(**inputs, return_dict=True).logits.view(-1, ).float()\\n      print(scores)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer generation\n",
        "\n",
        "Optimization potential: different LLMs, different prompt templates"
      ],
      "metadata": {
        "id": "IrE01KH_n4LO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt_qa_template = \"\"\"\\\n",
        "Your task is to answer a question based on a context.\n",
        "Your answer should be concise and you should only return your answer.\n",
        "\n",
        "context: {context}\n",
        "question: {question}\n",
        "answer: \"\"\"\n",
        "\n",
        "prompt_qa_template = PromptTemplate.from_template(prompt_qa_template)\n"
      ],
      "metadata": {
        "id": "RnBR_tyHRD6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFaceEndpoint\n",
        "\n",
        "provider_answer_model = \"MISTRAL\"\n",
        "\n",
        "\n",
        "if provider_answer_model == \"HF\":\n",
        "  llm_qa = HuggingFaceEndpoint(\n",
        "    endpoint_url=hf_endpoint.url,  #\"https://nqoa2is3qe7y82ww.us-east-1.aws.endpoints.huggingface.cloud\",\n",
        "    task=\"text-generation\",\n",
        "    huggingfacehub_api_token=userdata.get('HF_TOKEN'),\n",
        "    model_kwargs={}\n",
        "  )\n",
        "\n",
        "elif provider_answer_model == \"OAI\":\n",
        "  llm_qa = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "elif provider_for_question_generation == \"MISTRAL\":\n",
        "  # source: https://github.com/langchain-ai/langchain/blob/9b3962fc2521ec0d6ef2ea7c0a40b9c32977671a/libs/partners/mistralai/langchain_mistralai/chat_models.py#L156C6-L156C6\n",
        "  # docs: https://docs.mistral.ai/platform/client/  or https://python.langchain.com/docs/integrations/chat/mistralai\n",
        "  llm_qa = ChatMistralAI(\n",
        "      mistral_api_key=userdata.get('MISTRAL_KEY'),\n",
        "      max_retries=5,\n",
        "      timeout=60,\n",
        "      max_concurrent_requests=2,\n",
        "      model=\"mistral-small\",\n",
        "      temperature=0.2,\n",
        "      max_tokens=1024,\n",
        "      top_p=0.95,  #Decode using nucleus sampling: consider the smallest set of tokens whose probability sum is at least top_p. Must be in the closed interval [0.0, 1.0].\n",
        "      random_seed=42,\n",
        "      safe_mode=False,\n",
        "  )\n",
        "\n",
        "\n",
        "chain = prompt_qa_template | llm_qa | StrOutputParser()\n",
        "\n",
        "answer_lst = []\n",
        "for question, context in zip(question_lst , context_retrieved_lst):\n",
        "  answer = chain.invoke({\"context\": context, \"question\": question})\n",
        "  answer_lst.append(answer)\n"
      ],
      "metadata": {
        "id": "vpARrdu-lP2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Automatic LLM evaluation of generated answer"
      ],
      "metadata": {
        "id": "6bpcF8ZuohC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this scoring prompt can be freely adapted to evaluation criteria\n",
        "# of different use-cases\n",
        "\n",
        "instruction_judge_answer = \"\"\"\\\n",
        "Your task is to score the quality of an answer to a question in a given context.\n",
        "\n",
        "Your scoring criteria for assessing the answer are:\n",
        "- pertinence: Does the answer directly answer the question?\n",
        "- context grounding: Is the answer clearly grounded in the context? To be well grounded, the answer does not need to explicitly reference the context.\n",
        "- conciseness: Is the answer concise without unnecessary verbosity?\n",
        "\n",
        "Your quality score should be in the range of 0 to 100.\\\n",
        "100 means a very good answer, 0 means a very bad answer, 50 means a mediocre answer.\n",
        "\n",
        "First briefly reason step-by-step to assess the extent to which the answer fulfills these criteria. Your reasoning should be short.\n",
        "Then return the quality score.\n",
        "\n",
        "Always answer in this JSON evaluation format: {{\"reason\": \"...\", \"score\": \"...\"}}\n",
        "\n",
        "context: {context}\\n\n",
        "question: \"{question}\"\\n\n",
        "answer: \"{answer}\"\\n\n",
        "JSON evaluation: \"\"\"\n",
        "\n",
        "instruction_judge_answer = ChatPromptTemplate.from_template(instruction_judge_answer)\n",
        "\n",
        "# currently need to use OAI here, because it enforces JSON very well\n",
        "llm_evaluation = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "chain = instruction_judge_answer | llm_evaluation\n",
        "\n",
        "\n",
        "output_quality_lst = []\n",
        "for answer, question, context_retrieved in zip(answer_lst, question_lst, context_retrieved_lst):\n",
        "\n",
        "  output_quality = chain.invoke({\n",
        "      \"context\": context_retrieved.strip(),\n",
        "      \"question\": question.strip().replace(\"\\n\", \" \"),\n",
        "      \"answer\": answer.strip().replace(\"\\n\", \" \")\n",
        "  })\n",
        "\n",
        "  output_quality_lst.append(output_quality.content)\n",
        "\n"
      ],
      "metadata": {
        "id": "NEDmoocl7xzS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a0c6509-e4fa-447c-e203-4a8c363da619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parsing the JSON output can lead to errors\n",
        "# with open-source models, which don't enforce JSON as well as OAI\n",
        "import ast\n",
        "\n",
        "output_quality_dic = [ast.literal_eval(output) for output in output_quality_lst]\n",
        "output_quality_score = [int(dic[\"score\"]) for dic in output_quality_dic]\n",
        "output_quality_reason = [dic[\"reason\"] for dic in output_quality_dic]\n"
      ],
      "metadata": {
        "id": "eIAgcti6JfAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "OcAmsd5YVqq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_results = pd.DataFrame({\n",
        "    \"question\": question_lst,\n",
        "    \"answer\": answer_lst,\n",
        "    \"answer_quality_score\": output_quality_score,\n",
        "    \"answer_quality_reason\": output_quality_reason,\n",
        "    \"correct_context\": [a == b for a, b in zip(context_for_q_generation, context_retrieved_lst)],\n",
        "    \"context_retrieved\": context_retrieved_lst,\n",
        "    \"context_for_q_generation\": context_for_q_generation\n",
        "})\n",
        "\n",
        "mean_answer_score = df_results[\"answer_quality_score\"].mean()\n",
        "retrieval_accuracy = sum(df_results[\"correct_context\"]) / len(df_results[\"correct_context\"])\n",
        "\n",
        "print(f\"Retrieval accuracy: {retrieval_accuracy}\")\n",
        "print(f\"Mean answer socre: {mean_answer_score}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "df_results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2810
        },
        "id": "Glmejky1I2Uv",
        "outputId": "79daccb5-9933-42fb-deac-d6af66ec8eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieval accuracy: 0.2\n",
            "Mean answer socre: 96.0\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  How does the framework suggest assessing AI ri...   \n",
              "1  Which approach to innovations centers is consi...   \n",
              "2  What is EDRI's stance on the necessity and pro...   \n",
              "3  How can artificial intelligence impact researc...   \n",
              "4  What article in GDPR outlines the data subject...   \n",
              "\n",
              "                                              answer  answer_quality_score  \\\n",
              "0  The framework suggests assessing AI risks by f...                   100   \n",
              "1  The approach to innovation centered on industr...                   100   \n",
              "2  EDRI believes that using facial recognition sy...                   100   \n",
              "3  Artificial intelligence can impact research in...                    90   \n",
              "4  Article 22 of GDPR outlines the data subject's...                    90   \n",
              "\n",
              "                               answer_quality_reason  correct_context  \\\n",
              "0  The answer directly answers the question by ex...            False   \n",
              "1  The answer directly answers the question by st...            False   \n",
              "2  The answer directly addresses the question by ...             True   \n",
              "3  The answer directly answers the question by ex...            False   \n",
              "4  The answer directly answers the question by st...            False   \n",
              "\n",
              "                                   context_retrieved  \\\n",
              "0  the possible harm caused by the ai system is p...   \n",
              "1  and be applicable without prejudice to cultura...   \n",
              "2  cnil, for permission to use a facial recogniti...   \n",
              "3  response to the public consultation on the eur...   \n",
              "4  , to express his or her point of view and to c...   \n",
              "\n",
              "                            context_for_q_generation  \n",
              "0  framework to assess the potential benefits. su...  \n",
              "1  zivilgesellschaft eingebunden werden sollen un...  \n",
              "2  cnil, for permission to use a facial recogniti...  \n",
              "3  le domaine de l ’ ia pourrait etre a meme de s...  \n",
              "4  i. e., which data was influential ), and to fa...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-56a5cb23-5afd-40bc-86e9-10ad90d4e414\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>answer_quality_score</th>\n",
              "      <th>answer_quality_reason</th>\n",
              "      <th>correct_context</th>\n",
              "      <th>context_retrieved</th>\n",
              "      <th>context_for_q_generation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How does the framework suggest assessing AI ri...</td>\n",
              "      <td>The framework suggests assessing AI risks by f...</td>\n",
              "      <td>100</td>\n",
              "      <td>The answer directly answers the question by ex...</td>\n",
              "      <td>False</td>\n",
              "      <td>the possible harm caused by the ai system is p...</td>\n",
              "      <td>framework to assess the potential benefits. su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Which approach to innovations centers is consi...</td>\n",
              "      <td>The approach to innovation centered on industr...</td>\n",
              "      <td>100</td>\n",
              "      <td>The answer directly answers the question by st...</td>\n",
              "      <td>False</td>\n",
              "      <td>and be applicable without prejudice to cultura...</td>\n",
              "      <td>zivilgesellschaft eingebunden werden sollen un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is EDRI's stance on the necessity and pro...</td>\n",
              "      <td>EDRI believes that using facial recognition sy...</td>\n",
              "      <td>100</td>\n",
              "      <td>The answer directly addresses the question by ...</td>\n",
              "      <td>True</td>\n",
              "      <td>cnil, for permission to use a facial recogniti...</td>\n",
              "      <td>cnil, for permission to use a facial recogniti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How can artificial intelligence impact researc...</td>\n",
              "      <td>Artificial intelligence can impact research in...</td>\n",
              "      <td>90</td>\n",
              "      <td>The answer directly answers the question by ex...</td>\n",
              "      <td>False</td>\n",
              "      <td>response to the public consultation on the eur...</td>\n",
              "      <td>le domaine de l ’ ia pourrait etre a meme de s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What article in GDPR outlines the data subject...</td>\n",
              "      <td>Article 22 of GDPR outlines the data subject's...</td>\n",
              "      <td>90</td>\n",
              "      <td>The answer directly answers the question by st...</td>\n",
              "      <td>False</td>\n",
              "      <td>, to express his or her point of view and to c...</td>\n",
              "      <td>i. e., which data was influential ), and to fa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56a5cb23-5afd-40bc-86e9-10ad90d4e414')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-56a5cb23-5afd-40bc-86e9-10ad90d4e414 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-56a5cb23-5afd-40bc-86e9-10ad90d4e414');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-239ef852-2152-4331-8ff0-b412f801390e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-239ef852-2152-4331-8ff0-b412f801390e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-239ef852-2152-4331-8ff0-b412f801390e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "83ec21e9f690429ea09a9ce4f04ad7f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e24e5a0d37a4ee3b8f519a454862c6e",
              "IPY_MODEL_27c8a1be1d8540e69145cfcf07725fd1",
              "IPY_MODEL_2d856a03851d45449144c85974c4147d"
            ],
            "layout": "IPY_MODEL_eee0f381993b43178d6d53dab74d6749"
          }
        },
        "3e24e5a0d37a4ee3b8f519a454862c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93046f607bd1445a9a591aff4cdfcfc8",
            "placeholder": "​",
            "style": "IPY_MODEL_041c17a8fbf8450a9a58c812fdfc131f",
            "value": "100%"
          }
        },
        "27c8a1be1d8540e69145cfcf07725fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98c887a6a4a5482491e7b2d66880a271",
            "max": 440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c30b006237e4878ab3df0acd0ce59d0",
            "value": 440
          }
        },
        "2d856a03851d45449144c85974c4147d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a2c1eecf3ed46aca857805690e721a7",
            "placeholder": "​",
            "style": "IPY_MODEL_3b6f0f396b8446e78de4e364a80d8b74",
            "value": " 440/440 [00:40&lt;00:00, 17.55it/s]"
          }
        },
        "eee0f381993b43178d6d53dab74d6749": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93046f607bd1445a9a591aff4cdfcfc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "041c17a8fbf8450a9a58c812fdfc131f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98c887a6a4a5482491e7b2d66880a271": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c30b006237e4878ab3df0acd0ce59d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a2c1eecf3ed46aca857805690e721a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b6f0f396b8446e78de4e364a80d8b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}