{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoritzLaurer/rag-demo/blob/master/rag_haystack_ai_law.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tocCqFNnQqgo"
      },
      "source": [
        "## Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myUZd_CK4zeL"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "pip install --upgrade pip\n",
        "pip install farm-haystack[colab,inference]~=1.23.0\n",
        "# for reading pdfs\n",
        "wget --no-check-certificate https://dl.xpdfreader.com/xpdf-tools-linux-4.04.tar.gz && tar -xvf xpdf-tools-linux-4.04.tar.gz && sudo cp xpdf-tools-linux-4.04/bin64/pdftotext /usr/local/bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE9Aj1bcQnMN"
      },
      "source": [
        "## Prepare example data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download PDF data"
      ],
      "metadata": {
        "id": "GKSJzyg9tinB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## download PDF data\n",
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# URL of the zip file in your GitHub repo (make sure it's the raw file URL)\n",
        "zip_url = 'https://github.com/MoritzLaurer/rag-demo/blob/master/data/position-papers-pdfs.zip?raw=true'\n",
        "\n",
        "# Download the zip file\n",
        "print(\"Downloading zip file...\")\n",
        "response = requests.get(zip_url)\n",
        "zip_content = BytesIO(response.content)\n",
        "\n",
        "# Define the extraction path\n",
        "extract_path = '/content/data'\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "if not os.path.exists(extract_path):\n",
        "    os.makedirs(extract_path)\n",
        "\n",
        "# Extract the zip file\n",
        "print(\"Extracting zip file...\")\n",
        "with zipfile.ZipFile(zip_content, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Extraction completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa-86eodrEez",
        "outputId": "a7b74eb1-e047-4ac8-95ff-1d8d1e670152"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading zip file...\n",
            "Extracting zip file...\n",
            "Extraction completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download and prepare meta data"
      ],
      "metadata": {
        "id": "JuGF61HNtmKJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "bi5hXOj5Kix3",
        "outputId": "8acc5296-0095-4883-b0cb-c19d183ff417"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       stakeholder_name  \\\n",
              "0                       Governance of AI Research Group   \n",
              "1     European Technology Policy Committee (EUTPC) o...   \n",
              "2                                       EIT Health e.V.   \n",
              "3     on behalf of: Chairman of the National Broadca...   \n",
              "4                                                   NaN   \n",
              "...                                                 ...   \n",
              "1211                                                NaN   \n",
              "1212                         CUBE ROBOT X by haleez.com   \n",
              "1213                                                NaN   \n",
              "1214                                                NaN   \n",
              "1215                                                NaN   \n",
              "\n",
              "                   stakeholder_type          stakeholder_size  \\\n",
              "0     Academic/Research Institution    Micro (< 10 employees)   \n",
              "1     Academic/Research Institution       Large (250 or more)   \n",
              "2                             Other  Medium (< 250 employees)   \n",
              "3                  Public authority  Medium (< 250 employees)   \n",
              "4                               NaN                       NaN   \n",
              "...                             ...                       ...   \n",
              "1211                            NaN                       NaN   \n",
              "1212           Business Association    Micro (< 10 employees)   \n",
              "1213                            NaN                       NaN   \n",
              "1214                            NaN                       NaN   \n",
              "1215                            NaN                       NaN   \n",
              "\n",
              "     stakeholder_country stakeholder_scope     document_date language  \\\n",
              "0          United States               NaN  19-06-2020 23:58  English   \n",
              "1          United States               NaN  19-06-2020 22:38  English   \n",
              "2                Germany               NaN  19-06-2020 21:54  English   \n",
              "3                 Poland          National  19-06-2020 17:58   Polish   \n",
              "4                    NaN               NaN  19-06-2020 17:17  English   \n",
              "...                  ...               ...               ...      ...   \n",
              "1211                 NaN               NaN  19-02-2020 16:09  English   \n",
              "1212             Germany               NaN  19-02-2020 15:58   German   \n",
              "1213                 NaN               NaN  19-02-2020 14:33  English   \n",
              "1214                 NaN               NaN  19-02-2020 13:17  English   \n",
              "1215                 NaN               NaN  19-02-2020 13:14  English   \n",
              "\n",
              "     document_reference                                      document_name  \n",
              "0               F529892  F529892-Governance_of_AI_Research_Group_EU_Com...  \n",
              "1               F529891                                                NaN  \n",
              "2               F529890  F529890-EIT_Health_Consultative_Group_on_EC_Da...  \n",
              "3               F529889  F529889-feedback_Consultation_on_the_White_Pap...  \n",
              "4               F529888  F529888-DIGITAL_SME_Position_Paper_AI_White_Pa...  \n",
              "...                 ...                                                ...  \n",
              "1211            F518570                                                NaN  \n",
              "1212            F518569                                                NaN  \n",
              "1213            F518568                                                NaN  \n",
              "1214            F518567                                                NaN  \n",
              "1215            F518566                                                NaN  \n",
              "\n",
              "[1216 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e3e3a6f-e3b9-4874-b088-977c1e394a4f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stakeholder_name</th>\n",
              "      <th>stakeholder_type</th>\n",
              "      <th>stakeholder_size</th>\n",
              "      <th>stakeholder_country</th>\n",
              "      <th>stakeholder_scope</th>\n",
              "      <th>document_date</th>\n",
              "      <th>language</th>\n",
              "      <th>document_reference</th>\n",
              "      <th>document_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Governance of AI Research Group</td>\n",
              "      <td>Academic/Research Institution</td>\n",
              "      <td>Micro (&lt; 10 employees)</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19-06-2020 23:58</td>\n",
              "      <td>English</td>\n",
              "      <td>F529892</td>\n",
              "      <td>F529892-Governance_of_AI_Research_Group_EU_Com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>European Technology Policy Committee (EUTPC) o...</td>\n",
              "      <td>Academic/Research Institution</td>\n",
              "      <td>Large (250 or more)</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19-06-2020 22:38</td>\n",
              "      <td>English</td>\n",
              "      <td>F529891</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EIT Health e.V.</td>\n",
              "      <td>Other</td>\n",
              "      <td>Medium (&lt; 250 employees)</td>\n",
              "      <td>Germany</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19-06-2020 21:54</td>\n",
              "      <td>English</td>\n",
              "      <td>F529890</td>\n",
              "      <td>F529890-EIT_Health_Consultative_Group_on_EC_Da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>on behalf of: Chairman of the National Broadca...</td>\n",
              "      <td>Public authority</td>\n",
              "      <td>Medium (&lt; 250 employees)</td>\n",
              "      <td>Poland</td>\n",
              "      <td>National</td>\n",
              "      <td>19-06-2020 17:58</td>\n",
              "      <td>Polish</td>\n",
              "      <td>F529889</td>\n",
              "      <td>F529889-feedback_Consultation_on_the_White_Pap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19-06-2020 17:17</td>\n",
              "      <td>English</td>\n",
              "      <td>F529888</td>\n",
              "      <td>F529888-DIGITAL_SME_Position_Paper_AI_White_Pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1211</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19-02-2020 16:09</td>\n",
              "      <td>English</td>\n",
              "      <td>F518570</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1212</th>\n",
              "      <td>CUBE ROBOT X by haleez.com</td>\n",
              "      <td>Business Association</td>\n",
              "      <td>Micro (&lt; 10 employees)</td>\n",
              "      <td>Germany</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19-02-2020 15:58</td>\n",
              "      <td>German</td>\n",
              "      <td>F518569</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1213</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19-02-2020 14:33</td>\n",
              "      <td>English</td>\n",
              "      <td>F518568</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1214</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19-02-2020 13:17</td>\n",
              "      <td>English</td>\n",
              "      <td>F518567</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1215</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19-02-2020 13:14</td>\n",
              "      <td>English</td>\n",
              "      <td>F518566</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1216 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e3e3a6f-e3b9-4874-b088-977c1e394a4f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8e3e3a6f-e3b9-4874-b088-977c1e394a4f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8e3e3a6f-e3b9-4874-b088-977c1e394a4f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4408d872-e82f-4865-af66-9ed1ff9f0713\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4408d872-e82f-4865-af66-9ed1ff9f0713')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4408d872-e82f-4865-af66-9ed1ff9f0713 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "## prepare meta data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# load meta data\n",
        "df_metadata = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/MoritzLaurer/rag-demo/master/data/position-papers-metadata.csv\",\n",
        "    sep=\";\", on_bad_lines='error', encoding=\"cp1252\"\n",
        ")\n",
        "\n",
        "df_metadata = df_metadata[[\n",
        "    'Organisation name', #'Transparency register number',\n",
        "    'User type', 'Organisation size', 'Country', 'Scope',\n",
        "    'Feedback date', 'Language', 'Reference',\n",
        "    #'Publication privacy settings', 'First name', 'Surname',\n",
        "    #'You can upload a document here:\\n\\n'\n",
        "]]\n",
        "\n",
        "df_metadata = df_metadata.rename(columns={\n",
        "    'Reference': \"document_reference\", 'Feedback date': \"document_date\", 'Language': \"language\",\n",
        "    'User type': \"stakeholder_type\", 'Scope': \"stakeholder_scope\",\n",
        "    'Organisation name': \"stakeholder_name\",\n",
        "    #'Transparency register number': \"transparency_register_number\",\n",
        "    #'First name': \"first_name\", 'Surname': \"surname\",\n",
        "    'Organisation size': \"stakeholder_size\", 'Country': \"stakeholder_country\",\n",
        "    #'Publication privacy settings', 'You can upload a document here:\\n\\n'\n",
        "})\n",
        "\n",
        "# add column with exact pdf names corresponding to pdf reference\n",
        "# not all respondents provided PDFs\n",
        "def find_string_with_substring(substring, string_list):\n",
        "    for string in string_list:\n",
        "        if substring in string:\n",
        "            return string\n",
        "    return np.nan\n",
        "\n",
        "doc_dir = \"./data\"\n",
        "file_names = os.listdir(doc_dir)\n",
        "pdf_name_col = [find_string_with_substring(ref, file_names) for ref in df_metadata[\"document_reference\"]]\n",
        "\n",
        "# note that not all respondents provided PDFs\n",
        "# document_name is NaN if no PDF is available\n",
        "df_metadata.loc[:, \"document_name\"] = pdf_name_col\n",
        "\n",
        "df_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-mL7xkUf3F6"
      },
      "source": [
        "## Create a search index with the downloaded data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.utils import convert_files_to_docs\n",
        "\n",
        "# Convert all PDF files in folder to Haystack doc object\n",
        "# https://docs.haystack.deepset.ai/reference/utils-api#convert_files_to_docs\n",
        "dir_path = \"./data\"\n",
        "docs = convert_files_to_docs(dir_path)\n",
        "\n",
        "print(\"Example for PDF converted to doc object:\\n\")\n",
        "print(docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mLdybv6IiQO",
        "outputId": "4017a3b0-14ec-4d4a-b6fe-b8aef07b01ad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example for PDF converted to doc object:\n",
            "\n",
            "<Document: id=c8d68f7d442a07b88be295981f52f229, content='Stellungnahme\n",
            "Zur EU-Konsultation zum Weißbuch zur Künstlichen Intelligenz - ein\n",
            "europäisches Konzep...'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add meta data to docs based on unique reference\n",
        "for doc in docs:\n",
        "    # the unique reference of each respondent are the first 7 characters of the PDF name\n",
        "    # this reference can be used to merge the PDFs with meta data from the .csv\n",
        "    if doc.meta[\"name\"]:\n",
        "        doc_reference = doc.meta[\"name\"][:7]\n",
        "        for col in df_metadata.columns:\n",
        "            doc.meta[col] = df_metadata[df_metadata[\"document_reference\"] == doc_reference][col].iloc[0]\n",
        "\n",
        "print(\"Example for meta data added to document\")\n",
        "print(docs[0].meta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF8gSaVtJWw-",
        "outputId": "465e12cd-18e5-406d-d2c9-1540183b4635"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example for meta data added to document\n",
            "{'name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', 'stakeholder_name': 'Deutscher Naturschutzring', 'stakeholder_type': 'Environmental Organisation', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '14-06-2020 16:17', 'language': 'German', 'document_reference': 'F530333', 'document_name': 'F530333-Stellungnahme_KI_Weissbuch.pdf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack import Pipeline\n",
        "from haystack.nodes import PreProcessor, PDFToTextConverter\n",
        "from haystack.document_stores import InMemoryDocumentStore\n",
        "import os\n",
        "\n",
        "# Initialize the document store\n",
        "document_store = InMemoryDocumentStore(embedding_dim=384, use_bm25=True)\n",
        "\n",
        "# preprocessor: https://docs.haystack.deepset.ai/docs/preprocessor\n",
        "preprocessor = PreProcessor(\n",
        "    clean_whitespace=True,\n",
        "    clean_header_footer=True,\n",
        "    clean_empty_lines=True,\n",
        "    split_by=\"word\",\n",
        "    split_length=200,\n",
        "    split_overlap=20,\n",
        "    split_respect_sentence_boundary=True,\n",
        "    add_page_number=True,\n",
        "    max_chars_check=100_000\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DGwGyyoIpYW",
        "outputId": "4886c5a8-4041-45c3-f38a-32c80fa9562f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding meta data to the text passages\n",
        "from haystack.nodes import BaseComponent\n",
        "from haystack.schema import Document\n",
        "from typing import Any, Dict, List, Tuple, Union\n",
        "\n",
        "class MetaData2TextAugmenter(BaseComponent):\n",
        "    outgoing_edges = 1\n",
        "\n",
        "    def __init__(self, meta_data_to_add: List[str]):\n",
        "        super().__init__()\n",
        "        self.meta_data_to_add = meta_data_to_add\n",
        "\n",
        "    def run(self, documents: List[Document]) -> Tuple[Dict[str, Any], str]:\n",
        "        for doc in documents:\n",
        "            # Append specified meta_data to text content\n",
        "            #if doc.meta:\n",
        "            content_with_meta = \"Passage meta data: \"\n",
        "            for meta_data_key in self.meta_data_to_add:\n",
        "                if meta_data_key in doc.meta:\n",
        "                    content_with_meta += f'{meta_data_key}: {doc.meta[meta_data_key]}, '\n",
        "            doc.content = content_with_meta + \"\\n\\nPassage: \" + doc.content\n",
        "\n",
        "        return {\"documents\": documents}, \"output_1\"\n",
        "\n",
        "    def run_batch(self, documents: List[Document]) -> Tuple[Dict[str, Any], str]:\n",
        "        return self.run(documents)\n",
        "\n",
        "\n",
        "meta_data_to_add = [\n",
        "    \"stakeholder_name\",  \"stakeholder_type\",  \"stakeholder_scope\",\n",
        "    \"stakeholder_size\", \"stakeholder_country\",\n",
        "    \"document_date\", \"language\"\n",
        "    #\"document_reference\", \"document_name\",\n",
        "]\n",
        "\n",
        "meta2text_augmenter = MetaData2TextAugmenter(meta_data_to_add=meta_data_to_add)\n"
      ],
      "metadata": {
        "id": "XIsQ34qSherI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK1gg3SWf56z",
        "outputId": "1e0528c2-3166-4ad4-ea1e-678b3d551ef6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocessing:   1%|▏         | 6/440 [00:00<00:27, 15.78docs/s]WARNING:haystack.nodes.preprocessor.preprocessor:We found one or more sentences whose split count is higher than the split length.\n",
            "Preprocessing: 100%|██████████| 440/440 [00:15<00:00, 27.82docs/s]\n",
            "Updating BM25 representation...: 100%|██████████| 12585/12585 [00:01<00:00, 11070.97 docs/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'documents': [<Document: {'content': 'Passage meta data: stakeholder_name: Deutscher Naturschutzring, stakeholder_type: Environmental Organisation, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Germany, document_date: 14-06-2020 16:17, language: German, \\n\\nPassage: Stellungnahme\\nZur EU-Konsultation zum Weißbuch zur Künstlichen Intelligenz - ein\\neuropäisches Konzept für Exzellenz und Vertrauen\\nGemeinsame Stellungnahme vom Bund für Umwelt und Naturschutz Deutschland (BUND),\\nNaturschutzbund Deutschland (NABU), Germanwatch sowie dem Umweltdachverband Deutscher\\nNaturschutzring (DNR)\\nGrundsätzliche Einschätzung:\\nDer digitale Wandel und der sinnvolle Einsatz algorithmischer Entscheidungssysteme/ Künstlicher\\nIntelligenz (KI) können einen substantiellen Beitrag zu einer nachhaltigen Entwicklung leisten. Die\\nEinführung von KI in alle Bereiche unserer Gesellschaft birgt jedoch zugleich Risiken – soziale,\\nökologische und wirtschaftliche. Auf beides weist das Weißbuch hin; das größte Risiko scheint jedoch\\nin den Augen der Kommission jenes zu sein, die EU könne bei Forschung und Entwicklung und\\nwirtschaftlicher Nutzung von KI international ins Hintertreffen geraten. Dieser Einschätzung folgen wir\\nnicht.\\nDie Europäische Union ist mehr als ein Wirtschaftsraum. KI wird, dank Big Data und Fortschritten in\\nder Verarbeitungsleistung, tiefgreifende Veränderungen in sämtlichen Bereichen der Gesellschaft mit\\nsich bringen. Die EU muss diese Auswirkungen, z. B. auf Energieversorgung, Regionalentwicklung,\\nNaturschutz/Artenvielfalt, im Rahmen ihres Kompetenzbereiches ebenso gestalten wie die\\nwirtschaftlichen im engeren Sinne.\\nDie vorgeschlagene Strategie aus Risikominimierung und (vorwiegend wirtschaftsrelevanter und\\nwirtschaftsnaher) Forschung greift darum zu kurz. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', 'stakeholder_name': 'Deutscher Naturschutzring', 'stakeholder_type': 'Environmental Organisation', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '14-06-2020 16:17', 'language': 'German', 'document_reference': 'F530333', 'document_name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': '56a2a45a94c256ed5cf528dac35bd0bf', 'range': (1192, 1503)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '382735dbeb928ffcf88af1b9ab3fa051'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutscher Naturschutzring, stakeholder_type: Environmental Organisation, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Germany, document_date: 14-06-2020 16:17, language: German, \\n\\nPassage: B. auf Energieversorgung, Regionalentwicklung,\\nNaturschutz/Artenvielfalt, im Rahmen ihres Kompetenzbereiches ebenso gestalten wie die\\nwirtschaftlichen im engeren Sinne.\\nDie vorgeschlagene Strategie aus Risikominimierung und (vorwiegend wirtschaftsrelevanter und\\nwirtschaftsnaher) Forschung greift darum zu kurz. Ob eine KI aus gesellschaftlicher Perspektive\\nwünschenswert ist, hängt nicht davon ab, ob sie als wenig riskant gesehen werden kann (was eine\\nmethodisch schwierige Einschätzung ist), sondern davon, ob sie zu einer nachhaltigen Energie-,\\nVerkehrs-, Agrar- und Ressourcenwende, zur Klimaneutralität bis 2050 und sozialer Gerechtigkeit\\nbeiträgt. Als Referenzrahmen taugt die einseitig auf Wettbewerbsfähigkeit fokussierte Horizon\\nEurope-Strategie hierfür nicht.\\nVielmehr gilt es, einen durchdachten und auf Nachhaltigkeit ausgerichteten, verbindlichen\\nRechtsrahmen für die Entwicklung und den Einsatz von KI zu entwerfen. Umwelt- und Naturschutz\\nmüssen in diesem fest verankert sein. Das Weißbuch in seiner jetzigen Form bleibt hinter diesem\\nAnspruch weit zurück.\\nRef. Ares(2020)3360010 - 26/06/2020\\x0cUnsere Analyse im Einzelnen:\\na) Das Weißbuch ist auf Wirtschaftsbelange fokussiert: Bei der Einschätzung der KI und damit\\nauch bei den Gestaltungsvorschlägen des Weißbuchs stehen Fragen der Wirtschaftsförderung\\nund Wettbewerbsfähigkeit im Zentrum; andere Felder werden vergleichsweise kurz und\\nundifferenziert behandelt. Entsprechend sind die Gestaltungspläne fokussiert auf\\nwirtschaftsnahe (bzw. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', 'stakeholder_name': 'Deutscher Naturschutzring', 'stakeholder_type': 'Environmental Organisation', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '14-06-2020 16:17', 'language': 'German', 'document_reference': 'F530333', 'document_name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', '_split_id': 1, 'page': 1, '_split_overlap': [{'doc_id': '382735dbeb928ffcf88af1b9ab3fa051', 'range': (0, 311)}, {'doc_id': '7f80bfded6cfd6c92b1b23637c4bae03', 'range': (1078, 1505)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '56a2a45a94c256ed5cf528dac35bd0bf'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutscher Naturschutzring, stakeholder_type: Environmental Organisation, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Germany, document_date: 14-06-2020 16:17, language: German, \\n\\nPassage: Ares(2020)3360010 - 26/06/2020\\x0cUnsere Analyse im Einzelnen:\\na) Das Weißbuch ist auf Wirtschaftsbelange fokussiert: Bei der Einschätzung der KI und damit\\nauch bei den Gestaltungsvorschlägen des Weißbuchs stehen Fragen der Wirtschaftsförderung\\nund Wettbewerbsfähigkeit im Zentrum; andere Felder werden vergleichsweise kurz und\\nundifferenziert behandelt. Entsprechend sind die Gestaltungspläne fokussiert auf\\nwirtschaftsnahe (bzw. wirtschaftlich relevante) Forschung, Zusammenarbeit mit der\\nWirtschaft1 und auf Gefahrenabwehr2, wobei auch hier Fragen von Produktsicherheit und\\nProdukthaftung im Vordergrund stehen. Die Anerkennung, dass die Einführung von KI in allen\\nBereichen der Gesellschaft der Steuerung bedarf, erscheint damit als Lippenbekenntnis. Die\\ngesellschaftlichen Wirkungen von KI ergeben sich zudem nicht allein aus einzelnen KI-\\nAnwendungen, sondern auch aus deren Zusammenspiel. Gesamtgesellschaftliche\\nAuswirkungen aber, wie ein Anstieg der strukturellen Arbeitslosigkeit infolge von\\nKI/IoT3/Robotik, werden im Weißbuch verkürzt in den Blick genommen und kein Vorschlag zur\\nAntizipation, Erfassung und Prävention derselben gemacht.\\nb) Gestaltungsansatz: Das Weißbuch schlägt eine Strategie aus Minderung von Risiken (für\\nGrundrechte, aber auch Unternehmen) und Förderung von KI-Forschung und -Anwendungen\\nin Partnerschaft mit der Wirtschaft vor; beides harmonisiert mit relevanten bestehenden\\nBestimmungen insbesondere zur Wettbewerbsfähigkeit und Innovationskapazität (S. 11).\\nDieser Ansatz greift zu kurz. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', 'stakeholder_name': 'Deutscher Naturschutzring', 'stakeholder_type': 'Environmental Organisation', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '14-06-2020 16:17', 'language': 'German', 'document_reference': 'F530333', 'document_name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', '_split_id': 2, 'page': 1, '_split_overlap': [{'doc_id': '56a2a45a94c256ed5cf528dac35bd0bf', 'range': (0, 427)}, {'doc_id': '662600027b1b955fe434bbad4a1fd91e', 'range': (1147, 1522)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7f80bfded6cfd6c92b1b23637c4bae03'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutscher Naturschutzring, stakeholder_type: Environmental Organisation, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Germany, document_date: 14-06-2020 16:17, language: German, \\n\\nPassage: b) Gestaltungsansatz: Das Weißbuch schlägt eine Strategie aus Minderung von Risiken (für\\nGrundrechte, aber auch Unternehmen) und Förderung von KI-Forschung und -Anwendungen\\nin Partnerschaft mit der Wirtschaft vor; beides harmonisiert mit relevanten bestehenden\\nBestimmungen insbesondere zur Wettbewerbsfähigkeit und Innovationskapazität (S. 11).\\nDieser Ansatz greift zu kurz. Ob eine KI aus gesellschaftlicher Perspektive wünschenswert ist,\\nhängt nicht davon ab, ob sie vordergründig als wenig riskant gesehen werden kann, sondern\\ndavon, ob sie zu einer nachhaltigen Energie-, Verkehrs-, Agrar- und Ressourcenwende, zur\\nKlimaneutralität bis 2050 und sozialer Gerechtigkeit beiträgt. Als Referenzrahmen taugt die\\neinseitig auf Wettbewerbsfähigkeit fokussierte Horizon Europe-Strategie hierfür nicht. Der\\nEuropean Green Deal der EU-Kommission – der mit dem Weißbuch kaum zusammengedacht\\nscheint – sieht die Klimaneutralität der Staatengemeinschaft bis 2050 vor. In den letzten\\nJahrzehnten ist eine Entkoppelung der Wirtschaftsleistung von Energie- und\\nRessourcenverbrauch weit hinter den Zielen zurückgeblieben, wohingegen die Digitalisierung\\n(und die KI als wesentlicher Bestandteil derselben) zu einer Konsumsteigerung geführt hat. Die\\nGestaltung der KI-Entwicklung darf folglich nicht auf Wirtschaftswachstum ausgerichtet sein,\\nsondern muss zu Effizienz, aber auch Suffizienz beitragen.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', 'stakeholder_name': 'Deutscher Naturschutzring', 'stakeholder_type': 'Environmental Organisation', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '14-06-2020 16:17', 'language': 'German', 'document_reference': 'F530333', 'document_name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', '_split_id': 3, 'page': 2, '_split_overlap': [{'doc_id': '7f80bfded6cfd6c92b1b23637c4bae03', 'range': (0, 375)}, {'doc_id': 'a17dd663b69ce139f409755c29c03c04', 'range': (960, 1387)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '662600027b1b955fe434bbad4a1fd91e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutscher Naturschutzring, stakeholder_type: Environmental Organisation, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Germany, document_date: 14-06-2020 16:17, language: German, \\n\\nPassage: In den letzten\\nJahrzehnten ist eine Entkoppelung der Wirtschaftsleistung von Energie- und\\nRessourcenverbrauch weit hinter den Zielen zurückgeblieben, wohingegen die Digitalisierung\\n(und die KI als wesentlicher Bestandteil derselben) zu einer Konsumsteigerung geführt hat. Die\\nGestaltung der KI-Entwicklung darf folglich nicht auf Wirtschaftswachstum ausgerichtet sein,\\nsondern muss zu Effizienz, aber auch Suffizienz beitragen.\\nc) Rollenverteilung der Akteure unklar: Die KI wirft erhebliche ethische und rechtliche Fragen wie\\nauch Fragen der politischen Steuerung auf, die im nationalstaatlichen Alleingang zu\\nbeantworten angesichts der Globalisierung wenig effektiv sein wird. Insofern ist die Initiative\\nder EU-Kommission zur Zusammenarbeit zu begrüßen. Die von der Kommission\\nvorgeschlagene Rollenverteilung hinsichtlich der Steuerung bleibt im Weißbuch jedoch an\\nvielen Stellen unklar hinsichtlich\\n1 „Ökosystem für Exzellenz“, vgl. S. 4; S. 8; S.9\\n2 „Ökosystem für Vertrauen“, Problemstellung, S. 12\\n3 Internet of Things (IoT)\\x0ci. des Gestaltungsanspruchs bzw. Zuständigkeiten der EU-Institutionen gegenüber den\\nMitgliedsländern,\\nii. der Anforderungen an den Privatsektor im Kontext der angekündigten\\nPartnerschaften: Wohl wird öffentliche Förderung privater Investitionen und für\\ngemeinsame Forschungsprogramme in Aussicht gestellt (z.B. S. 5, S. 9); dargestellt\\nwird nicht, an welche Bedingungen (z.B. hinsichtlich Ko-Finanzierung, CO2-arme und\\nallgemein „grüne“ Technologien und Arbeitsplätze) diese geknüpft sein sollen. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', 'stakeholder_name': 'Deutscher Naturschutzring', 'stakeholder_type': 'Environmental Organisation', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '14-06-2020 16:17', 'language': 'German', 'document_reference': 'F530333', 'document_name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', '_split_id': 4, 'page': 2, '_split_overlap': [{'doc_id': '662600027b1b955fe434bbad4a1fd91e', 'range': (0, 427)}, {'doc_id': '69e58ca1bd6cc2a2cd58a09f1ef15f00', 'range': (1343, 1528)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a17dd663b69ce139f409755c29c03c04'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutscher Naturschutzring, stakeholder_type: Environmental Organisation, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Germany, document_date: 14-06-2020 16:17, language: German, \\n\\nPassage: S. 5, S. 9); dargestellt\\nwird nicht, an welche Bedingungen (z.B. hinsichtlich Ko-Finanzierung, CO2-arme und\\nallgemein „grüne“ Technologien und Arbeitsplätze) diese geknüpft sein sollen. Die\\nErfahrungen der letzten beiden Jahrzehnte mit Public-Private-Partnerships müssen\\nhier einfließen.\\niii. der für die Vertrauensbildung und Legitimität zentralen Beteiligung der Bevölkerung\\nund der Zivilgesellschaft.\\nUnsere Forderungen:\\nWas für eine auf Nachhaltigkeit und Vertrauen ausgerichtete Gestaltung der Entwicklung\\nvon KI nötig ist:\\n\\uf0b7 Reduzierung des ökologischen Fußabdrucks: KI-Techniken sind sowohl in der Entwicklung als\\nauch in der Anwendung enorm energieintensiv. Die dahinterstehende Infrastruktur muss\\nressourcenschonender werden, wie auch das Weißbuch anerkennt. Das große Potenzial, den\\nStrombedarf von Rechnerzentren zu senken, wird bisher nicht ausgenutzt,\\nEffizienzmaßnahmen finden unzureichend statt. Um dem entgegenzuwirken, braucht es\\ndringend einen gesetzlich verankerten Mindesteffizienzstandard, der im Weißbuch jedoch\\nnicht vorgesehen ist. Darüber hinaus gilt es, den benötigten Strombedarf mit erneuerbaren\\nEnergien zu decken. Auch die bei der Herstellung der für KI benötigte Hardware der\\nRechnerzentren verwendeten Ressourcen, wie Seltene Erden und Metall-Erze, müssen in den\\nBlick genommen werden: Es braucht sowohl für die Lieferkette geltende Umwelt- und\\nMenschenrechtsstandards wie auch Mindeststandards für das Recycling. Bei der Bewertung\\nvon KI-gestützten Systemen, sind Rebound-Effekte zu erforschen und zu berücksichtigen.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', 'stakeholder_name': 'Deutscher Naturschutzring', 'stakeholder_type': 'Environmental Organisation', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '14-06-2020 16:17', 'language': 'German', 'document_reference': 'F530333', 'document_name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', '_split_id': 5, 'page': 3, '_split_overlap': [{'doc_id': 'a17dd663b69ce139f409755c29c03c04', 'range': (0, 185)}, {'doc_id': 'c5851bdabafb558f2c04dbc658536f38', 'range': (1144, 1550)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '69e58ca1bd6cc2a2cd58a09f1ef15f00'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutscher Naturschutzring, stakeholder_type: Environmental Organisation, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Germany, document_date: 14-06-2020 16:17, language: German, \\n\\nPassage: Auch die bei der Herstellung der für KI benötigte Hardware der\\nRechnerzentren verwendeten Ressourcen, wie Seltene Erden und Metall-Erze, müssen in den\\nBlick genommen werden: Es braucht sowohl für die Lieferkette geltende Umwelt- und\\nMenschenrechtsstandards wie auch Mindeststandards für das Recycling. Bei der Bewertung\\nvon KI-gestützten Systemen, sind Rebound-Effekte zu erforschen und zu berücksichtigen.\\n\\uf0b7 Entwicklung ethischer Leitlinien: Die Erarbeitung auf Nachhaltigkeit ausgerichteter ethischer\\nGrundsätze für den Einsatz und die Entwicklung von KI muss vorangetrieben werden. Es gilt die\\nMaßgabe, dass diese einen konstruktiven Beitrag zu Herausforderungen bei Umwelt und Klima\\ndarstellen. Hier geht es sowohl um bestehende als auch um neue Technologien. Zudem ist es\\neine wichtige Aufgabe des Gesetzgebers regulierend einzugreifen, um Anforderungen für Daten\\nzur Entwicklung von KI-Anwendungen zu etablieren. Diese müssen an diesen ethischen\\nPrinzipien ausgerichtet werden, digitale Diskriminierung und Sicherheitsrisiken begegnen und\\nden Grundsätzen der EU-Datenschutz-Grundverordnung (DSGVO) entsprechen.\\n\\uf0b7 Transparenz und Kontrollierbarkeit: Im Weißbuch weist die Kommission zu Recht auf die\\nKomplexität und damit zusammenhängende Intransparenz (Opazität) von KI-Algorithmen bzw.\\nder KI-Technologien hin. Eine Offenlegung der Beziehungen zwischen den einzelnen Variablen\\neines Algorithmus (‚explainable AI‘4) hilft, Transparenz zu schaffen und mögliche Verzerrungen\\n4 Vgl. hierzu https://www.bigdata-insider.de/koennen-maschinen-ethisch-korrekt-agieren-a-921380/\\x0caufzudecken. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', 'stakeholder_name': 'Deutscher Naturschutzring', 'stakeholder_type': 'Environmental Organisation', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '14-06-2020 16:17', 'language': 'German', 'document_reference': 'F530333', 'document_name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', '_split_id': 6, 'page': 3, '_split_overlap': [{'doc_id': '69e58ca1bd6cc2a2cd58a09f1ef15f00', 'range': (0, 406)}, {'doc_id': '59858712f91a7a30869a735bfd7178ff', 'range': (1318, 1588)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c5851bdabafb558f2c04dbc658536f38'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutscher Naturschutzring, stakeholder_type: Environmental Organisation, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Germany, document_date: 14-06-2020 16:17, language: German, \\n\\nPassage: Eine Offenlegung der Beziehungen zwischen den einzelnen Variablen\\neines Algorithmus (‚explainable AI‘4) hilft, Transparenz zu schaffen und mögliche Verzerrungen\\n4 Vgl. hierzu https://www.bigdata-insider.de/koennen-maschinen-ethisch-korrekt-agieren-a-921380/\\x0caufzudecken. Die DSGVO etabliert bereits einen solchen Anspruch von Verbraucher*innen auf\\nOffenlegung einer Entscheidungsfindung – dies muss rechtsverbindlich sichergestellt werden\\n(Art. 22). Dieses Recht auf Offenlegung und Mindeststandards für Transparenz müssen auch\\nauf andere Bereiche der KI-Anwendung ausgeweitet werden, etwa für Verbände im Hinblick\\nauf behördliche Entscheidungen. Geschäftsgeheimnisse dürfen keinen Anspruch auf\\nAusnahmen begründen. Bei der Anwendung von KI im öffentlichen Sektor muss gelten, dass\\nProzesse und Entscheidungen des Staates (z. B. in der Raumplanung oder bei der Erteilung von\\nLizenzen) für die Bürger*innen nachvollziehbar sind und ihre Möglichkeiten zur Mitgestaltung\\ngegeben sind. Die Anwendung von KI kann zu neuen Problemen mit Ermessensspielräumen und\\nPrognoseentscheidungen von Behörden führen, die nicht zu Lasten des Umweltschutzes\\naufgelöst werden dürfen.\\n\\uf0b7 Wirtschaftsförderung mit Vorausschau: Ziel jeglicher KI-bezogener Wirtschaftsförderung muss\\nes sein, Produkte und Dienstleistungen zu fördern, die zur Lösung sozialer und/oder\\nökologischer Herausforderungen und dem Erreichen der entsprechenden Ziele der EU -\\ninsbesondere der völkerrechtlich verbindlichen - beitragen. Die Vorteile von Innovation sollen\\ngenutzt werden, jedoch unter Berücksichtigung des Vorsorgeprinzips. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', 'stakeholder_name': 'Deutscher Naturschutzring', 'stakeholder_type': 'Environmental Organisation', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '14-06-2020 16:17', 'language': 'German', 'document_reference': 'F530333', 'document_name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', '_split_id': 7, 'page': 3, '_split_overlap': [{'doc_id': 'c5851bdabafb558f2c04dbc658536f38', 'range': (0, 270)}, {'doc_id': '856598817adcc5da761d6f827bb85810', 'range': (1164, 1587)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '59858712f91a7a30869a735bfd7178ff'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutscher Naturschutzring, stakeholder_type: Environmental Organisation, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Germany, document_date: 14-06-2020 16:17, language: German, \\n\\nPassage: \\uf0b7 Wirtschaftsförderung mit Vorausschau: Ziel jeglicher KI-bezogener Wirtschaftsförderung muss\\nes sein, Produkte und Dienstleistungen zu fördern, die zur Lösung sozialer und/oder\\nökologischer Herausforderungen und dem Erreichen der entsprechenden Ziele der EU -\\ninsbesondere der völkerrechtlich verbindlichen - beitragen. Die Vorteile von Innovation sollen\\ngenutzt werden, jedoch unter Berücksichtigung des Vorsorgeprinzips. Ein auf dieser Grundlage\\nklug gesetzter rechtlicher Rahmen gibt Planungs- und Investitionssicherheit.\\n\\uf0b7 Vielfalt sichert Resilienz: Forschungsförderung nachhaltig gestalten: Das Weißbuch\\nkonstatiert zu Recht einen hohen Forschungsbedarf. Der Versuch, alle Fördermittel zu bündeln\\nund den Einsatz zentral zu koordinieren, würde jedoch die Resilienz der Forschung und der\\nForschungslandschaften senken und ein starres bürokratisches Korsett auf Kosten von\\nFlexibilität und lokalen/nationalen Forschungsbedarfen schaffen.\\n\\uf0b7 Inhalte: Mit dem European Green Deal erhebt die Gemeinschaft Anspruch auf eine\\nFührungsrolle in der internationalen Klimapolitik; entsprechend sollte das Streben nach\\ninternationaler Exzellenz in der KI-Forschung, insbesondere die KI-gestützte (nicht-\\nnukleare) Dekarbonisierung der Wirtschaft, Ressourcen- und Energieeffizienz und\\nBiodiversitätsschutz oben auf die Agenda stellen, aber auch sozial-ökologische Forschung\\nzu den gesellschaftlichen Auswirkungen der KI und zu der Frage, wie KI die politische\\nInformation und demokratische Beteiligung der Bürgern fördern kann.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', 'stakeholder_name': 'Deutscher Naturschutzring', 'stakeholder_type': 'Environmental Organisation', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '14-06-2020 16:17', 'language': 'German', 'document_reference': 'F530333', 'document_name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', '_split_id': 8, 'page': 4, '_split_overlap': [{'doc_id': '59858712f91a7a30869a735bfd7178ff', 'range': (0, 423)}, {'doc_id': '5bb3a9a5fd109d13cb9a397af553d62', 'range': (943, 1519)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '856598817adcc5da761d6f827bb85810'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutscher Naturschutzring, stakeholder_type: Environmental Organisation, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Germany, document_date: 14-06-2020 16:17, language: German, \\n\\nPassage: \\uf0b7 Inhalte: Mit dem European Green Deal erhebt die Gemeinschaft Anspruch auf eine\\nFührungsrolle in der internationalen Klimapolitik; entsprechend sollte das Streben nach\\ninternationaler Exzellenz in der KI-Forschung, insbesondere die KI-gestützte (nicht-\\nnukleare) Dekarbonisierung der Wirtschaft, Ressourcen- und Energieeffizienz und\\nBiodiversitätsschutz oben auf die Agenda stellen, aber auch sozial-ökologische Forschung\\nzu den gesellschaftlichen Auswirkungen der KI und zu der Frage, wie KI die politische\\nInformation und demokratische Beteiligung der Bürgern fördern kann.\\n\\uf0b7 Vernetzung, Koordination: Eine verstärkte Vernetzung der Forschungsinstitutionen in der\\nEU und eine engere Koordination der Forschungsagenden sollte mit Augenmaß geschehen\\nund muss den Mitgliedstaaten die Möglichkeit lassen, nationale Forschungsprioritäten zu\\nsetzen und universitäre Forschung zu fördern. Exzellenzzentren mögen internationale\\nLeuchttürme erzeugen; wenn diese nicht national und lokal nachhaltige Entwicklung\\nfördern, bleiben Europas Küsten dunkel.\\n\\uf0b7 Partnerschaften mit der Wirtschaft und mit wirtschaftsnahen Forschungsinstitutionen\\nliegen andere Interessenstrukturen zugrunde als Förderung universitärer Forschung. Solche\\nPartnerschaften müssen klaren Bedingungen zu finanziellem Eigenbeitrag und den\\nNutzungsrechten der Ergebnisse öffentlich geförderter Forschung folgen. Eine Förderung\\nder Privatwirtschaft sollte einer Marktkonzentration entgegenwirken, bspw. durch eine\\nprioritäre Förderung von kleinen und mittleren Unternehmen (KMU).\\n\\uf0b7 Marktregulierung: Das EU-Wettbewerbsrecht muss an digitale Geschäftsmodelle\\nangepasst werden, um zunehmende Machtkonzentrationen einiger weniger Unternehmen\\nzu begrenzen. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', 'stakeholder_name': 'Deutscher Naturschutzring', 'stakeholder_type': 'Environmental Organisation', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '14-06-2020 16:17', 'language': 'German', 'document_reference': 'F530333', 'document_name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', '_split_id': 9, 'page': 4, '_split_overlap': [{'doc_id': '856598817adcc5da761d6f827bb85810', 'range': (0, 576)}, {'doc_id': '63fc23e2cf683f83281529fee681ead0', 'range': (1462, 1711)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5bb3a9a5fd109d13cb9a397af553d62'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutscher Naturschutzring, stakeholder_type: Environmental Organisation, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Germany, document_date: 14-06-2020 16:17, language: German, \\n\\nPassage: durch eine\\nprioritäre Förderung von kleinen und mittleren Unternehmen (KMU).\\n\\uf0b7 Marktregulierung: Das EU-Wettbewerbsrecht muss an digitale Geschäftsmodelle\\nangepasst werden, um zunehmende Machtkonzentrationen einiger weniger Unternehmen\\nzu begrenzen. Die derzeitigen Marktkonzentrationen in der Digitalwirtschaft führen zu\\x0cIneffizienzen, Abhängigkeiten und Innovationsfeindlichkeit. Open Data ist mit Blick auf die\\nEntwicklung von Open-Source-Anwendungen wünschenswert, nutzt aber großen\\nUnternehmen mit hoher Rechenleistung und Speicherkapazitäten überproportional mehr\\nals anderen Nutzern. Deshalb muss einem Machtgewinn großer Unternehmen durch eine\\nOpen-Data-Politik entgegengewirkt werden.\\n\\uf0b7 Datenschutz und Manipulationsfreiheit: Neben einem starken Datenschutz und\\ninformationeller Selbstbestimmung, welche die EU-Kommission als Grundlage für Vertrauen\\nanerkennt, muss auch Manipulationsfreiheit über die Bestimmungen der DSGVO\\ngewährleistet werden. Dafür müssen entsprechende gesetzliche Rahmenbedingungen\\ngeschaffen werden, etwa durch ein Verbot manipulativer Werbung und Wahlbeeinflussung.\\nAlgorithmen können beabsichtigt oder unbeabsichtigt bestimmte gesellschaftliche Gruppen\\ndiskriminieren, indem bereits vorhandene Muster von Diskriminierung oder Vorurteile\\nübernommen und im schlimmsten Fall noch verstärkt werden. KI darf aufgrund der Gefahr\\nvon Verzerrungen nicht zur Beurteilung von individuellen Menschen angewendet werden.\\n\\uf0b7 Open Data: Große Datenmengen spielen bei der Entwicklung von KI-Anwendungen, wie z.\\nB. dem maschinellen Lernen, eine zentrale Rolle. Oft sind es große Tech-Konzerne die durch\\nihr Angebot digitaler Dienste und vernetzter Geräte in großem Umfang Daten erheben\\nkönnen. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', 'stakeholder_name': 'Deutscher Naturschutzring', 'stakeholder_type': 'Environmental Organisation', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '14-06-2020 16:17', 'language': 'German', 'document_reference': 'F530333', 'document_name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', '_split_id': 10, 'page': 4, '_split_overlap': [{'doc_id': '5bb3a9a5fd109d13cb9a397af553d62', 'range': (0, 249)}, {'doc_id': '658b183e096e16192dfe6894a823e2d1', 'range': (1577, 1709)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '63fc23e2cf683f83281529fee681ead0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutscher Naturschutzring, stakeholder_type: Environmental Organisation, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Germany, document_date: 14-06-2020 16:17, language: German, \\n\\nPassage: Oft sind es große Tech-Konzerne die durch\\nihr Angebot digitaler Dienste und vernetzter Geräte in großem Umfang Daten erheben\\nkönnen. Daten sollten genutzt werden für die Erreichung der Nachhaltigkeitsziele wie\\nBekämpfung des anthropogenen Klimawandels, Kreislaufwirtschaft, das Null-Schadstoff-\\nZiel, Schutz der Biodiversität und für die Gewährleistung der Einhaltung von Vorschriften\\neingesetzt werden. Offene Daten können Alternativen zu den Konzentrationsprozessen bei\\neinigen wenigen Tech-Konzernen schaffen, ebenso besteht jedoch die Gefahr, dass sie\\nsolche Konzentrationsprozesse verstärken. Hier gilt es behutsam und mit Augenmaß zu\\nsteuern. Wir brauchen eine offene gesamtgesellschaftliche Diskussion über die Frage wem\\nwelche Daten gehören und welche personenbezogenen Daten in eine Open Data-Allmende\\nübergehen.\\n\\uf0b7 Soziale Auswirkungen mitdenken: Neben digitaler Diskriminierung, sind weitere soziale\\nAuswirkungen eines Einsatzes von KI-basierten Anwendungen zu untersuchen und im Sinne\\neiner sozial gerechten Gemeinschaft politisch zu gestalten. Zu den Risiken gehören\\nbeispielsweise die mögliche Verschärfung von Einkommens- und Wohlfahrtsunterschieden\\ndurch KI-Anwendungen oder auch steigende Kapital- und sinkende Lohneinkommen, wenn\\nmaschinelle Arbeit menschliche Arbeit (teilweise) ersetzt.\\n\\uf0b7 Vertrauen braucht Beteiligung. Das als wichtig erachtete Vertrauen der Bürger*innen der\\nGemeinschaft in KI setzt voraus, dass in der Bevölkerung ein Grundverständnis und effektive\\nBeteiligungsmöglichkeiten für sie vorhanden sind. Hierbei ist die Zivilgesellschaft ein\\nwichtiger Mittler und Interessensvertreter. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', 'stakeholder_name': 'Deutscher Naturschutzring', 'stakeholder_type': 'Environmental Organisation', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '14-06-2020 16:17', 'language': 'German', 'document_reference': 'F530333', 'document_name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', '_split_id': 11, 'page': 5, '_split_overlap': [{'doc_id': '63fc23e2cf683f83281529fee681ead0', 'range': (0, 132)}, {'doc_id': '5ebac72cd9b35d3c2d11ec15144d5ea3', 'range': (1339, 1619)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '658b183e096e16192dfe6894a823e2d1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutscher Naturschutzring, stakeholder_type: Environmental Organisation, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Germany, document_date: 14-06-2020 16:17, language: German, \\n\\nPassage: Das als wichtig erachtete Vertrauen der Bürger*innen der\\nGemeinschaft in KI setzt voraus, dass in der Bevölkerung ein Grundverständnis und effektive\\nBeteiligungsmöglichkeiten für sie vorhanden sind. Hierbei ist die Zivilgesellschaft ein\\nwichtiger Mittler und Interessensvertreter. Erforderlich sind:\\na) Breitenbildung für ein Grundverständnis und eine informierte, reflektierte Nutzung\\nvon KI;\\nb) Beteiligungsmöglichkeiten in der Entwicklung der Forschungsagenda;\\nc) Beteiligungsmöglichkeiten im weiteren Arbeitsprozess der High-Level Expert Group\\n(HLEG) und der Umsetzung der KI-Strategie der Kommission;\\nd) Beteiligungsmöglichkeiten bei der Anwendung von KI in nationalen und lokalen\\nKontexten, z.B. in der Raumplanung, in der Verkehrsplanung oder im Naturschutz.\\x0cWir halten fest, dass das Weißbuch dringend nachjustiert werden muss. Umwelt- und Klimabelange\\nwerden zu wenig berücksichtigt, eine Nachhaltigkeitsperspektive wird lediglich angedeutet, bleibt aber\\nweit hinter den notwendigen Anforderungen zurück. Ob eine KI aus gesellschaftlicher Perspektive\\nwünschenswert ist, hängt davon ab, ob sie zu einer nachhaltigen Energie-, Verkehrs-, Agrar- und\\nRessourcenwende, zur Klimaneutralität bis 2050 und sozialer Gerechtigkeit beiträgt. Dies muss\\nsichergestellt werden.\\nEs bedarf hierfür eines verbindlichen Rechtsrahmens und einer durchdachten Zielvorgabe für die\\nEntwicklung und Anwendung von KI. Ein solcher Rahmen gibt Planungs- und Investitionssicherheit für\\nalle Akteure und gewährleistet die Transparenz der algorithmischen Entscheidungssysteme. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', 'stakeholder_name': 'Deutscher Naturschutzring', 'stakeholder_type': 'Environmental Organisation', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '14-06-2020 16:17', 'language': 'German', 'document_reference': 'F530333', 'document_name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', '_split_id': 12, 'page': 5, '_split_overlap': [{'doc_id': '658b183e096e16192dfe6894a823e2d1', 'range': (0, 280)}, {'doc_id': '4efbae612814fff6c13a398930d9384a', 'range': (1273, 1555)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5ebac72cd9b35d3c2d11ec15144d5ea3'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutscher Naturschutzring, stakeholder_type: Environmental Organisation, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Germany, document_date: 14-06-2020 16:17, language: German, \\n\\nPassage: Es bedarf hierfür eines verbindlichen Rechtsrahmens und einer durchdachten Zielvorgabe für die\\nEntwicklung und Anwendung von KI. Ein solcher Rahmen gibt Planungs- und Investitionssicherheit für\\nalle Akteure und gewährleistet die Transparenz der algorithmischen Entscheidungssysteme. Die\\nBeteiligung der zivilgesellschaftlichen Akteure an der Entwicklung eines solchen Rechtsrahmens stellt\\neinen gesellschaftlichen Dialog sicher und schafft damit die Basis für Vertrauen und Akzeptanz der\\nneuen Technologien.\\nGerne beteiligen sich die unterzeichnenden Organisationen an der weiteren Diskussion.\\nDatum: 05.06.2020', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', 'stakeholder_name': 'Deutscher Naturschutzring', 'stakeholder_type': 'Environmental Organisation', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '14-06-2020 16:17', 'language': 'German', 'document_reference': 'F530333', 'document_name': 'F530333-Stellungnahme_KI_Weissbuch.pdf', '_split_id': 13, 'page': 6, '_split_overlap': [{'doc_id': '5ebac72cd9b35d3c2d11ec15144d5ea3', 'range': (0, 282)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4efbae612814fff6c13a398930d9384a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Fortum, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Finland, document_date: 09-06-2020 15:52, language: English, \\n\\nPassage: 1 (2)\\nPublic Affairs 2020-05-11\\nDivision Postadress Besöksadress Telefon/Fax Org. Nr\\nMomsNr\\nHemort\\nCompany\\nFORTUM POSITION ON ARTIFICIAL INTELLIGENCE\\nFortum welcomes the EU Commissions initiatives to create a European digital single market. A\\nstrong digital single market must be based on trust and competitiveness. Regulatory frameworks for\\ndigital services and solutions needs to balance protection of consumers, personal integrity and\\ntransparency with the need for agility and competitiveness. Thus, it is important to limit the level of\\nbureaucracy to what is crucial in order to provide for protection of consumers and fundamental\\nrights. This means avoiding overlapping and non-coherent regulation and creating or introducing\\nnew regulatory bodies in areas where control and oversight is already covered. Many issues related\\nto AI is currently regulated through the GDPR (General Data Protections Regulation) of 2018.\\nFortum believe in a risk-based approach to AI, however such approach must be quite open and\\nflexible. In the current proposal the Commission wants to set an exhaustive list of sectors combined\\nwith definitions of critical use which would the constitute high risk applications with demands for\\nprior conformity assessments and authority approval. The approval would then cover algorithms\\nand data sets etc. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530497-Fortum_AI_position.pdf', 'stakeholder_name': 'Fortum', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Finland', 'stakeholder_scope': nan, 'document_date': '09-06-2020 15:52', 'language': 'English', 'document_reference': 'F530497', 'document_name': 'F530497-Fortum_AI_position.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': 'cadca8b62b014a395d606db7d0b5eb85', 'range': (1027, 1330)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4e43d26afd5d30167b47745ad30d8acd'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Fortum, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Finland, document_date: 09-06-2020 15:52, language: English, \\n\\nPassage: In the current proposal the Commission wants to set an exhaustive list of sectors combined\\nwith definitions of critical use which would the constitute high risk applications with demands for\\nprior conformity assessments and authority approval. The approval would then cover algorithms\\nand data sets etc. Creating an exhaustive list of sectors and usage of AI to determine high risk will\\ndistort the market for digital systems and services since the same service may be classified\\ndifferently depending supplier. To give an example, a system set up to increase accuracy in\\ncostumer communication could be high risk for an energy company but not for an insurance\\ncompany utilizing the same solution. Trying to define a sector can be proven difficult looking at the\\ntelecom sector as an example going from providing means for communications to supplying media\\nservices and media content.\\nAt this point in time it’s difficult to clearly define what can or should be considered as AI.\\nUnderstanding this difficulty, and as mentioned above the disadvantages with pinpointing certain\\nsectors, Fortum would like to see a regulatory framework based on accountability. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530497-Fortum_AI_position.pdf', 'stakeholder_name': 'Fortum', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Finland', 'stakeholder_scope': nan, 'document_date': '09-06-2020 15:52', 'language': 'English', 'document_reference': 'F530497', 'document_name': 'F530497-Fortum_AI_position.pdf', '_split_id': 1, 'page': 1, '_split_overlap': [{'doc_id': '4e43d26afd5d30167b47745ad30d8acd', 'range': (0, 303)}, {'doc_id': '9f66991fb63e17f2e12b2e58733611e4', 'range': (980, 1158)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'cadca8b62b014a395d606db7d0b5eb85'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Fortum, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Finland, document_date: 09-06-2020 15:52, language: English, \\n\\nPassage: Understanding this difficulty, and as mentioned above the disadvantages with pinpointing certain\\nsectors, Fortum would like to see a regulatory framework based on accountability. Organizations\\nutilizing AI for decision making would then have to verify that they have a setup with sufficient\\nlaws into risk-based, verifiable, demonstrable and enforceable corporate practices and controls,\\nsupported by technology tools. Organizations should be held accountable for establishing systems\\nand governance needed to be in compliance with current legislation.\\nFortum would like to see a regulatory framework for AI based on the following principles:\\n\\uf0b7 Accountability should be the key element when creating an AI regulatory framework instead\\nof creating exhaustive lists of sectors and critical use with demands of prior conformity\\nassessments and approval. Accountability-based compliance and governance programs\\nenable organizations to operationalize principles-based laws into risk-based, verifiable,\\ndemonstrable and enforceable corporate practices and controls, supported by technology\\ntools.\\n\\uf0b7 New regulation should only be introduced when there is a gap in GDPR or other legislation.\\nIt’s important to avoid regulatory overlaps and conflicts.\\n\\uf0b7 Sectors that already have a primary authority for control and oversights should not be\\nburdened with additional supervision. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530497-Fortum_AI_position.pdf', 'stakeholder_name': 'Fortum', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Finland', 'stakeholder_scope': nan, 'document_date': '09-06-2020 15:52', 'language': 'English', 'document_reference': 'F530497', 'document_name': 'F530497-Fortum_AI_position.pdf', '_split_id': 2, 'page': 1, '_split_overlap': [{'doc_id': 'cadca8b62b014a395d606db7d0b5eb85', 'range': (0, 178)}, {'doc_id': 'b32b2a8fbbb5c0d5678d0ab2b64c812a', 'range': (1184, 1369)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9f66991fb63e17f2e12b2e58733611e4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Fortum, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Finland, document_date: 09-06-2020 15:52, language: English, \\n\\nPassage: It’s important to avoid regulatory overlaps and conflicts.\\n\\uf0b7 Sectors that already have a primary authority for control and oversights should not be\\nburdened with additional supervision. This would be the case with nuclear where new\\napplications and systems usually gets approval from the national radiation authorities.\\nRef. Ares(2020)3359052 - 26/06/2020\\x0c2 (2)\\nAuthor Date\\nDivision Org. Nr\\nCompany MomsNr\\nHemort', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530497-Fortum_AI_position.pdf', 'stakeholder_name': 'Fortum', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Finland', 'stakeholder_scope': nan, 'document_date': '09-06-2020 15:52', 'language': 'English', 'document_reference': 'F530497', 'document_name': 'F530497-Fortum_AI_position.pdf', '_split_id': 3, 'page': 1, '_split_overlap': [{'doc_id': '9f66991fb63e17f2e12b2e58733611e4', 'range': (0, 185)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b32b2a8fbbb5c0d5678d0ab2b64c812a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Why a Right to Explanation of Automated\\nDecision-Making Does Not Exist in the General\\nData Protection Regulation\\nSandra Wachter*, Brent Mittelstadt** and Luciano Floridi***\\nIntroduction\\nIn recent months, researchers,1 government bodies,2\\nand the media3 have claimed that a ‘right to\\nexplanation’ of decisions made by automated and artiﬁ-\\ncially intelligent algorithmic systems is legally mandated\\nKey Points\\n\\x15 Since approval of the European Union General\\nData Protection Regulation (GDPR) in 2016, it\\nhas been widely and repeatedly claimed that a\\n‘right to explanation’ of all decisions made by\\nautomated or artiﬁcially intelligent algorithmic\\nsystems will be legally mandated by the GDPR\\nonce it is in force, in 2018.\\n\\x15 However, there are several reasons to doubt both\\nthe legal existence and the feasibility of such a\\nright. In contrast to the right to explanation of\\nspeciﬁc automated decisions claimed elsewhere,\\nthe GDPR only mandates that data subjects\\nreceive meaningful, but properly limited, infor-\\nmation (Articles 13–15) about the logic involved,\\nas well as the signiﬁcance and the envisaged con-\\nsequences of automated decision-making sys-\\ntems, what we term a ‘right to be informed’.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': '3fe2b5c7bf1698c832328631c7f98d45', 'range': (827, 1196)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ec98fb74b0e4e44a85b414aaf4a0a7b7'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: In contrast to the right to explanation of\\nspeciﬁc automated decisions claimed elsewhere,\\nthe GDPR only mandates that data subjects\\nreceive meaningful, but properly limited, infor-\\nmation (Articles 13–15) about the logic involved,\\nas well as the signiﬁcance and the envisaged con-\\nsequences of automated decision-making sys-\\ntems, what we term a ‘right to be informed’.\\n\\x15 The ambiguity and limited scope of the ‘right not\\nto be subject to automated decision-making’\\ncontained in Article 22 (from which the alleged\\n‘right to explanation’ stems) raises questions over\\nthe protection actually afforded to data subjects.\\n\\x15 These problems show that the GDPR lacks precise\\nlanguage as well as explicit and well-deﬁned rights\\nand safeguards against automated decision-mak-\\ning, and therefore runs the risk of being toothless.\\n\\x15 We propose a number of legislative steps that, if\\nimplemented, may improve the transparency and\\naccountability of automated decision-making\\nwhen the GDPR comes into force in 2018.\\n* Sandra Wachter, Oxford Internet Institute, University of Oxford,\\nOxford, UK; The Alan Turing Institute, British Library, London, UK.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 1, 'page': 1, '_split_overlap': [{'doc_id': 'ec98fb74b0e4e44a85b414aaf4a0a7b7', 'range': (0, 369)}, {'doc_id': '2db8c9d7c26a4e72bd29b8863ddd2a73', 'range': (819, 1135)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3fe2b5c7bf1698c832328631c7f98d45'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: \\x15 We propose a number of legislative steps that, if\\nimplemented, may improve the transparency and\\naccountability of automated decision-making\\nwhen the GDPR comes into force in 2018.\\n* Sandra Wachter, Oxford Internet Institute, University of Oxford,\\nOxford, UK; The Alan Turing Institute, British Library, London, UK.\\n** Brent Mittelstadt, The Alan Turing Institute, British Library, London,\\nUK; Department of Science and Technology Studies, University College\\nLondon, London, UK; Oxford Internet Institute, University of Oxford,\\nOxford, UK.\\n*** Luciano Floridi, Oxford Internet Institute, University of Oxford, Oxford,\\nUK; The Alan Turing Institute, British Library, London, UK.\\nWe are deeply indebted to Prof Peggy Valcke, Prof Massimo Durante, Prof\\nUgo Pagallo, Dr Natascha Scherzer and Mag Priska Lueger for their invaluable\\ncomments and insightful feedback, from which the paper greatly beneﬁtted.\\nWe want to especially thank Dr Alessandro Spina whose intensive review and\\nin-depth comments strengthened the arguments in the paper. Further we are\\ngreatly thankful to Dr Joris van Hoboken for the inspiring conversation as\\nwell as written feedback on the draft that signiﬁcantly improved the quality of\\nthe paper. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 2, 'page': 1, '_split_overlap': [{'doc_id': '3fe2b5c7bf1698c832328631c7f98d45', 'range': (0, 316)}, {'doc_id': 'd0b6fd5b3d8a2de6df9c0407189fe6b', 'range': (1036, 1216)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2db8c9d7c26a4e72bd29b8863ddd2a73'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Further we are\\ngreatly thankful to Dr Joris van Hoboken for the inspiring conversation as\\nwell as written feedback on the draft that signiﬁcantly improved the quality of\\nthe paper. We also want to thank Prof Tal Zarsky and Prof Lee Bygrave not\\nonly for their pioneering and groundbreaking work that inspired this paper,\\nbut also their positive feedback, in-depth review, and invaluable comments.\\nLast but not least, we want to thank the anonymous reviewer for the time\\nspent reading and commenting so thoroughly on the paper. This study was\\nfunded by the Alan Turing Institute (Luciano Floridi, Brent Mittelstadt, and\\nSandra Wachter), the PETRAS IoT Hub - a EPSRC project (Luciano Floridi,\\nBrent Mittelstadt, and Sandra Wachter), and a research grant from the\\nUniversity of Oxford’s John Fell Fund (Brent Mittelstadt). The authors declare\\nthey do not have any conﬂicts of interest.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 3, 'page': 1, '_split_overlap': [{'doc_id': '2db8c9d7c26a4e72bd29b8863ddd2a73', 'range': (0, 180)}, {'doc_id': '6b2d940145bc516a1f28260f0a3e49d5', 'range': (526, 881)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd0b6fd5b3d8a2de6df9c0407189fe6b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: This study was\\nfunded by the Alan Turing Institute (Luciano Floridi, Brent Mittelstadt, and\\nSandra Wachter), the PETRAS IoT Hub - a EPSRC project (Luciano Floridi,\\nBrent Mittelstadt, and Sandra Wachter), and a research grant from the\\nUniversity of Oxford’s John Fell Fund (Brent Mittelstadt). The authors declare\\nthey do not have any conﬂicts of interest.\\n1 See eg Bryce Goodman and Seth Flaxman, ‘EU Regulations on\\nAlgorithmic Decision-Making and a “right to Explanation”’ [2016]\\narXiv:1606.08813 [cs, stat] <http://arxiv.org/abs/1606.08813> accessed\\n30 June 2016; Francesca Rossi, ‘Artiﬁcial Intelligence: Potential Beneﬁts\\nand Ethical Considerations’ (European Parliament: Policy Department C:\\nCitizens’ Rights and Constitutional Affairs 2016) Brieﬁng PE 571.380\\n<http://www.europarl.europa.eu/RegData/etudes/BRIE/2016/571380/\\nIPOL_BRI(2016)571380_EN.pdf> accessed 20 April 2017; Mireille\\nHildebrandt, ‘The New Imbroglio - Living with Machine Algorithms’,\\nThe Art of Ethics in the Information Society (2016) <https://works.\\nbepress.com/mireille_hildebrandt/75/> accessed 28 December 2016;\\nIEEE Global Initiative, ‘Ethically Aligned Designed - A Vision for\\nPrioritizing Human Wellbeing with Artiﬁcial Intelligence and\\nAutonomous Systems’ (IEEE 2016) Version 1 <http://standards.ieee.org/\\ndevelop/indconn/ec/ead_v1.pdf> accessed 19 January 2017; Ben Wagner,\\n‘Efﬁciency vs. Accountability? ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 4, 'page': 1, '_split_overlap': [{'doc_id': 'd0b6fd5b3d8a2de6df9c0407189fe6b', 'range': (0, 355)}, {'doc_id': '7daec6a63dc1797b0a35a5d56b31d17d', 'range': (1027, 1389)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6b2d940145bc516a1f28260f0a3e49d5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: bepress.com/mireille_hildebrandt/75/> accessed 28 December 2016;\\nIEEE Global Initiative, ‘Ethically Aligned Designed - A Vision for\\nPrioritizing Human Wellbeing with Artiﬁcial Intelligence and\\nAutonomous Systems’ (IEEE 2016) Version 1 <http://standards.ieee.org/\\ndevelop/indconn/ec/ead_v1.pdf> accessed 19 January 2017; Ben Wagner,\\n‘Efﬁciency vs. Accountability? – Algorithms, Big Data and Public\\nAdministration’ <https://cihr.eu/efﬁciency-vs-accountability-algorithms-\\nbig-data-and-public-administration/> accessed 14 January 2017; Fusion,\\n‘EU Introduces “right to Explanation” on Algorithms j Fusion’ (2016),\\nquoting Ryan Calo <http://fusion.net/story/321178/european-union-\\nright-to-algorithmic-explanation/> accessed 10 November 2016.\\nV\\nC The Author 2017. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com\\n76 ARTICLE International Data Privacy Law, 2017, Vol. 7, No. 2\\nRef. Ares(2020)3357466 - 26/06/2020\\x0cby the forthcoming European Union General Data\\nProtection Regulation4 2016/679 (GDPR). The right to\\nexplanation is viewed as a promising mechanism in the\\nbroader pursuit by government and industry for\\naccountability and transparency in algorithms, artiﬁcial\\nintelligence, robotics, and other automated systems.5\\nAutomated systems can have many unintended and\\nunexpected effects.6 Public assessment of the extent and\\nsource of these problems is often difﬁcult,7 owing to the\\nuse of complex and opaque algorithmic mechanisms.8\\nThe alleged right to explanation would require data\\ncontrollers to explain how such mechanisms reach deci-\\nsions. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 5, 'page': 1, '_split_overlap': [{'doc_id': '6b2d940145bc516a1f28260f0a3e49d5', 'range': (0, 362)}, {'doc_id': '9c46b5fc85ddca8a8eda6a34340ab927', 'range': (1065, 1616)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7daec6a63dc1797b0a35a5d56b31d17d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The right to\\nexplanation is viewed as a promising mechanism in the\\nbroader pursuit by government and industry for\\naccountability and transparency in algorithms, artiﬁcial\\nintelligence, robotics, and other automated systems.5\\nAutomated systems can have many unintended and\\nunexpected effects.6 Public assessment of the extent and\\nsource of these problems is often difﬁcult,7 owing to the\\nuse of complex and opaque algorithmic mechanisms.8\\nThe alleged right to explanation would require data\\ncontrollers to explain how such mechanisms reach deci-\\nsions. Signiﬁcant hype has been mounting over the\\nempowering effects of such a legally enforceable right\\nfor data subjects, and the disruption of data intensive\\nindustries, which would be forced to explain how com-\\nplex and perhaps inscrutable automated methods work\\nin practice.\\nHowever, there are several reasons to doubt the exis-\\ntence, scope, and feasibility of a ‘right to explanation’ of\\nautomated decisions. In this article, we examine the\\nlegal status of the ‘right to explanation’ in the GDPR,\\nand identify several barriers undermining its implemen-\\ntation. We argue that the GDPR does not, in its current\\nform, implement a right to explanation, but rather what\\nwe term a limited ‘right to be informed’. Here is a quick\\noverview.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 6, 'page': 2, '_split_overlap': [{'doc_id': '7daec6a63dc1797b0a35a5d56b31d17d', 'range': (0, 551)}, {'doc_id': '2183ad53489e2f35644a3e821d35d971', 'range': (1113, 1284)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9c46b5fc85ddca8a8eda6a34340ab927'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: We argue that the GDPR does not, in its current\\nform, implement a right to explanation, but rather what\\nwe term a limited ‘right to be informed’. Here is a quick\\noverview.\\nIn section ‘What is meant by a right to explanation?’,\\nwe disentangle the types and timing of explanations that\\ncan be offered of automated decision-making. The right\\nto explanation, as popularly proposed, is thought to\\ngrant an explanation of speciﬁc automated decisions,\\nafter such a decision has been made.9\\nIn section ‘Why there is no ‘right to explanation’ in\\nthe GDPR’, we assess three possible legal bases for a\\nright to explanation in the GDPR: the right not to be\\nsubject to automated decision-making and safeguards\\nenacted thereof (Article 22 and Recital 71); notiﬁcation\\nduties of data controllers (Articles 13–14 and Recitals\\n60–62); and the right to access (Article 15 and\\nRecital 63).\\nThe aforementioned claim for a right to explana-\\ntion10 muddles the ﬁrst and second legal bases. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 7, 'page': 2, '_split_overlap': [{'doc_id': '9c46b5fc85ddca8a8eda6a34340ab927', 'range': (0, 171)}, {'doc_id': '9f92ecc4ff8c52df73c7c2784c7377d2', 'range': (329, 967)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2183ad53489e2f35644a3e821d35d971'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The right\\nto explanation, as popularly proposed, is thought to\\ngrant an explanation of speciﬁc automated decisions,\\nafter such a decision has been made.9\\nIn section ‘Why there is no ‘right to explanation’ in\\nthe GDPR’, we assess three possible legal bases for a\\nright to explanation in the GDPR: the right not to be\\nsubject to automated decision-making and safeguards\\nenacted thereof (Article 22 and Recital 71); notiﬁcation\\nduties of data controllers (Articles 13–14 and Recitals\\n60–62); and the right to access (Article 15 and\\nRecital 63).\\nThe aforementioned claim for a right to explana-\\ntion10 muddles the ﬁrst and second legal bases. It con-\\nﬂates (i) legally binding requirements of Article 22 and\\n2 See eg Information Commissioner’s Ofﬁce, ‘Overview of the General\\nData Protection Regulation (GDPR)’ (Information Commissioner’s\\nOfﬁce 2016) 1.1.1 <https://ico.org.uk/for-organisations/data-protection-\\nreform/overview-of-the-gdpr/individuals-rights/rights-related-to-auto\\nmated-decision-making-and-proﬁling/> accessed 10 November 2016;\\nHouse of Commons Science and Technology Committee, ‘Robotics and\\nArtiﬁcial Intelligence’ (House of Commons 2016) HC 145 <http://www.\\npublications.parliament.uk/pa/cm201617/cmselect/cmsctech/145/145.\\npdf> accessed 10 November 2016; European Parliament Committee on\\nLegal Affairs, ‘Report with Recommendations to the Commission on\\nCivil Law Rules on Robotics’ (European Parliament 2017) 2015/\\n2103(INL) <http://www.europarl.europa.eu/sides/getDoc.do?pubRef¼-//\\nEP//NONSGMLþREPORTþA8-2017-0005þ0þDOCþPDFþV0//EN>\\naccessed 11 November 2016.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 8, 'page': 2, '_split_overlap': [{'doc_id': '2183ad53489e2f35644a3e821d35d971', 'range': (0, 638)}, {'doc_id': '4a3bb54c4311a958e9439e1269b5fcfe', 'range': (1241, 1577)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9f92ecc4ff8c52df73c7c2784c7377d2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: pdf> accessed 10 November 2016; European Parliament Committee on\\nLegal Affairs, ‘Report with Recommendations to the Commission on\\nCivil Law Rules on Robotics’ (European Parliament 2017) 2015/\\n2103(INL) <http://www.europarl.europa.eu/sides/getDoc.do?pubRef¼-//\\nEP//NONSGMLþREPORTþA8-2017-0005þ0þDOCþPDFþV0//EN>\\naccessed 11 November 2016.\\n3 See eg Joon Ian Wong, ‘The UK Could Become a Leader in AI Ethics—if\\nThis EU Data Law Survives Brexit’ <http://qz.com/807303/uk-parlia\\nment-ai-and-robotics-report-brexit-could-affect-eu-gdpr-right-to-explan\\nation-law/> accessed 10 November 2016; Cade Metz, ‘Artiﬁcial\\nIntelligence Is Setting Up the Internet for a Huge Clash With Europe’\\nWIRED (2016) <https://www.wired.com/2016/07/artiﬁcial-intelligence-\\nsetting-internet-huge-clash-europe/> accessed 10 November 2016;\\nFusion (n 1); Bernard Marr, ‘New Report: Revealing the Secrets of AI Or\\nKilling Machine Learning?’ <http://www.forbes.com/sites/bernardmarr/\\n2017/01/12/new-report-revealing-the-secrets-of-ai-or-killing-machine-\\nlearning/#258189058e56> accessed 14 January 2017; Liisa Jaakonsaari,\\n‘Who Sets the Agenda on Algorithmic Accountability?’ (EURACTIV.com,\\n26 October 2016) <https://www.euractiv.com/section/digital/opinion/\\nwho-sets-the-agenda-on-algorithmic-accountability/> accessed 3 March\\n2017; Nick Wallace, ‘EU’s Right to Explanation: A Harmful Restriction\\non Artiﬁcial Intelligence’ <https://www.datainnovation.org/2017/01/eus-\\nright-to-explanation-a-harmful-restriction-on-artiﬁcial-intelligence/>\\naccessed 3 March 2017.\\n4 Reg (EU) 2016/679 of the European Parliament and of the Council of 27\\nApril 2016 on the protection of natural persons with regard to the proc-\\nessing of personal data and on the free movement of such data, and\\nrepealing Dir 95/46/EC (General Data Protection Regulation) 2016.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 9, 'page': 2, '_split_overlap': [{'doc_id': '9f92ecc4ff8c52df73c7c2784c7377d2', 'range': (0, 336)}, {'doc_id': '28bd1f6aa0488dc9095086daf21d9339', 'range': (1529, 1806)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4a3bb54c4311a958e9439e1269b5fcfe'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 4 Reg (EU) 2016/679 of the European Parliament and of the Council of 27\\nApril 2016 on the protection of natural persons with regard to the proc-\\nessing of personal data and on the free movement of such data, and\\nrepealing Dir 95/46/EC (General Data Protection Regulation) 2016.\\n5 The proliferation of unaccountable and inscrutable automated systems\\nhas proven a major concern among government bodies, as reﬂected in\\nnumerous recent reports on the future ethical and social impacts auto-\\nmated systems. See, for instance, Catherine Stupp, ‘Commission to Open\\nProbe into Tech Companies’ Algorithms next Year’ (EurActiv.com, 8\\nNovember 2016) <http://www.euractiv.com/section/digital/news/com\\nmission-to-open-probe-into-tech-companies-algorithms-next-year/>\\naccessed 11 November 2016; Partnership on AI, ‘Partnership on Artiﬁcial\\nIntelligence to Beneﬁt People and Society’ (Partnership on Artiﬁcial\\nIntelligence to Beneﬁt People and Society, 2016) <https://www.partnershi\\nponai.org/> accessed 11 November 2016; National Science and\\nTechnology Council Committee on Technology, ‘Preparing for the\\nFuture of Artiﬁcial Intelligence’ (Executive Ofﬁce of the President 2016)\\n<https://www.whitehouse.gov/sites/default/ﬁles/whitehouse_ﬁles/micro\\nsites/ostp/NSTC/preparing_for_the_future_of_ai.pdf> accessed 11\\nNovember 2016; European Parliament Committee on Legal Affairs (n 2);\\nHouse of Commons Science and Technology Committee (n 2);\\nGovernment Ofﬁce for Science, ‘Artiﬁcial Intelligence: An Overview for\\nPolicy-Makers’ (Government Ofﬁce for Science 2016) <https://www.gov.\\nuk/government/publications/artiﬁcial-intelligence-an-overview-for-pol\\nicy-makers> accessed 11 November 2016.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 10, 'page': 2, '_split_overlap': [{'doc_id': '4a3bb54c4311a958e9439e1269b5fcfe', 'range': (0, 277)}, {'doc_id': '7c7d4d1dc5b8015c1de64fbe19f5a949', 'range': (502, 1672)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '28bd1f6aa0488dc9095086daf21d9339'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: See, for instance, Catherine Stupp, ‘Commission to Open\\nProbe into Tech Companies’ Algorithms next Year’ (EurActiv.com, 8\\nNovember 2016) <http://www.euractiv.com/section/digital/news/com\\nmission-to-open-probe-into-tech-companies-algorithms-next-year/>\\naccessed 11 November 2016; Partnership on AI, ‘Partnership on Artiﬁcial\\nIntelligence to Beneﬁt People and Society’ (Partnership on Artiﬁcial\\nIntelligence to Beneﬁt People and Society, 2016) <https://www.partnershi\\nponai.org/> accessed 11 November 2016; National Science and\\nTechnology Council Committee on Technology, ‘Preparing for the\\nFuture of Artiﬁcial Intelligence’ (Executive Ofﬁce of the President 2016)\\n<https://www.whitehouse.gov/sites/default/ﬁles/whitehouse_ﬁles/micro\\nsites/ostp/NSTC/preparing_for_the_future_of_ai.pdf> accessed 11\\nNovember 2016; European Parliament Committee on Legal Affairs (n 2);\\nHouse of Commons Science and Technology Committee (n 2);\\nGovernment Ofﬁce for Science, ‘Artiﬁcial Intelligence: An Overview for\\nPolicy-Makers’ (Government Ofﬁce for Science 2016) <https://www.gov.\\nuk/government/publications/artiﬁcial-intelligence-an-overview-for-pol\\nicy-makers> accessed 11 November 2016.\\n6 Brent Mittelstadt and others, ‘The Ethics of Algorithms: Mapping the\\nDebate’ [2016] 3 Big Data & Society 2.\\n7 Christian Sandvig and others, ‘Auditing Algorithms: Research Methods\\nfor Detecting Discrimination on Internet Platforms’ [2014] Data and\\nDiscrimination: Converting Critical Concerns into Productive Inquiry\\n<http://social.cs.uiuc.edu/papers/pdfs/ICA2014-Sandvig.pdf> accessed\\n13 February 2016.\\n8 Mike Ananny, ‘Toward an Ethics of Algorithms Convening, Observation,\\nProbability, and Timeliness’ (2016) 41 Science, Technology & Human\\nValues 93.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 11, 'page': 2, '_split_overlap': [{'doc_id': '28bd1f6aa0488dc9095086daf21d9339', 'range': (0, 1170)}, {'doc_id': '370b854d7da2d960d45594d643101df6', 'range': (1576, 1724)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7c7d4d1dc5b8015c1de64fbe19f5a949'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 8 Mike Ananny, ‘Toward an Ethics of Algorithms Convening, Observation,\\nProbability, and Timeliness’ (2016) 41 Science, Technology & Human\\nValues 93.\\n9 This is the type of explanation of automated decision-making imagined\\nin Recital 71 GDPR, which states ‘In any case, such processing should be\\nsubject to suitable safeguards, which should include speciﬁc information\\nto the data subject and the right to obtain human intervention, to express\\nhis or her point of view, to obtain an explanation of the decision reached\\nafter such assessment and to challenge the decision.’\\n10 Goodman and Flaxman (n 1).\\nSandra Wachter et al. Á No Right to Explanation of Automated Decision-Making 77\\nARTICLE\\x0cnon-binding provisions of Recital 71 and (ii) notiﬁca-\\ntion duties (Articles 13–14) that require data subjects to\\nbe provided with information about \"the existence of\\nautomated decision-making, including proﬁling, referred\\nto in Article 22(1) and (4) and, at least in those cases,\\nmeaningful information about the logic involved, as well\\nas the signiﬁcance and the envisaged consequences of such\\nprocessing for the data subject\" (emphasis added).\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 12, 'page': 2, '_split_overlap': [{'doc_id': '7c7d4d1dc5b8015c1de64fbe19f5a949', 'range': (0, 148)}, {'doc_id': '99d12e67798ace10d4ae7f29c9f9fc1b', 'range': (623, 1135)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '370b854d7da2d960d45594d643101df6'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Á No Right to Explanation of Automated Decision-Making 77\\nARTICLE\\x0cnon-binding provisions of Recital 71 and (ii) notiﬁca-\\ntion duties (Articles 13–14) that require data subjects to\\nbe provided with information about \"the existence of\\nautomated decision-making, including proﬁling, referred\\nto in Article 22(1) and (4) and, at least in those cases,\\nmeaningful information about the logic involved, as well\\nas the signiﬁcance and the envisaged consequences of such\\nprocessing for the data subject\" (emphasis added).\\nHaving challenged the legal basis for a right to\\nexplanation, we then consider whether the right of\\naccess in Article 15 provides a stronger legal basis.\\nFollowing our analysis of the implementation and juris-\\nprudence of the 1995 Data Protection Directive (95/46/\\nEC), we argue that the GDPR’s right of access allows for\\na limited right to explanation of the functionality of\\nautomated decision-making systems—what we refer to\\nas the ‘right to be informed’. However, the right of\\naccess does not establish a right to explanation of spe-\\nciﬁc automated decisions of the type currently imagined\\nelsewhere in public discourse. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 13, 'page': 2, '_split_overlap': [{'doc_id': '370b854d7da2d960d45594d643101df6', 'range': (0, 512)}, {'doc_id': '710db44acd9d7aa8446740d1fa3c60cd', 'range': (972, 1137)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '99d12e67798ace10d4ae7f29c9f9fc1b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: However, the right of\\naccess does not establish a right to explanation of spe-\\nciﬁc automated decisions of the type currently imagined\\nelsewhere in public discourse. Not only is a right to\\nexplanation of speciﬁc decisions not granted by the\\nGDPR, it also appears to have been intentionally not\\nadopted in the ﬁnal text of the GDPR after appearing in\\nan earlier draft.\\nIn section ‘What if a right to explanation were\\ngranted?’, we consider the limitations of scope and\\napplicability, if a right to explanation were to exist. We\\nshow that a ‘general’ right to explanation, applicable to\\nall automated decisions, would not exist even if Recital\\n71 were legally binding. A right to explanation, derived\\nfrom the right of access (Article 15) or safeguards\\ndescribed in Article 22(3), would only apply to a narrow\\nrange of decisions ‘solely based on automated proc-\\nessing’ and with ‘legal’ or ‘similarly signiﬁcant’ effects\\nfor the data subject (Article 22(1) GDPR). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 14, 'page': 3, '_split_overlap': [{'doc_id': '99d12e67798ace10d4ae7f29c9f9fc1b', 'range': (0, 165)}, {'doc_id': '5f25b95350c08a67c6c8defceb1881f0', 'range': (667, 961)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '710db44acd9d7aa8446740d1fa3c60cd'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: A right to explanation, derived\\nfrom the right of access (Article 15) or safeguards\\ndescribed in Article 22(3), would only apply to a narrow\\nrange of decisions ‘solely based on automated proc-\\nessing’ and with ‘legal’ or ‘similarly signiﬁcant’ effects\\nfor the data subject (Article 22(1) GDPR). We examine\\nthe limited cases in which the right would apply, includ-\\ning the impact of a critical ambiguity of language that\\nallows the broader ‘right not to be subject to automated\\ndecision-making’ (Article 22 GDPR) to be interpreted\\neither as a prohibition, or right to object.\\nThe last section concludes the article with recom-\\nmendations for a number of legislative and policy steps\\nthat, if implemented, may improve the transparency\\nand accountability of automated decision-making when\\nthe GDPR comes into force in 2018.\\nWhat is meant by a right to\\nexplanation?\\nBefore examining whether the GDPR speciﬁes a right to\\nexplanation, it is necessary to examine what one may\\nmean by an ‘explanation’ of automated decision-\\nmaking. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 15, 'page': 3, '_split_overlap': [{'doc_id': '710db44acd9d7aa8446740d1fa3c60cd', 'range': (0, 294)}, {'doc_id': '14b96d0f0a623454c3e638c0bea8abcb', 'range': (862, 1024)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5f25b95350c08a67c6c8defceb1881f0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Before examining whether the GDPR speciﬁes a right to\\nexplanation, it is necessary to examine what one may\\nmean by an ‘explanation’ of automated decision-\\nmaking. Two kinds of explanations may be in question,\\ndepending on whether one refers to:\\n\\x15 system functionality, ie the logic, signiﬁcance, envisaged\\nconsequences, and general functionality of an auto-\\nmated decision-making system, eg the system’s\\nrequirements speciﬁcation, decision trees, pre-deﬁned\\nmodels, criteria, and classiﬁcation structures; or to\\n\\x15 speciﬁc decisions, ie the rationale, reasons, and indi-\\nvidual circumstances of a speciﬁc automated deci-\\nsion, eg the weighting of features, machine-deﬁned\\ncase-speciﬁc decision rules, information about refer-\\nence or proﬁle groups.11\\nFurthermore, one can also distinguish between explana-\\ntions in terms of their timing in relation to the\\ndecision-making process:\\n\\x15 an ex ante explanation occurs prior to an automated\\ndecision-making taking place. Note that an ex ante\\nexplanation can logically address only system func-\\ntionality, as the rationale of a speciﬁc decision cannot\\nbe known before the decision is made;\\n\\x15 an ex post explanation occurs after an automated\\ndecision has taken place. Note that an ex post explan-\\nation can address both system functionality and the\\nrationale of a speciﬁc decision.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 16, 'page': 3, '_split_overlap': [{'doc_id': '5f25b95350c08a67c6c8defceb1881f0', 'range': (0, 162)}, {'doc_id': '18ab0a1f28b422f378e2b89003f427cc', 'range': (964, 1322)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '14b96d0f0a623454c3e638c0bea8abcb'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Note that an ex ante\\nexplanation can logically address only system func-\\ntionality, as the rationale of a speciﬁc decision cannot\\nbe known before the decision is made;\\n\\x15 an ex post explanation occurs after an automated\\ndecision has taken place. Note that an ex post explan-\\nation can address both system functionality and the\\nrationale of a speciﬁc decision.\\nAn example may help clarify how these distinctions\\ninteract. Take an automated credit scoring system. Prior\\nto a decision being made (ex ante), the system provider\\ncan inform the data subject about the system functional-\\nity, including the general logic (such as types of data\\nand features considered, categories in the decision tree),\\npurpose or signiﬁcance (in this case, to assign a credit\\nscore), and envisaged consequences (eg the credit score\\ncan be used by lenders to assess credit worthiness,\\naffecting the terms of credit such as interest rate). After\\na decision has been made (ex post), an explanation of\\nsystem functionality can still be provided to the data\\nsubject. However, the provider can also explain to the\\n11 This is speciﬁcally a kind of explanation possible only once a decision has\\nbeen taken. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 17, 'page': 3, '_split_overlap': [{'doc_id': '14b96d0f0a623454c3e638c0bea8abcb', 'range': (0, 358)}, {'doc_id': 'c2c02ad941036e58752f135c4a44d564', 'range': (1038, 1174)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '18ab0a1f28b422f378e2b89003f427cc'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: However, the provider can also explain to the\\n11 This is speciﬁcally a kind of explanation possible only once a decision has\\nbeen taken. It refers to a particular decision, not the decision-making\\nmethod or system itself. This is the type of explanation imagined in\\nRecital 71 GDPR, which calls for ‘an explanation of the decision reached\\nafter such assessment’. The Recital explicitly refers to a singular decision\\nthat has been reached.\\n78 ARTICLE International Data Privacy Law, 2017, Vol. 7, No. 2\\x0cdata subject the logic and individual circumstances of\\ntheir speciﬁc decision, such as her credit score, the data\\nor features that were considered in her particular case,\\nand their weighting within the decision tree or model.\\nIn other words, the provider can explain how a particu-\\nlar score was assigned. Further, when pre-deﬁned sim-\\nplistic or linear models are used and fully disclosed,\\npredictions about the rationale of a speciﬁc decision are\\npossible in principle ex ante. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 18, 'page': 3, '_split_overlap': [{'doc_id': '18ab0a1f28b422f378e2b89003f427cc', 'range': (0, 136)}, {'doc_id': '7a433b560eedb0b0caf8b62eb3b9b031', 'range': (808, 981)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c2c02ad941036e58752f135c4a44d564'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Further, when pre-deﬁned sim-\\nplistic or linear models are used and fully disclosed,\\npredictions about the rationale of a speciﬁc decision are\\npossible in principle ex ante. However, in both cases the\\nprovider’s ability to offer an explanation of the rationale\\nof a speciﬁc decision may be limited by several legal (see\\nsection ‘What if a right to explanation were granted?’)\\nand technical factors, including the use of complex\\nprobabilistic analytics and decision-making methods.12\\nThese distinctions between two kinds and two differ-\\nent timings of explanations are implicit in the GDPR.\\nTheir importance will be highlighted as we examine the\\npossible legal bases for a right to explanation.\\nWhy there is no ‘right to explanation’ in\\nthe GDPR\\nThree distinct possible legal bases for a right to explana-\\ntion of automated decision-making can be found in the\\nGDPR. A right to explanation can possibly be derived\\nfrom: safeguards against automated decision-making as\\nrequired under Article 22(3), and commented upon by\\nRecital 71; notiﬁcation duties under Articles 13–14\\ncommented upon by Recitals 60–62; or the right of\\naccess under Article 15, and commented upon by\\nRecital 63.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 19, 'page': 4, '_split_overlap': [{'doc_id': 'c2c02ad941036e58752f135c4a44d564', 'range': (0, 173)}, {'doc_id': '8191394cdfbd1b1183d8468bb0c0580e', 'range': (865, 1178)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7a433b560eedb0b0caf8b62eb3b9b031'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: A right to explanation can possibly be derived\\nfrom: safeguards against automated decision-making as\\nrequired under Article 22(3), and commented upon by\\nRecital 71; notiﬁcation duties under Articles 13–14\\ncommented upon by Recitals 60–62; or the right of\\naccess under Article 15, and commented upon by\\nRecital 63.\\nThese bases are respectively referred to as a right to\\nexplanation derived from (i) safeguards, (ii) notiﬁcation\\nduties, and (iii) the right of access. We will assess each\\nin turn. On the whole, the claim that a right is granted\\nby the GDPR to an ex post explanation of speciﬁc deci-\\nsions (at a minimum) that seemingly applies to any\\ninstance of automated decision-making is based on a\\ncombination of safeguards and notiﬁcation duties. It\\ncombines non-binding Recital 71 with binding provi-\\nsions of Articles 13–14 and 22 to argue that \"The law\\nwill [. . .] effectively create a \"right to explanation,\"\\nwhereby a user can ask for an explanation of an algo-\\nrithmic decision that was made about them.\"13 This\\nclaim is incorrect for several reasons, explained below.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 20, 'page': 4, '_split_overlap': [{'doc_id': '7a433b560eedb0b0caf8b62eb3b9b031', 'range': (0, 313)}, {'doc_id': '18a1f40a2a43e3c0feef677693182b98', 'range': (873, 1079)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8191394cdfbd1b1183d8468bb0c0580e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: effectively create a \"right to explanation,\"\\nwhereby a user can ask for an explanation of an algo-\\nrithmic decision that was made about them.\"13 This\\nclaim is incorrect for several reasons, explained below.\\nA right to explanation derived from safeguards\\nagainst automated decision-making\\nStarting with the claim14 for a right to explanation\\nderived from safeguards, Article 22 (see Figure 1) and\\nRecital 71 of the GDPR address a data subject’s right\\nnot to be subject to automated decision-making. Article\\n22(3), which addresses safeguards against automated\\ndecision-making, states that:\\nthe data controller shall implement suitable measures to\\nsafeguard the data subject’s rights and freedoms and legiti-\\nmate interests, at least the right to obtain human interven-\\ntion on the part of the controller, to express his or her point of\\nview and to contest the decision. (emphasis added)\\nCritically, a right to explanation is not mentioned.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 21, 'page': 4, '_split_overlap': [{'doc_id': '8191394cdfbd1b1183d8468bb0c0580e', 'range': (0, 206)}, {'doc_id': '2c6f0a21cb90895ecc4353c28718a0fa', 'range': (498, 937)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '18a1f40a2a43e3c0feef677693182b98'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Article\\n22(3), which addresses safeguards against automated\\ndecision-making, states that:\\nthe data controller shall implement suitable measures to\\nsafeguard the data subject’s rights and freedoms and legiti-\\nmate interests, at least the right to obtain human interven-\\ntion on the part of the controller, to express his or her point of\\nview and to contest the decision. (emphasis added)\\nCritically, a right to explanation is not mentioned.\\nRather, after a decision has been made, and assuming\\nthe decision meets a condition speciﬁed in Article\\n22(3)a (to enter or fulﬁl a contract) or Article 22(3)c\\n(with explicit consent), data subjects are granted addi-\\ntional safeguards to obtain human intervention, express\\nviews, or contest a decision (Article 22(3)), but not to\\nobtain an explanation of the decision reached.\\nFigure 1. Article 22 of the General Data Protection Regulation.\\n12 Jenna Burrell, ‘How the Machine “Thinks:” Understanding Opacity in\\nMachine Learning Algorithms’ [2016] 3 Big Data & Society 1.\\n13 Goodman and Flaxman (n 1). The ‘right to explanation’ is proposed as\\nfollows. ‘The law will also effectively create a “right to explanation,”\\nwhereby a user can ask for an explanation of an algorithmic decision that\\nwas made about them’ (1). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 22, 'page': 4, '_split_overlap': [{'doc_id': '18a1f40a2a43e3c0feef677693182b98', 'range': (0, 439)}, {'doc_id': '53495c72f92a3aaf532efee53fc17a53', 'range': (1092, 1255)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2c6f0a21cb90895ecc4353c28718a0fa'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: ‘The law will also effectively create a “right to explanation,”\\nwhereby a user can ask for an explanation of an algorithmic decision that\\nwas made about them’ (1). Further, ‘Paragraph 71 of the recitals (the pre-\\namble to the GDPR, which explains the rationale behind it but is not\\nitself law) explicitly requires data controllers to “implement appropriate\\ntechnical and organizational measures” that “prevents, inter alia, discrim-\\ninatory effects” on the basis of processing sensitive data’ (3) Further,\\n‘The provisions outlined in Articles 13-15 specify that data subjects have\\nthe right to access information collected about them, and also requires\\ndata processors to ensure data subjects are notiﬁed about the data col-\\nlected. However, it is important to distinguish between these rights,\\nwhich may be termed the right to access and notiﬁcation, and additional\\n“safeguards for the rights and freedoms of the data subject” required\\nunder Article 22 when proﬁling takes place. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 23, 'page': 4, '_split_overlap': [{'doc_id': '2c6f0a21cb90895ecc4353c28718a0fa', 'range': (0, 163)}, {'doc_id': '90fad71dd244fb5df02a3b0b1cd4259a', 'range': (733, 980)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '53495c72f92a3aaf532efee53fc17a53'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: However, it is important to distinguish between these rights,\\nwhich may be termed the right to access and notiﬁcation, and additional\\n“safeguards for the rights and freedoms of the data subject” required\\nunder Article 22 when proﬁling takes place. Although the Article does\\nnot elaborate what these safeguards are beyond “the right to obtain\\nhuman intervention”, Articles 13 and 14 state that, when proﬁling takes\\nplace, a data subject has the right to “meaningful information about the\\nlogic involved.” This requirement prompts the question: what does it\\nmean, and what is required, to explain an algorithm’s decision?’ (6).\\n14 Ibid; Rossi (n 1).\\nSandra Wachter et al. Á No Right to Explanation of Automated Decision-Making 79\\nARTICLE\\x0cIn all of the GDPR, a right to explanation is only\\nexplicitly mentioned in Recital 71, which states that a\\nperson who has been subject to automated decision-\\nmaking:\\nshould be subject to suitable safeguards, which should\\ninclude speciﬁc information to the data subject and the\\nright to obtain human intervention, to express his or her\\npoint of view, to obtain an explanation of the decision\\nreached after such assessment and to challenge the decision.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 24, 'page': 4, '_split_overlap': [{'doc_id': '53495c72f92a3aaf532efee53fc17a53', 'range': (0, 247)}, {'doc_id': 'dfecd97aec1bc79620e5f23202954c2b', 'range': (670, 1187)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '90fad71dd244fb5df02a3b0b1cd4259a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Á No Right to Explanation of Automated Decision-Making 79\\nARTICLE\\x0cIn all of the GDPR, a right to explanation is only\\nexplicitly mentioned in Recital 71, which states that a\\nperson who has been subject to automated decision-\\nmaking:\\nshould be subject to suitable safeguards, which should\\ninclude speciﬁc information to the data subject and the\\nright to obtain human intervention, to express his or her\\npoint of view, to obtain an explanation of the decision\\nreached after such assessment and to challenge the decision.\\n(emphasis added)\\nIf legally binding, this provision would require an ex\\npost explanation of speciﬁc decisions, as Recital 71\\naddresses safeguards to be in place once a decision has\\nbeen reached. To show why Recital 71 does not establish\\na legally binding right, a brief aside into the legal status\\nof Recitals is required.\\nRecitals provide guidance15 on how to interpret the\\nArticles, but are not themselves legally binding.16 As\\nKlimas and Vaiciukaite explain, \"Recitals have no posi-\\ntive operation of their own\" and \"cannot cause legiti-\\nmate expectations to arise.\"17 Baratta further expands:\\nIn principle the ECJ does not give effect to recitals that are\\ndrafted in normative terms. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 25, 'page': 4, '_split_overlap': [{'doc_id': '90fad71dd244fb5df02a3b0b1cd4259a', 'range': (0, 517)}, {'doc_id': 'c1ba7e2a773d50abf5af555f091365b8', 'range': (1086, 1205)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'dfecd97aec1bc79620e5f23202954c2b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: \"17 Baratta further expands:\\nIn principle the ECJ does not give effect to recitals that are\\ndrafted in normative terms. Recitals can help to explain the\\npurpose and intent behind a normative instrument. They\\ncan also be taken into account to resolve ambiguities in the\\nlegislative provisions to which they relate, but they do not\\nhave any autonomous legal effect.18\\nJurisprudence of the European Court of Justice (ECJ)\\nshows that the role of Recitals is to dissolve ambiguity\\nin the operative text of a framework. The ECJ has com-\\nmented directly on the legal status of Recitals, clarifying\\nthat: \"Whilst a recital in the preamble to a regulation\\nmay cast light on the interpretation to be given to a legal\\nrule, it cannot in itself constitute such a rule.\"19\\nReturning to the GDPR, Article 22(3) lists the mini-\\nmum requirements that have to be met for lawful auto-\\nmated decision-making. There are no ambiguities in the\\nlanguage that would require further interpretation with\\nregard to the minimum requirements that must be met\\nby data controllers. As long as these requirements are\\nmet, automated decision-making is lawful and in com-\\npliance with the GDPR. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 26, 'page': 5, '_split_overlap': [{'doc_id': 'dfecd97aec1bc79620e5f23202954c2b', 'range': (0, 119)}, {'doc_id': '7da65dadcf41ad3c69960a3d0519d94', 'range': (890, 1160)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c1ba7e2a773d50abf5af555f091365b8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: There are no ambiguities in the\\nlanguage that would require further interpretation with\\nregard to the minimum requirements that must be met\\nby data controllers. As long as these requirements are\\nmet, automated decision-making is lawful and in com-\\npliance with the GDPR. With this said, future jurispru-\\ndence (see section ‘What if a right to explanation were\\ngranted?’) can still interpret the meaning of ‘suitable\\nmeasures to safeguard’, and establish future mandatory\\nor case-to-case requirements to be met by data control-\\nlers, including a right to explanation. This is, however,\\nonly one possible future. A right to explanation is thus\\nnot currently legally mandated by the requirements set\\nin Article 22(3).\\nIn addition, rights have to be explicitly legally estab-\\nlished prior to their enforcement. This idea stems from\\nthe relationship between legal rights and duties. The\\nscope of a right can be subject to interpretation; a legal\\nbasis for its existence must, however, ﬁrst be beyond\\ndoubt. Rights of data subjects typically correspond with\\na duty on the side of the data controller.20 Negligence in\\nrelation to legal duties can be punished through ﬁnes\\nand other procedures. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 27, 'page': 5, '_split_overlap': [{'doc_id': 'c1ba7e2a773d50abf5af555f091365b8', 'range': (0, 270)}, {'doc_id': '464629264a73c36255add6bd612b827b', 'range': (1002, 1186)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7da65dadcf41ad3c69960a3d0519d94'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Rights of data subjects typically correspond with\\na duty on the side of the data controller.20 Negligence in\\nrelation to legal duties can be punished through ﬁnes\\nand other procedures. It would be highly controversial\\nto impose ﬁnes on data controllers without having pre-\\nviously clariﬁed explicitly and beyond doubt what\\nduties must be met. Doing otherwise would conﬂict\\nwith the principles of fair trial (Article 6 of the\\nEuropean Convention on Human Rights and Article 47\\nof the Charter of Fundamental Rights of the European\\nUnion) and the rule of law.21 Criminal and administra-\\ntive procedures have to be laid down precisely.\\nIt can be concluded that data subjects will not be\\ngranted a legally binding ex post right to explanation of\\nspeciﬁc automated decisions on the basis of legal safe-\\nguards in Article 22 as it currently stands. That this is\\nthe case does not appear to be the result of an oversight\\nor ﬁddling with subtle interpretations (eg the meaning\\nof ‘suitable measures to safeguard’ in Article 22(3)). On\\nthe contrary, the omission of a right to explanation\\n15 ‘Recitals explain the background to the legislation and the aims and\\nobjectives of the legislation. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 28, 'page': 5, '_split_overlap': [{'doc_id': '7da65dadcf41ad3c69960a3d0519d94', 'range': (0, 184)}, {'doc_id': '64a2499b1c3f0cac631a98b894e780df', 'range': (1023, 1181)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '464629264a73c36255add6bd612b827b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: On\\nthe contrary, the omission of a right to explanation\\n15 ‘Recitals explain the background to the legislation and the aims and\\nobjectives of the legislation. They are, therefore, important to an under-\\nstanding of the legislation which follows.’ EUROPA, ‘Guide to the\\nApproximation of EU Environmental Legislation ANNEX I’\\n(Environment, 2015) <http://ec.europa.eu/environment/archives/guide/\\nannex1.htm> accessed 3 March 2017. See also Case C-355/95 P\\nTextilwerke Deggendorf GmbH (TWD) v Commission of the European\\nCommunities and Federal Republic of Germany [1997] ECR I (15 May\\n1997), p. I-02549 para 21: ‘In that regard, it should be stated that the\\noperative part of an act is indissociably linked to the statement of reasons\\nfor it, so that, when it has to be interpreted, account must be taken of the\\nreasons which led to its adoption.’\\n16 For a detailed overview of the jurisprudence of the European Court of\\nJustice on the limited role of Recitals in EU law, see Roberto Baratta,\\n‘Complexity of EU Law in the Domestic Implementing Process’ (2014) 2\\nThe Theory and Practice of Legislation 293. An opposing view is offered\\nby Pagallo, who claims that secondary rules of law (eg Recitals) can alter\\nprimary rules of law. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 29, 'page': 5, '_split_overlap': [{'doc_id': '464629264a73c36255add6bd612b827b', 'range': (0, 158)}, {'doc_id': 'a012711cf9beea1b66dc37a2ffb36811', 'range': (1102, 1226)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '64a2499b1c3f0cac631a98b894e780df'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: An opposing view is offered\\nby Pagallo, who claims that secondary rules of law (eg Recitals) can alter\\nprimary rules of law. Ugo Pagallo, ‘Three Lessons Learned for Intelligent\\nTransport Systems That Abide by the Law’ (2016) Jusletter IT RZ 13,\\nNovember 2016 <http://jusletter-it.weblaw.ch/issues/2016/24-\\nNovember-2016/three-lessons-learne_9251e5d324.html> accessed 14\\nMarch 2017.\\n17 Tadas Klimas and Jurate Vaiciukaite, ‘The Law of Recitals in European\\nCommunity Legislation’ (2008) 15 ILSA Journal of International &\\nComparative Law 32 <https://papers.ssrn.com/sol3/papers.cfm?abstract_\\nid¼1159604> accessed 22 January 2017. The paper discusses in detail the\\nlegal status of Recitals in European law.\\n18 Baratta (n 16) 17.\\n19 Case 215/88 Casa Fleischhandels [1989] ECR-2789, para 31; See also\\nBaratta (n 16) 13.\\n20 Peter Jones, ‘Group Rights’, The Stanford Encyclopedia of Philosophy\\n(Summer 2016 edn (2016, forthcoming)) <http://plato.stanford.edu/\\narchives/sum2016/entries/rights-group/>.\\n21 Christoph Grabenwarter, The European Convention for the Protection of\\nHuman Rights and Fundamental Freedoms: A Commentary (01 edn,\\nVerlag C.H. Beck 2014).\\n80 ARTICLE International Data Privacy Law, 2017, Vol. 7, No. 2\\x0cfrom Article 22 appears to be intentional. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 30, 'page': 5, '_split_overlap': [{'doc_id': '64a2499b1c3f0cac631a98b894e780df', 'range': (0, 124)}, {'doc_id': '764136df54d584436dc68e17c01cf24e', 'range': (1140, 1257)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a012711cf9beea1b66dc37a2ffb36811'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Beck 2014).\\n80 ARTICLE International Data Privacy Law, 2017, Vol. 7, No. 2\\x0cfrom Article 22 appears to be intentional. The safe-\\nguards speciﬁed in Recital 71 are almost identical to\\nthose in Article 22(3), with the signiﬁcant difference of\\nthe further inclusion of a right ‘to obtain an explanation\\nof the decision reached after such assessment’ in Recital\\n71. The purposeful omission of this text from Article 22\\nmay not be an oversight but suggests that legislators did\\nnot intend to implement a right to explanation of spe-\\nciﬁc decisions in the GDPR. What happened?\\nLooking at previous drafts of the GDPR and commen-\\ntary from the trilogue negotiations,22 one can see that\\nlegislators had stricter safeguards in place on automated\\ndecision-making and proﬁling, but that these were even-\\ntually dropped, including a legally binding right to\\nexplanation of speciﬁc decisions.23 An early indication of\\nthe debate around the right to explanation can be seen in\\nthe November 2013 report of the European Parliament\\n(EP)24 and the December 2014 report of the European\\nCouncil in response to the original GDPR text proposed\\nby the European Commission (EC)25 in 2012.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 31, 'page': 5, '_split_overlap': [{'doc_id': 'a012711cf9beea1b66dc37a2ffb36811', 'range': (0, 117)}, {'doc_id': 'bbf364f4a45e48090fc53622ac68dd01', 'range': (570, 1162)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '764136df54d584436dc68e17c01cf24e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Looking at previous drafts of the GDPR and commen-\\ntary from the trilogue negotiations,22 one can see that\\nlegislators had stricter safeguards in place on automated\\ndecision-making and proﬁling, but that these were even-\\ntually dropped, including a legally binding right to\\nexplanation of speciﬁc decisions.23 An early indication of\\nthe debate around the right to explanation can be seen in\\nthe November 2013 report of the European Parliament\\n(EP)24 and the December 2014 report of the European\\nCouncil in response to the original GDPR text proposed\\nby the European Commission (EC)25 in 2012.\\nThe EC’s proposed text did not contain a right to\\nexplanation. The EP proposed the following amend-\\nment to Article 20 (now Article 22 in the adopted ver-\\nsion of the GDPR), paragraph 5:\\nProﬁling which leads to measures producing legal effects\\nconcerning the data subject or does similarly signiﬁcantly\\naffect the interests, rights or freedoms of the concerned\\ndata subject shall not be based solely or predominantly on\\nautomated processing and shall include human assessment,\\nincluding an explanation of the decision reached after such\\nan assessment. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 32, 'page': 6, '_split_overlap': [{'doc_id': '764136df54d584436dc68e17c01cf24e', 'range': (0, 592)}, {'doc_id': '92befb3aabf82053befae713275814d4', 'range': (656, 1144)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bbf364f4a45e48090fc53622ac68dd01'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The EP proposed the following amend-\\nment to Article 20 (now Article 22 in the adopted ver-\\nsion of the GDPR), paragraph 5:\\nProﬁling which leads to measures producing legal effects\\nconcerning the data subject or does similarly signiﬁcantly\\naffect the interests, rights or freedoms of the concerned\\ndata subject shall not be based solely or predominantly on\\nautomated processing and shall include human assessment,\\nincluding an explanation of the decision reached after such\\nan assessment. The suitable measures to safeguard the data\\nsubject’s legitimate interests referred to in paragraph 2 shall\\ninclude the right to obtain human assessment and an explan-\\nation of the decision reached after such assessment . . ..\\n(emphasis added)\\nThe EP’s preferred text mandated a ‘right to obtain\\nhuman assessment and an explanation of the decision\\nreached after such assessment’. These safeguards would\\nhave been part of Article 20, meaning that they would\\nhave been legally binding. However, the proposed safe-\\nguards were not adopted in trilogue. This change suggests\\nthat legislators intentionally chose to make the right to\\nexplanation non-binding by placing it in Recital 71.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 33, 'page': 6, '_split_overlap': [{'doc_id': 'bbf364f4a45e48090fc53622ac68dd01', 'range': (0, 488)}, {'doc_id': '3c93abd860bb5d4767adbbaaf0cb8a9', 'range': (1038, 1169)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '92befb3aabf82053befae713275814d4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: This change suggests\\nthat legislators intentionally chose to make the right to\\nexplanation non-binding by placing it in Recital 71.\\nThe European Council’s 2014 draft,26 on the other\\nhand, only required that:\\nthe data controller shall implement suitable measures to\\nsafeguard the data subject’s rights and freedoms and legiti-\\nmate interests, such as the right to obtain human interven-\\ntion on the part of the controller, to express his or her point of\\nview and to contest the decision. (emphasis added)\\nThe Council suggested to add the text:\\nto express his or her point of view, to get an explanation of\\nthe decision reached after such assessment and the right to\\ncontest the decision, (emphasis added)\\nto Recital 58 (equivalent to Recital 71 GDPR).27 The\\nCouncil thus suggested to place the right to explanation\\nadded in the EP’s draft in a Recital. This approach was\\neventually taken in the ﬁnal text adopted in 2016.\\nInterestingly, despite years of negotiations, the ﬁnal\\nwording of the GDPR concerning protections against\\nproﬁling and automated decision-making hardly\\nchanged from the relevant Articles and Recitals of the\\nData Protection Directive 1995. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 34, 'page': 6, '_split_overlap': [{'doc_id': '92befb3aabf82053befae713275814d4', 'range': (0, 131)}, {'doc_id': '6e2fdf7ae05282a36b8c6654aa963138', 'range': (921, 1159)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3c93abd860bb5d4767adbbaaf0cb8a9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Interestingly, despite years of negotiations, the ﬁnal\\nwording of the GDPR concerning protections against\\nproﬁling and automated decision-making hardly\\nchanged from the relevant Articles and Recitals of the\\nData Protection Directive 1995. As with the GDPR, a\\n‘right to explanation’ does not appear in Article 15 of\\nthe Directive (see Figure 2), which addresses automated\\nindividual decisions.\\nAlthough Article 22 GDPR has not greatly changed\\nfrom Article 15 of the Directive, a few changes are still\\nnoteworthy. First, the only safeguard against automated\\ndecision-making mentioned in the Directive is the\\nopportunity to express one’s views. Article 22(3) addi-\\ntionally names contesting the decision and the right to\\nobtain human intervention as suitable measures.\\nSecondly, explicit consent is included as a case in which\\nautomated decision-making is allowed (Article 22(2)c).\\n22 The ‘trilogue negotiations’ describe a series of meetings between the\\nEuropean Commission, Council, and Parliament to adopt a ﬁnal text for\\nthe GDPR. For an introduction and discussion of the legal basis of tri-\\nlogue, see Oliver Proust, ‘Unravelling the Mysteries of the GDPR\\nTrilogues’ (Privacy, Security and Information Law, 2015) <http://privacy\\nlawblog.ﬁeldﬁsher.com/2015/unravelling-the-mysteries-of-the-gdpr-tri\\nlogues/> accessed 16 December 2016.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 35, 'page': 6, '_split_overlap': [{'doc_id': '3c93abd860bb5d4767adbbaaf0cb8a9', 'range': (0, 238)}, {'doc_id': '330ab6456507d2d82b1d206b05155f92', 'range': (1032, 1336)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6e2fdf7ae05282a36b8c6654aa963138'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: For an introduction and discussion of the legal basis of tri-\\nlogue, see Oliver Proust, ‘Unravelling the Mysteries of the GDPR\\nTrilogues’ (Privacy, Security and Information Law, 2015) <http://privacy\\nlawblog.ﬁeldﬁsher.com/2015/unravelling-the-mysteries-of-the-gdpr-tri\\nlogues/> accessed 16 December 2016.\\n23 Rita Heimes, ‘Top 10 Operational Impacts of the GDPR: Part 5 -\\nProﬁling’ <https://iapp.org/news/a/top-10-operational-impacts-of-the-\\ngdpr-part-5-proﬁling/> accessed 10 November 2016: ‘A hotly contested\\nprovision of the GDPR, the “proﬁling” restrictions ultimately adopted\\nwere narrower than initially proposed.’\\n24 European Parliament Committee on Civil Liberties, Justice and Home\\nAffairs, ‘Report on the Proposal for a Regulation of the European\\nParliament and of the Council on the Protection of Individuals with\\nRegard to the Processing of Personal Data and on the Free Movement of\\nSuch Data (General Data Protection Regulation) - A7-0402/2013’\\n(European Parliament 2013) A7–0402/2013 <http://www.europarl.\\neuropa.eu/sides/getDoc.do?type¼REPORT&reference¼A7-2013-\\n0402&language¼EN> accessed 10 November 2016.\\n25 European Commission, ‘Regulation of the European Parliament and the\\nCouncil on the Protection of Individuals with Regard to the Processing\\nof Personal Data and on the Free Movement of Such Data (General Data\\nProtection Regulation)’ (European Commission 2012) 2012/0011 (COD)\\n<http://ec.europa.eu/justice/data-protection/document/review2012/\\ncom_2012_11_en.pdf> accessed 10 November 2016.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 36, 'page': 6, '_split_overlap': [{'doc_id': '6e2fdf7ae05282a36b8c6654aa963138', 'range': (0, 304)}, {'doc_id': 'd5aa87d41b692e2c5b7914e723e9398c', 'range': (1121, 1511)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '330ab6456507d2d82b1d206b05155f92'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 25 European Commission, ‘Regulation of the European Parliament and the\\nCouncil on the Protection of Individuals with Regard to the Processing\\nof Personal Data and on the Free Movement of Such Data (General Data\\nProtection Regulation)’ (European Commission 2012) 2012/0011 (COD)\\n<http://ec.europa.eu/justice/data-protection/document/review2012/\\ncom_2012_11_en.pdf> accessed 10 November 2016.\\n26 European Digital Rights, ‘Comparison of the Parliament and Council\\nText on the General Data Protection Regulation’ (European Digital\\nRights International 2016) 140 <https://edri.org/ﬁles/EP_Council_\\nComparison.pdf> accessed 20 November 2016. This source provides a\\nside-by-side comparison of the aforementioned drafts from the European\\nParliament (n 24).and European Commission (n 25), as well as amend-\\nments to the Commission’s text proposed by the European Council.\\n27 European Digital Rights, ibid 40.\\nSandra Wachter et al. Á No Right to Explanation of Automated Decision-Making 81\\nARTICLE\\x0cFinally, as opposed to the provisions in Article 15 of the\\nDirective, it is no longer necessary that the data subject\\nrequests the contract in order for automated decision-\\nmaking to be lawful.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 37, 'page': 6, '_split_overlap': [{'doc_id': '330ab6456507d2d82b1d206b05155f92', 'range': (0, 390)}, {'doc_id': '5b96b2e73148390048683adab5215979', 'range': (922, 1181)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd5aa87d41b692e2c5b7914e723e9398c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Á No Right to Explanation of Automated Decision-Making 81\\nARTICLE\\x0cFinally, as opposed to the provisions in Article 15 of the\\nDirective, it is no longer necessary that the data subject\\nrequests the contract in order for automated decision-\\nmaking to be lawful.\\nA right to explanation derived from\\nnotiﬁcation duties\\nArticles 13 and 14 GDPR specify notiﬁcation duties for\\ndata controllers concerning the processing of data col-\\nlected from the data subject (Article 13) or from a third\\nparty (Article 14). In the aforementioned claim, these\\nArticles are cited as a basis for a right to an ex post\\nexplanation of speciﬁc decisions. The claim starts with\\nArticles 13(2) and 14(2), which state that data control-\\nlers need to:\\nprovide the data subject with the following information\\nnecessary to ensure fair and transparent processing.\\nAccording to Articles 13(2)f and 14(2)g, this informa-\\ntion includes:\\nthe existence of automated decision-making, including proﬁl-\\ning, referred to in Article 22(1) and (4) and, at least in those\\ncases, meaningful information about the logic involved, as\\nwell as the signiﬁcance and the envisaged consequences of\\nsuch processing for the data subject. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 38, 'page': 6, '_split_overlap': [{'doc_id': 'd5aa87d41b692e2c5b7914e723e9398c', 'range': (0, 259)}, {'doc_id': 'd012809b77534619bcd63c89bf0218c', 'range': (831, 1181)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5b96b2e73148390048683adab5215979'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: According to Articles 13(2)f and 14(2)g, this informa-\\ntion includes:\\nthe existence of automated decision-making, including proﬁl-\\ning, referred to in Article 22(1) and (4) and, at least in those\\ncases, meaningful information about the logic involved, as\\nwell as the signiﬁcance and the envisaged consequences of\\nsuch processing for the data subject. (emphasis added)\\nThis duty applies in cases of automated processing\\nmeeting the requirements of Article 22(1) or 22(4)\\n(more on this later).\\nIt has been suggested that the notiﬁcation duties in\\nArticles 13–14, in combination with the safeguards\\ndeﬁned in Article 22(3), grant an ex post right to explana-\\ntion of the ‘existence of . . . logic involved . . . signiﬁcance\\n. . . and envisaged consequences’ of automated decision-\\nmaking.28 This claim is mistaken for two reasons.\\nFirst, only an ex ante explanation of system functional-\\nity is explicitly required by Articles 13(2)f and 14(2)g.\\nThese notiﬁcation duties precede decision-making.\\nNotiﬁcation occurs before a decision is made, at the point\\nwhen data is collected for processing. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 39, 'page': 7, '_split_overlap': [{'doc_id': '5b96b2e73148390048683adab5215979', 'range': (0, 350)}, {'doc_id': '58d24e4381511f1d7f2fd7e8bf0e6868', 'range': (828, 1090)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd012809b77534619bcd63c89bf0218c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: First, only an ex ante explanation of system functional-\\nity is explicitly required by Articles 13(2)f and 14(2)g.\\nThese notiﬁcation duties precede decision-making.\\nNotiﬁcation occurs before a decision is made, at the point\\nwhen data is collected for processing. This holds true\\neven if Article 14 introduces some ambiguities when data\\nare collected from third parties rather than data subjects\\n(insofar as the controller needs only to notify the data\\nsubject within 30 days of collection). As explained in\\nsection ‘What is meant by a right to explanation?’, only\\nan explanation of system functionality is logically possi-\\nble prior to decision-making. Therefore, Articles 13–14\\ncannot be used as evidence of an ex post right to explana-\\ntion of speciﬁc decisions that can logically only be given\\nonce a decision has been made (timeline problem).29\\nSecondly, the claim links Articles 13(2)f and 14(2)g\\nto the safeguards in Article 22(3). This link is not made\\nin the GDPR. Articles 13(2)f and 14(2)g apply only to\\nArticles 22(1) and 22(4), which do not address safe-\\nguards against automated decision-making. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 40, 'page': 7, '_split_overlap': [{'doc_id': 'd012809b77534619bcd63c89bf0218c', 'range': (0, 262)}, {'doc_id': '643fcb5e8dc2887060b4d33b68d02dee', 'range': (973, 1108)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '58d24e4381511f1d7f2fd7e8bf0e6868'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Articles 13(2)f and 14(2)g apply only to\\nArticles 22(1) and 22(4), which do not address safe-\\nguards against automated decision-making. The sup-\\nposed link—between notiﬁcation about the logic\\ninvolved, signiﬁcance, and envisaged consequences of\\nautomated decision-making in Articles 13–14, and the\\nex post right to explanation incorrectly attributed to\\nArticle 22(3) (which only features in Recital 71)—is\\ntherefore untenable and can be dismissed. The claim\\nalso conﬂates the legally binding notiﬁcation duties,\\nspeciﬁed in Articles 13–14, and the non-binding right,\\nspeciﬁed in Recital 71.\\nIt follows that the claim for an ex post right to\\nexplanation of speciﬁc decisions30 is not correct. Any\\nsuggestion to the contrary fails to distinguish between\\n(i) the legally binding duty to notify the data subject of\\nthe logic involved, signiﬁcance, and envisaged conse-\\nquences of automated decision-making system before\\ndecision-making occurs (timeline problem) (Articles\\n13–14), and (ii) the data subject’s non-binding right to\\nan explanation of speciﬁc decisions (Recital 71) after\\ndecision-making occurs.\\nFigure 2. Article 15 of the 1995 Directive.\\n28 Goodman and Flaxman (n 1).\\n29 See also Suzanne Rodway, ‘Just How Fair Will Processing Notices Need\\nto be under the GDPR’ (2016) 16 Privacy & Data Protection 16. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 41, 'page': 7, '_split_overlap': [{'doc_id': '58d24e4381511f1d7f2fd7e8bf0e6868', 'range': (0, 135)}, {'doc_id': 'e28ebc97db9668191aeba0cc6623592e', 'range': (1178, 1311)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '643fcb5e8dc2887060b4d33b68d02dee'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 29 See also Suzanne Rodway, ‘Just How Fair Will Processing Notices Need\\nto be under the GDPR’ (2016) 16 Privacy & Data Protection 16. Note the\\npaper focused on the EC draft but talks in general about the aim and\\npurpose of notiﬁcation duties. The author explains that these provisions\\nmainly mean that data controllers have to update their privacy notices.\\nFurther: ‘whether any automated decisions will be made using the data\\n(including for proﬁling purposes) and, if so, a meaningful explanation\\nabout the logic used in those decisions and the possible consequences of\\nthose decisions for the data subject. Examples include whether a credit\\ncard application might be declined or a job application rejected’. This\\nsuggests that Articles 13–14 only create a notiﬁcation duty to inform\\nabout the general usage of automated decision-making before a decision\\nhas been made, and to inform about the possible future consequences.\\nFurther support for this argument can be found in Recitals 60–62 GDPR.\\n30 Goodman and Flaxman (n 1).\\n82 ARTICLE International Data Privacy Law, 2017, Vol. 7, No. 2\\x0cThe language used in Articles 13(2)f and 14(2)g also\\nsupports the interpretation that only an ex ante explana-\\ntion is required. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 42, 'page': 7, '_split_overlap': [{'doc_id': '643fcb5e8dc2887060b4d33b68d02dee', 'range': (0, 133)}, {'doc_id': '236d6612975cf2ec688aec31fc28ecdb', 'range': (1087, 1217)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e28ebc97db9668191aeba0cc6623592e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 2\\x0cThe language used in Articles 13(2)f and 14(2)g also\\nsupports the interpretation that only an ex ante explana-\\ntion is required. Data controllers must inform the data\\nsubject about the\\nexistence of automated decision-making, including proﬁl-\\ning . . . [and provide data subjects with] meaningful infor-\\nmation about the logic involved, as well as the signiﬁcance\\nand the envisaged consequences of such processing.\\nThe language used suggests that data subjects must be\\nprovided with information about how an automated\\ndecision-making system works in general, for which\\npurposes, and with what predicted impact, before auto-\\nmated decisions are made. Notably this cannot include\\nany information about how a speciﬁc decision was\\nmade or reached, but rather addresses how the system\\nitself functions, eg its decision tree or rules, or predic-\\ntions about how inputs will be processed. For fully dis-\\nclosed simplistic or linear models, this may show how\\nspeciﬁc decisions would be reached in the future.31\\nA right to explanation derived from the right\\nof access\\nIn contrast to prior claims (see ’Introduction’ section), it\\nmay also be possible to derive a right to explanation from\\nthe right of access established in Article 15 GDPR. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 43, 'page': 7, '_split_overlap': [{'doc_id': 'e28ebc97db9668191aeba0cc6623592e', 'range': (0, 130)}, {'doc_id': '96feda6d4ae66d59d2b76f31e9fcd530', 'range': (883, 1231)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '236d6612975cf2ec688aec31fc28ecdb'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: For fully dis-\\nclosed simplistic or linear models, this may show how\\nspeciﬁc decisions would be reached in the future.31\\nA right to explanation derived from the right\\nof access\\nIn contrast to prior claims (see ’Introduction’ section), it\\nmay also be possible to derive a right to explanation from\\nthe right of access established in Article 15 GDPR. Article\\n15(1)h is identical to Articles 13(2)f and 14(2)h: data sub-\\njects are granted a right to be informed about the exis-\\ntence of automated decision-making and to obtain\\nmeaningful information about the signiﬁcance, envisaged\\nconsequences, and logic involved. Speciﬁcally, the subject\\nshould be informed about the existence, purposes, and\\nlogic of data processing, and the intentions and legal con-\\nsequences of such processing. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 44, 'page': 8, '_split_overlap': [{'doc_id': '236d6612975cf2ec688aec31fc28ecdb', 'range': (0, 348)}, {'doc_id': '2e0e6c607248f8a326e33c8f76ee3b49', 'range': (614, 782)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '96feda6d4ae66d59d2b76f31e9fcd530'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Speciﬁcally, the subject\\nshould be informed about the existence, purposes, and\\nlogic of data processing, and the intentions and legal con-\\nsequences of such processing. By having this information,\\nthe data subject should be able to examine the lawfulness\\nof data processing and invoke legal remedies.32\\nTogether, Articles 13–15 form what has been called\\nthe ‘Magna Carta’ of data subject’s rights to obtain\\ninformation about the data held about them, and to\\nscrutinize the legitimacy of data processing.33 Articles\\n13–14 create notiﬁcation duties for data controllers,\\nwhile Article 15 establishes a corresponding right of\\naccess for data subjects.34 In contrast to the notiﬁcation\\nduties of data controllers in Articles 13–14, the right of\\naccess has to be invoked by the data subject. The articles\\nare a unit, insofar as they provide the data subject access\\nto identical information, and use the same language.\\nAlthough seemingly insigniﬁcant, the change from a\\nnotiﬁcation duty to an access right has important conse-\\nquences for the timing of explanations required from\\nthe data controller. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 45, 'page': 8, '_split_overlap': [{'doc_id': '96feda6d4ae66d59d2b76f31e9fcd530', 'range': (0, 168)}, {'doc_id': 'd701d98f44e6644fa80dc80312c6ad99', 'range': (913, 1094)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2e0e6c607248f8a326e33c8f76ee3b49'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Although seemingly insigniﬁcant, the change from a\\nnotiﬁcation duty to an access right has important conse-\\nquences for the timing of explanations required from\\nthe data controller. Given that the phrasing of Article\\n15(1)h is identical to Articles 13(2)f and 14 (2)g, one\\ncould assume that the right of access similarly only\\ngrants access to an ex ante explanation of system func-\\ntionality. However, the right of access is dependent\\nupon the request of the data subject and has no dead-\\nline; the ‘timeline problem’ of Articles 13(2)f and\\n14(2)g does not apply. At ﬁrst glance, the data subject\\ncan request this information at any time, including after\\nan automated decision has been made, making an ex\\npost explanation of the rationale of speciﬁc decisions\\nplausible.\\nNonetheless, it is reasonable to doubt that the right\\nof access grants a right to ex post explanations of speciﬁc\\ndecisions already reached. Consider the semantics of\\nArticle 15(1)h. The phrase ‘envisaged consequences’ is\\nfuture oriented, suggesting that the data controller must\\ninform the data subject of possible consequences of the\\nautomated decision-making before such processing\\noccurs. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 46, 'page': 8, '_split_overlap': [{'doc_id': '2e0e6c607248f8a326e33c8f76ee3b49', 'range': (0, 181)}, {'doc_id': 'bbc1f84bbb28d75fe6a6774ed6c54343', 'range': (912, 1163)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd701d98f44e6644fa80dc80312c6ad99'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Consider the semantics of\\nArticle 15(1)h. The phrase ‘envisaged consequences’ is\\nfuture oriented, suggesting that the data controller must\\ninform the data subject of possible consequences of the\\nautomated decision-making before such processing\\noccurs. This interpretation follows the timeline con-\\nstraints of identical provisions in Articles 13(2)f and\\n14(2)g discussed above, which only allow for ex ante\\nexplanations. Data controllers are required to predict\\nthe possible consequences of their automated decision-\\nmaking methods. The term ‘envisaged’ limits these pre-\\ndictions to ex ante explanations of system functionality,\\nfor instance, concerning the general purpose of the sys-\\ntem, or the type of impact to be expected from the type\\nof decision it makes. For instance, a credit agency could\\npredict that the scores they produce will impact on\\ncredit worthiness (eg interest rates). If applied to deci-\\nsions already made, the phrasing becomes incoherent.35\\n31 Burrell (n 12).\\n32 Boris P. Paal, ‘DS-GVO Art. 15 Auskunftsrecht der betroffenen Person’\\nin Boris P. Paal and Daniel Pauly (eds), Datenschutz-Grundverordnung\\n(1st edn, beck-online 2017) Rn 3. Recital 63 GDPR also supports this\\ninterpretation in stating that ‘A data subject should have the right of\\naccess to personal data . . . ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 47, 'page': 8, '_split_overlap': [{'doc_id': 'd701d98f44e6644fa80dc80312c6ad99', 'range': (0, 251)}, {'doc_id': '5fcfd2ec64d72628f2d17123ffd59a87', 'range': (1162, 1298)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bbc1f84bbb28d75fe6a6774ed6c54343'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Recital 63 GDPR also supports this\\ninterpretation in stating that ‘A data subject should have the right of\\naccess to personal data . . . and to exercise that right . . . in order to be\\naware of, and verify, the lawfulness of processing’ (emphasis added).\\n33 Florian Schmidt-Wudy, ‘DS-GVO Art. 15 Auskunftsrecht der betroffenen\\nPerson’ in Heinrich A. Wolff and Stefan Brink (eds), Datenschutz-\\nGrundverordnung (18th edn, beck-online 2016) Rn 2.\\n34 Mario Martini, ‘DS-GVO Art. 22 Automatisierte Entscheidungen im\\nEinzelfall einschließlich Proﬁling’ in Boris P. Paal and Daniel Pauly (n\\n32) Rn 4–6.\\n35 Peter Br€\\nautigam and Florian Schmidt-Wudy, ‘Das geplante Auskunfts-\\nund Herausgaberecht des Betroffenen nach Art. 15 Der EU-\\nDatenschutzgrundverordnung’ (2015) 31 Computer und Recht 56, 62\\nsupports this interpretation in commenting on the EP’s draft of the\\nGDPR. The EP’s draft contains the same phrasing as the ﬁnal adopted\\ntext: Art 15(h) requires information about ‘the signiﬁcance and envisaged\\nconsequences of such processing’. The authors note that the phrasing is\\nvery imprecise. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 48, 'page': 8, '_split_overlap': [{'doc_id': 'bbc1f84bbb28d75fe6a6774ed6c54343', 'range': (0, 136)}, {'doc_id': 'af4f6eb9a00ef9da821cb10a967c69a', 'range': (863, 1086)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5fcfd2ec64d72628f2d17123ffd59a87'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The EP’s draft contains the same phrasing as the ﬁnal adopted\\ntext: Art 15(h) requires information about ‘the signiﬁcance and envisaged\\nconsequences of such processing’. The authors note that the phrasing is\\nvery imprecise. An example is given of an Internet provider being obli-\\ngated to inform that automated processing methods are being used to\\ndetermine creditworthiness, which could lead to the consequence that\\nthe person has to pay in advance (rather than being offered credit). This\\nexample suggests that the authors believe that art 15(h) aims to inform\\nabout system functionality rather than to provide information about\\nhow an individual decision was reached.\\nSandra Wachter et al. Á No Right to Explanation of Automated Decision-Making 83\\nARTICLE\\x0cIt would seem to require data controllers to predict the\\npersonal consequences of decision-making for individ-\\nual data subjects after an automated decision has been\\nmade, including how the decision could be used by\\nother data controllers and processors.\\nThe semantics of the German translation of Article\\n15(1)h GDPR provides further support. The German\\nArticle 15(1)h states:\\nTragweite und angestrebten Auswirkungen einer derartigen\\nVerarbeitung fu\\n¨r die betroffene Person. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 49, 'page': 8, '_split_overlap': [{'doc_id': '5fcfd2ec64d72628f2d17123ffd59a87', 'range': (0, 223)}, {'doc_id': 'a65fcfe5e55cd407e73b06ddec5dc7fb', 'range': (1014, 1235)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'af4f6eb9a00ef9da821cb10a967c69a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The semantics of the German translation of Article\\n15(1)h GDPR provides further support. The German\\nArticle 15(1)h states:\\nTragweite und angestrebten Auswirkungen einer derartigen\\nVerarbeitung fu\\n¨r die betroffene Person. (emphasis added)\\nThis sentence translates to ‘the scope and intended con-\\nsequences of such processing for the person concerned’\\n(authors’ translation, emphasis added). This indicates\\nthat the data controller must inform the data subject\\nabout the consequences the controller wishes to achieve\\nwith automated decision-making. According to this\\nphrasing, the data controller is not asked to predict con-\\nsequences but rather explain the scope, intention, and\\nthe purpose of such processing. This suggests that the\\nright of access is not addressing how an individual deci-\\nsion was reached, but rather the duty of the data con-\\ntroller to provide information about the existence, aims\\nand consequences of such processing. This equates to an\\nexplanation of system functionality.36\\nThere are similar reasons to doubt that Article\\n15(1)h grants an ex post right to explanation of speciﬁc\\ndecisions. Data controllers are required to provide infor-\\nmation about the ‘existence of automated decision-\\nmaking’ (emphasis added). This phrase does not suggest\\nan explanation of how a decision was reached. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 50, 'page': 9, '_split_overlap': [{'doc_id': 'af4f6eb9a00ef9da821cb10a967c69a', 'range': (0, 221)}, {'doc_id': '4577e803ee8322301a8679013ea9099f', 'range': (1116, 1315)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a65fcfe5e55cd407e73b06ddec5dc7fb'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Data controllers are required to provide infor-\\nmation about the ‘existence of automated decision-\\nmaking’ (emphasis added). This phrase does not suggest\\nan explanation of how a decision was reached. Rather,\\nthe data controller is only required to inform the data\\nsubject that automated decision-making methods are\\nbeing used to process her data.\\nThe phrasing of Article 15(1)h, as with Articles 13–\\n14, points to an explanation of system functionality.\\nHowever, data controllers are also required to provide\\n‘meaningful information about the logic involved’ in\\nautomated decision-making. As noted in section ‘A\\nright to explanation derived from notiﬁcation duties’,\\nthis phrase, as used in Articles 13–14, has been argued\\nby others to grant an ex post right to explanation. If cor-\\nrect, Article 15(1)h would grant a right to explanation\\nof speciﬁc decisions, not only system functionality, as the\\ndata subject can request the relevant information both\\nbefore and after a decision has been made. However,\\nthere are further reasons to doubt that this is the case.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 51, 'page': 9, '_split_overlap': [{'doc_id': 'a65fcfe5e55cd407e73b06ddec5dc7fb', 'range': (0, 199)}, {'doc_id': 'd8a3e25cbdd5e677177d1c741dae79d', 'range': (775, 1063)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4577e803ee8322301a8679013ea9099f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: If cor-\\nrect, Article 15(1)h would grant a right to explanation\\nof speciﬁc decisions, not only system functionality, as the\\ndata subject can request the relevant information both\\nbefore and after a decision has been made. However,\\nthere are further reasons to doubt that this is the case.\\nFor Article 15(1)h to be coherent as a whole, ‘mean-\\ningful information about the logic involved’ must be\\ninterpreted in connection with the other terms (exis-\\ntence of, meaningful information about signiﬁcance and\\nenvisaged consequences) used of Article 15(1)h, which\\nare limited to explanations of system functionality.\\nInterpreting ‘logic involved’ to grant an ex post explana-\\ntion of speciﬁc decisions would mean the other terms of\\nArticle 15(1)h would be incoherent, if the right of access\\nwas invoked after a decision was made. This interpreta-\\ntion is further supported by a comparison of the lan-\\nguage used in Article 15(1)h and Recital 71. Data\\ncontrollers are obligated to provide information about\\nthe\\nexistence of automated decision-making . . . meaningful\\ninformation about the logic involved, as well as the signiﬁ-\\ncance and envisaged consequences of such processing\\n(Article 15(1)h), [as opposed to] an explanation of the\\ndecision reached (Recital 71).\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 52, 'page': 9, '_split_overlap': [{'doc_id': '4577e803ee8322301a8679013ea9099f', 'range': (0, 288)}, {'doc_id': 'ff0d7f7d3bb8b8efc35eb1fb3116a193', 'range': (1049, 1259)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd8a3e25cbdd5e677177d1c741dae79d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: meaningful\\ninformation about the logic involved, as well as the signiﬁ-\\ncance and envisaged consequences of such processing\\n(Article 15(1)h), [as opposed to] an explanation of the\\ndecision reached (Recital 71).\\nThe phrasing of Article 15(1)h is future oriented, and\\nappears to refer to the existence and planned scope of\\ndecision-making itself, rather than to the circumstances\\nof a speciﬁc decision as suggested in Recital 71. If an\\nexplanation of speciﬁc automated decisions was\\nintended to be granted by Article 15(1)h, as in Recital\\n71, the usage of different language between the two\\nwould be odd.\\nNevertheless, given the lack of an explicit deadline\\nfor invoking the right of access, one cannot be cer-\\ntain, on the basis of semantics alone, that the right\\nof access is limited to explanations of system func-\\ntionality. Despite this, we argue that, as with notiﬁ-\\ncation duties in Articles 13–14, and regardless of\\nwhen it is invoked by the data subject, the GDPR’s\\nright of access only grants an explanation of auto-\\nmated decision-making addressing system functional-\\nity, not the rationale and circumstances of speciﬁc\\ndecisions. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 53, 'page': 9, '_split_overlap': [{'doc_id': 'd8a3e25cbdd5e677177d1c741dae79d', 'range': (0, 210)}, {'doc_id': 'f8b4dd52d553eacde46bcc41cf6a7f08', 'range': (827, 1139)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ff0d7f7d3bb8b8efc35eb1fb3116a193'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Despite this, we argue that, as with notiﬁ-\\ncation duties in Articles 13–14, and regardless of\\nwhen it is invoked by the data subject, the GDPR’s\\nright of access only grants an explanation of auto-\\nmated decision-making addressing system functional-\\nity, not the rationale and circumstances of speciﬁc\\ndecisions. This conclusion is supported by implemen-\\ntation of the 1995 Directive’s right of access by\\nMember States, which has mostly limited informa-\\ntional obligations to system functionality. If interpre-\\ntation of the GDPR follows historical precedence, its\\nright of access will be similarly limited. To articulate\\nthis claim further, it is necessary to examine in\\ndetail Member State implementations and interpreta-\\ntions of the Directive’s right of access.\\n36 Prior drafts of art 15 also support this view. The German translation of\\nthe EC draft stated in art 15(h) ‘die Tragweite der Verarbeitung und die\\nmit ihr angestrebten Auswirkungen, zumindest im Fall der Maßnahmen\\ngem€\\naß Artikel 20’, which translates to ‘the scope [rather than signiﬁ-\\ncance] of the data processing and its intended consequences’. In addition,\\nthe EP draft stated in art 15(h) ,die Tragweite der Verarbeitung und die\\nmit ihr angestrebten Wirkungen’. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 54, 'page': 9, '_split_overlap': [{'doc_id': 'ff0d7f7d3bb8b8efc35eb1fb3116a193', 'range': (0, 312)}, {'doc_id': '4a118202339046c384de29012c8e0492', 'range': (816, 1235)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f8b4dd52d553eacde46bcc41cf6a7f08'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The German translation of\\nthe EC draft stated in art 15(h) ‘die Tragweite der Verarbeitung und die\\nmit ihr angestrebten Auswirkungen, zumindest im Fall der Maßnahmen\\ngem€\\naß Artikel 20’, which translates to ‘the scope [rather than signiﬁ-\\ncance] of the data processing and its intended consequences’. In addition,\\nthe EP draft stated in art 15(h) ,die Tragweite der Verarbeitung und die\\nmit ihr angestrebten Wirkungen’. The phrase ‘angestrebten Wirkungen’\\ntranslates to ‘the scope and its intended effects’, not consequences. Even\\nthough the adopted language in the GDPR is vaguer, prior drafts demon-\\nstrate art 15 was intended to inform data subjects about data processor’s\\n‘intended effects’ for the data subject by using automated decision-\\nmaking methods. For further discussion, see: ibid 61ff.\\n84 ARTICLE International Data Privacy Law, 2017, Vol. 7, No. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 55, 'page': 9, '_split_overlap': [{'doc_id': 'f8b4dd52d553eacde46bcc41cf6a7f08', 'range': (0, 419)}, {'doc_id': '64ff21b20d04e4ed15890f72277cba67', 'range': (526, 861)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4a118202339046c384de29012c8e0492'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Even\\nthough the adopted language in the GDPR is vaguer, prior drafts demon-\\nstrate art 15 was intended to inform data subjects about data processor’s\\n‘intended effects’ for the data subject by using automated decision-\\nmaking methods. For further discussion, see: ibid 61ff.\\n84 ARTICLE International Data Privacy Law, 2017, Vol. 7, No. 2\\x0cRight of access in the 1995 Data Protection Directive\\n95/46/EC\\nIt is important to note that a right of access that grants\\ndata subjects some explanation of automated decision-\\nmaking is not new, and has not proven an effective\\ntransparency mechanism.37 Rather, this right has existed\\nsince the 1995 Data Protection Directive, and has been\\nimplemented in national law by most European\\nMember States.38 Similar to the scope of the GDPR’s\\nright of access, the Directive’s right of access provides\\nmeans for data subjects to discover whether a controller\\nis processing personal data. If so, the data subject is\\nthen entitled to know the extent of data being proc-\\nessed. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 56, 'page': 9, '_split_overlap': [{'doc_id': '4a118202339046c384de29012c8e0492', 'range': (0, 335)}, {'doc_id': '7737843467038493570d37a4bb7ee800', 'range': (336, 1004)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '64ff21b20d04e4ed15890f72277cba67'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 2\\x0cRight of access in the 1995 Data Protection Directive\\n95/46/EC\\nIt is important to note that a right of access that grants\\ndata subjects some explanation of automated decision-\\nmaking is not new, and has not proven an effective\\ntransparency mechanism.37 Rather, this right has existed\\nsince the 1995 Data Protection Directive, and has been\\nimplemented in national law by most European\\nMember States.38 Similar to the scope of the GDPR’s\\nright of access, the Directive’s right of access provides\\nmeans for data subjects to discover whether a controller\\nis processing personal data. If so, the data subject is\\nthen entitled to know the extent of data being proc-\\nessed. This shall enable the data subject to scrutinize\\nwhat data are used and take appropriate action such as\\nrequesting rectiﬁcation or erasure.39 Notably, the\\nDirective’s right of access has generally not been inter-\\npreted as granting a right to explanation of speciﬁc deci-\\nsions already reached, as it is not part of the safeguards\\nat the time automated decisions are made in Article\\n15(2)a of the Directive; this distinction is comparable to\\nthe difference between Articles 15 and 22 of the GDPR.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 57, 'page': 9, '_split_overlap': [{'doc_id': '64ff21b20d04e4ed15890f72277cba67', 'range': (0, 668)}, {'doc_id': '3381b94e0477a4f14571bb59e99debdf', 'range': (669, 1165)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7737843467038493570d37a4bb7ee800'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: This shall enable the data subject to scrutinize\\nwhat data are used and take appropriate action such as\\nrequesting rectiﬁcation or erasure.39 Notably, the\\nDirective’s right of access has generally not been inter-\\npreted as granting a right to explanation of speciﬁc deci-\\nsions already reached, as it is not part of the safeguards\\nat the time automated decisions are made in Article\\n15(2)a of the Directive; this distinction is comparable to\\nthe difference between Articles 15 and 22 of the GDPR.\\nThe Directive names only one safeguard against auto-\\nmated decision-making, namely the right for the data\\nsubject to ‘put his point of view’. A right to explanation\\nof speciﬁc decisions as a safeguard to ensure lawful\\nautomated decision-making was not envisaged.\\nThe implementation and interpretation of the\\nDirective’s right of access varied across the Member\\nStates. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 58, 'page': 10, '_split_overlap': [{'doc_id': '7737843467038493570d37a4bb7ee800', 'range': (0, 496)}, {'doc_id': '9aad3ccc2ccc26b6919fc10d2bfb1501', 'range': (639, 865)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3381b94e0477a4f14571bb59e99debdf'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: A right to explanation\\nof speciﬁc decisions as a safeguard to ensure lawful\\nautomated decision-making was not envisaged.\\nThe implementation and interpretation of the\\nDirective’s right of access varied across the Member\\nStates. Despite much debate,40 consensus has not\\nemerged concerning the type of information data con-\\ntrollers must disclose to provide data subjects with\\n‘knowledge of the logic involved in any automatic proc-\\nessing of data’ per Article 12(a).41 A report published in\\n2010 on the implementation of the Directive across\\nMember States suggested that it was left to the Member\\nStates to deﬁne the scope and requirements of the right\\nof access. The report urges clariﬁcation of the require-\\nments and limitations on the right of access concerning\\ninformation about the ‘logic involved’ due to the grow-\\ning importance of automated decisions.42 In part, the\\nlack of consensus over the meaning and requirements of\\n‘logic involved’ owes to the relative lack of jurispru-\\ndence on the right of access. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 59, 'page': 10, '_split_overlap': [{'doc_id': '3381b94e0477a4f14571bb59e99debdf', 'range': (0, 226)}, {'doc_id': 'f2e21c5c005ddf91e69ae1402503799', 'range': (662, 1014)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9aad3ccc2ccc26b6919fc10d2bfb1501'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The report urges clariﬁcation of the require-\\nments and limitations on the right of access concerning\\ninformation about the ‘logic involved’ due to the grow-\\ning importance of automated decisions.42 In part, the\\nlack of consensus over the meaning and requirements of\\n‘logic involved’ owes to the relative lack of jurispru-\\ndence on the right of access. Despite the Directive hav-\\ning been in force for over 20 years, the requirements\\nand limitations of the right of access applied to auto-\\nmated decision-making have not been extensively clari-\\nﬁed or tested in courts across Europe.43\\nThe limited jurisprudence available reveals limita-\\ntions on the Directive’s right of access. Several overrid-\\ning interests and exceptions have been identiﬁed that\\nsigniﬁcantly limit both the scope of applicability and\\ncontent of the explanation. In general, data subjects are\\nentitled to receive some information about the general\\nfunctionality of an automated decision-making system,\\nbut little to no information about the rationale or cir-\\ncumstances of a speciﬁc decision. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 60, 'page': 10, '_split_overlap': [{'doc_id': '9aad3ccc2ccc26b6919fc10d2bfb1501', 'range': (0, 352)}, {'doc_id': '7951629488b934874f2bf0d12613c46a', 'range': (834, 1063)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f2e21c5c005ddf91e69ae1402503799'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: In general, data subjects are\\nentitled to receive some information about the general\\nfunctionality of an automated decision-making system,\\nbut little to no information about the rationale or cir-\\ncumstances of a speciﬁc decision. The 2010 report reﬂects\\nthis, noting that the language used in the Directive\\nreﬂects a very narrow scope of applicability for the right\\nof access due to a number of exceptions and limiting or\\noverriding interests.44 Recital 41 of the Directive clariﬁes\\nthat the right of access can be limited by trade secrets\\nand intellectual property, especially relating to soft-\\nware.45 These interests have proven strong limiting\\n37 C-141/12 and C-372/12 [2014] European Court of Justice\\nECLI:EU:C:2014:2081 <http://curia.europa.eu/juris/document/docu\\nment.jsf?\\ntext¼&docid¼155114&pageIndex¼0&doclang¼EN&mode¼lst&dir¼&o\\ncc¼ﬁrst&part¼1&cid¼420117> accessed 12 January 2017.\\n38 Douwe Korff, ‘New Challenges to Data Protection Study - Working\\nPaper No. 2: Data Protection Laws in the EU: The Difﬁculties in Meeting\\nthe Challenges Posed by Global Social and Technical Developments’\\n(European Commission DG Justice, Freedom and Security 2010)\\n<http://papers.ssrn.com/sol3/papers.cfm?abstract_id¼1638949>\\naccessed 8 December 2016.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 61, 'page': 10, '_split_overlap': [{'doc_id': 'f2e21c5c005ddf91e69ae1402503799', 'range': (0, 229)}, {'doc_id': 'd4f24d9154a18124883f983dc3d4ff6a', 'range': (968, 1242)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7951629488b934874f2bf0d12613c46a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 2: Data Protection Laws in the EU: The Difﬁculties in Meeting\\nthe Challenges Posed by Global Social and Technical Developments’\\n(European Commission DG Justice, Freedom and Security 2010)\\n<http://papers.ssrn.com/sol3/papers.cfm?abstract_id¼1638949>\\naccessed 8 December 2016.\\n39 See Recital 41 of the Directive ‘Whereas any person must be able to exer-\\ncise the\\nright of access to data relating to him which are being processed, in\\norder to verify in particular the accuracy of the data and the lawfulness\\nof the processing’ See also Paal (n 32) Rn 19–22, who notes that the\\ngeneral purpose of the right of access according to art 15 GDPR is the\\nrealization of the so called ‘two step model’. In a ﬁrst step data subjects\\nhave to right to (i) know if is data being processed and (ii) if so, what\\ndata is used and in some cases data controllers have to provide addi-\\ntional information (such as the logic involved in automated\\nprocessing).\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 62, 'page': 10, '_split_overlap': [{'doc_id': '7951629488b934874f2bf0d12613c46a', 'range': (0, 274)}, {'doc_id': '4195b939aa848db8c2d1f7c599663859', 'range': (692, 937)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd4f24d9154a18124883f983dc3d4ff6a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: In a ﬁrst step data subjects\\nhave to right to (i) know if is data being processed and (ii) if so, what\\ndata is used and in some cases data controllers have to provide addi-\\ntional information (such as the logic involved in automated\\nprocessing).\\n40 See, for instance, debate in the UK House of Lords concerning the mean-\\ning of ‘logic involved’ and ‘trade secrets’ in the 1998 Data Protection Act:\\nGrand Committee on the Data Protection Bill, ‘Ofﬁcial Report of the\\nGrand Committee on the Data Protection Bill [HL] (Hansard, 23\\nFebruary 1998)’ (UK Parliament - House of Lords 1998) <http://han\\nsard.millbanksystems.com/grand_committee_report/1998/feb/23/ofﬁcial-\\nreport-of-the-grand-committee#S5LV0586P0_19980223_GCR_1>\\naccessed 15 December 2016. See also Philip Coppel, Information Rights:\\nLaw and Practice (Bloomsbury Publishing 2014) ch 5, s 3, which discusses\\nhow trade secrets limit the right of access and to know about the logic\\ninvolved in automated processing, and provides an overview of the right\\nof access as implemented by Member States.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 63, 'page': 10, '_split_overlap': [{'doc_id': 'd4f24d9154a18124883f983dc3d4ff6a', 'range': (0, 245)}, {'doc_id': '15c60bdf4f973475b0dc317b0bbabfe9', 'range': (747, 1050)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4195b939aa848db8c2d1f7c599663859'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: See also Philip Coppel, Information Rights:\\nLaw and Practice (Bloomsbury Publishing 2014) ch 5, s 3, which discusses\\nhow trade secrets limit the right of access and to know about the logic\\ninvolved in automated processing, and provides an overview of the right\\nof access as implemented by Member States.\\n41 As an example, Council of Europe, ‘The Protection of Individuals with\\nRegard to Automatic Processing of Personal Data in the Context of\\nProﬁling’ (Council of Europe 2010) Recommendation CM/Rec(2010)13,\\n138 argues that the right of access in art 12 of the Directive equates to a\\nright to be informed, not a right to an explanation of a decision reached:\\n‘Principle 5.1 states that the data subject should be entitled to know\\nabout the personal data concerning him or her and the logic which\\nserved as a basis for the proﬁling. It is indeed essential that a data subject\\nexercising the right of access should be informed of the statistical method\\nand inferences used for his or her proﬁling, the logic underpinning the proc-\\nessing and the envisaged consequences of the proﬁle’s attribution’ (emphasis\\nadded).\\n42 Korff (n 38) 86.\\n43 Ibid 85.\\n44 Ibid 86.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 64, 'page': 10, '_split_overlap': [{'doc_id': '4195b939aa848db8c2d1f7c599663859', 'range': (0, 303)}, {'doc_id': '23ff627b2240087cbd148c418ca4a7e1', 'range': (833, 1158)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '15c60bdf4f973475b0dc317b0bbabfe9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: It is indeed essential that a data subject\\nexercising the right of access should be informed of the statistical method\\nand inferences used for his or her proﬁling, the logic underpinning the proc-\\nessing and the envisaged consequences of the proﬁle’s attribution’ (emphasis\\nadded).\\n42 Korff (n 38) 86.\\n43 Ibid 85.\\n44 Ibid 86.\\n45 Note that Recital 41 of the Directive also states in relation to trade secrets\\nthat ‘these considerations must not, however, result in the data subject\\nSandra Wachter et al. Á No Right to Explanation of Automated Decision-Making 85\\nARTICLE\\x0cfactors on the right of access as implemented and tested\\nby Member States.\\nSeveral examples can be offered. French data protec-\\ntion law46 grants data subjects a right to receive infor-\\nmation about the ‘logic involved’ as long as it does not\\ncontravene copyright regulations. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 65, 'page': 10, '_split_overlap': [{'doc_id': '15c60bdf4f973475b0dc317b0bbabfe9', 'range': (0, 325)}, {'doc_id': '4e49de456576dde0ac589bbeed8ff2a', 'range': (677, 845)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '23ff627b2240087cbd148c418ca4a7e1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: French data protec-\\ntion law46 grants data subjects a right to receive infor-\\nmation about the ‘logic involved’ as long as it does not\\ncontravene copyright regulations. To allow data subjects\\nto challenge decisions, information must be provided\\nabout the general logic and types of data taken into\\naccount, ‘but not (or at least not fully) of the weight\\nthat is attached’ to speciﬁc features.47 The full code of\\nthe automated decision-making system or algorithm\\ndoes not need to be revealed.48 A similar approach is\\ntaken in the UK’s Data Protection Act 1998, which also\\nlimits the right of access to protect trade secrets.49 As\\nwith French law, data controllers\\nmust inform data subjects of the factors which they take\\ninto account in the \"evaluation\" underlying the decision,\\nbut without having to reveal the exact weight given to each\\nof these factors (i.e. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 66, 'page': 11, '_split_overlap': [{'doc_id': '23ff627b2240087cbd148c418ca4a7e1', 'range': (0, 168)}, {'doc_id': '37eec0a8d0d2ffd537db76dea6c196f7', 'range': (169, 860)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4e49de456576dde0ac589bbeed8ff2a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: To allow data subjects\\nto challenge decisions, information must be provided\\nabout the general logic and types of data taken into\\naccount, ‘but not (or at least not fully) of the weight\\nthat is attached’ to speciﬁc features.47 The full code of\\nthe automated decision-making system or algorithm\\ndoes not need to be revealed.48 A similar approach is\\ntaken in the UK’s Data Protection Act 1998, which also\\nlimits the right of access to protect trade secrets.49 As\\nwith French law, data controllers\\nmust inform data subjects of the factors which they take\\ninto account in the \"evaluation\" underlying the decision,\\nbut without having to reveal the exact weight given to each\\nof these factors (i.e. the copyright-protected algorithm used\\nin the automated decision-taking process).50\\nGerman data protection law has similarly recognized a\\ndistinction between explanations of system functionality\\nand speciﬁc automated decisions in section 6(a) of the\\nBundesdatenschutzgesetz, which jointly implements\\nArticles 12 (right of access) and 15 (safeguards for auto-\\nmated individual decisions) of the Directive.51 Notably,\\nGermany implemented a right allowing data subject’s to\\nrequest an explanation of automated decisions that are\\nnot made in their favour. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 67, 'page': 11, '_split_overlap': [{'doc_id': '4e49de456576dde0ac589bbeed8ff2a', 'range': (0, 691)}, {'doc_id': '8923bd00561ed28edfd32eacfcb04e52', 'range': (692, 1243)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '37eec0a8d0d2ffd537db76dea6c196f7'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: the copyright-protected algorithm used\\nin the automated decision-taking process).50\\nGerman data protection law has similarly recognized a\\ndistinction between explanations of system functionality\\nand speciﬁc automated decisions in section 6(a) of the\\nBundesdatenschutzgesetz, which jointly implements\\nArticles 12 (right of access) and 15 (safeguards for auto-\\nmated individual decisions) of the Directive.51 Notably,\\nGermany implemented a right allowing data subject’s to\\nrequest an explanation of automated decisions that are\\nnot made in their favour. The right is implemented as\\nan explicit safeguard against automated decisions in\\nsection 6(a)2(2) of the Bundesdatenschutzgesetz. The\\nright was voluntarily enacted as a safeguard beyond the\\nrequirements set in Article 15 of the Directive, which\\ngrants the right to express views as the only safeguard\\nagainst automated individual decisions. Interestingly,\\nthe right to an explanation as an extra safeguard pro-\\nvides some insight into how the Directive’s requirement\\nto explain the ‘logic involved’ was interpreted by\\nGerman legislators. Section 6(a)3 of the German Data\\nProtection Act separately extends the right of access\\nenshrined in sections 19 and 34, allowing data subjects\\nbeing refused all information’ (emphasis added). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 68, 'page': 11, '_split_overlap': [{'doc_id': '37eec0a8d0d2ffd537db76dea6c196f7', 'range': (0, 551)}, {'doc_id': 'f77cc493c0952f4ddee1ca8453f935d', 'range': (1090, 1281)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8923bd00561ed28edfd32eacfcb04e52'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Section 6(a)3 of the German Data\\nProtection Act separately extends the right of access\\nenshrined in sections 19 and 34, allowing data subjects\\nbeing refused all information’ (emphasis added). See also Lee A Bygrave,\\n‘Automated Proﬁling: Minding the Machine: Article 15 of the EC Data\\nProtection Directive and Automated Proﬁling’ (2001) 17 Computer Law\\n& Security Review 17. The author notes that arts 12 and 15(1) considered\\ntogether suggest that the data controller must understand and document\\nthe logic involved in an automated decision, including the categories of\\ndata considered, and their role in the decision-making process. However,\\nthe extent to which this information must be given to the data subject\\ncan be limited by overriding interests of the controller, including trade\\nsecrets.\\n46 Korff (n 38) 86.\\n47 Douwe Korff, ‘New Challenges to Data Protection Study - Country\\nReport: France’ (European Commission DG Justice, Freedom and\\nSecurity 2010) 27 <https://papers.ssrn.com/abstract¼1638955> accessed\\n15 December 2016.\\n48 Ibid.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 69, 'page': 11, '_split_overlap': [{'doc_id': '8923bd00561ed28edfd32eacfcb04e52', 'range': (0, 191)}, {'doc_id': '8d234f5c63c425b6e9aa1c083d31c2fa', 'range': (816, 1040)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f77cc493c0952f4ddee1ca8453f935d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 47 Douwe Korff, ‘New Challenges to Data Protection Study - Country\\nReport: France’ (European Commission DG Justice, Freedom and\\nSecurity 2010) 27 <https://papers.ssrn.com/abstract¼1638955> accessed\\n15 December 2016.\\n48 Ibid.\\n49 Art 8(5) of the UK Data Protection Act 1998 states that ‘Section 7(1)(d)\\nis not to be regarded as requiring the provision of information as to the\\nlogic involved in any decision-taking if, and to the extent that, the infor-\\nmation constitutes a trade secre’ (emphasis added).\\n50 Douwe Korff, ‘New Challenges to Data Protection Study - Country\\nReport: United Kingdom’ (European Commission DG Justice, Freedom\\nand Security 2010) 48 <http://papers.ssrn.com/sol3/papers.cfm?abstract_\\nid¼1638938> accessed 15 December 2016.\\n51 Concerning how an explanation is required both as a safeguard against\\nautomated decision-making and through the right of access, see: Douwe\\nKorff, ‘New Challenges to Data Protection Study - Country Report:\\nGermany’ (European Commission DG Justice, Freedom and Security\\n2010) 27 <http://ec.europa.eu/justice/data-protection/document/studies/\\nﬁles/new_privacy_challenges/ﬁnal_report_country_report_a4_germany.\\npdf> accessed 15 December 2016.\\nConcerning s 6(a)2(2) right to explanation: Kai von Lewinski, ‘BDSG\\n§ 6a Automatisierte Einzelentscheidung’ in Wolff and Brink (eds),\\nBeck’scher Online-Kommentar Datenschutzrecht (17th edn, beck-online\\n2016) Rn 45–49; ibid Rn 47–48.1. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 70, 'page': 11, '_split_overlap': [{'doc_id': 'f77cc493c0952f4ddee1ca8453f935d', 'range': (0, 224)}, {'doc_id': '9efa8072cd4d9e3e6b545ab1870e2f62', 'range': (1190, 1424)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8d234f5c63c425b6e9aa1c083d31c2fa'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Concerning s 6(a)2(2) right to explanation: Kai von Lewinski, ‘BDSG\\n§ 6a Automatisierte Einzelentscheidung’ in Wolff and Brink (eds),\\nBeck’scher Online-Kommentar Datenschutzrecht (17th edn, beck-online\\n2016) Rn 45–49; ibid Rn 47–48.1. states the required explanation can be\\nshort and must only include the main reason for the decision. The data\\nsubject must be able to understand why a decision has not been made in\\nher favour.\\nFor discussion of s 6(a)3 (the extended right of access and its limita-\\ntions due to trade secrets), see Peter Gola, Christoph Klug, and Barbara\\nKo\\n¨rffer, ‘BDSG § 6a Automatisierte Einzelentscheidung’ in Peter Gola\\nand Rudolf Schomerus (eds), Bundesdatenschutzgesetz (12th edn,\\nVerlag C.H. Beck 2015) Rn 18–19. Lewinski, ibid Rn 50–53 comment-\\ning on s 6(a)3 (the extended right of access) explains that the data sub-\\nject needs to have a basis to evaluate that an automated decision is\\naccurate. This suggests that there is a least some basis to obtain an\\nexplanation after the decision has been made under the extended right\\nof access. However, it is noted that trade secrets restrict this right: only\\nthe basis of decision parameters have to be disclosed, but not details of\\nthe parameters. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 71, 'page': 11, '_split_overlap': [{'doc_id': '8d234f5c63c425b6e9aa1c083d31c2fa', 'range': (0, 234)}, {'doc_id': '227d9e14afe1017eb9b50e11075112ba', 'range': (1067, 1222)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9efa8072cd4d9e3e6b545ab1870e2f62'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: However, it is noted that trade secrets restrict this right: only\\nthe basis of decision parameters have to be disclosed, but not details of\\nthe parameters. The ‘logical structure’ must be disclosed, which refers\\nto the ‘decision tree’, but not the software or the code. Lewinski, ibid\\nRn 47–48.1 also notes that the scope (the extent to which information\\nmust be disclosed) of the right of access and the safeguards in s 6(a)2\\nare comparable.\\nOn safeguards in s 6, see Gola, Klug and Ko\\n¨rffer, ibid Rn 1–20, com-\\nmenting on s 6(a), explains a right to explanation is granted under s\\n6(a)2(2), which is one of the safeguards relating to the second exemp-\\ntion of the general prohibition of automated decision-making.\\nSafeguards in this article require the data controller to inform about\\nhow the decision was reached (three-step model: to be informed about\\nthe fact that such a decision was taken and, upon request of the data\\nsubject, to receive an explanation of the decision reached and the right\\nto contest the decision). For a discussion, see Gola, Klug and Ko\\n¨rffer,\\nibid, Rn 12–14c. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 72, 'page': 11, '_split_overlap': [{'doc_id': '9efa8072cd4d9e3e6b545ab1870e2f62', 'range': (0, 155)}, {'doc_id': 'bca0de41b808887ff8e97ba0d342bbfe', 'range': (717, 1090)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '227d9e14afe1017eb9b50e11075112ba'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Safeguards in this article require the data controller to inform about\\nhow the decision was reached (three-step model: to be informed about\\nthe fact that such a decision was taken and, upon request of the data\\nsubject, to receive an explanation of the decision reached and the right\\nto contest the decision). For a discussion, see Gola, Klug and Ko\\n¨rffer,\\nibid, Rn 12–14c. The ﬁrst exception under s 6(a)2(1) (performance of\\na contract and if the decision has been made in favour of the data sub-\\nject) does not explicitly require an explanation (unlike s 6(a)2(2)).\\nRather, the right of access in s 6(a)3 will apply in these cases which, per\\nabove, could be interpreted as a right to obtain an explanation after the\\ndecision has been made. The phrasing of s 6(a)3 (extended right of\\naccess) can be interpreted both ways: as granting an explanation both\\nbefore and after a decision has been made; see Lewinski, ibid Rn 1–4.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 73, 'page': 11, '_split_overlap': [{'doc_id': '227d9e14afe1017eb9b50e11075112ba', 'range': (0, 373)}, {'doc_id': 'a8109ed95cf60e7e66caf745b993cc23', 'range': (742, 924)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bca0de41b808887ff8e97ba0d342bbfe'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The phrasing of s 6(a)3 (extended right of\\naccess) can be interpreted both ways: as granting an explanation both\\nbefore and after a decision has been made; see Lewinski, ibid Rn 1–4.\\nFurther, the SCHUFA judgments (see section ‘Right of access in the\\n1995 Data Protection Directive 95/46/EC’) show that judges inter-\\npreted the right of access to grant a limited right to obtain an explana-\\ntion after a decision has been made; see Lewinski, Rn 50–51.\\nFor further discussion of the overlap of automated decision-making\\nunder s 6a and scoring provisions under s 28b see Gola, Klug and\\nKo\\n¨rffer, ibid Rn 6–7, 15–17. Note that the German commentators\\nmentioned do not see a difference between s 6(a)2 right to explanation\\nand s 6(a)3 right of access when discussing the limitations imposed by\\ntrade secrets on information given to the data subject. See also\\nLewinski, ibid Rn 1–4; Gola, Klug and Ko\\n¨rffer, ibid Rn 14–14a.\\n86 ARTICLE International Data Privacy Law, 2017, Vol. 7, No. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 74, 'page': 11, '_split_overlap': [{'doc_id': 'bca0de41b808887ff8e97ba0d342bbfe', 'range': (0, 182)}, {'doc_id': '5be32bcf586d6e6de12d267c02a1c2b2', 'range': (846, 980)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a8109ed95cf60e7e66caf745b993cc23'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: See also\\nLewinski, ibid Rn 1–4; Gola, Klug and Ko\\n¨rffer, ibid Rn 14–14a.\\n86 ARTICLE International Data Privacy Law, 2017, Vol. 7, No. 2\\x0cto obtain information about the ‘logical structure’ of\\nautomated processing, which refers back to Article\\n12(a) of the Directive.52 If ‘knowledge of logic involved’\\nin Article 12(a) was intended to establish a right to\\nobtain an explanation about decisions reached, it would\\nnot have been necessary for German legislators to enact\\nseparately a right to explanation (section 6(a)2(2)) in\\nthe same Article containing the extended right of access\\n(section 6(a)3), especially considering both rights must\\nbe invoked by the data subject. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 75, 'page': 11, '_split_overlap': [{'doc_id': 'a8109ed95cf60e7e66caf745b993cc23', 'range': (0, 134)}, {'doc_id': '5454981fabe37ffcc11e11831c86a13a', 'range': (135, 669)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5be32bcf586d6e6de12d267c02a1c2b2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 2\\x0cto obtain information about the ‘logical structure’ of\\nautomated processing, which refers back to Article\\n12(a) of the Directive.52 If ‘knowledge of logic involved’\\nin Article 12(a) was intended to establish a right to\\nobtain an explanation about decisions reached, it would\\nnot have been necessary for German legislators to enact\\nseparately a right to explanation (section 6(a)2(2)) in\\nthe same Article containing the extended right of access\\n(section 6(a)3), especially considering both rights must\\nbe invoked by the data subject. Even if one wishes to\\nargue that sections 6(a)2(2) and 6(a)3 refer to the same\\ntype of explanation (ie of speciﬁc decisions), the use of\\ndifferent wording across the articles—‘main reasons for\\nthe decision and have it explained’ in section 6(a)2(2),\\n‘logical structure of the automated processing of the\\ndata that concerns [the data subject]’ (authors’ trans-\\nlation) in section 6(a)3)—suggests that the two mecha-\\nnisms entitle the data subject to different types of\\ninformation.53\\nFollowing this, German legal commentary and juris-\\nprudence54 addressing the extended right of access (sec-\\ntion 6(a)3) suggest that the information it requires is\\nlimited mostly to system functionality. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 76, 'page': 11, '_split_overlap': [{'doc_id': '5be32bcf586d6e6de12d267c02a1c2b2', 'range': (0, 534)}, {'doc_id': '20a2ef2a929ad47eb6f2bb6373087751', 'range': (535, 1221)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5454981fabe37ffcc11e11831c86a13a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Even if one wishes to\\nargue that sections 6(a)2(2) and 6(a)3 refer to the same\\ntype of explanation (ie of speciﬁc decisions), the use of\\ndifferent wording across the articles—‘main reasons for\\nthe decision and have it explained’ in section 6(a)2(2),\\n‘logical structure of the automated processing of the\\ndata that concerns [the data subject]’ (authors’ trans-\\nlation) in section 6(a)3)—suggests that the two mecha-\\nnisms entitle the data subject to different types of\\ninformation.53\\nFollowing this, German legal commentary and juris-\\nprudence54 addressing the extended right of access (sec-\\ntion 6(a)3) suggest that the information it requires is\\nlimited mostly to system functionality. The data control-\\nler does not need to disclose the software used, as the\\nsoftware is considered to be a trade secret.55 Some\\nGerman commentators believe that some (or the ‘top\\nfour’) features factored into a decision have to be dis-\\nclosed, but not the algorithm used due to trade\\nsecrets.56 Data controllers are not obligated to explain\\nhow the software is working or, especially, to give any\\ndetails about its code. The data controller is only obli-\\ngated to explain the logic of the ‘decision tree’. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 77, 'page': 12, '_split_overlap': [{'doc_id': '5454981fabe37ffcc11e11831c86a13a', 'range': (0, 686)}, {'doc_id': 'aee3094a67282806239eca4e48d3a6bb', 'range': (687, 1190)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '20a2ef2a929ad47eb6f2bb6373087751'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The data control-\\nler does not need to disclose the software used, as the\\nsoftware is considered to be a trade secret.55 Some\\nGerman commentators believe that some (or the ‘top\\nfour’) features factored into a decision have to be dis-\\nclosed, but not the algorithm used due to trade\\nsecrets.56 Data controllers are not obligated to explain\\nhow the software is working or, especially, to give any\\ndetails about its code. The data controller is only obli-\\ngated to explain the logic of the ‘decision tree’. The\\n‘weighting’ (authors’ translation) of speciﬁc features\\nand the parameters used to make the decision do not\\nhave to be disclosed. This is meant to protect trade\\nsecrets and manipulation of the decision-making\\nsystem.57\\nThis interpretation of the right of access as being lim-\\nited to system functionality in order not to contravene\\ntrade secrets is also reﬂected in German jurisprudence.\\nAccording to several commentators,58 the German\\nSCHUFA59 judgments60 show that data subjects do not\\nhave a right to investigate fully the accuracy of auto-\\nmated processing systems (in this case, credit scoring),\\nas the underlying formulas are protected as trade\\nsecrets. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 78, 'page': 12, '_split_overlap': [{'doc_id': '20a2ef2a929ad47eb6f2bb6373087751', 'range': (0, 503)}, {'doc_id': '336bea554090788258f5d2f1d84a30bd', 'range': (895, 1166)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'aee3094a67282806239eca4e48d3a6bb'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: According to several commentators,58 the German\\nSCHUFA59 judgments60 show that data subjects do not\\nhave a right to investigate fully the accuracy of auto-\\nmated processing systems (in this case, credit scoring),\\nas the underlying formulas are protected as trade\\nsecrets. The protected formula would consist of, for\\nexample, statistical values, weighting of certain elements\\nto calculate probabilities (eg the likelihood of loan\\nrepayment), and reference or comparison groups.\\nThe judgments indicate that all three elements of\\nthe right of access enshrined in Article 12(a) of the\\nDirective aim to provide general information about the\\nusage and purpose of data processing. Concrete ele-\\nments of the screening procedures do not have to be\\ndisclosed.61 The data subject is entitled to know which\\ndata and features were taken into account when the\\ndecision was made, in order to be able to contest the\\ndecision or demand that inaccurate or incomplete data\\nbe rectiﬁed. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 79, 'page': 12, '_split_overlap': [{'doc_id': 'aee3094a67282806239eca4e48d3a6bb', 'range': (0, 271)}, {'doc_id': '97d302f7530ee1101131082a6c143b1c', 'range': (674, 967)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '336bea554090788258f5d2f1d84a30bd'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Concrete ele-\\nments of the screening procedures do not have to be\\ndisclosed.61 The data subject is entitled to know which\\ndata and features were taken into account when the\\ndecision was made, in order to be able to contest the\\ndecision or demand that inaccurate or incomplete data\\nbe rectiﬁed. However, the weighting of these elements,\\nthe method (scoring formula), the statistical values, and\\nthe information about the reference groups62 used does\\nnot have to be disclosed.63 The judgments state that\\njurisprudence, academic literature, and legal commen-\\ntary commonly agree that the abstract methods used to\\n52 Philip Scholz, ‘BDSG § 6a Automatisierte Einzelentscheidung’ in Spiros\\nSimitis (ed), Bundesdatenschutzgesetz (8th edn, Nomos 2014) Rn 38.\\n53 Lewinski (n 51) Rn 50–52 states that the wording of the German Data\\nProtection Act is not clear regarding whether the right of access refers to\\ninformation about the ‘process’ (meaning the system) or ‘a decision\\nmade’.\\n54 BGH: kein umfassender Auskunftsanspruch gegen SCHUFA 2014 (VI ZR\\n156/13) BDSG s 34 Abs 4; Mario Martini, ‘Big Data als Herausforderung\\nfu\\n¨r den Perso\\n¨nlichkeitsschutz und das Datenschutzrecht’ [2014] DVBI\\n1481.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 80, 'page': 12, '_split_overlap': [{'doc_id': '336bea554090788258f5d2f1d84a30bd', 'range': (0, 293)}, {'doc_id': '9c58ace8792e20537998dab7d072ef5e', 'range': (973, 1188)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '97d302f7530ee1101131082a6c143b1c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 54 BGH: kein umfassender Auskunftsanspruch gegen SCHUFA 2014 (VI ZR\\n156/13) BDSG s 34 Abs 4; Mario Martini, ‘Big Data als Herausforderung\\nfu\\n¨r den Perso\\n¨nlichkeitsschutz und das Datenschutzrecht’ [2014] DVBI\\n1481.\\n55 Gola, Klug and Ko\\n¨rffer (n 51) Rn 18–19 ‘€\\nUber die allgemeinen\\nAuskunftsanspru\\n¨che nach § 19 bzw. § 34 sind nach Absatz 3 auch\\nAngaben zu machen u\\n¨ber den logischen Aufbau der automatisierten\\nVerarbeitung. Dem Betroffenen soll in erster Linie veranschaulicht wer-\\nden, was mit seinen Daten geschieht. Er soll in die Lage versetzt werden,\\nGesichtspunkte vorzubringen, die inhaltliche €\\nUberpru\\n¨fung der automa-\\ntisiert vorgenommen’ vermuteten ‘Bewertung ermo\\n¨glichen. Unter dem\\nGesichtspunkt des Schutzes von Gesch€\\naftsgeheimnissen und des\\nUrheberrechtsschutzes umfasst die Auskunftspﬂicht jedoch nicht die ver-\\nwendete Software (zur sog. Scoreformel als Gesch€\\naftsgeheimnis vgl.\\nBGH, NJW 2014, 1235, der die Frage der Reichweite des\\nAuskunftsanspruchs u\\n¨ber den logischen Aufbau der automatisierten\\nVerarbeitung mangels Vorliegens einer automatisierten\\nEinzelentscheidung dahinstehen ließ).’\\n56 Korff (n 51) 27 ff.\\n57 Lewinski (n 51) Rn 50–53\\n58 Br€\\nautigam and Schmidt-Wudy (n 35) 62; Jens Hammersen and Ulrich\\nEisenried, ‘Ist ,,Redlining” in Deutschland erlaubt? ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 81, 'page': 12, '_split_overlap': [{'doc_id': '97d302f7530ee1101131082a6c143b1c', 'range': (0, 215)}, {'doc_id': '700770dc86afe537de5aa7df259767de', 'range': (1143, 1292)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9c58ace8792e20537998dab7d072ef5e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 57 Lewinski (n 51) Rn 50–53\\n58 Br€\\nautigam and Schmidt-Wudy (n 35) 62; Jens Hammersen and Ulrich\\nEisenried, ‘Ist ,,Redlining” in Deutschland erlaubt? Pl€\\nadoyer fu\\n¨r eine\\nweite Auslegung des Auskunftsanspruchs’ [2014] ZD Zeitschrift fu\\n¨r\\nDatenschutz 342.\\n59 Amongst others, see judgment of the German Federal Court BGH, ZD\\n2014, 306. It is important to note that the German court refused to talk\\nabout the extent to which the data subject is entitled to know about the\\nlogic involved as the Court ruled that in this case there was no automated\\ndecision, as explained in: Gola, Klug and Ko\\n¨rffer (n 51) Rn 18–19.\\n60 Judgment of the German Federal Court Bundesgerichtshof 28 January\\n2014 – VI ZR 156/13. Also LG Gießen 6 March 2013 – 1 S 301/12. Also,\\nAG Gießen 11 October 2014 – 47 C 206/12.\\n61 Judgment of the German Federal Court: Scoring und Datenschutz BGH,\\n28 January 2014 - VI ZR 156/13 (LG Gießen, AG Gießen) 169.\\n62 ‘Reference groups’ refer to proﬁles or classiﬁcations that inform the\\nassessment of creditworthiness. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 82, 'page': 12, '_split_overlap': [{'doc_id': '9c58ace8792e20537998dab7d072ef5e', 'range': (0, 149)}, {'doc_id': '975ebbfcbd5671749c328e8cc89dc63e', 'range': (794, 1027)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '700770dc86afe537de5aa7df259767de'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 61 Judgment of the German Federal Court: Scoring und Datenschutz BGH,\\n28 January 2014 - VI ZR 156/13 (LG Gießen, AG Gießen) 169.\\n62 ‘Reference groups’ refer to proﬁles or classiﬁcations that inform the\\nassessment of creditworthiness. For a discussion, see for instance:\\nMittelstadt and others (n 6); Mireille Hildebrandt and Serge Gutwirth,\\nProﬁling the European Citizen (Springer 2008).\\n63 Judgment of the German Federal Court : BGH: Umfang einer von der\\nSCHUFA zu erteilenden Auskunft BGH, Urteil vom 28 January 2014 - VI\\nZR 156/13 (LG Gießen, AG Gießen) 490. The judgments show that the\\nright of access is very limited.\\nSandra Wachter et al. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 83, 'page': 12, '_split_overlap': [{'doc_id': '700770dc86afe537de5aa7df259767de', 'range': (0, 233)}, {'doc_id': 'da3f7c01d38830e8fd6e9e9b1c512250', 'range': (388, 644)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '975ebbfcbd5671749c328e8cc89dc63e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 63 Judgment of the German Federal Court : BGH: Umfang einer von der\\nSCHUFA zu erteilenden Auskunft BGH, Urteil vom 28 January 2014 - VI\\nZR 156/13 (LG Gießen, AG Gießen) 490. The judgments show that the\\nright of access is very limited.\\nSandra Wachter et al. Á No Right to Explanation of Automated Decision-Making 87\\nARTICLE\\x0cdeﬁne credit scores do not have to be disclosed, and\\nthat this position is in accordance with the intention of\\nGerman data protection legislation.64\\nIt is worth noting that the SCHUFA judgments do\\nnot explicitly address automated decision-making, as\\nthe court decided an automated decision was not made\\nbecause automated processing was only used for prepa-\\nration of evidence, while the actual decision was made\\nby a human being.65 The judgements are nonetheless\\ninsightful insofar as they demonstrate a strong tendency\\nto protect trade secrets in relation to the right of access.\\nAs discussed below, this case provides an example of an\\nimportant limitation on a right to explanation estab-\\nlished on any of the three legal bases in the GDPR iden-\\ntiﬁed above. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 84, 'page': 12, '_split_overlap': [{'doc_id': '975ebbfcbd5671749c328e8cc89dc63e', 'range': (0, 256)}, {'doc_id': 'fc371fd29089b52328bca60057fb9edf', 'range': (904, 1083)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'da3f7c01d38830e8fd6e9e9b1c512250'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: As discussed below, this case provides an example of an\\nimportant limitation on a right to explanation estab-\\nlished on any of the three legal bases in the GDPR iden-\\ntiﬁed above. Automated decision-making is deﬁned in\\nboth the Directive and GDPR as decision-making based\\nsolely on automated processes.66 Quite crucially, this\\ncreates a loophole whereby even nominal involvement\\nof a human in the decision-making process allows for\\nan otherwise automated mechanism to avoid invoking\\nelements of the right of access (both in the Directive\\nand GDPR) addressing automated decisions.\\nFinally, Austrian legislators similarly implemented\\nthe requirements of Articles 12a and 15 of the Directive\\nin section 49(3)67 of the Austrian Data Protection Act.\\nAs opposed to German law, the right to obtain an\\nexplanation about how an individual decision was\\nreached was not implemented as a safeguard. Only the\\nright to express one’s view is named as one of the man-\\ndatory safeguards, as mandated by Article 15 of the\\nDirective. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 85, 'page': 13, '_split_overlap': [{'doc_id': 'da3f7c01d38830e8fd6e9e9b1c512250', 'range': (0, 179)}, {'doc_id': 'd3e367418d9fc07b7e6812d1fa1612e7', 'range': (887, 1014)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fc371fd29089b52328bca60057fb9edf'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Only the\\nright to express one’s view is named as one of the man-\\ndatory safeguards, as mandated by Article 15 of the\\nDirective. Section 49(3) establishes an extended right of\\naccess (section 26) which is the data subject’s right to\\nknow, upon request, about the logic of the process of\\nautomated decision-making.68\\nAustrian jurisprudence69 is very vague on the right of\\naccess and automated decision-making. Existing deci-\\nsions do not fully explain how much the data controller\\nis obligated to disclose under the right of access, and are\\nin some sense contradictory. In most decisions, an obli-\\ngation was recognized to explain how the system in\\nquestions functions.70 In contrast, one decision stated\\nthat the right of access according to section 26 and the\\nright to know about the logic of the process (section\\n49(3)) also includes the criteria and the weighting of the\\ncriteria which would then allow the data subject to\\nunderstand how a decision was reached. However, the\\nAustrian Data Protection Commission simultaneously\\nacknowledged that trade secrets can limit this right. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 86, 'page': 13, '_split_overlap': [{'doc_id': 'fc371fd29089b52328bca60057fb9edf', 'range': (0, 127)}, {'doc_id': '509c13bd524130564e119835fa31e16b', 'range': (568, 1081)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd3e367418d9fc07b7e6812d1fa1612e7'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: In most decisions, an obli-\\ngation was recognized to explain how the system in\\nquestions functions.70 In contrast, one decision stated\\nthat the right of access according to section 26 and the\\nright to know about the logic of the process (section\\n49(3)) also includes the criteria and the weighting of the\\ncriteria which would then allow the data subject to\\nunderstand how a decision was reached. However, the\\nAustrian Data Protection Commission simultaneously\\nacknowledged that trade secrets can limit this right. The\\nCommission concluded that the extent to which the\\ndata controller needs to disclose decision criteria and\\nweighting must be determined on a case by case basis.71\\nIn another case, the Commission denied the existence of\\nan individual automated decision because the criteria\\nused were based on a large group rather than on the\\nindividual. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 87, 'page': 13, '_split_overlap': [{'doc_id': 'd3e367418d9fc07b7e6812d1fa1612e7', 'range': (0, 513)}, {'doc_id': '735826d1cf800a299b932bd9408dbcc2', 'range': (514, 853)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '509c13bd524130564e119835fa31e16b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The\\nCommission concluded that the extent to which the\\ndata controller needs to disclose decision criteria and\\nweighting must be determined on a case by case basis.71\\nIn another case, the Commission denied the existence of\\nan individual automated decision because the criteria\\nused were based on a large group rather than on the\\nindividual. Therefore, the rights of access and to know\\nabout the logic of automated processing do not apply, if\\nthe basis of that decision is a group (‘peer group’\\n[authors’ translation]) rather than (data about) the\\nindividual.72 This distinction highlights a tension in the\\ndeﬁnition of automated decision-making and proﬁling\\n64 The court, however, acknowledged that there is discussion about whether\\nor not information about the weighting of features and reference groups\\nshould be included in disclosures, and to what extent.\\n65 Reﬂecting this, the court subsequently refused to discuss the extent to\\nwhich the logic involved needed to be disclosed by the data controller.\\nRather, it addressed the general obligation of data controllers to provide\\ninformation about the data being processed, derived from the right of\\naccess.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 88, 'page': 13, '_split_overlap': [{'doc_id': '509c13bd524130564e119835fa31e16b', 'range': (0, 339)}, {'doc_id': '7f228120df632b468adfed98f85db226', 'range': (1006, 1158)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '735826d1cf800a299b932bd9408dbcc2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Rather, it addressed the general obligation of data controllers to provide\\ninformation about the data being processed, derived from the right of\\naccess.\\n66 Art 15(1) of the Directive deﬁnes ‘automated individual decisions’ as ‘a\\ndecision which produces legal effects concerning him or signiﬁcantly\\naffects him and which is based solely on automated processing of data\\nintended to evaluate certain personal aspects relating to him, such as his\\nperformance at work, creditworthiness, reliability, conduct, etc.’\\nSimilarly, Art 22(1) GDPR deﬁnes ‘automated decision-making’ as ‘a\\ndecision based solely on automated processing, including proﬁling,\\nwhich produces legal effects concerning him or her or similarly signiﬁ-\\ncantly affects him or her.’\\n67 Bundesgesetz u\\n¨ber den Schutz personenbezogener Daten\\n(Datenschutzgesetz 2000 - DSG 2000) 2000 (DSG 2000) 49 Abs (3). –\\n‘Dem Betroffenen ist bei automatisierten Einzelentscheidungen auf\\nAntrag der logische Ablauf der automatisierten Entscheidungsﬁndung in\\nallgemein verst€\\nandlicher Form darzulegen. § 26 Abs. 2 bis 10 gilt\\nsinngem€\\naß.’\\n68 Decision of the Austrian Data Protection Commission 24 April 2009,\\nApp no K121.461/0003-DSK/2009.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 89, 'page': 13, '_split_overlap': [{'doc_id': '735826d1cf800a299b932bd9408dbcc2', 'range': (0, 152)}, {'doc_id': '81c63516582542fa6aba0335ffb8a705', 'range': (1058, 1186)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7f228120df632b468adfed98f85db226'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 2 bis 10 gilt\\nsinngem€\\naß.’\\n68 Decision of the Austrian Data Protection Commission 24 April 2009,\\nApp no K121.461/0003-DSK/2009.\\n69 Amongst others, Decisions of the Austrian Data Protection Commission:\\n24 April 2009 App no K121.461/0003-DSK/2009, addressing the need to\\nexplain the system used; 27 August 2010 App no K121.599/0014-DSK/\\n2010; 22 May 2013 App no K121.935/0006-DSK/2013; 25 April 2008 App\\nno 121.348/0007-DSK/2008, addressing the need to explain the system\\nused; 8 May 2009 App no K121.470/0007-DSK/2009, addressing whether\\na process counts as an automated decision; 20 March 2009 App no\\nK121.467/0007-DSK/2009; 25 April 2008 App no K121.348/0007-DSK/\\n2008; 25 April 2008 App no K121.348/0007-DSK/2008; 25 May 2012 App\\nno K121.791/0008-DSK/2012; 9 June 2009 App no K121.460/0008-DSK/\\n2009; 19 June 2009 App no K121.494/0013-DSK/2009; 2 February 2007\\nApp no K121.238/0006-DSK/2007; Austrian Administrative Court judg-\\nments 11 December 2009 App no 009/17/0223; 15 November 2012 App\\nno 2008/17/0096; 20 February 2008 App no 2005/15/0161.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 90, 'page': 13, '_split_overlap': [{'doc_id': '7f228120df632b468adfed98f85db226', 'range': (0, 128)}, {'doc_id': 'df1c37a22a1a2d46cc816239562190ed', 'range': (129, 1049)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '81c63516582542fa6aba0335ffb8a705'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 69 Amongst others, Decisions of the Austrian Data Protection Commission:\\n24 April 2009 App no K121.461/0003-DSK/2009, addressing the need to\\nexplain the system used; 27 August 2010 App no K121.599/0014-DSK/\\n2010; 22 May 2013 App no K121.935/0006-DSK/2013; 25 April 2008 App\\nno 121.348/0007-DSK/2008, addressing the need to explain the system\\nused; 8 May 2009 App no K121.470/0007-DSK/2009, addressing whether\\na process counts as an automated decision; 20 March 2009 App no\\nK121.467/0007-DSK/2009; 25 April 2008 App no K121.348/0007-DSK/\\n2008; 25 April 2008 App no K121.348/0007-DSK/2008; 25 May 2012 App\\nno K121.791/0008-DSK/2012; 9 June 2009 App no K121.460/0008-DSK/\\n2009; 19 June 2009 App no K121.494/0013-DSK/2009; 2 February 2007\\nApp no K121.238/0006-DSK/2007; Austrian Administrative Court judg-\\nments 11 December 2009 App no 009/17/0223; 15 November 2012 App\\nno 2008/17/0096; 20 February 2008 App no 2005/15/0161.\\n70 According to a decision of the Austrian Data Protection Commission 25\\nApril 2008 App no K121.348/0007-DSK/2008, the obligation is with the\\ndata controller to inform about the procedure of automated decision-\\nmaking in an understandable manner: “die Pﬂicht, dem Betroffenen den\\nAblauf der automatisierten Entscheidungsﬁndung in allgemein verst€\\nand-\\nlicher Form darzulegen.”\\n71 Decision of the Austrian Data Protection Commission 12 December\\n2007 App no K121.313/0016-DSK/2007. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 91, 'page': 13, '_split_overlap': [{'doc_id': '81c63516582542fa6aba0335ffb8a705', 'range': (0, 920)}, {'doc_id': '6ad069c9e9973d3aa3ef5cbdd1d84e92', 'range': (921, 1400)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'df1c37a22a1a2d46cc816239562190ed'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 70 According to a decision of the Austrian Data Protection Commission 25\\nApril 2008 App no K121.348/0007-DSK/2008, the obligation is with the\\ndata controller to inform about the procedure of automated decision-\\nmaking in an understandable manner: “die Pﬂicht, dem Betroffenen den\\nAblauf der automatisierten Entscheidungsﬁndung in allgemein verst€\\nand-\\nlicher Form darzulegen.”\\n71 Decision of the Austrian Data Protection Commission 12 December\\n2007 App no K121.313/0016-DSK/2007. See also 12 December 2007 App\\nno K121.313/0016-DSK/2007. It is important to note that in the latter\\ndecision the Commission talked about a hypothetical obligation of the\\ndata controller, since the applicant did not lodge a request under s 49(3)\\nbut rather invoked his general right of access under s 26. The\\nCommission stated that if the data subject had lodged a complaint under\\ns 49(3), the data controller would need to disclose this information, but\\nhow far trade secrets would limit the disclosure would need to be exam-\\nined on a case to case basis, therefore there is no precedent yet:.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 92, 'page': 13, '_split_overlap': [{'doc_id': 'df1c37a22a1a2d46cc816239562190ed', 'range': (0, 479)}, {'doc_id': 'f6b0cbce07615e4d3fb2e9548866a64e', 'range': (784, 1073)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6ad069c9e9973d3aa3ef5cbdd1d84e92'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The\\nCommission stated that if the data subject had lodged a complaint under\\ns 49(3), the data controller would need to disclose this information, but\\nhow far trade secrets would limit the disclosure would need to be exam-\\nined on a case to case basis, therefore there is no precedent yet:.\\n72 In this decision it was found that there is no automated decision because\\nthe decision was based on a group (‘peer group’) rather than the individ-\\nual and it was stated that such an automated decision (marketing\\n88 ARTICLE International Data Privacy Law, 2017, Vol. 7, No. 2\\x0cin the Directive, insofar as automated processing of data\\ndescribing groups, rather than individuals, does not\\nallow for invocation of the right of access.73\\nFrom the Directive to the GDPR: the right to be\\ninformed\\nThe Directive’s right of access provides an explanation\\nof the system’s functionality which has been heavily lim-\\nited by trade secrets. The loophole—through which\\nautomated processes that merely produce evidence for\\ndecision-making (rather than actually making deci-\\nsions) are not subject to the right of access (speciﬁcally,\\nthe provision to disclose information about the ‘logic\\ninvolved’)—has also proven to be a signiﬁcant limiting\\nfactor. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 93, 'page': 13, '_split_overlap': [{'doc_id': '6ad069c9e9973d3aa3ef5cbdd1d84e92', 'range': (0, 289)}, {'doc_id': '5d06e46d082995b4d3e2949d27bebf70', 'range': (921, 1229)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f6b0cbce07615e4d3fb2e9548866a64e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The loophole—through which\\nautomated processes that merely produce evidence for\\ndecision-making (rather than actually making deci-\\nsions) are not subject to the right of access (speciﬁcally,\\nthe provision to disclose information about the ‘logic\\ninvolved’)—has also proven to be a signiﬁcant limiting\\nfactor. A relative lack of jurisprudence across Member\\nStates has not helped clarify and unify the requirements.\\nThis is problematic given the current and emerging\\ngrowth in automated decision-making and data\\nprocessing.\\nThe GDPR appears to offer less protection to data\\nsubjects concerning explanations of automated\\ndecision-making than some current data protection\\nlaws in Europe based on the Directive.74 In particular,\\nthe GDPR’s right of access appears to not offer more\\nprotection for data subjects’ interests than the\\nDirective’s right of access.75 The use of future-oriented\\nsemantics in the GDPR (unlike the Directive which did\\nnot explicitly acknowledge a decision-making timeline),\\nas well as its terminological overlap with notiﬁcation\\nduties, suggest that the GDPR intends to further limit\\nthe right of access regarding automated decision-\\nmaking to explanations of system functionality.76 The\\nphrasing of Article 15 GDPR in particular points\\ntowards a general explanation of the existence and func-\\ntionality of automated decision-making systems. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 94, 'page': 14, '_split_overlap': [{'doc_id': 'f6b0cbce07615e4d3fb2e9548866a64e', 'range': (0, 308)}, {'doc_id': '6c77c0ebcfdf2ae54c7ff89f1117258a', 'range': (522, 1361)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5d06e46d082995b4d3e2949d27bebf70'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The GDPR appears to offer less protection to data\\nsubjects concerning explanations of automated\\ndecision-making than some current data protection\\nlaws in Europe based on the Directive.74 In particular,\\nthe GDPR’s right of access appears to not offer more\\nprotection for data subjects’ interests than the\\nDirective’s right of access.75 The use of future-oriented\\nsemantics in the GDPR (unlike the Directive which did\\nnot explicitly acknowledge a decision-making timeline),\\nas well as its terminological overlap with notiﬁcation\\nduties, suggest that the GDPR intends to further limit\\nthe right of access regarding automated decision-\\nmaking to explanations of system functionality.76 The\\nphrasing of Article 15 GDPR in particular points\\ntowards a general explanation of the existence and func-\\ntionality of automated decision-making systems. Article\\n12(a) of the Directive grants data subjects a right to\\nobtain ‘knowledge of the logic involved in any auto-\\nmatic processing of data concerning him at least in the\\ncase of the automated decisions referred to in Article\\n15(1)’.77 It is interesting to note that this phrase is open\\nto greater interpretation than Article 15 GDPR, 78 which\\nrequires only information about ‘the existence of auto-\\nmated decision-making, including proﬁling, referred to\\nin Article 22(1) and (4) and, at least in those cases,\\nmeaningful information about the logic involved, as\\nwell as the signiﬁcance and the envisaged consequences\\nof such processing for the data subject’. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 95, 'page': 14, '_split_overlap': [{'doc_id': '5d06e46d082995b4d3e2949d27bebf70', 'range': (0, 839)}, {'doc_id': '97af0ea8fadf1c78eb632a42b2f681bd', 'range': (840, 1499)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6c77c0ebcfdf2ae54c7ff89f1117258a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Article\\n12(a) of the Directive grants data subjects a right to\\nobtain ‘knowledge of the logic involved in any auto-\\nmatic processing of data concerning him at least in the\\ncase of the automated decisions referred to in Article\\n15(1)’.77 It is interesting to note that this phrase is open\\nto greater interpretation than Article 15 GDPR, 78 which\\nrequires only information about ‘the existence of auto-\\nmated decision-making, including proﬁling, referred to\\nin Article 22(1) and (4) and, at least in those cases,\\nmeaningful information about the logic involved, as\\nwell as the signiﬁcance and the envisaged consequences\\nof such processing for the data subject’. As argued\\nabove, this phrase in the GDPR requires that the data\\nsubject be informed merely about the usage and func-\\ntionality of automated decision-making methods. The\\nchange of wording indicates that the intention of the\\nright of access in the GDPR is to grant access to infor-\\nmation about the ‘usage’ and functionality of such auto-\\nmated decision-making. Again, this suggests an even\\nstronger intention to limit the right to explanations of\\nsystem functionality, not the rationale and circumstances\\nof speciﬁc decisions.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 96, 'page': 14, '_split_overlap': [{'doc_id': '6c77c0ebcfdf2ae54c7ff89f1117258a', 'range': (0, 659)}, {'doc_id': 'ab211f66fa0e6147828c1e41f504f750', 'range': (1020, 1185)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '97af0ea8fadf1c78eb632a42b2f681bd'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Again, this suggests an even\\nstronger intention to limit the right to explanations of\\nsystem functionality, not the rationale and circumstances\\nof speciﬁc decisions.\\nLegal scholars are already debating the scope of the\\nright of access in the GDPR. According to German com-\\nmentary79 on the GDPR, it is sufﬁcient to be informed\\nabout the envisaged consequences in a very simple man-\\nner. For instance, an explanation of how a low rating of\\ncreditworthiness can affect the choice of payment\\noptions would be sufﬁcient.80 The type of explanation\\npurposes) would not have enough signiﬁcant effects and consequences to\\nhave s 49 (3) apply; see: Decision of the Austrian Data Protection\\nCommission 10 March 2016 App no DSB-D122.322/0001-DSB/2016.\\n73 This loophole points towards the need to recognise some type of group\\nprivacy right in data protection law, as processing of identiﬁable data is\\nnot required to learn about and take actions towards an individual. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 97, 'page': 14, '_split_overlap': [{'doc_id': '97af0ea8fadf1c78eb632a42b2f681bd', 'range': (0, 165)}, {'doc_id': 'f658f294d7cccf51da1e1921860b29f0', 'range': (741, 956)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ab211f66fa0e6147828c1e41f504f750'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 73 This loophole points towards the need to recognise some type of group\\nprivacy right in data protection law, as processing of identiﬁable data is\\nnot required to learn about and take actions towards an individual. For\\nfurther discussion, see: Mittelstadt and others (n 6); Brent Mittelstadt,\\n‘From Individual to Group Privacy in Big Data Analytics’ [2017]\\nPhilosophy & Technology 1; Linnet Taylor, Luciano Floridi and Bart van\\nder Sloot (eds), Group Privacy: New Challenges of Data Technologies (1st\\nedn, Springer 2017); Alessandro Mantelero, ‘Personal Data for Decisional\\nPurposes in the Age of Analytics: From an Individual to a Collective\\nDimension of Data Protection’ (2016) 32 Computer Law & Security\\nReview 238; Lee A Bygrave, Data Protection Law: Approaching Its\\nRationale, Logic and Limits (Kluwer Law Intl 2002) ch 15.\\n74 Martini (n 34) Rn 42–44 explains how other provisions of the GDPR fall\\nbehind and weaken the current data protection standards, e.g. in terms\\nof contractual relations as a legitimate reason for automated decisions, in\\nthat regard, see also Alexander Roßnagel, Philipp Richter and Maxi\\nNebel, ‘Besserer Internetdatenschutz fu\\n¨r Europa. Vorschl€\\nage Zur\\nSpeziﬁzierung Der DS-GVO’ (2013) 3 Zeitschrift fu\\n¨r Datenschutz 103.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 98, 'page': 14, '_split_overlap': [{'doc_id': 'ab211f66fa0e6147828c1e41f504f750', 'range': (0, 215)}, {'doc_id': 'be34c8989880e61e13992f8046319f70', 'range': (966, 1255)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f658f294d7cccf51da1e1921860b29f0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: in terms\\nof contractual relations as a legitimate reason for automated decisions, in\\nthat regard, see also Alexander Roßnagel, Philipp Richter and Maxi\\nNebel, ‘Besserer Internetdatenschutz fu\\n¨r Europa. Vorschl€\\nage Zur\\nSpeziﬁzierung Der DS-GVO’ (2013) 3 Zeitschrift fu\\n¨r Datenschutz 103.\\n75 Hammersen and Eisenried (n 58), commenting on the EC’s original 2012\\ndraft, note that the interpretation of the Directive’s right of access\\nthrough jurisprudence suggests that the right grants a very weak type of\\nexplanation of automated processing of data. The data subject is not pro-\\nvided a basis to scrutinize the outcome of automated processing of data,\\nincluding the method or algorithm used, or reference groups. The GDPR\\nhas not strengthened the right of access compared to the Directive in any\\nnotable way, meaning similar limitations are likely to apply.\\n76 The Directive’s right of access does not refer to the future, or use identi-\\ncal language to notiﬁcation duties. The latter point is unremarkable, as\\nthe Directive did not contain notiﬁcation duties. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 99, 'page': 14, '_split_overlap': [{'doc_id': 'f658f294d7cccf51da1e1921860b29f0', 'range': (0, 289)}, {'doc_id': '1bdd6fa65e19c263edb92db86945271f', 'range': (859, 1061)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'be34c8989880e61e13992f8046319f70'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 76 The Directive’s right of access does not refer to the future, or use identi-\\ncal language to notiﬁcation duties. The latter point is unremarkable, as\\nthe Directive did not contain notiﬁcation duties. We can thus only dis-\\ncuss whether a right to explanation of system functionality or speciﬁc\\ndecisions was derived by Member States from the right of access in art 12\\nof the Directive, as opposed to ex ante or ex post explanations.\\n77 Recital 41 of the Directive makes a similar claim.\\n78 The right of access only exists if the data controller has personal data of\\nthe data subjects, see: Mireille Hildebrandt, ‘The Dawn of a Critical\\nTransparency Right for the Proﬁling Era’, Digital Enlightenment Yearbook\\n2012 (IOS Press 2012). Further, the right of access is limited as far as data\\nof other data subjects are concerned, see Hildebrandt and Gutwirth (n\\n62).\\n79 Paal, ‘DS-GVO Art. 13 Informationspﬂicht bei Erhebung von\\nPersonenbezogenen Daten bei der Betroffenen Person’ in Paal and Pauly\\n(n 32); Martini (n 34) Rn 42–44.\\n80 Paal (n 79).\\nSandra Wachter et al. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 100, 'page': 14, '_split_overlap': [{'doc_id': 'be34c8989880e61e13992f8046319f70', 'range': (0, 202)}, {'doc_id': '158a87824261e10736485d31bf440d29', 'range': (886, 1065)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1bdd6fa65e19c263edb92db86945271f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 13 Informationspﬂicht bei Erhebung von\\nPersonenbezogenen Daten bei der Betroffenen Person’ in Paal and Pauly\\n(n 32); Martini (n 34) Rn 42–44.\\n80 Paal (n 79).\\nSandra Wachter et al. Á No Right to Explanation of Automated Decision-Making 89\\nARTICLE\\x0crecognized in prior German jurisprudence81 and\\nGerman commentary82 on the GDPR is limited by over-\\nriding interests of the data controller, eg protection of\\ntrade secrets, or prevention of ‘gaming the system’ by\\nusers. The process that the algorithms use does not have\\nto be disclosed.83 Furthermore, the rating of similar\\ngroups has historically not needed to be disclosed.84\\nThese recent commentaries on the GDPR follow the\\ngeneral interpretation and prior jurisprudence on the\\nright of access in the 1995 Directive. According to com-\\nmentators, data controllers do not need to explain fully\\nthe rationale and circumstances of a speciﬁc decision to\\nprovide data subjects with ‘meaningful information\\nabout the logic involved’ (Article 15(1)h GDPR).\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 101, 'page': 14, '_split_overlap': [{'doc_id': '1bdd6fa65e19c263edb92db86945271f', 'range': (0, 179)}, {'doc_id': '531c47a2c33fb36d311ca5802d9e63b7', 'range': (765, 996)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '158a87824261e10736485d31bf440d29'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: According to com-\\nmentators, data controllers do not need to explain fully\\nthe rationale and circumstances of a speciﬁc decision to\\nprovide data subjects with ‘meaningful information\\nabout the logic involved’ (Article 15(1)h GDPR).\\nRather, the information offered by data controllers will\\naddress general system functionality, and could be heav-\\nily curtailed to protect the controller’s interests (eg trade\\nsecrets, intellectual property; see Recital 63).85 It is\\nworth noting that additional limitations can also be\\nimposed to protect the interests of other parties via\\nUnion or Member State law.86 Paal also notes that the\\npurpose of Article 15 GDPR is to allow data subjects to\\nbe informed about the usage and functionality of auto-\\nmated decision-making. As the scope of information\\ndata controllers are required to disclose in Article 15 is\\nthe same as in Article 13, Article 15 similarly requires\\nonly limited information about the functionality of the\\nautomated decision-making system. Paal also notes that\\n“meaningful information” does not create an obligation\\nto disclose the algorithm, but only to provide basic\\ninformation about its logic. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 102, 'page': 15, '_split_overlap': [{'doc_id': '158a87824261e10736485d31bf440d29', 'range': (0, 231)}, {'doc_id': 'bafe8b8791b7db0ac12c716c78bf93cf', 'range': (994, 1151)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '531c47a2c33fb36d311ca5802d9e63b7'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Paal also notes that\\n“meaningful information” does not create an obligation\\nto disclose the algorithm, but only to provide basic\\ninformation about its logic. Schmidt-Wudy argues that\\nif necessary to assess the accuracy of data processing,\\ninformation about the algorithm could be given, with\\nappropriate limitations to protect trade secrets.87\\nHowever, the type of information to be provided is not\\nspeciﬁed.\\nAs with the Directive, the practical requirements and\\nutility of the GDPR’s right of access will similarly only\\nbe revealed through testing and clariﬁcation via juris-\\nprudence and expert opinion, such as from the Article\\n29 Working Party, the new European Data Protection\\nBoard established by Article 68 GDPR,88 the European\\nData Protection Supervisor, or its Ethics Advisory\\nGroup89 (see ‘Conclusion’ section). However, the\\nimplementation of the Directive’s right of access\\nstrongly suggests that the GDPR’s right of access will be\\nfar from the ex post ‘general’ right to explanation of sys-\\ntem functionality and speciﬁc decisions, which we have\\nargued it is mistakenly attributed to the GDPR. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 103, 'page': 15, '_split_overlap': [{'doc_id': '531c47a2c33fb36d311ca5802d9e63b7', 'range': (0, 157)}, {'doc_id': '9bb9153e2bb2ec09df188fc10faf4000', 'range': (822, 1105)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bafe8b8791b7db0ac12c716c78bf93cf'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: However, the\\nimplementation of the Directive’s right of access\\nstrongly suggests that the GDPR’s right of access will be\\nfar from the ex post ‘general’ right to explanation of sys-\\ntem functionality and speciﬁc decisions, which we have\\nargued it is mistakenly attributed to the GDPR. Rather,\\nthrough the right of access, the GDPR will grant a ‘right\\nto be informed’ about the existence of automated\\ndecision-making and system functionality, limited in\\napplicability along the lines above and those described\\nin the following section.\\nWhat if a right to explanation were\\ngranted?\\nAlthough a meaningful right to explanation of speciﬁc\\nautomated decisions will not be introduced by the\\nGDPR, the contribution of such a right to the account-\\nability and transparency of automated decision-making\\nmay provide compelling reasons for legislators or data\\ncontrollers to introduce one in the future. It is possible\\nto envisage at least four main scenarios that may lead to\\n81 BGH, 2812014 - VI ZR 156/13 - BGH: Umfang einer von der SCHUFA zu\\nerteilenden Auskunft Rn 489-494 [2014] BGH VI ZR 156/13, 2014 MMR\\nRn 494; Br€\\nautigam and Schmidt-Wudy (n 35) 61.\\n82 Paal (n 79).\\n83 Ibid.\\n84 BGH (n 54).\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 104, 'page': 15, '_split_overlap': [{'doc_id': 'bafe8b8791b7db0ac12c716c78bf93cf', 'range': (0, 283)}, {'doc_id': 'bd5222b4a16115e03eec2ff495544ebd', 'range': (891, 1186)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9bb9153e2bb2ec09df188fc10faf4000'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: It is possible\\nto envisage at least four main scenarios that may lead to\\n81 BGH, 2812014 - VI ZR 156/13 - BGH: Umfang einer von der SCHUFA zu\\nerteilenden Auskunft Rn 489-494 [2014] BGH VI ZR 156/13, 2014 MMR\\nRn 494; Br€\\nautigam and Schmidt-Wudy (n 35) 61.\\n82 Paal (n 79).\\n83 Ibid.\\n84 BGH (n 54).\\n85 Recitals 47 and 63 GDPR address protection of the interests of data\\ncontrollers. Recital 63 notes, in relation to the right of access, ‘That\\nright should not adversely affect the rights or freedoms of others,\\nincluding trade secrets or intellectual property and in particular the\\ncopyright protecting the software.’\\n86 Art 23(1) GDPR addresses possible further limitations on obligations\\nand rights under arts 12–22, including the right of access; art 89(2)\\nsimilarly allows for limitations on rights and obligations for processing\\nfor scientiﬁc or historical research or statistical purposes. Finally,\\nart 89(3) addresses limitations for processing for archiving purposes or\\nin the public interest.\\n87 On “meaningful information” and Article 13, see Paal (n 32) Rn 19–22.\\nThe general purpose of the right of access according to art 15 GDPR is\\nthe realisation of the so-called ‘two step model’. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 105, 'page': 15, '_split_overlap': [{'doc_id': '9bb9153e2bb2ec09df188fc10faf4000', 'range': (0, 295)}, {'doc_id': '1579f4b3f9e1954c19d2556d98b9b7e4', 'range': (1072, 1193)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bd5222b4a16115e03eec2ff495544ebd'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The general purpose of the right of access according to art 15 GDPR is\\nthe realisation of the so-called ‘two step model’. In a ﬁrst step data sub-\\njects have to right to (i) know if their data is being processed and (ii) if\\nso, what data are used. In some cases data controllers have to provide\\nadditional information (such as the logic involved in processing).\\nFurther, ibid Rn 31 the author suggests that the content and scope of the\\ndisclosure according to art 13 is the same as in art 15. The authors cite\\nBr€\\nautigam and Schmidt-Wudy (n 35) in discussing the scope of art 13\\nGDPR as one of the sources to limit the data controller’s obligations\\nunder art 15. This suggests that arts 13 and 15 GDPR do not differ in the\\nobligation of the data controllers to disclose information. See also Paal (n\\n79) Rn 31–33. On disclosure of the algorithm, see: Paal Paal/Pauly,\\nDatenschutz-Grundverordnung, DS-GVO Art. 13 Informationspﬂicht\\nbei Erhebung von personenbezogenen Daten bei der betroffenen Person,\\nRn. 31–32. On the necessity of disclosure to verify accuracy, see:\\nSchmidt-Wudy in Beck’scher Online-Kommentar Datenschutzrecht,\\nWolff/Brink 19. Edition, DS-GVO Artikel 15 Auskunftsrecht der\\nbetroffenen Person, Rn. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 106, 'page': 15, '_split_overlap': [{'doc_id': 'bd5222b4a16115e03eec2ff495544ebd', 'range': (0, 121)}, {'doc_id': '4e166b5befb1e5bf0426ba6c275d8a3', 'range': (1012, 1215)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1579f4b3f9e1954c19d2556d98b9b7e4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: On the necessity of disclosure to verify accuracy, see:\\nSchmidt-Wudy in Beck’scher Online-Kommentar Datenschutzrecht,\\nWolff/Brink 19. Edition, DS-GVO Artikel 15 Auskunftsrecht der\\nbetroffenen Person, Rn. 76-80.\\n88 The Board ﬁlls a similar role to the Article 29 Working Party established\\nby the Directive. Interestingly, the Board has explicitly been called upon\\nin art 70(1)f to ‘issue guidelines, recommendations and best practices . . .\\nfor further specifying the criteria and conditions for decisions based on\\nproﬁling pursuant to Article 22(2).’ In doing so, the GDPR is implicitly\\nacknowledging that the applicability of the three cases speciﬁed in art\\n22(2) (contract, Union or Member State law, or consent) remains an\\nopen issue.\\n89 European Data Protection Supervisor, ‘Ethics Advisory Group’ (2015)\\n<https://secure.edps.europa.eu/EDPSWEB/edps/EDPS/Ethics> accessed\\n8 March 2017.\\n90 ARTICLE International Data Privacy Law, 2017, Vol. 7, No. 2\\x0ca right of explanation of speciﬁc automated decisions in\\npractice:\\n\\x15 An additional legal requirement is enacted by\\nMember States, separate from the GDPR, granting a\\nright of explanation of speciﬁc decisions (similar to\\nactions taken by German legislators under the 1995\\nDirective) (see also ‘Conclusion’ section).\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 107, 'page': 15, '_split_overlap': [{'doc_id': '1579f4b3f9e1954c19d2556d98b9b7e4', 'range': (0, 203)}, {'doc_id': 'fb8c1e59f58af0f28c0369e7d0d9e67c', 'range': (950, 1265)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4e166b5befb1e5bf0426ba6c275d8a3'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 2\\x0ca right of explanation of speciﬁc automated decisions in\\npractice:\\n\\x15 An additional legal requirement is enacted by\\nMember States, separate from the GDPR, granting a\\nright of explanation of speciﬁc decisions (similar to\\nactions taken by German legislators under the 1995\\nDirective) (see also ‘Conclusion’ section).\\n\\x15 Based on GDPR Article 22 and Recital 71, data con-\\ntrollers voluntary choose to offer a right to explana-\\ntion of speciﬁc decisions as a ‘suitable . . . safeguard’.\\nThe right would be an additional and voluntary safe-\\nguard to those already required by Article 22(3).\\nControllers could do this on the basis that an explan-\\nation is required to invoke one of the three legally\\nrequired Article 22(3) safeguards, ie express their\\nviews, obtain human intervention, or contest a\\ndecision.\\n\\x15 Future jurisprudence broadly interprets the safe-\\nguards against automated decision-making (Article\\n22(3)) to establish a right to explanation of speciﬁc\\ndecisions. This could occur, for example, on the basis\\nthat an explanation of the rationale of an automated\\ndecision is required in order to contest it or express\\nviews. Future guidelines of the European Data\\nProtection Board could support this interpretation.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 108, 'page': 15, '_split_overlap': [{'doc_id': '4e166b5befb1e5bf0426ba6c275d8a3', 'range': (0, 315)}, {'doc_id': '2170a0fae03156ab77918a7d9b6700f6', 'range': (970, 1219)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fb8c1e59f58af0f28c0369e7d0d9e67c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: This could occur, for example, on the basis\\nthat an explanation of the rationale of an automated\\ndecision is required in order to contest it or express\\nviews. Future guidelines of the European Data\\nProtection Board could support this interpretation.\\n\\x15 Future jurisprudence establishes that the right of\\naccess (Article 15 GDPR) provides a basis for explan-\\nations of speciﬁc automated decisions, as a require-\\nment to provide information about the ‘existence of\\n. . . logic involved . . . signiﬁcance . . . [or] envisaged\\nconsequences’ of automated decision-making\\n(Article 15(h)1). This interpretation could also be\\nsupported in future guidelines of the European Data\\nProtection Board.\\nOf these scenarios, the third and fourth seem to be the\\nmost plausible at the moment. Concerning the third,\\nArticle 22(3) guarantees that human intervention is\\navailable for automated decisions rendered in fulﬁlment\\nof a contract or with explicit consent (see below). On\\nthis basis, one may argue that, although it is certainly\\nnot explicit in the phrasing of Article 22(3), the right to\\nobtain human intervention, express views or contest a\\ndecision is meaningless if the data subject cannot under-\\nstand how the contested decision was taken. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 109, 'page': 16, '_split_overlap': [{'doc_id': 'fb8c1e59f58af0f28c0369e7d0d9e67c', 'range': (0, 249)}, {'doc_id': '4c254d9c46fd0af864d2db5f71feb256', 'range': (955, 1230)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2170a0fae03156ab77918a7d9b6700f6'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: On\\nthis basis, one may argue that, although it is certainly\\nnot explicit in the phrasing of Article 22(3), the right to\\nobtain human intervention, express views or contest a\\ndecision is meaningless if the data subject cannot under-\\nstand how the contested decision was taken. The right\\nto contest has already been interpreted by Member\\nStates, in enacting the 1995 Directive, as merely a right\\nto force a controller to make a new decision. This\\ninterpretation is found in the UK Data Protection Act\\n1998 (Article 12(2)b): subjects can demand a new deci-\\nsion to be made, albeit without any way to assess the\\nreliability of the old decision. A broad reading of Article\\n22(3), according to which an explanation is required to\\ncontest a decision, would strengthen the right to con-\\ntest. In this case, the argument for a right to explanation\\nof speciﬁc decisions could be further buttressed by\\ndrawing on the rights to fair trial and effective remedy\\nenshrined in Articles 6 and 13 of the European\\nConvention on Human Rights and Article 47 of the\\nCharter of Fundamental Rights of the European Union.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 110, 'page': 16, '_split_overlap': [{'doc_id': '2170a0fae03156ab77918a7d9b6700f6', 'range': (0, 275)}, {'doc_id': '76620d9b907d4d5b424b49d74dca09bd', 'range': (785, 1096)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4c254d9c46fd0af864d2db5f71feb256'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: In this case, the argument for a right to explanation\\nof speciﬁc decisions could be further buttressed by\\ndrawing on the rights to fair trial and effective remedy\\nenshrined in Articles 6 and 13 of the European\\nConvention on Human Rights and Article 47 of the\\nCharter of Fundamental Rights of the European Union.\\nWithout an explanation of how the algorithm works,\\nboth rights are hard to enforce, because the decisions/\\nevidence used will be impossible to contest in court.90\\nConcerning the fourth option, implementation of\\nthe right of access in the 1995 Directive has shown the\\nneed for interpretation of vague provisions by Member\\nStates and national courts. As noted above, consensus\\nhas not emerged over the meaning or requirements\\nimplied for data controllers when explaining the ‘logic\\ninvolved’ in automated individual decisions. Austrian\\njurisprudence has demonstrated that the scope of ‘logic\\ninvolved’ is sufﬁciently broad to include that some ele-\\nments of the rationale or circumstances of a speciﬁc\\ndecision be explained along with system functionality,\\nalbeit limited severely by data controller’s interests (eg\\ntrade secrets). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 111, 'page': 16, '_split_overlap': [{'doc_id': '4c254d9c46fd0af864d2db5f71feb256', 'range': (0, 311)}, {'doc_id': '98be2ed70d9ee8add3103960a7c3033e', 'range': (837, 1141)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '76620d9b907d4d5b424b49d74dca09bd'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Austrian\\njurisprudence has demonstrated that the scope of ‘logic\\ninvolved’ is sufﬁciently broad to include that some ele-\\nments of the rationale or circumstances of a speciﬁc\\ndecision be explained along with system functionality,\\nalbeit limited severely by data controller’s interests (eg\\ntrade secrets). Despite aiming to unify data protection\\nlaw across the Member States, the GDPR’s right of\\naccess will need to be similarly interpreted and tested.\\nGiven that the reference to ‘logic involved’ occurs in\\nboth the Directive and GDPR, it is plausible (but\\nunlikely) that future legal interpretation of the right of\\naccess could establish a right to explanation of speciﬁc\\ndecisions.\\nLimitations on a right to explanation derived\\nfrom the right of access (Article 15) or\\nsafeguards against automated decision-making\\n(Article 22(3))\\nAssuming one or indeed a combination of the previous\\nfour scenarios occurs, and hence that a right to explana-\\ntion of speciﬁc decisions is granted, other provisions in\\nthe GDPR may still limit its scope signiﬁcantly. A ‘gen-\\neral’ right to explanation as proposed elsewhere (see\\n‘Introduction’ section), seemingly applicable to all types\\nof automated processing, would not exist. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 112, 'page': 16, '_split_overlap': [{'doc_id': '76620d9b907d4d5b424b49d74dca09bd', 'range': (0, 304)}, {'doc_id': '1dd6ea195a6de2ba2c4ce02192e64ec3', 'range': (1050, 1212)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '98be2ed70d9ee8add3103960a7c3033e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: A ‘gen-\\neral’ right to explanation as proposed elsewhere (see\\n‘Introduction’ section), seemingly applicable to all types\\nof automated processing, would not exist. A primary\\n90 Tal Zarsky, ‘Transparent Predictions’ (2013) 2013 University of Illinois\\nLaw Review <http://papers.ssrn.com/sol3/Papers.cfm?abstract_\\nid¼2324240> accessed 17 June 2016. A right to contest realised through\\nexpert human intervention may be the most pragmatic safeguard against\\nautomated decisions. Elsewhere it has been argued that transparency dis-\\nclosures prove more impactful if tailored towards trained third parties or\\nregulators as opposed to data subjects themselves.\\nSandra Wachter et al. Á No Right to Explanation of Automated Decision-Making 91\\nARTICLE\\x0climitation is the narrow deﬁnition of automated\\ndecision-making in Article 22(1),91 deﬁned as:\\na decision based solely on automated processing, including\\nproﬁling, which produces legal effects concerning [the data\\nsubject] or similarly signiﬁcantly affects him or her.\\nAn automated process must meet this deﬁnition for\\nArticles 15(1)h (right of access) or 22(3) to apply, and\\nthus for a future right to explanation established on\\neither basis to be invoked.\\nAutomated decision-making must have ‘legal or\\nother signiﬁcant effects’, with a decision based ‘solely on\\nautomated processing of data’ (Article 22(1)). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 113, 'page': 16, '_split_overlap': [{'doc_id': '98be2ed70d9ee8add3103960a7c3033e', 'range': (0, 162)}, {'doc_id': 'de4904d567e6bef74a8a8c3be287ccac', 'range': (1196, 1348)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1dd6ea195a6de2ba2c4ce02192e64ec3'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Automated decision-making must have ‘legal or\\nother signiﬁcant effects’, with a decision based ‘solely on\\nautomated processing of data’ (Article 22(1)). The latter\\nrequirement opens a loophole whereby any human\\ninvolvement in a decision-making process could mean\\nit is not ‘automated decision-making’.92 While the\\nrequired level of human involvement is not clear in\\npractice, the phrase ‘solely’ suggests even some nominal\\nhuman involvement may be sufﬁcient. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 114, 'page': 17, '_split_overlap': [{'doc_id': '1dd6ea195a6de2ba2c4ce02192e64ec3', 'range': (0, 152)}, {'doc_id': '407e5215980d838e0827427a9ad9ff1c', 'range': (153, 458)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'de4904d567e6bef74a8a8c3be287ccac'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The latter\\nrequirement opens a loophole whereby any human\\ninvolvement in a decision-making process could mean\\nit is not ‘automated decision-making’.92 While the\\nrequired level of human involvement is not clear in\\npractice, the phrase ‘solely’ suggests even some nominal\\nhuman involvement may be sufﬁcient. There is still\\nuncertainty as to whether the usage of automated proc-\\nessing for the preparation of a decision ultimately acted\\nupon by a human constitutes a decision ‘solely based on\\nautomated processing’, if the human does not interfere,\\nverify, or modify the decision or decision-making\\nrationale.93 Preparation of evidence for a decision, and\\nmaking the decision itself, are not necessarily equivalent\\nacts.94 Martini believes that automated processing of\\ndata for ‘assistance to make a decision’ or ‘preparation\\nof a decision’ is not within the scope of Article 22.95\\nDecisions based predominantly on automated proc-\\nesses, but with nominal human involvement, would\\nthus not invoke Article 15(1)h (right of access) or\\nArticle 22(3) (safeguards against automated decision-\\nmaking), and thus would not require an explanation of\\nsystem functionality or the rationale of speciﬁc deci-\\nsions, assuming that such a right to explanation of spe-\\nciﬁc decisions was established on either basis.96\\nInterpretation of Article 15 of the Directive, which\\nwas also limited to decisions ‘based solely on automated\\ndata processing’, does not provide clariﬁcation. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 115, 'page': 17, '_split_overlap': [{'doc_id': 'de4904d567e6bef74a8a8c3be287ccac', 'range': (0, 305)}, {'doc_id': 'd0ffefac15460d52ca9e2abff50a8d9', 'range': (306, 1457)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '407e5215980d838e0827427a9ad9ff1c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: There is still\\nuncertainty as to whether the usage of automated proc-\\nessing for the preparation of a decision ultimately acted\\nupon by a human constitutes a decision ‘solely based on\\nautomated processing’, if the human does not interfere,\\nverify, or modify the decision or decision-making\\nrationale.93 Preparation of evidence for a decision, and\\nmaking the decision itself, are not necessarily equivalent\\nacts.94 Martini believes that automated processing of\\ndata for ‘assistance to make a decision’ or ‘preparation\\nof a decision’ is not within the scope of Article 22.95\\nDecisions based predominantly on automated proc-\\nesses, but with nominal human involvement, would\\nthus not invoke Article 15(1)h (right of access) or\\nArticle 22(3) (safeguards against automated decision-\\nmaking), and thus would not require an explanation of\\nsystem functionality or the rationale of speciﬁc deci-\\nsions, assuming that such a right to explanation of spe-\\nciﬁc decisions was established on either basis.96\\nInterpretation of Article 15 of the Directive, which\\nwas also limited to decisions ‘based solely on automated\\ndata processing’, does not provide clariﬁcation. The\\nstrict reading of ‘solely’ by Martini was reﬂected in the\\nSCHUFA judgements already discussed (see section\\n‘Right of access in the 1995 Data Protection Directive\\n95/46/EC’). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 116, 'page': 17, '_split_overlap': [{'doc_id': '407e5215980d838e0827427a9ad9ff1c', 'range': (0, 1151)}, {'doc_id': '4ea22d4eb935a7c857906a234aac32d5', 'range': (1152, 1329)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd0ffefac15460d52ca9e2abff50a8d9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The\\nstrict reading of ‘solely’ by Martini was reﬂected in the\\nSCHUFA judgements already discussed (see section\\n‘Right of access in the 1995 Data Protection Directive\\n95/46/EC’). In contrast, Bygrave argues that a relative\\nnotion of ‘solely’ is required for the phrase to be mean-\\ningful. According to this position, decisions formally\\nattributed to humans, but originating ‘from an auto-\\nmated data-processing operation the result of which is\\nnot actively assessed by either that person or other per-\\nsons before being formalised as a decision’, would fall\\nunder the scope of ‘automated decision-making’.97 It is\\nnot clear how this provision in the GDPR will be inter-\\npreted in the future.\\nThe scope of data processing to which Article 22\\n(and Recital 71) applies was narrowed in the adopted\\nversion of the GDPR compared to prior drafts. The\\nphrase ‘a decision based solely on automated proc-\\nessing’ proved a point of contention between the EC\\nand EP drafts. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 117, 'page': 17, '_split_overlap': [{'doc_id': 'd0ffefac15460d52ca9e2abff50a8d9', 'range': (0, 177)}, {'doc_id': '9a33fff023f8153eb48360ba0dcce285', 'range': (839, 960)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4ea22d4eb935a7c857906a234aac32d5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The\\nphrase ‘a decision based solely on automated proc-\\nessing’ proved a point of contention between the EC\\nand EP drafts. Article 20(5) of the EP’s proposed\\namendments98 to the EC’s draft99 adds the phrase ‘pre-\\ndominantly’ to the measures to which the Article would\\napply (‘Proﬁling which leads to measures producing\\nlegal effects concerning the data subject or does simi-\\nlarly signiﬁcantly affect the interests, rights or freedoms\\nof the concerned data subject shall not be based solely or\\npredominantly on automated processing and shall include\\nhuman assessment . . .’ (emphasis added)). Following\\nthis, the EP wanted to restrict automated decisions on a\\nbroader basis than the EC, ie those predominantly and\\nnot only solely on automated processes. With\\n‘predominantly’ not being adopted in the ﬁnal text of\\nthe GDPR, it would appear the strict reading of ‘solely’\\nwas intended.\\nQuestions can also be raised over what constitutes\\n‘legal effects’ or ‘similarly signiﬁcant effects’100 required\\nfor Article 22 to apply. Recital 71 provides some guid-\\nance, as it describes certain situations of ‘signiﬁcances’\\neg online credit applications and e-recruiting practices.\\nWhere a decision has no legal or signiﬁcant effect,\\nArticle 22 does not apply. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 118, 'page': 17, '_split_overlap': [{'doc_id': '4ea22d4eb935a7c857906a234aac32d5', 'range': (0, 121)}, {'doc_id': 'af36d506ad555d61040e1f761ec87b48', 'range': (1021, 1247)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9a33fff023f8153eb48360ba0dcce285'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Recital 71 provides some guid-\\nance, as it describes certain situations of ‘signiﬁcances’\\neg online credit applications and e-recruiting practices.\\nWhere a decision has no legal or signiﬁcant effect,\\nArticle 22 does not apply. For an automated decision to\\n91 Bygrave (n 45) discusses comparable limitations on the deﬁnition of\\n‘automated individual decisions’ in the 1995 Directive.\\n92 This position is also adopted in Fusion (n 1); Bygrave (n 45);\\nHildebrandt (n 78) 51 in reference to the EC’s 2012 draft, explains that\\nhuman intervention will render art 20 inapplicable.\\n93 Martini (n 34) Rn 16–19.\\n94 Bygrave (n 45).\\n95 Martini (n 34) Rn 20.\\n96 Possible grounds for opposing views to Martini can be found in\\nDimitrios Pachtitis v European Commission F-35/08 [2010] European\\nCivil Service Tribunal ECLI:EU:F:2010:51 [63] <http://eur-lex.europa.\\neu/legal-content/EN/ALL/?uri¼CELEX%3A62008FJ0035> accessed 22\\nFebruary 2017: ‘Furthermore, although it is true that, as the Commission\\nobserves, the correction of the admission tests was carried out by com-\\nputer and that, therefore, it is based on an automated procedure with no\\nsubjective discretion, the fact remains that the conduct of that automated\\nprocedure involved a decision on the merits, in so far as the ‘advisory\\ncommittee’ . . . ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 119, 'page': 17, '_split_overlap': [{'doc_id': '9a33fff023f8153eb48360ba0dcce285', 'range': (0, 226)}, {'doc_id': '43b777d0f2190e083bafb2108a5fca29', 'range': (848, 1291)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'af36d506ad555d61040e1f761ec87b48'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: eu/legal-content/EN/ALL/?uri¼CELEX%3A62008FJ0035> accessed 22\\nFebruary 2017: ‘Furthermore, although it is true that, as the Commission\\nobserves, the correction of the admission tests was carried out by com-\\nputer and that, therefore, it is based on an automated procedure with no\\nsubjective discretion, the fact remains that the conduct of that automated\\nprocedure involved a decision on the merits, in so far as the ‘advisory\\ncommittee’ . . . ﬁrst, determined the level of difﬁculty of the multiple\\nchoice questions set during the admission tests and, second, cancelled\\ncertain questions, as recounted in paragraph 26 of this judgment. Those\\nare evidently tasks to be carried out by a competition selection board.’\\n97 Bygrave (n 45).\\n98 European Parliament Committee on Civil Liberties, Justice and Home\\nAffairs (n 24).\\n99 European Commission (n 25).\\n100 Martini (n 34) Rn 25–28. Legal effects must inﬂuence the legal status of\\nthe data subject, whereas signiﬁcant effects could mean [our translation\\nof Rn 27] ‘being denied to be part of a contract or being denied to choose\\na payment method e.g. PayPal.’\\n92 ARTICLE International Data Privacy Law, 2017, Vol. 7, No. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 120, 'page': 17, '_split_overlap': [{'doc_id': 'af36d506ad555d61040e1f761ec87b48', 'range': (0, 443)}, {'doc_id': 'dd315bd93214ad63c2cbebedbf52a46a', 'range': (881, 1168)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '43b777d0f2190e083bafb2108a5fca29'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Legal effects must inﬂuence the legal status of\\nthe data subject, whereas signiﬁcant effects could mean [our translation\\nof Rn 27] ‘being denied to be part of a contract or being denied to choose\\na payment method e.g. PayPal.’\\n92 ARTICLE International Data Privacy Law, 2017, Vol. 7, No. 2\\x0chave legal effects on the data subjects, it would need to\\naffect their legal status.101 Since in most cases the data\\nsubject has no legal right to be hired or to be approved\\nfor a credit application, cases of being denied an inter-\\nview or credit by an automated process would not fall\\nunder these categories.102 Admittedly, such cases could\\nbe considered to have ‘similarly signiﬁcant’ effects.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 121, 'page': 17, '_split_overlap': [{'doc_id': '43b777d0f2190e083bafb2108a5fca29', 'range': (0, 287)}, {'doc_id': '45a8db9618a542b2405e0f684704f3c0', 'range': (288, 685)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'dd315bd93214ad63c2cbebedbf52a46a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 2\\x0chave legal effects on the data subjects, it would need to\\naffect their legal status.101 Since in most cases the data\\nsubject has no legal right to be hired or to be approved\\nfor a credit application, cases of being denied an inter-\\nview or credit by an automated process would not fall\\nunder these categories.102 Admittedly, such cases could\\nbe considered to have ‘similarly signiﬁcant’ effects.\\nHowever, the term ‘similarly signiﬁcant’ is itself vague\\nand requires interpretation; signiﬁcance varies on the\\nperception of the data subject (effects of receiving a\\nrejection letter will depend on the economic situation of\\nthe data subject, for instance), whereas impacts on legal\\nstatus can be determined according to the letter of the\\nlaw.103 Further, in practice it may cause a burden for\\nthe data subject to prove that processing affects them\\nsigniﬁcantly.104 Alternatively an external standard for\\nwhat constitutes signiﬁcant effects could be deﬁned.\\nAs these constraints demonstrate, the deﬁnition of\\nautomated decision-making in Article 22(1) signiﬁ-\\ncantly narrows the scope of any future right to explana-\\ntion. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 122, 'page': 17, '_split_overlap': [{'doc_id': 'dd315bd93214ad63c2cbebedbf52a46a', 'range': (0, 397)}, {'doc_id': '39ae31cb57cbc85485e60374209f1b48', 'range': (956, 1120)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '45a8db9618a542b2405e0f684704f3c0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: As these constraints demonstrate, the deﬁnition of\\nautomated decision-making in Article 22(1) signiﬁ-\\ncantly narrows the scope of any future right to explana-\\ntion. Automated decision-making that does not meet\\nthe deﬁnition provided in Article 22(1) would not be\\nconstrained by provisions of Article 22, or the addi-\\ntional measures required as part of notiﬁcation duties\\n(Article 13(2)f and 14(2)g) or the right of access (Article\\n15(1)h), including information regarding the ‘logic\\ninvolved’ (see section ‘A right to explanation derived\\nfrom the right of access’). A right to explanation imple-\\nmented through any of the four paths speciﬁed above\\nwould similarly not apply, still signiﬁcantly narrowing\\nthe right’s potential applicability to a very narrow range\\nof cases meeting all the requirements in Article 22(1)\\nand discussed in this section.\\nA further factor would constrain the information\\noffered as part of an explanation. As indicated in the dis-\\ncussion of the right of access in the 1995 Directive, any\\nfuture right to explanation would likely also be limited by\\noverriding interests of the data controller. Recital 63 of the\\nGDPR similarly establishes that the right of access should\\nnot infringe upon the rights and freedoms of others,\\nincluding data controllers. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 123, 'page': 18, '_split_overlap': [{'doc_id': '45a8db9618a542b2405e0f684704f3c0', 'range': (0, 164)}, {'doc_id': '1e6a5c293ebf5ff54e0e273135ee06ca', 'range': (1122, 1279)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '39ae31cb57cbc85485e60374209f1b48'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Recital 63 of the\\nGDPR similarly establishes that the right of access should\\nnot infringe upon the rights and freedoms of others,\\nincluding data controllers. The right can be limited for the\\nsake of trade secrets or intellectual property rights, espe-\\ncially regarding copyright of software. As with the right of\\naccess itself, the speciﬁc disclosure requirements of Recital\\n63 require interpretation.105 The Recital notes that:\\nthe result of those considerations should not be a refusal to\\nprovide all information to the data subject.\\nJurisprudence and legal commentary concerning the\\nDirective’s right of access (see section ‘Right of access in\\nthe 1995 Data Protection Directive 95/46/EC’) suggest\\nthat the balance between the data subject’s right of\\naccess and data controllers’ rights and freedoms will\\nrequire limited disclosures of the ‘logic involved’ in\\nautomated decision-making, primarily concerning sys-\\ntem functionality rather than the rationale and circum-\\nstances of speciﬁc decisions.\\nLimitations exclusive to a right to explanation\\nderived from safeguards against automated\\ndecision-making (Article 22(3))\\nIn addition to the above limitations on a future right to\\nexplanation, a number of further limitations are exclu-\\nsive to a right derived from Article 22(3). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 124, 'page': 18, '_split_overlap': [{'doc_id': '39ae31cb57cbc85485e60374209f1b48', 'range': (0, 157)}, {'doc_id': '41ab18bbfec4cd62bf9040068e540dcd', 'range': (1002, 1281)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1e6a5c293ebf5ff54e0e273135ee06ca'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Limitations exclusive to a right to explanation\\nderived from safeguards against automated\\ndecision-making (Article 22(3))\\nIn addition to the above limitations on a future right to\\nexplanation, a number of further limitations are exclu-\\nsive to a right derived from Article 22(3). In the ﬁrst\\ninstance, Article 22(2) states three conditions that, if\\nmet by an automated decision-making process, cause\\nArticle 22(1) not to apply:\\n(a) is necessary for entering into, or performance of, a con-\\ntract between the data subject and a data controller;\\n(b) is authorised by Union or Member State law to which\\nthe controller is subject and which also lays down suitable\\nmeasures to safeguard the data subject’s rights and free-\\ndoms and legitimate interests; or\\n(c) is based on the data subject’s explicit consent.\\nArticle 22(3) speciﬁes that safeguards (ie the rights to\\nhuman intervention, expression, and contest) only\\napply when automated decision-making meets Article\\n22(2)a or c. The scope of any future right to explanation\\nenacted in relation to the safeguards speciﬁed in Article\\n22(3) is therefore limited to cases meeting clause (a) or\\n(c), ie those necessary for entering or performing a con-\\ntract,106 or with the subject’s explicit consent. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 125, 'page': 18, '_split_overlap': [{'doc_id': '1e6a5c293ebf5ff54e0e273135ee06ca', 'range': (0, 279)}, {'doc_id': '329f18ff516d22e8408b90ef11f08dff', 'range': (805, 1244)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '41ab18bbfec4cd62bf9040068e540dcd'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Article 22(3) speciﬁes that safeguards (ie the rights to\\nhuman intervention, expression, and contest) only\\napply when automated decision-making meets Article\\n22(2)a or c. The scope of any future right to explanation\\nenacted in relation to the safeguards speciﬁed in Article\\n22(3) is therefore limited to cases meeting clause (a) or\\n(c), ie those necessary for entering or performing a con-\\ntract,106 or with the subject’s explicit consent. It is worth\\nnoting that the safeguards in 22(3) do not apply when a\\ndecision is made in accordance with Union or Member\\nState law (Article 22(2)b). In the latter case, explicit and\\n101 Bygrave (n 45).\\n102 Lewinski (n 51) Rn 28–31; ibid Rn 32–37.\\n103 Bygrave (n 45).\\n104 Hajar Malekian, ‘Proﬁling under General Data Protection Regulation\\n(GDPR): Stricter Regime?’ [2016] ResearchGate <https://www.research\\ngate.net/publication/304102392_Proﬁling_under_General_Data_\\nProtection_Regulation_GDPR_Stricter_Regime> accessed 20 November\\n2016.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 126, 'page': 18, '_split_overlap': [{'doc_id': '41ab18bbfec4cd62bf9040068e540dcd', 'range': (0, 439)}, {'doc_id': '1b10da0e8c2e0b7da3086f317599630b', 'range': (706, 975)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '329f18ff516d22e8408b90ef11f08dff'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 104 Hajar Malekian, ‘Proﬁling under General Data Protection Regulation\\n(GDPR): Stricter Regime?’ [2016] ResearchGate <https://www.research\\ngate.net/publication/304102392_Proﬁling_under_General_Data_\\nProtection_Regulation_GDPR_Stricter_Regime> accessed 20 November\\n2016.\\n105 Recital 63 suggests the right of access should allow a data subject to\\n‘know and obtain communication in particular with regard to the\\npurposes for which the personal data are processed, where possible the\\nperiod for which the personal data are processed, the recipients of the\\npersonal data, the logic involved in any automatic personal data process-\\ning and, at least when based on proﬁling, the consequences of such\\nprocessing’.\\n106 Martini (n 34) Rn 31–32., according to whom the necessity for the per-\\nformance of a contract hinges on the agreed goals of the contract between\\nthe data controller and the data subject. However, the authors do not\\nconsider the vagueness of the passage and fail to address the lack of con-\\nsent which is not a precondition as is it listed under lit. C.\\nSandra Wachter et al. Á No Right to Explanation of Automated Decision-Making 93\\nARTICLE\\x0cspeciﬁc safeguards are not described. Rather, ‘suitable\\nmeasures to safeguard the data subject’ must be laid\\ndown in the relevant Union or Member State law. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 127, 'page': 18, '_split_overlap': [{'doc_id': '329f18ff516d22e8408b90ef11f08dff', 'range': (0, 269)}, {'doc_id': '11d304ea5331128271e209cf9256d04e', 'range': (1189, 1307)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1b10da0e8c2e0b7da3086f317599630b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Rather, ‘suitable\\nmeasures to safeguard the data subject’ must be laid\\ndown in the relevant Union or Member State law. This\\nclause potentially excludes a signiﬁcant range of cases of\\nautomated decision-making from the safeguards in\\nArticle 22(3) and any right to explanation derived\\nthereof. German commentary on the GDPR has sug-\\ngested that the ‘suitable measures’ called for in Article\\n22(2)b do not include the disclosure of the algorithm\\nused due to the risk posed to trade secrets; however,\\nmeasures to minimize and correct discrimination and\\nbiases should be implemented.107\\nThe exemption for automated decisions related to\\ncontracts raises a further limitation. Article 22 does not\\ndeﬁne when automated decision-making is ‘necessary’\\nfor entering or performing a contract, which runs the\\nrisk of ‘necessity’ being deﬁned solely by the data con-\\ntroller. Additionally, it is important to note that Article\\n22(2)a envisions a situation that is different from\\nexplicit consent (which is listed as a separate exception\\nin Article 22(2)c). Legislators were contemplating a sit-\\nuation where data controllers make automated deci-\\nsions that are necessary for a contract, but without\\nseeking consent ﬁrst. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 128, 'page': 19, '_split_overlap': [{'doc_id': '1b10da0e8c2e0b7da3086f317599630b', 'range': (0, 118)}, {'doc_id': '69df53f9faf41d1c128670fbedfb35f4', 'range': (1043, 1206)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '11d304ea5331128271e209cf9256d04e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Legislators were contemplating a sit-\\nuation where data controllers make automated deci-\\nsions that are necessary for a contract, but without\\nseeking consent ﬁrst. If consent would be necessary, it\\nwould have been enough to list the contractual excep-\\ntion under Article 22(2)c. This structure suggests that\\nthere can be situations in which the data subject does\\nnot consent to an automated decision and, apart from\\nthe general notiﬁcation requirements and right of access\\nin Articles 13–15, does not know about the decision.\\nData controllers are therefore allowed to decide that\\nautomated decision-making is necessary for contractual\\nobligations, while the data subject is unable to object to\\nit. In this case, the data subject retains the right to con-\\ntest, express views or obtain human intervention for a\\ndecision reached under Article 22(3), but not to object\\nto it being made in the ﬁrst place.\\nTwo interpretations of Article 22\\nSeveral other restrictions on Article 22(3) and any\\nfuture right to explanation derived thereof depend\\nupon whether Article 22 is interpreted as a prohibition\\nor a right to object. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 129, 'page': 19, '_split_overlap': [{'doc_id': '11d304ea5331128271e209cf9256d04e', 'range': (0, 163)}, {'doc_id': 'fc86fa3087aaa98cb4b734e9baeffffd', 'range': (902, 1116)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '69df53f9faf41d1c128670fbedfb35f4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Two interpretations of Article 22\\nSeveral other restrictions on Article 22(3) and any\\nfuture right to explanation derived thereof depend\\nupon whether Article 22 is interpreted as a prohibition\\nor a right to object. Article 22(1) GDPR states that ‘the\\ndata subject shall have the right not to be subject to a\\ndecision based solely on automated processing, includ-\\ning proﬁling, which produces legal effects concerning\\nhim or her or similarly signiﬁcantly affects him or her’.\\nDue to its language (‘a right not to’), Article 22(1) can\\nbe interpreted in two ways: as a prohibition108 or a right\\nto object to automated decision-making. The two inter-\\npretations offer very different protection to the interests\\nof data subjects and data controllers.\\nThe ﬁrst interpretation reads Article 22(1) as a pro-\\nhibition, meaning that data controllers would be obli-\\ngated not to engage in automated decision-making\\nprior to showing that a condition in Article 22(2)a-c is\\nmet. The second interpretation reads Article 22(1) as\\nestablishing for data subjects a right to object to auto-\\nmated decision-making, which will not apply if one of\\nthe requirements in Article 22(2)a-c are met. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 130, 'page': 19, '_split_overlap': [{'doc_id': '69df53f9faf41d1c128670fbedfb35f4', 'range': (0, 214)}, {'doc_id': 'ddd153b02bc07dc6def9027cde315fb6', 'range': (966, 1172)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fc86fa3087aaa98cb4b734e9baeffffd'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The second interpretation reads Article 22(1) as\\nestablishing for data subjects a right to object to auto-\\nmated decision-making, which will not apply if one of\\nthe requirements in Article 22(2)a-c are met. These\\ninterpretations are differentiated by whether action is\\nrequired by the data subject to restrict automated\\ndecision-making. The action in question, a formal\\nobjection by the data subject, requires both awareness\\nof the existence of automated decision-making and a\\nwillingness to intercede, both of which require inten-\\ntional effort on the part of the data subject.\\nNotably, this ambiguity has existed since the Data\\nProtection Directive 1995.109 The wording of Article 15\\nof the Directive110 allowed the ‘right not to be subject of\\nan automated decision’ referred to in Section 1\\n(‘Member States shall grant the right to every person not\\nto be subject to a decision which produces legal effects\\nconcerning him or signiﬁcantly affects him and which is\\nbased solely on automated processing . . .’ (emphasis\\nadded)) to be interpreted as a prohibition or a right to\\nobject.111 The ambiguity led Member States to imple-\\nment this right and associated protections differently.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 131, 'page': 19, '_split_overlap': [{'doc_id': 'fc86fa3087aaa98cb4b734e9baeffffd', 'range': (0, 206)}, {'doc_id': '9fd416b09bac2bb16412e4c1d6704296', 'range': (1006, 1184)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ddd153b02bc07dc6def9027cde315fb6'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: .’ (emphasis\\nadded)) to be interpreted as a prohibition or a right to\\nobject.111 The ambiguity led Member States to imple-\\nment this right and associated protections differently.\\nArticle 15 of the Directive has been implemented by\\nAustria, Belgium, Germany, Finland, the Netherlands,\\nPortugal, Sweden and Ireland as a general\\n107 Ibid Rn 33–37.\\n108 Ibid Rn 1–7, 15 argues that it is a prohibition, however it is acknowl-\\nedged that the placement of art 22 in the ‘rights section of the data sub-\\njects’ causes confusion. The argument is based on the German\\nimplementation of the 1995 Directive into national law, which was in\\nfact phrased as a prohibition. However, the author also states that the\\nlegal status (right to object or prohibition) of art 15 of the Directive and\\nart 22 GDPR is disputed: see ibid Rn 14 a, 29.\\n109 Bird & Bird, ‘Proﬁling and Automated Decision-Taking’ <http://www.\\ntwobirds.com/$/media/pdfs/gdpr-pdfs/35–guide-to-the-gdpr–proﬁling-\\nand-automated-decisiontaking.pdf?la¼en> accessed 10 November 2016\\nexplains how different countries either have prohibitions or rights to\\nobject: ‘This could either be read as a prohibition on such processing or\\nthat the processing may take place but that individuals have a right to\\nobject to it. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 132, 'page': 19, '_split_overlap': [{'doc_id': 'ddd153b02bc07dc6def9027cde315fb6', 'range': (0, 178)}, {'doc_id': '91e65e83ad2e241b1758e2ece194e2b8', 'range': (893, 1256)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9fd416b09bac2bb16412e4c1d6704296'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: twobirds.com/$/media/pdfs/gdpr-pdfs/35–guide-to-the-gdpr–proﬁling-\\nand-automated-decisiontaking.pdf?la¼en> accessed 10 November 2016\\nexplains how different countries either have prohibitions or rights to\\nobject: ‘This could either be read as a prohibition on such processing or\\nthat the processing may take place but that individuals have a right to\\nobject to it. This ambiguity is also present in the Data Protection\\nDirective and Member States differ in their approaches to the point.’\\n110 Martini (n 34) Rn 42–44 explains how the Germans made use of the\\nmargin of appreciation of art 15 of the Directive and phrased it like a\\nprohibition.\\n111 Hildebrandt (n 78) 50 hints towards but does not make it explicit ‘it may\\nbe that if I don’t exercise the right, the automated decision is not a viola-\\ntion of the directive’. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 133, 'page': 19, '_split_overlap': [{'doc_id': '9fd416b09bac2bb16412e4c1d6704296', 'range': (0, 363)}, {'doc_id': 'eccff9eacaddb6053e99d3f080ad3fc0', 'range': (642, 821)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '91e65e83ad2e241b1758e2ece194e2b8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 111 Hildebrandt (n 78) 50 hints towards but does not make it explicit ‘it may\\nbe that if I don’t exercise the right, the automated decision is not a viola-\\ntion of the directive’. Additionally, ‘The draft Regulation, however, stipu-\\nlates that a person may only be subjected to automated decisions under\\nspeciﬁed conditions, implying that this right is not merely a right to\\nobject.’ She further explains how the same can be true for the original\\ndraft art 20 GDPR proposal of 25 January 2012; Bygrave (n 45) 3 sees art\\n15 of the Directive as sufﬁciently ambiguous to be interpreted as both a\\nprohibition and a right to object.\\n94 ARTICLE International Data Privacy Law, 2017, Vol. 7, No. 2\\x0cprohibition,112 with some exceptions. The UK has a dif-\\nferent model: data subjects are entitled to request that\\nno automated decision is made about them, but not in\\nthe case of so-called ‘exempt decisions’. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 134, 'page': 19, '_split_overlap': [{'doc_id': '91e65e83ad2e241b1758e2ece194e2b8', 'range': (0, 179)}, {'doc_id': '5ddd4481e40380ec5b121f9e68171cd1', 'range': (729, 898)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'eccff9eacaddb6053e99d3f080ad3fc0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The UK has a dif-\\nferent model: data subjects are entitled to request that\\nno automated decision is made about them, but not in\\nthe case of so-called ‘exempt decisions’. In cases where\\ndata subjects have not lodged such a request, data con-\\ntrollers have to inform them about the fact that an auto-\\nmated decision has been made as well as about the\\noutcome.113\\nDue to the similarities of language and content\\nbetween Article 15 of the Directive and Article 22\\nGDPR, the varying implementation of Article 15 as a\\nprohibition or right to object by Member states sup-\\nports the interpretation that Article 22 is ambiguous\\nand can be read as a prohibition or right to object.\\nResolving the ambiguity prior to 2018 is critical, as the\\ntwo interpretations have very different consequences for\\ndata subjects and data controllers.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 135, 'page': 20, '_split_overlap': [{'doc_id': 'eccff9eacaddb6053e99d3f080ad3fc0', 'range': (0, 169)}, {'doc_id': 'b884ca828ca98a218860e30f0af7dce4', 'range': (672, 822)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5ddd4481e40380ec5b121f9e68171cd1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Resolving the ambiguity prior to 2018 is critical, as the\\ntwo interpretations have very different consequences for\\ndata subjects and data controllers.\\nImpact of the interpretation of Article 22 on a right\\nto explanation\\nIf Article 22 is interpreted as a prohibition, data control-\\nlers will not be allowed to make automated decisions\\nabout a data subject until one of the three requirements\\nspeciﬁed in Article 22(2) (necessary to enter or to per-\\nform a contract, authorized by law, or explicit consent)\\nis met. Data subjects do not need to act to prevent auto-\\nmated decision-making, but are rather protected by\\ndefault. Supervisory Authorities would shoulder the\\nburden of enforcing Article 22 by ensuring automated\\ndecision-making is carried out legally, and could levy\\npenalties and ﬁnes in cases of illegal decision-making.\\nData controllers, when making automated decisions\\nunder Article 22(2)a or c, would need to enact safe-\\nguards as speciﬁed in Article 22(3). As explained above\\n(see section ‘What if a right to explanation were\\ngranted?’), these safeguards could be voluntarily or\\nlegally extended to include a right to explanation.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 136, 'page': 20, '_split_overlap': [{'doc_id': '5ddd4481e40380ec5b121f9e68171cd1', 'range': (0, 150)}, {'doc_id': 'b49651c8c4e61855d1d3185e8396f160', 'range': (970, 1143)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b884ca828ca98a218860e30f0af7dce4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: As explained above\\n(see section ‘What if a right to explanation were\\ngranted?’), these safeguards could be voluntarily or\\nlegally extended to include a right to explanation.\\nIf Article 22 is interpreted as a right to object, auto-\\nmated decision-making is restricted only to cases in\\nwhich the data subject actively objects. When an objec-\\ntion is entered, decision-making must be shown to meet\\nArticle 22(2)a-c. For automated decisions that meet a\\nrequirement of Article 22(2), the data subject cannot\\nobject. However, when Article 22(2)a or c is met—\\nmeaning that the decision is made under contract or\\nwith consent—the safeguards speciﬁed in Article 22(3)\\nwould also apply. In these cases, the data subject would\\nbe able to request human intervention, express her\\nviews, and contest the decision and, if enacted in the\\nfuture, demand a right to explanation (see section ‘A\\nright to explanation derived from safeguards against\\nautomated decision-making’). Critically, if Article 22\\ngrants a right to object automated decision-making is\\nlegally unchallenged by default, even if it does not meet\\nany of the requirements set out in Article 22(2), so long\\nas the data subject does not enter an objection. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 137, 'page': 20, '_split_overlap': [{'doc_id': 'b884ca828ca98a218860e30f0af7dce4', 'range': (0, 173)}, {'doc_id': '3e43f601f1f4e70dd01e411641ddb2b9', 'range': (958, 1202)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b49651c8c4e61855d1d3185e8396f160'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Critically, if Article 22\\ngrants a right to object automated decision-making is\\nlegally unchallenged by default, even if it does not meet\\nany of the requirements set out in Article 22(2), so long\\nas the data subject does not enter an objection. This\\nlimitation increases the burden on data subjects to pro-\\ntect actively their interests relating to proﬁling and\\nautomated decision-making by monitoring and object-\\ning to automated decision-making.\\nWith this comparison in mind, interpreting Article\\n22 as a prohibition grants greater protections by default\\nto data subject’s interests, at least in the cases in which\\nArticle 22(3) would apply. As a prohibition, data con-\\ntrollers would be legally obliged to limit automated\\ndecision-making meeting the deﬁnition in Article 22(1)\\nto the three cases identiﬁed in Article 22(2) (contract,\\nUnion or Member State law, consent).\\nIn contrast, a right to object would not pre-emptively\\nrestrict the types of automated decision-making under-\\ntaken by data controllers to the three cases deﬁned in\\nArticle 22(2). Rather, these restrictions would only\\napply when a data subject lodged an objection against a\\nspeciﬁc instance of decision-making. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 138, 'page': 20, '_split_overlap': [{'doc_id': 'b49651c8c4e61855d1d3185e8396f160', 'range': (0, 244)}, {'doc_id': 'dde5ae20a6dbb53bcb2d07d8baa90bc0', 'range': (874, 1184)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3e43f601f1f4e70dd01e411641ddb2b9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: In contrast, a right to object would not pre-emptively\\nrestrict the types of automated decision-making under-\\ntaken by data controllers to the three cases deﬁned in\\nArticle 22(2). Rather, these restrictions would only\\napply when a data subject lodged an objection against a\\nspeciﬁc instance of decision-making. At that point,\\nprocesses not meeting a requirement of Article 22(2)\\nwould need to stop, and the safeguards speciﬁed in\\nArticles 22(2)b or 22(3) would never be triggered.\\nArticle 22 as a right to object would thus circumvent a\\nright to explanation introduced through Article 22(3)\\nby allowing automated decision-making not meeting a\\nrequirement in Article 22(2) to occur until the data sub-\\nject enters an objection. Such ‘legal’ but pre-objection\\ndecision-making would not be subject to a right to\\nexplanation derived from Article 22(3). With that said,\\na right to explanation derived from the right of access\\nwould not be similarly circumvented. In this case a data\\nsubject’s right to explanation would apply to any\\ndecision-making meeting the deﬁnition provided in\\nArticle 22(1), even if the decision-making proved to not\\nmeet a requirement of Article 22(2) following the data\\nsubject’s objection.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 139, 'page': 20, '_split_overlap': [{'doc_id': '3e43f601f1f4e70dd01e411641ddb2b9', 'range': (0, 310)}, {'doc_id': 'e51e30a1a097eacdd283f3e9344d8328', 'range': (958, 1210)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'dde5ae20a6dbb53bcb2d07d8baa90bc0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: In this case a data\\nsubject’s right to explanation would apply to any\\ndecision-making meeting the deﬁnition provided in\\nArticle 22(1), even if the decision-making proved to not\\nmeet a requirement of Article 22(2) following the data\\nsubject’s objection.\\nTo summarize, if a right to explanation is enacted in\\nthe future, at best, data subjects will only deserve an\\nexplanation when automated decisions have (i) legal or\\nsimilarly signiﬁcant effects, and (ii) are based solely on\\nautomated processes. Further, if a right to explanation\\nis derived speciﬁcally from Article 22(3), explanations\\nwill be required only if automated decision-making is\\n(iii) carried out to enter or under contract, or with\\n112 Korff (n 38) 84. See also page 84 ff for further details on how other\\nMember States implemented the Directive.\\n113 Korff, ‘New Challenges to Data Protection Study-Country Report’ (n 50)\\n37 ff.\\nSandra Wachter et al. Á No Right to Explanation of Automated Decision-Making 95\\nARTICLE\\x0cexplicit consent; and (iv) when overriding interests of the\\ndata controller (eg trade secrets) do not exist, as speci-\\nﬁed in Recital 63. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 140, 'page': 20, '_split_overlap': [{'doc_id': 'dde5ae20a6dbb53bcb2d07d8baa90bc0', 'range': (0, 252)}, {'doc_id': '29ba708427068e77e6b00f1a5f32bde8', 'range': (916, 1119)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e51e30a1a097eacdd283f3e9344d8328'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Á No Right to Explanation of Automated Decision-Making 95\\nARTICLE\\x0cexplicit consent; and (iv) when overriding interests of the\\ndata controller (eg trade secrets) do not exist, as speci-\\nﬁed in Recital 63. Further restrictions on a right to\\nexplanation derived from Article 22(3) depend upon\\nthe prevailing interpretation of Article 22 as a prohibi-\\ntion or a right to object.\\nTo disambiguate this limited type of right to explana-\\ntion from the ‘general’ right to explanation in future\\ndiscussion of the impact of the GDPR on automated\\nprocessing of data, and to reﬂect accurately the scope of\\nlimitations on any such right, we recommend address-\\ning instead a ‘right to be informed’ about the existence\\nof automated decision-making and system\\nfunctionality. The right to be informed addresses the\\ninformation provided to data subjects about automated\\ndecision-making, taking into account all of the limita-\\ntions on the scope of applicability and type of informa-\\ntion to be provided by data controllers as described in\\nthe preceding two sections. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 141, 'page': 20, '_split_overlap': [{'doc_id': 'e51e30a1a097eacdd283f3e9344d8328', 'range': (0, 203)}, {'doc_id': '147b152c40576678d070fa2d7f9e30d9', 'range': (758, 1047)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '29ba708427068e77e6b00f1a5f32bde8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The right to be informed addresses the\\ninformation provided to data subjects about automated\\ndecision-making, taking into account all of the limita-\\ntions on the scope of applicability and type of informa-\\ntion to be provided by data controllers as described in\\nthe preceding two sections. The right to be informed\\nfurther accounts for precedents set in the 1995\\nDirective, and the impact these precedents will likely\\nhave on future interpretation of the GDPR’s notiﬁcation\\nduties (Articles 13–14), right of access (Article 15), and\\nright not to be subject to automated decision-making\\n(Article 22)\\nConclusion: future of the accountable\\nautomated decision-making\\nDespite claims to the contrary, a meaningful right to\\nexplanation is not legally mandated by the GDPR.\\nGiven the proliferation of automated decision-making\\nand automated processing of data to support human\\ndecision-making (ie ‘not solely’), this is a critical gap in\\ntransparency and accountability. The GDPR appears to\\ngive strong protection against automated decision-\\nmaking but, as it stands, the protections may prove inef-\\nfectual. However, transparent and accountable auto-\\nmated decision-making can still be achieved before the\\nGDPR comes into force in 2018.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 142, 'page': 21, '_split_overlap': [{'doc_id': '29ba708427068e77e6b00f1a5f32bde8', 'range': (0, 289)}, {'doc_id': '5e75cb64142ee739ebdafe128447c5c9', 'range': (963, 1229)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '147b152c40576678d070fa2d7f9e30d9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: The GDPR appears to\\ngive strong protection against automated decision-\\nmaking but, as it stands, the protections may prove inef-\\nfectual. However, transparent and accountable auto-\\nmated decision-making can still be achieved before the\\nGDPR comes into force in 2018.\\nA right to explanation of speciﬁc decisions is not\\nlegally mandated by the safeguards contained in Article\\n22(3), or notiﬁcation duties in Articles 13 and 14. As\\nproven by the 1995 Directive, the right of access is\\nambiguous. However, the GDPR’s right of access pro-\\nvides a right to explanation of system functionality,\\nwhat we call a ‘right to be informed’, restricted by the\\ninterests of data controllers and future interpretations\\nof Article 15. Any future right to explanation will\\nfurther be constrained by the deﬁnition of ‘automated\\ndecision-making’ in Article 22(1), which is limited to\\ndecisions based solely on automated processing with\\nlegal or similarly signiﬁcant effects for the data subject.\\nAs it stands, a meaningful right of explanation to the\\nrationale and circumstances of speciﬁc automated deci-\\nsions is not forthcoming.\\nAnalysis of prior drafts of the GDPR has revealed sev-\\neral tensions between the EP, Commission, and\\nCouncil. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 143, 'page': 21, '_split_overlap': [{'doc_id': '147b152c40576678d070fa2d7f9e30d9', 'range': (0, 266)}, {'doc_id': '9256a38691063f8876957079b91e5b19', 'range': (975, 1220)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5e75cb64142ee739ebdafe128447c5c9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: As it stands, a meaningful right of explanation to the\\nrationale and circumstances of speciﬁc automated deci-\\nsions is not forthcoming.\\nAnalysis of prior drafts of the GDPR has revealed sev-\\neral tensions between the EP, Commission, and\\nCouncil. The placement of the right to explanation in\\nnon-binding Recital 71 appears to be a purposeful\\nchange deliberated in trilogue. The EP generally sought\\nstronger protections for data subjects against automated\\ndecision-making than the EC or Council. Speciﬁcally,\\nthe EP wanted to include a right to explanation in\\nArticle 20,114 whereas the Council would have preferred\\nto have the right to explanation in Recital 58.115 The EC\\ndid not include such a right at all. Further, the EP\\nwanted to protect citizens from automated decision that\\nhave legal or signiﬁcant effects when predominantly,116\\nand not just solely,117 based on automated processes.\\nHuman assessment would also have been required.118\\nAs the GDPR is intended to unify data protection\\nlaw across all European Member States, the interpreta-\\ntion of Article 22 as a prohibition or right to object is\\ncritically important. Which interpretation will win out\\nin the implementation of the GDPR in 2018 is not yet\\nclear. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 144, 'page': 21, '_split_overlap': [{'doc_id': '5e75cb64142ee739ebdafe128447c5c9', 'range': (0, 245)}, {'doc_id': 'bae4cfcead88b1cf38ca1c0e047f3b94', 'range': (891, 1219)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9256a38691063f8876957079b91e5b19'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Human assessment would also have been required.118\\nAs the GDPR is intended to unify data protection\\nlaw across all European Member States, the interpreta-\\ntion of Article 22 as a prohibition or right to object is\\ncritically important. Which interpretation will win out\\nin the implementation of the GDPR in 2018 is not yet\\nclear. Both are viable as suggested by the split in the\\nimplementation of Article 15 in the Data Protection\\nDirective 1995 by Member States. Without clariﬁcation\\nprior to enforcement, Article 22 will allow for conﬂict-\\ning interpretations of the rights of data subjects and\\ncontrollers concerning automated decision-making\\nacross Member States. Conﬂicts may soon become\\ninevitable because the two interpretations protect very\\ndifferent interests.\\nArticle 22 interpreted as a prohibition offers greater\\nprotection to the interests of data subjects by prohibit-\\ning all automated decision-making not meeting a\\nrequirement of Article 22(2). In contrast, when inter-\\npreted as a right, Article 22 creates a loophole that\\nallows data controllers to undertake automated\\ndecision-making without meeting a requirement in\\nArticle 22(2), unless the data subject objects. Once an\\nobjection is entered, decision-making must be shown to\\nmeet one of these requirements or must stop altogether.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 145, 'page': 21, '_split_overlap': [{'doc_id': '9256a38691063f8876957079b91e5b19', 'range': (0, 328)}, {'doc_id': '284335c2d84726c12d74af9dd7aafdf0', 'range': (960, 1301)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bae4cfcead88b1cf38ca1c0e047f3b94'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: In contrast, when inter-\\npreted as a right, Article 22 creates a loophole that\\nallows data controllers to undertake automated\\ndecision-making without meeting a requirement in\\nArticle 22(2), unless the data subject objects. Once an\\nobjection is entered, decision-making must be shown to\\nmeet one of these requirements or must stop altogether.\\nAs a right, the data subject’s interests in not being sub-\\njected to automated decision-making are undermined,\\ninsofar as signiﬁcant effort (ie entering an objection) is\\n114 European Digital Rights (n 26) 140.\\n115 Ibid 40.\\n116 Ibid 140.\\n117 Both the EC and European Council only sought protections for decisions\\nsolely based on automated processing, see ibid 139.\\n118 Ibid 140.\\n96 ARTICLE International Data Privacy Law, 2017, Vol. 7, No. 2\\x0crequired from the subject to protect her interests.\\nArticle 22 therefore roughly favours the interests of data\\nsubjects when interpreted as a prohibition, and the\\ninterests of data controllers when interpreted as a right.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 146, 'page': 21, '_split_overlap': [{'doc_id': 'bae4cfcead88b1cf38ca1c0e047f3b94', 'range': (0, 341)}, {'doc_id': '5d9b617a2127c8fb1404e8693e12a855', 'range': (835, 1004)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '284335c2d84726c12d74af9dd7aafdf0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Article 22 therefore roughly favours the interests of data\\nsubjects when interpreted as a prohibition, and the\\ninterests of data controllers when interpreted as a right.\\nThe ambiguity of the right not to be subject to auto-\\nmated decision-making (Article 22), and the loopholes\\nand weaknesses it creates, shows that the GDPR is lack-\\ning precise language and explicit and well-deﬁned rights\\nand safeguards, and therefore runs the risk of being\\ntoothless. Several actions may be recommended to cor-\\nrect some of the weaknesses identiﬁed in our analysis.\\nThe following recommendations are intended as guid-\\nance for legislative and policy steps to correct the deﬁ-\\nciencies we have identiﬁed in the protections afforded\\nto data subjects against automated decision-making.\\nLegislative progress can be achieved by modifying the\\nGDPR prior to its enforcement, or passage of additional\\nlaws by Member States. Additional legislative steps by\\nMember States are highly likely, as seen with the UK’s\\nHouse of Commons’ Science and Technology\\nCommittee’s recent inquiry on ‘algorithms in decision-\\nmaking’,119 which was inspired in part by informal con-\\nsultations by ‘Sense about Science’ (a UK-based charita-\\nble trust) with the authors of this article. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 147, 'page': 22, '_split_overlap': [{'doc_id': '284335c2d84726c12d74af9dd7aafdf0', 'range': (0, 169)}, {'doc_id': 'f63ee3bda083e4f990f88776a529b1ee', 'range': (903, 1243)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5d9b617a2127c8fb1404e8693e12a855'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Additional legislative steps by\\nMember States are highly likely, as seen with the UK’s\\nHouse of Commons’ Science and Technology\\nCommittee’s recent inquiry on ‘algorithms in decision-\\nmaking’,119 which was inspired in part by informal con-\\nsultations by ‘Sense about Science’ (a UK-based charita-\\nble trust) with the authors of this article. The inquiry\\ngathers expert opinions on how to achieve accountabil-\\nity and transparency in algorithmic decision-making,\\nincluding identiﬁcation of barriers (eg trade secrets),\\nmechanisms for oversight, and requirements to make\\ndecisions explainable. As evidence that the recommen-\\ndations made here can be the starting point for new\\nlaws, the inquiry explicitly refers to the rights and duties\\nlaid out in the GDPR. On the policy side, the recom-\\nmendations can inﬂuence future guidelines issued by\\nbodies such as the Article 29 Working Party, the\\nEuropean Data Protection Board, the European Data\\nProtection Supervisor, and its Ethics Advisory Group.\\nWe make the following recommendations:\\n1) Add a right to explanation to legally binding\\nArticle 22(3)\\nIf a right to explanation is intended as suggested in\\nRecital 71, it should be explicitly added to a legally bind-\\ning Article of the GDPR. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 148, 'page': 22, '_split_overlap': [{'doc_id': '5d9b617a2127c8fb1404e8693e12a855', 'range': (0, 340)}, {'doc_id': 'd968f81d611e86b287f8017131ecd43a', 'range': (993, 1234)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f63ee3bda083e4f990f88776a529b1ee'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: We make the following recommendations:\\n1) Add a right to explanation to legally binding\\nArticle 22(3)\\nIf a right to explanation is intended as suggested in\\nRecital 71, it should be explicitly added to a legally bind-\\ning Article of the GDPR. Such an implementation\\nshould clarify the scope of applicability of the right with\\nregard to the impact of Article 22 interpreted as a pro-\\nhibition or right to object. Alternatively, Member States\\ncan be encouraged to implement law on top of the\\nGDPR that requires an explanation of speciﬁc decisions.\\nA right to explanation of speciﬁc decisions could be\\nconsidered a suitable safeguard necessitated by Article\\n22(2)b and 22(3) if an explanation is necessary to con-\\ntest a decision, as already prescribed in 22(3). The rights\\nto contest a decision, to obtain human intervention or\\nto express views granted in Article 22(3) may be mean-\\ningless if the data subject cannot understand how the\\ncontested decision was made. To this end, a right to\\nexplanation can be introduced requiring data control-\\nlers to provide information about the rationale of the\\ncontested decision. Clear requirements should be intro-\\nduced stating the evidence to be supplied by the data\\ncontroller. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 149, 'page': 22, '_split_overlap': [{'doc_id': 'f63ee3bda083e4f990f88776a529b1ee', 'range': (0, 241)}, {'doc_id': 'f6b7b2829fa0f67db3227c4dde33d365', 'range': (963, 1217)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd968f81d611e86b287f8017131ecd43a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: To this end, a right to\\nexplanation can be introduced requiring data control-\\nlers to provide information about the rationale of the\\ncontested decision. Clear requirements should be intro-\\nduced stating the evidence to be supplied by the data\\ncontroller. Evidence regarding the weighting of features,\\ndecision tree or classiﬁcation structure, and general\\nlogic of the decision-making system may be sufﬁcient.\\nHowever, the risks for innovation and beneﬁcial proc-\\nessing posed by a right to explanation that requires\\nautomated decision-making methods to be human\\ninterpretable should be seriously considered.120\\n2) Clarify the meaning of the ‘existence of . . . signiﬁ-\\ncance . . . envisaged consequences . . . [and] logic\\ninvolved’ in Article 15(1)h.\\nThe language and meaning of core concepts in\\nArticle 15 is ambiguous. This leaves open the possibility\\nof a right to explanation of the rationale of speciﬁc deci-\\nsions (see section ‘From the Directive to the GDPR: the\\nright to be informed’). However this interpretation is\\nimplausible for a number of reasons. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 150, 'page': 22, '_split_overlap': [{'doc_id': 'd968f81d611e86b287f8017131ecd43a', 'range': (0, 254)}, {'doc_id': 'df929e923af84d6ce58ef023b8ad4b9b', 'range': (821, 1061)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f6b7b2829fa0f67db3227c4dde33d365'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: This leaves open the possibility\\nof a right to explanation of the rationale of speciﬁc deci-\\nsions (see section ‘From the Directive to the GDPR: the\\nright to be informed’). However this interpretation is\\nimplausible for a number of reasons. As explained in\\nsection ‘A right to explanation derived from the right of\\naccess’, the semantics and history of the right to access,\\nand the duplication of provisions in Articles 13–14, sug-\\ngest that the right of access is intended merely as a\\ncounterweight to the notiﬁcation duties of data control-\\nlers, and not as a means to introduce a new right (ie a\\nright to explanation of speciﬁc decisions) beyond the\\nscope of Articles 13–14.121 Critically, interpreting\\nArticle 15 to introduce a right to explanation of speciﬁc\\ndecisions would not match the intended purpose of the\\nright of access, which according to Recital 63 GDPR is\\nmeant to allow the data subject ‘to be aware of, and ver-\\nify, the lawfulness of processing’. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 151, 'page': 22, '_split_overlap': [{'doc_id': 'f6b7b2829fa0f67db3227c4dde33d365', 'range': (0, 240)}, {'doc_id': 'f542274d6b61603b3b9c354409318d9a', 'range': (241, 966)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'df929e923af84d6ce58ef023b8ad4b9b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: As explained in\\nsection ‘A right to explanation derived from the right of\\naccess’, the semantics and history of the right to access,\\nand the duplication of provisions in Articles 13–14, sug-\\ngest that the right of access is intended merely as a\\ncounterweight to the notiﬁcation duties of data control-\\nlers, and not as a means to introduce a new right (ie a\\nright to explanation of speciﬁc decisions) beyond the\\nscope of Articles 13–14.121 Critically, interpreting\\nArticle 15 to introduce a right to explanation of speciﬁc\\ndecisions would not match the intended purpose of the\\nright of access, which according to Recital 63 GDPR is\\nmeant to allow the data subject ‘to be aware of, and ver-\\nify, the lawfulness of processing’. Language should be\\nadded to clarify that Article 15 is intended either as a\\ncounterweight to Articles 13–14, and thus provides a\\n‘right to be informed’ about the existence of automated\\ndecision-making as well as system functionality, or as a\\nright to explanation of speciﬁc decisions. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 152, 'page': 22, '_split_overlap': [{'doc_id': 'df929e923af84d6ce58ef023b8ad4b9b', 'range': (0, 725)}, {'doc_id': '3d125bf3653354a1b11f857611dc01bc', 'range': (726, 1010)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f542274d6b61603b3b9c354409318d9a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Language should be\\nadded to clarify that Article 15 is intended either as a\\ncounterweight to Articles 13–14, and thus provides a\\n‘right to be informed’ about the existence of automated\\ndecision-making as well as system functionality, or as a\\nright to explanation of speciﬁc decisions. The intended\\nmeaning of the ﬁve core concepts of Article 15(1)h\\nshould be made explicit, and their impact on the infor-\\nmation required for data controllers to communicate to\\n119 Commons Select Committee, ‘Algorithms in Decision-Making Inquiry\\nLaunched’ (UK Parliament, 2017) <http://www.parliament.uk/business/\\ncommittees/committees-a-z/commons-select/science-and-technology-\\ncommittee/news-parliament-2015/algorithms-in-decision-making-\\ninquiry-launch-16-17/> accessed 8 March 2017.\\n120 Mittelstadt and others (n 6).\\n121 Paal (n 32) Rn 19–22.\\nSandra Wachter et al. Á No Right to Explanation of Automated Decision-Making 97\\nARTICLE\\x0cdata subjects under the right to access (and, similarly,\\nArticles 13–14 notiﬁcation duties).\\n3) Clarify the language of Article 22(1) to indicate\\nwhen decisions are based solely on automated\\nprocessing\\nArticle 22 is limited in applicability to decisions\\nbased solely on automated processing. However, it is\\nunclear what the phrase means in practice. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 153, 'page': 22, '_split_overlap': [{'doc_id': 'f542274d6b61603b3b9c354409318d9a', 'range': (0, 284)}, {'doc_id': '8c278173ea1be157fe3fd957d11069c1', 'range': (1011, 1267)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3d125bf3653354a1b11f857611dc01bc'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 3) Clarify the language of Article 22(1) to indicate\\nwhen decisions are based solely on automated\\nprocessing\\nArticle 22 is limited in applicability to decisions\\nbased solely on automated processing. However, it is\\nunclear what the phrase means in practice. The poten-\\ntial loophole (similarly seen in the German SCHUFA\\njudgements), by which nominal involvement of a\\nhuman at any stage of the automated process means the\\nprocess is not solely automated, should be closed. There\\nis still uncertainty if the usage of automated processes\\nfor the preparation of a decision constitutes solely auto-\\nmated processes, if the human that takes the ﬁnal deci-\\nsion does not wish to interfere or to adopt the decision.\\nClariﬁcation can be offered by returning to the phrasing\\n‘solely or predominantly based on’ proposed by the\\nEP122 in Article 20(5), or by providing speciﬁc examples\\nof decision-making based solely and predominantly on\\nautomated processing of data.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 154, 'page': 23, '_split_overlap': [{'doc_id': '3d125bf3653354a1b11f857611dc01bc', 'range': (0, 256)}, {'doc_id': '75c62f927078c130296f329b8fc7294c', 'range': (707, 954)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8c278173ea1be157fe3fd957d11069c1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Clariﬁcation can be offered by returning to the phrasing\\n‘solely or predominantly based on’ proposed by the\\nEP122 in Article 20(5), or by providing speciﬁc examples\\nof decision-making based solely and predominantly on\\nautomated processing of data.\\n4) Clarify the language of Article 22(1) to indicate\\nwhat counts as a legal or signiﬁcant effect of automated\\ndecision, including proﬁling\\nArticle 22 only applies for automated decision-\\nmaking with ‘legal effects’ or ‘similarly signiﬁcant\\neffects’.123 Recital 71 only names two examples of such\\neffects: automatic refusal of an online credit application\\nand e-recruiting practices. The scope of these phrases\\nshould be made explicit: do they, for instance, refer only\\nto effects identiﬁed in the Articles of the GDPR, or to\\nsome broader deﬁnition? At a minimum, the perspec-\\ntive to be taken in deﬁning \"signiﬁcant effects\" should\\nbe identiﬁed. Do effects need to be signiﬁcant from the\\nsubjective perspective of the data subject, or according\\nto some external standard?\\n5) Clarify the language of Article 22(2)a, ‘necessary\\nfor entering, or performance of a contract’\\nArticle 22(2)a names this case as an exception of\\neither the prohibition of automated decision-making or\\nthe right to object to automated decision-making. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 155, 'page': 23, '_split_overlap': [{'doc_id': '8c278173ea1be157fe3fd957d11069c1', 'range': (0, 247)}, {'doc_id': '5e7b7e46829bb0faab74e2ecfd997c5e', 'range': (1020, 1272)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '75c62f927078c130296f329b8fc7294c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 5) Clarify the language of Article 22(2)a, ‘necessary\\nfor entering, or performance of a contract’\\nArticle 22(2)a names this case as an exception of\\neither the prohibition of automated decision-making or\\nthe right to object to automated decision-making. Since\\nit is likely that the necessity of such measures will be\\ndeﬁned by the data controller and lit (a) does not\\nrequire consent of the data subject (since this is a\\nseparate exception listed under lit (c), this exemption\\nruns the risk of weakening the rights of data subjects.\\n6) Clarify the language of Article 22 to indicate a\\nprohibition\\nIdeally, the language that allows for two plausible\\ninterpretations should be clariﬁed prior to 2018 when\\nthe GDPR comes into force. Due to the number of\\nloopholes and weakening of Article 22(3) safeguards\\nintroduced if Article 22 is interpreted as a right to\\nobject, as well as wide implementation of Article 15 of\\nthe 1995 Directive as a prohibition, we recommend that\\nthe language used in Article 22(2) (‘Paragraph 1 shall\\nnot apply if the decision:’) be revised to indicate clearly\\nand explicitly that Article 22 is intended as a prohibition\\nagainst automated decision-making.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 156, 'page': 23, '_split_overlap': [{'doc_id': '75c62f927078c130296f329b8fc7294c', 'range': (0, 252)}, {'doc_id': '84b17ff56e7490e1424452c7b2f0ebef', 'range': (729, 1176)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5e7b7e46829bb0faab74e2ecfd997c5e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: Due to the number of\\nloopholes and weakening of Article 22(3) safeguards\\nintroduced if Article 22 is interpreted as a right to\\nobject, as well as wide implementation of Article 15 of\\nthe 1995 Directive as a prohibition, we recommend that\\nthe language used in Article 22(2) (‘Paragraph 1 shall\\nnot apply if the decision:’) be revised to indicate clearly\\nand explicitly that Article 22 is intended as a prohibition\\nagainst automated decision-making.\\n7) As a counterweight to trade secrets, introduce an\\nexternal auditing mechanism for automated decision-\\nmaking, or set internal auditing requirements for data\\ncontrollers\\nBoth the right of access and any future right to\\nexplanation will face signiﬁcant limitations due to the\\nsensitivity of trade secrets and intellectual property\\nrights. As our examination of the 1995 Directive shows,\\nexplanations granted under the right of access are nor-\\nmally limited to system functionality and signiﬁcantly\\nlimited to protect data controller interests. An ideal sol-\\nution would allow for examination of automated\\ndecision-making systems, including the rationale and\\ncircumstances of speciﬁc decisions, by a trusted third\\nparty. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 157, 'page': 23, '_split_overlap': [{'doc_id': '5e7b7e46829bb0faab74e2ecfd997c5e', 'range': (0, 447)}, {'doc_id': '46efd476e389585b3dd9aaec38b9deed', 'range': (993, 1168)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '84b17ff56e7490e1424452c7b2f0ebef'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: An ideal sol-\\nution would allow for examination of automated\\ndecision-making systems, including the rationale and\\ncircumstances of speciﬁc decisions, by a trusted third\\nparty. This approach limits the risk to data controllers\\nof exposing trade secrets, while also providing an over-\\nsight mechanism for data subjects that can operate\\nwhen explanations are infeasible or too complex for lay\\ncomprehension. The powers of Supervisory Authorities\\ncould be expanded in this regard. Alternatively, a\\nEuropean regulator could be created speciﬁcally for\\nauditing algorithms, before (certiﬁcations) and/or after\\nalgorithms are being deployed.124\\n8) Support further research into the feasibility of\\nexplanations alternative accountability mechanisms\\nEven if a right to explanation is legally granted in the\\nfuture, the feasibility and practical requirements to offer\\nexplanations to data subjects remain unclear. In line\\nwith current work on interpretable automated decision-\\nmaking and machine learning methods,125 research\\n122 European Parliament Committee on Civil Liberties, Justice and Home\\nAffairs (n 24).\\n123 As already proposed by the Article 29 Working Party, see ‘Advice Paper\\non Essential Elements of a Deﬁnition and a Provision on Proﬁling within\\nthe EU General Data Protection Regulation’ (2013) 29 <http://ec.europa.\\neu/justice/data-protection/article-29/documentation/other-document/\\nﬁles/2013/20130513_advice-paper-on-proﬁling_en.pdf> accessed 10\\nMarch 2017.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 158, 'page': 23, '_split_overlap': [{'doc_id': '84b17ff56e7490e1424452c7b2f0ebef', 'range': (0, 175)}, {'doc_id': '7f43e9af4e1e65e586368d39161de890', 'range': (1102, 1464)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '46efd476e389585b3dd9aaec38b9deed'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 123 As already proposed by the Article 29 Working Party, see ‘Advice Paper\\non Essential Elements of a Deﬁnition and a Provision on Proﬁling within\\nthe EU General Data Protection Regulation’ (2013) 29 <http://ec.europa.\\neu/justice/data-protection/article-29/documentation/other-document/\\nﬁles/2013/20130513_advice-paper-on-proﬁling_en.pdf> accessed 10\\nMarch 2017.\\n124 Comparable approaches to regulating Big Data and algorithms have been\\nsuggested by: Viktor Mayer-Scho\\n¨nberger and Kenneth Cukier, Big Data:\\nA Revolution That Will Transform How We Live, Work and Think (John\\nMurray 2013); Andrew Tutt, ‘An FDA for Algorithms’ (Social Science\\nResearch Network 2016) SSRN Scholarly Paper ID 2747994 <http://\\npapers.ssrn.com/abstract¼2747994> accessed 13 April 2016.\\n125 For a detailed discussion on regulatory and interpretability issues related\\nto algorithms, see: Danielle Keats Citron and Frank A Pasquale, ‘The\\nScored Society: Due Process for Automated Predictions’ (Social Science\\n98 ARTICLE International Data Privacy Law, 2017, Vol. 7, No. 2\\x0cneeds to be conducted in parallel to determine whether\\nand how explanations can and should be offered to data\\nsubjects (or proxies thereof) with differing levels of\\nexpertise and interests. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 159, 'page': 23, '_split_overlap': [{'doc_id': '46efd476e389585b3dd9aaec38b9deed', 'range': (0, 362)}, {'doc_id': 'f8e979eec9950371959bcd5c1071a658', 'range': (1045, 1236)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7f43e9af4e1e65e586368d39161de890'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 2\\x0cneeds to be conducted in parallel to determine whether\\nand how explanations can and should be offered to data\\nsubjects (or proxies thereof) with differing levels of\\nexpertise and interests. What counts as a meaningful\\nexplanation for one individual or group may not be\\nmeaningful for another; requirements for ‘meaningful\\nexplanations’ must be set if a legal right to explanation\\nis to be practically useful. The right to explanation is\\nalso not the only way to achieve accountability and\\ntransparency in automated decision-making.126 Further\\nattention should be given to the development and\\ndeployment of alternative legal safeguards that can sup-\\nplement the protections offered by the GDPR. Data\\ncontrollers working in highly sensitive or risky sectors\\ncould, for instance, be required to use human interpret-\\nable decision-making methods.127 Methods and (ethi-\\ncal) requirements for auditing algorithms128 should also\\nbe further developed, both as standalone accountability\\ntools and as mechanisms to provide an evidence trail\\nfor providing explanations of automated decisions.\\nAs the ambiguities highlighted in these recommenda-\\ntions indicate, the GDPR can be a toothless or powerful\\nmechanism to protect data subjects depending on its\\neventual legal interpretation. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 160, 'page': 23, '_split_overlap': [{'doc_id': '7f43e9af4e1e65e586368d39161de890', 'range': (0, 191)}, {'doc_id': '82b5986da9e71e69dbf448b2d42e1ef3', 'range': (1084, 1274)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f8e979eec9950371959bcd5c1071a658'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: As the ambiguities highlighted in these recommenda-\\ntions indicate, the GDPR can be a toothless or powerful\\nmechanism to protect data subjects depending on its\\neventual legal interpretation. The effectiveness of the new\\nframework will largely be determined by Supervisory\\nAuthorities, the Article 29 Working Party, the European\\nData Protection Board, the European Data Protection\\nSupervisor, its Ethics Advisory Group,129 as well as\\nnational courts and their future judgments.130 As it\\nstands, transparent and accountable automated decision-\\nmaking is not yet guaranteed by the GDPR; nor is a right\\nto explanation of speciﬁc decisions forthcoming. At best,\\ndata subjects will be granted a ‘right to be informed’\\nabout the existence of automated decision-making and\\nsystem functionality. These shortcomings should be\\naddressed before the GDPR comes into force in 2018.\\ndoi:10.1093/idpl/ipx005\\nAdvance Access Publication 3 June 2017\\nResearch Network 2014) SSRN Scholarly Paper ID 2376209 <https://\\npapers.ssrn.com/abstract¼2376209> accessed 4 March 2017; Alfredo\\nVellido, Jose\\n´ David Mart\\x13\\nın-Guerrero and Paulo JG Lisboa, ‘Making\\nMachine Learning Models Interpretable’, ESANN (Citeseer 2012).\\n126 For additional discussion of transparency and the GDPR, see: Dimitra\\nKamarinou, Christopher Millard and Jatinder Singh, ‘Machine Learning\\nwith Personal Data’ <https://papers.ssrn.com/sol3/papers.cfm?abstract_\\nid¼2865811> accessed 8 March 2017.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 161, 'page': 24, '_split_overlap': [{'doc_id': 'f8e979eec9950371959bcd5c1071a658', 'range': (0, 190)}, {'doc_id': '9fac84d9311fc8a5a2a31819dcb2a1db', 'range': (1193, 1440)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '82b5986da9e71e69dbf448b2d42e1ef3'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: University of Oxford, stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Austria, document_date: 09-06-2020 12:14, language: English, \\n\\nPassage: 126 For additional discussion of transparency and the GDPR, see: Dimitra\\nKamarinou, Christopher Millard and Jatinder Singh, ‘Machine Learning\\nwith Personal Data’ <https://papers.ssrn.com/sol3/papers.cfm?abstract_\\nid¼2865811> accessed 8 March 2017.\\n127 Burrell (n 12).\\n128 Sandvig and others (n 7); Mittelstadt and others (n 6); Brent Mittelstadt,\\n‘Auditing for Transparency in Content Personalization Systems’ (2016)\\n10 International Journal of Communication 12. See also the discussion of\\nex post tests of outcomes, and ex ante acceptability of errors in Zarsky (n\\n90).\\n129 Disclosure: Luciano Floridi is a member of the European Data Protection\\nSupervisors’ Ethics Advisory Group.\\n130 Art 83(5)b invests supervisory authorities with the power to impose ﬁnes\\nup to 4 percent of the total worldwide annual turnover in cases where\\nrights of the data subjects (arts 12–22) have been infringed. This lever\\ncan be used to enforce compliance and to enhance data protection.\\nSandra Wachter et al. Á No Right to Explanation of Automated Decision-Making 99\\nARTICLE', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', 'stakeholder_name': 'University of Oxford', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Austria', 'stakeholder_scope': nan, 'document_date': '09-06-2020 12:14', 'language': 'English', 'document_reference': 'F530487', 'document_name': 'F530487-Wachter_et_al_Why_a_Right_to_Explanation_of_Automated_Decisions_does_not_exist_in_GDPR.pdf', '_split_id': 162, 'page': 24, '_split_overlap': [{'doc_id': '82b5986da9e71e69dbf448b2d42e1ef3', 'range': (0, 247)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9fac84d9311fc8a5a2a31819dcb2a1db'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: EIT Digital, EIT Climate-KIC, EIT Health, EIT Manufacturing, and EIT Urban Mobility, all Knowledge and Innovation Communities (KICs) supported by the EIT and members of the cross-KIC Activity \"Artificial Intelligence\", stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Belgium, document_date: 14-06-2020 22:37, language: English, \\n\\nPassage: Addendum to the EC\\nConsultation on the White Paper\\non Artificial Intelligence – A\\nEuropean Approach\\nReports and studies by EIT Knowledge and Innovation\\nCommunities related to the Consultation on the White\\nPaper on Artificial Intelligence - A European Approach\\nArtificial Intelligence\\nEIT Digital, June 2020\\nEIT Digital is supported by the EIT,\\na body of the European Union\\nRef. Ares(2020)3359939 - 26/06/2020\\x0c1\\nEIT Digital, March 2019: Digital Transformation of European Industry – a Policy Perspective\\nSummary report: https://www.eitdigital.eu/fileadmin/files/2019/report/Digital-Transformation-of-\\nEuropean-Industry-Summary.pdf\\nFull Report (ISBN 978-91-87253-57-7): https://www.eitdigital.eu/newsroom/publications/full-report-\\ndigital-transformation-of-european-industry/\\nEIT Health, October 2019: AI and Ethics in the Health Innovation Community (EIT Health pilot of the AI &\\nethics guidelines of the European Commission’s (EC) High-Level Group)\\nhttps://eithealth.eu/wp-content/uploads/2020/01/AI-and-Ethics-in-the-Health-Innovation-\\nCommunity.pdf\\nEIT, February 2020: EIT Artificial Intelligence activities report 2019\\nhttps://eit.europa.eu/library/eit-artificial-intelligence-activities-report-2019\\nEIT Health, with McKinsey & Company, March 2020: Transforming healthcare with AI - The impact on the\\nworkforce and organisations\\nhttps://eithealth.eu/wp-content/uploads/2020/03/EIT-Health-and-McKinsey_Transforming-Healthcare-\\nwith-AI.pdf\\nEIT Digital, June 2020: European Digital Infrastructure and Data Sovereignty – a Policy Perspective\\nSummary Report: https://www.eitdigital.eu/fileadmin/files/2020/publications/data-sovereignty/EIT-\\nDigital-Data-Sovereignty-Summary-Report.pdf\\nFull Report (ISBN 978-91-87253-62-1): https://www.eitdigital.eu/newsroom/publications/full-report-\\neuropean-digital-infrastructure-and-data-sovereignty/', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530396-Addendum_for_EC_Consultation_Response.pdf', 'stakeholder_name': 'EIT Digital, EIT Climate-KIC, EIT Health, EIT Manufacturing, and EIT Urban Mobility, all Knowledge and Innovation Communities (KICs) supported by the EIT and members of the cross-KIC Activity \"Artificial Intelligence\"', 'stakeholder_type': 'Other', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:37', 'language': 'English', 'document_reference': 'F530396', 'document_name': 'F530396-Addendum_for_EC_Consultation_Response.pdf', '_split_id': 0, 'page': 1, '_split_overlap': []}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a614f7ff1d6404ae3bc9e2ee9d31069a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: Gruppe Deutsche Börse\\nComments on EC´s communication towards\\n„ White Paper on Artificial Intelligence - A European Approach “\\nFrankfurt am Main, June 2020\\nRef. Ares(2020)3359142 - 26/06/2020\\x0c2\\nDBG key messages\\nMutual understanding: The cooperation between authorities and market participants can bring\\nvaluable outcomes, not only during the actual cooperation but further, if it widens the mutual\\nunderstanding of benefits and risks associated with a technology and lays the ground for a wider\\necosystem. These ecosystems should be promoted and supported. Together with the Hessian\\nMinistries, DBG and other have such a cooperation within the so called “Financial Big Data\\nCluster”.\\nApply existing rules: From our point of view as a financial market infrastructure, most\\nactivities/services performed by AI applications in the financial sector would be regulated by\\nalready existing rules and legislation\\nSame business same risk same rules: In general, it might be useful to ask whether a completely\\n“new”, and therefore unregulated, task is performed by an AI application in contrast to an already\\n“known”, and therefore regulated task. In the latter case, adjustments to the existing framework\\nmight be sufficient.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': '36891e3b462cdde785ad67096beaa71a', 'range': (683, 1216)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '60c6c30f3e8086864acc9c8f39041af7'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: Apply existing rules: From our point of view as a financial market infrastructure, most\\nactivities/services performed by AI applications in the financial sector would be regulated by\\nalready existing rules and legislation\\nSame business same risk same rules: In general, it might be useful to ask whether a completely\\n“new”, and therefore unregulated, task is performed by an AI application in contrast to an already\\n“known”, and therefore regulated task. In the latter case, adjustments to the existing framework\\nmight be sufficient.\\nReview of requirements: The list of requirements for (high-risk) AI applications should be\\nreviewed and updated timely and frequently, e.g. without a level 1 change of the regulatory\\nframework, to keep up with technological innovation. The review of the criteria must not need to\\nbe in regulation but rather on guidelines published by supervisory authorities and could be\\nupdated on a more regular basis.\\nEfficiency of the assessment-process: it is crucial that the necessary capacities are in place to\\nassess the AI, to ensure the efficiency of the assessment-process to support the launch of AI\\nproducts.\\nWe support a certification of high-risk AI applications. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 1, 'page': 2, '_split_overlap': [{'doc_id': '60c6c30f3e8086864acc9c8f39041af7', 'range': (0, 533)}, {'doc_id': 'f67805364a155fffd76530c08a9ab76', 'range': (939, 1197)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '36891e3b462cdde785ad67096beaa71a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: Efficiency of the assessment-process: it is crucial that the necessary capacities are in place to\\nassess the AI, to ensure the efficiency of the assessment-process to support the launch of AI\\nproducts.\\nWe support a certification of high-risk AI applications. Further, for non-high risk AI applications\\nit should be allowed for companies to receive a voluntary certification. We prefer an official\\nharmonized labelling system for both applications with clear requirements and an official\\ncertification process performed by a formally authorized actor. This service could be offered by a\\npublic authority directly or by a private institution with a public permission on behalf of public\\nauthorities (like the German TÜV).\\x0c3\\nSelf-certification: We are opposing “self-certification” systems in general, as they lead to a lot of\\ncertificates and blurring the information for users in the end (negative developments in the area\\nof “bio”). If a “self-certification” system is used, there should be an external validation by auditors.\\nSandboxes: Sandboxes are a solution in the technical testing phase, however if the service is\\noffered to customers in reality / goes life, rules need to apply (no legal free-ride e.g. with regard\\nto GDPR).\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 2, 'page': 2, '_split_overlap': [{'doc_id': '36891e3b462cdde785ad67096beaa71a', 'range': (0, 258)}, {'doc_id': '96c8ed551c0ef16ca9bbc3f4b13a09a4', 'range': (1027, 1232)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f67805364a155fffd76530c08a9ab76'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: Sandboxes: Sandboxes are a solution in the technical testing phase, however if the service is\\noffered to customers in reality / goes life, rules need to apply (no legal free-ride e.g. with regard\\nto GDPR).\\nAI review life-cycle: every AI provider needs to think about internal processes (models, training\\nof data, handling of critical situations, handbooks, documentation etc.), the official certification,\\nboth ex-ante and ex-post assessments, later more ex-post than ex-ante assessments, after 5 years\\nrevision of processes, if necessary.\\nRisk Assessment: In general, any AI application must have clear and well-designed\\nrules/objectives to minimize the associated risks. High-risk AI applications: A combination of ex-\\nante assessments, based on an external conformity procedure, as well as ex-post market\\nsurveillance would be useful. Non high-risk AI applications: A combination of ex-ante\\nassessments, based on a self-assessment, as well as ex-post market surveillance would be useful.\\nIn cases where ex-ante assessments are difficult, more ex-post assessments are needed. Either\\nway, it is crucial that the necessary capacities are in place to assess the AI, to ensure the efficiency\\nto support the launch of AI products.\\nOpen/ closed systems: It is important to differentiate between AI applications operating in “open\\nsystems” (e.g. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 3, 'page': 3, '_split_overlap': [{'doc_id': 'f67805364a155fffd76530c08a9ab76', 'range': (0, 205)}, {'doc_id': 'ce746415121a0c55d5c9ed10865c403c', 'range': (1078, 1340)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '96c8ed551c0ef16ca9bbc3f4b13a09a4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: Either\\nway, it is crucial that the necessary capacities are in place to assess the AI, to ensure the efficiency\\nto support the launch of AI products.\\nOpen/ closed systems: It is important to differentiate between AI applications operating in “open\\nsystems” (e.g. road traffic) or “closed systems” (e.g. playing chess). In “open systems”, the AI\\nwill never be able to cover all eventualities, as the training data is always limited. Here humans\\nmust make the final decision. This is also true for high-risk AI applications in “closed systems”.\\x0c4\\nConsultation on the White Paper on Artificial\\nIntelligence - A European Approach\\nSection 1 - An ecosystem of excellence\\nTo build an ecosystem of excellence that can support the development and uptake of AI across the EU\\neconomy, the White Paper proposes a series of actions.\\nQuestion 1: In your opinion, how important are the six actions proposed in section 4 of the\\nWhite Paper on AI (1-5: 1 is not important at all, 5 is very important)?\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 4, 'page': 3, '_split_overlap': [{'doc_id': '96c8ed551c0ef16ca9bbc3f4b13a09a4', 'range': (0, 262)}, {'doc_id': '961c03b06ae76d1e8700d7c4a7ba2914', 'range': (820, 984)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ce746415121a0c55d5c9ed10865c403c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: Question 1: In your opinion, how important are the six actions proposed in section 4 of the\\nWhite Paper on AI (1-5: 1 is not important at all, 5 is very important)?\\n1 - Not\\nimportant\\nat all\\n2 - Not\\nimportant\\n3 -\\nNeutral\\n4 -\\nImportant\\n5 - Very\\nimportant\\nNo\\nopinion\\nWorking with Member states x\\nFocussing the efforts of the\\nresearch and innovation\\ncommunity\\nx\\nSkills x\\nFocus on SMEs x\\nPartnership with the private sector x\\nPromoting the adoption of AI by\\nthe public sector\\nx\\x0c5\\nQuestion 1a: Are there other actions that should be considered?\\nDBG RESPONSE:\\nThe cooperation between authorities and market participants can bring valuable outcomes, not\\nonly during the actual cooperation. It also widens the mutual understanding of benefits and risks\\nassociated with a technology and lays the ground for a wider ecosystem. These ecosystems should\\nbe promoted and supported. Together with the Hessian Ministries, Deutsche Börse Group and\\nothers, have such a cooperation within the so called “Financial Big Data Cluster”(FBDC).\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 5, 'page': 4, '_split_overlap': [{'doc_id': 'ce746415121a0c55d5c9ed10865c403c', 'range': (0, 164)}, {'doc_id': 'bd6c8e55fc8dec8b593793328a983fd1', 'range': (867, 1018)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '961c03b06ae76d1e8700d7c4a7ba2914'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: Together with the Hessian Ministries, Deutsche Börse Group and\\nothers, have such a cooperation within the so called “Financial Big Data Cluster”(FBDC).\\nRevising the Coordinated Plan on AI (Action 1)\\nThe Commission, taking into account the results of the public consultation on the White Paper, will propose to\\nMember States a revision of the Coordinated Plan to be adopted by end 2020.\\nQuestion 2: In your opinion, how important is it in each of these areas to align policies and\\nstrengthen coordination as described in section 4.A of the White Paper (1-5: 1 is not important\\nat all, 5 is very important)?\\n1 – Not\\nImportant at\\nall\\n2 – Not\\nimportant\\n3 -\\nNeutral\\n4 -\\nImportant\\n5 -\\nVeryimportant\\nNo\\nopinion\\nStrengthen excellence in\\nresearch\\nx\\nEstablish world-reference\\ntesting facilities for AI\\nx\\nPromote the uptake of AI\\nby business and the public\\nsector\\nx\\nIncrease the financing for\\nstart-ups innovating in AI\\nx\\nDevelop skills for AI and\\nadapt existing training\\nprogrammes\\nx\\nBuild up the European\\ndata space\\nx\\x0c6\\nQuestion 2a: Are there other areas that that should be considered?\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 6, 'page': 5, '_split_overlap': [{'doc_id': '961c03b06ae76d1e8700d7c4a7ba2914', 'range': (0, 151)}, {'doc_id': '700808388bc107a21525e8b0a5769d97', 'range': (606, 1077)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bd6c8e55fc8dec8b593793328a983fd1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: 1 – Not\\nImportant at\\nall\\n2 – Not\\nimportant\\n3 -\\nNeutral\\n4 -\\nImportant\\n5 -\\nVeryimportant\\nNo\\nopinion\\nStrengthen excellence in\\nresearch\\nx\\nEstablish world-reference\\ntesting facilities for AI\\nx\\nPromote the uptake of AI\\nby business and the public\\nsector\\nx\\nIncrease the financing for\\nstart-ups innovating in AI\\nx\\nDevelop skills for AI and\\nadapt existing training\\nprogrammes\\nx\\nBuild up the European\\ndata space\\nx\\x0c6\\nQuestion 2a: Are there other areas that that should be considered?\\nDBG RESPONSE:\\nA balanced approach is most beneficial, as it can support the cooperation of small/big\\npublic/private actors necessary for successful AI ecosystems within/beyond one industry sector.\\nRegarding the EU data spaces, we see the political interest, however one “single common EU\\ndata space” would not lead to innovation; a competitive approach would be preferable. Also, we\\nwould prefer to start with “meaningful content clusters” and develop standards for those data for\\ninteroperability.\\nA united and strengthened research and innovation community striving for excellence\\nJoining forces at all levels, from basic research to deployment, will be key to overcome fragmentation and\\ncreate synergies between the existing networks of excellence.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 7, 'page': 5, '_split_overlap': [{'doc_id': 'bd6c8e55fc8dec8b593793328a983fd1', 'range': (0, 471)}, {'doc_id': '8e3ea891f6266d91cfdcd4a8fc49a2fe', 'range': (971, 1223)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '700808388bc107a21525e8b0a5769d97'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: A united and strengthened research and innovation community striving for excellence\\nJoining forces at all levels, from basic research to deployment, will be key to overcome fragmentation and\\ncreate synergies between the existing networks of excellence.\\nQuestion 3: In your opinion how important are the three actions proposed in sections 4.B, 4.C\\nand 4.E of the White Paper on AI (1-5: 1 is not important at all, 5 is very important)?\\n1 – Not\\nImportant\\nat all\\n2 – Not\\nimportant\\n3 -\\nNeutral\\n4 -\\nImportant\\n5 -\\nVeryimportant\\nNo\\nopinion\\nSupport the establishment of a\\nlighthouse research centre that\\nis world class and able to attract\\nthe best minds\\nx\\nNetwork of existing AI research\\nexcellence centres\\nx\\nSet up a public-private\\npartnership for industrial\\nresearch\\nx\\nQuestion 3a: Are there any other actions to strengthen the research and innovation\\ncommunity that should be given a priority?\\x0c7\\nFocusing on Small and Medium Enterprises (SMEs)\\nThe Commission will work with Member States to ensure that at least one digital innovation hub per Member\\nState has a high degree of specialisation on AI.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 8, 'page': 6, '_split_overlap': [{'doc_id': '700808388bc107a21525e8b0a5769d97', 'range': (0, 252)}, {'doc_id': 'a51af6c2fd3517ea13fb865def2b6d5', 'range': (889, 1093)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8e3ea891f6266d91cfdcd4a8fc49a2fe'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: 7\\nFocusing on Small and Medium Enterprises (SMEs)\\nThe Commission will work with Member States to ensure that at least one digital innovation hub per Member\\nState has a high degree of specialisation on AI.\\nQuestion 4: In your opinion, how important are each of these tasks of the specialised Digital\\nInnovation Hubs mentioned in section 4.D of the White Paper in relation to SMEs (1-5: 1 is\\nnot important at all, 5 is very important)?\\n1 – Not\\nImportant at\\nall\\n2 – Not\\nimportant\\n3 -\\nNeutral\\n4 -\\nImportant\\n5 -\\nVeryimportant\\nNo\\nopinion\\nHelp to raise SME’s\\nawareness about\\npotential benefits of AI\\nx\\nProvide access to testing\\nand reference facilities\\nx\\nPromote knowledge\\ntransfer and support the\\ndevelopment of AI\\nexpertise for SMEs\\nx\\nSupport partnerships\\nbetween SMEs, larger\\nenterprises and academia\\naround AI projects\\nx\\nProvide information about\\nequity financing for AI\\nstartups\\nx\\nQuestion 4a: Are there any other tasks that you consider important for specialised Digital\\nInnovations Hubs?\\x0c8\\nSection 2 - An ecosystem of trust\\nChapter 5 of the White Paper sets out options for a regulatory framework for AI.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 9, 'page': 7, '_split_overlap': [{'doc_id': '8e3ea891f6266d91cfdcd4a8fc49a2fe', 'range': (0, 204)}, {'doc_id': '1fd72bdcb5bb15175fa24c535016f008', 'range': (988, 1104)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a51af6c2fd3517ea13fb865def2b6d5'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: 8\\nSection 2 - An ecosystem of trust\\nChapter 5 of the White Paper sets out options for a regulatory framework for AI.\\nQuestion 5: In your opinion, how important are the following concerns about AI (1-5: 1 is not\\nimportant at all, 5 is very important)?\\n1 – Not\\nImportant at\\nall\\n2 – Not\\nimportant\\n3 -\\nNeutral\\n4 -\\nImportant\\n5 -\\nVeryimportant\\nNo\\nopinion\\nAI may endanger safety x\\nAI may breach fundamental\\nrights (such as human\\ndignity, privacy, data\\nprotection, freedom of\\nexpression, workers' rights\\netc.)\\nx\\nThe use of AI may lead to\\ndiscriminatory outcomes\\nx\\nAI may take actions for\\nwhich the rationale cannot\\nbe explained\\nx\\nAI may make it more\\ndifficult for persons having\\nsuffered harm to obtain\\ncompensation\\nx\\nAI is not always accurate x\\x0c9\\nQuestion 5a: Do you have any other concerns about AI that are not mentioned above? Please\\nspecify:\\nDBG RESPONSE:\\nFrom our perspective as a financial market infrastructure, we see no safety concerns with AI\\nregarding the physically well-being.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 10, 'page': 8, '_split_overlap': [{'doc_id': 'a51af6c2fd3517ea13fb865def2b6d5', 'range': (0, 116)}, {'doc_id': '442e872ff7617da3e2c6ad15d7945666', 'range': (823, 982)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1fd72bdcb5bb15175fa24c535016f008'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: Please\\nspecify:\\nDBG RESPONSE:\\nFrom our perspective as a financial market infrastructure, we see no safety concerns with AI\\nregarding the physically well-being.\\nWe think it is necessary to focus on the tasks performed and the potential impact by AI\\napplications in order to evaluate whether the rationale of a decision must be explainable\\nmandatory. If AI applications would impact/interact with consumers directly this is more\\nimportant, than if an AI performs business-internal “technical” tasks.\\nQuestion 6: Do you think that the concerns expressed above can be addressed by applicable\\nEU legislation? If not, do you think that there should be specific new rules for AI systems?\\n1 Current legislation is fully sufficient\\n2 DBG RESPONSE: Current legislation may have some gaps\\n3 There is a need for a new legislation\\n4 Other\\n5 No opinion\\nOther, please specify\\nDBG RESPONSE:\\nFrom our point of view as a financial market infrastructure, most activities/services performed by\\nAI applications in the financial sector would be regulated by already existing rules and legislation.\\nExamples are the MiFID II/MiFIR framework or the GDPR, which would have to be respected\\nanyway. To ensure speed-to-market, we would prefer to adjust/finetune existing regulation, if\\nnecessary. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 11, 'page': 9, '_split_overlap': [{'doc_id': '1fd72bdcb5bb15175fa24c535016f008', 'range': (0, 159)}, {'doc_id': '97b28aefe996e629df51dcce095e3d8d', 'range': (1076, 1268)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '442e872ff7617da3e2c6ad15d7945666'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: Examples are the MiFID II/MiFIR framework or the GDPR, which would have to be respected\\nanyway. To ensure speed-to-market, we would prefer to adjust/finetune existing regulation, if\\nnecessary. New regulation should only cover new issues related to AI.\\x0c10\\nQuestion 7: If you think that new rules are necessary for AI system, do you agree that the\\nintroduction of new compulsory requirements should be limited to high-risk applications\\n(where the possible harm caused by the AI system is particularly high)?\\n1 DBG RESPONSE: Yes\\n2 No\\n3 Other\\n4 No opinion\\nOther, please specify:\\nDBG RESPONSE:\\nAs stated above, and in order to support the data driven EU economy as well as the usage of AI\\napplications, we think that the adjustment existing regulations is preferable to new rules.\\nTherefore, we think that the introduction of new compulsory requirements should be limited to\\nhigh-risk applications. Nevertheless, while we agree with the approach to determine risk in\\ngeneral, we think there is still a need for clear criteria to define “high-risk”.\\nQuestion 8: Do you agree with the approach to determine “high-risk” AI applications proposed\\nin Section 5.B of the White Paper?\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 12, 'page': 9, '_split_overlap': [{'doc_id': '442e872ff7617da3e2c6ad15d7945666', 'range': (0, 192)}, {'doc_id': 'a6d73255a4b325e830c4cb17bd860dd3', 'range': (1044, 1171)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '97b28aefe996e629df51dcce095e3d8d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: Question 8: Do you agree with the approach to determine “high-risk” AI applications proposed\\nin Section 5.B of the White Paper?\\n1 DBG RESPONSE: Yes\\n2 No\\n3 Other\\n4 No opinion\\nOther, please specify:\\x0c11\\nQuestion 9: If you wish, please indicate the AI application or use that is most concerning (“high-\\nrisk”) from your perspective:\\nDBG RESPONSE:\\nIn general, any AI application must have clear and well-designed rules/objectives to minimize the\\nassociated risks. Further, it is important to differentiate between AI applications operating in “open\\nsystems” (e.g. road traffic) or “closed systems” (e.g. playing chess). In “open systems”, the AI\\nwill never be able to cover all eventualities, as the training data is always limited. Here humans\\nmust make the final decision. This is also true for high-risk AI applications in “closed systems”.\\nQuestion 10: In your opinion, how important are the following mandatory requirements of a\\npossible future regulatory framework for AI (as section 5.D of the White Paper) (1-6: 1 is not\\nimportant at all, 6 is very important)?\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 13, 'page': 10, '_split_overlap': [{'doc_id': '97b28aefe996e629df51dcce095e3d8d', 'range': (0, 127)}, {'doc_id': '432fca80f04620fa2463581096127e59', 'range': (839, 1063)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a6d73255a4b325e830c4cb17bd860dd3'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: Question 10: In your opinion, how important are the following mandatory requirements of a\\npossible future regulatory framework for AI (as section 5.D of the White Paper) (1-6: 1 is not\\nimportant at all, 6 is very important)?\\n1 – Not\\nImportant at\\nall\\n2 – Not\\nimportant\\n3 -\\nNeutral\\n4 -\\nImportant\\n5 -\\nVeryimportant\\nNo\\nopinion\\nThe quality of training\\ndata sets\\nx\\nThe keeping of records\\nand data\\nx\\nInformation on the\\npurpose and the nature\\nof AI systems\\nX\\nRobustness and\\naccuracy of AI systems\\nx\\nHuman oversight x\\nClear liability and safety\\nrules\\nx\\nADDITIONAL DBG RESPONSE:\\nFrom an innovation standpoint it must be avoided that consumers must be informed about every\\nstep in the process while dealing with an AI.\\x0c12\\nQuestion 11: In addition to the existing EU legislation, in particular the data protection\\nframework, including the General Data Protection Regulation and the Law Enforcement\\nDirective, or, where relevant, the new possibly mandatory requirements foreseen above (see\\nquestion above), do you think that the use of remote biometric identification systems (e.g. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 14, 'page': 11, '_split_overlap': [{'doc_id': 'a6d73255a4b325e830c4cb17bd860dd3', 'range': (0, 224)}, {'doc_id': 'a627a1c4b9b84bdd50e5c537ba06f5db', 'range': (708, 1068)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '432fca80f04620fa2463581096127e59'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: 12\\nQuestion 11: In addition to the existing EU legislation, in particular the data protection\\nframework, including the General Data Protection Regulation and the Law Enforcement\\nDirective, or, where relevant, the new possibly mandatory requirements foreseen above (see\\nquestion above), do you think that the use of remote biometric identification systems (e.g. face\\nrecognition) and other technologies which may be used in public spaces need to be subject to\\nfurther EU-level guidelines or regulation:\\n1 No further guidelines or regulations are needed\\n2 Biometric identification systems should be allowed in publicly accessible spaces only in certain cases or if\\ncertain conditions are fulfilled (please specify)\\n3 Other special requirements in addition to those mentioned in the question above should be imposed\\n(please specify)\\n4 Use of Biometric identification systems in publicly accessible spaces, by way of exception to the current\\ngeneral prohibition, should not take place until a specific guideline or legislation at EU level is in place.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 15, 'page': 12, '_split_overlap': [{'doc_id': '432fca80f04620fa2463581096127e59', 'range': (0, 360)}, {'doc_id': '13a6b3243e12f96a9e745c46d849f75b', 'range': (361, 1047)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a627a1c4b9b84bdd50e5c537ba06f5db'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: face\\nrecognition) and other technologies which may be used in public spaces need to be subject to\\nfurther EU-level guidelines or regulation:\\n1 No further guidelines or regulations are needed\\n2 Biometric identification systems should be allowed in publicly accessible spaces only in certain cases or if\\ncertain conditions are fulfilled (please specify)\\n3 Other special requirements in addition to those mentioned in the question above should be imposed\\n(please specify)\\n4 Use of Biometric identification systems in publicly accessible spaces, by way of exception to the current\\ngeneral prohibition, should not take place until a specific guideline or legislation at EU level is in place.\\n5 Biometric identification systems should never be allowed in publicly accessible spaces\\n6 DBG RESPONSE: No opinion\\nPlease specify your answer:\\nQuestion 12: Do you believe that a voluntary labelling system (Section 5.G of the White Paper)\\nwould be useful for AI systems that are not considered high-risk in addition to existing\\nlegislation?\\n1 DBG RESPONSE: Very much\\n2 Much\\n3 Rather not\\n4 Not at all\\n5 No opinion\\x0c13\\nQuestion 12a: Do you have any further suggestion on a voluntary labelling system?\\nDBG RESPONSE:\\nWe support a certification of high-risk AI applications. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 16, 'page': 12, '_split_overlap': [{'doc_id': 'a627a1c4b9b84bdd50e5c537ba06f5db', 'range': (0, 686)}, {'doc_id': 'bf9741686727eab06a25bae5fa429edb', 'range': (1028, 1255)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '13a6b3243e12f96a9e745c46d849f75b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: 1 DBG RESPONSE: Very much\\n2 Much\\n3 Rather not\\n4 Not at all\\n5 No opinion\\x0c13\\nQuestion 12a: Do you have any further suggestion on a voluntary labelling system?\\nDBG RESPONSE:\\nWe support a certification of high-risk AI applications. Further, for non-high risk AI applications\\nit should be allowed for companies to receive a voluntary certification.\\nWe prefer an official harmonized labelling system for both applications with clear requirements\\nand an official certification process performed by a formally authorized actor. This service could\\nbe offered by a public authority directly or by a private institution with a public permission on\\nbehalf of public authorities (e.g. like the German TÜV).\\nA differentiated grading system (e.g. bronze, silver, gold) could be useful, if an AI application\\nfulfills only some of the categories/requirements. However, it must be secured that the formally\\nauthorized actors have the capacity (resources, budget etc.) to perform their tasks efficiently and\\nin time.\\nWe are opposing “self-certification” systems in general, as they lead to a lot of certificates and\\nblurring the information for users in the end (negative developments in the area of “bio”). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 17, 'page': 12, '_split_overlap': [{'doc_id': '13a6b3243e12f96a9e745c46d849f75b', 'range': (0, 227)}, {'doc_id': '610023f1c37fb0f36b80171386235ac4', 'range': (998, 1188)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bf9741686727eab06a25bae5fa429edb'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: We are opposing “self-certification” systems in general, as they lead to a lot of certificates and\\nblurring the information for users in the end (negative developments in the area of “bio”). If a\\n“self-certification” system is used, there should be an external validation by auditors.\\nQuestion 13: What is the best way to ensure that AI is trustworthy, secure and in respect of\\nEuropean values and rules?\\n1 Compliance of high-risk applications with the identified requirements should be self-assessed ex-ante (prior\\nto putting the system on the market)\\n2 Compliance of high-risk applications should be assessed ex-ante by means of an external conformity\\nassessment procedure\\n3 Ex-post market surveillance after the AI-enabled high-risk product or service has been put on the market\\nand, where needed, enforcement by relevant competent authorities\\n4 DBG RESPONSE: A combination of ex-ante compliance and ex-post enforcement mechanisms\\n5 Other enforcement system\\n6 No opinion\\x0c14\\nPlease specify any other enforcement system:\\nDBG RESPONSE:\\nHigh-risk AI applications: A combination of ex-ante assessments, based on an external conformity\\nprocedure, as well as ex-post market surveillance would be useful.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 18, 'page': 13, '_split_overlap': [{'doc_id': 'bf9741686727eab06a25bae5fa429edb', 'range': (0, 190)}, {'doc_id': '3b56301f03a201c492985ca8d96522ec', 'range': (405, 1199)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '610023f1c37fb0f36b80171386235ac4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: 1 Compliance of high-risk applications with the identified requirements should be self-assessed ex-ante (prior\\nto putting the system on the market)\\n2 Compliance of high-risk applications should be assessed ex-ante by means of an external conformity\\nassessment procedure\\n3 Ex-post market surveillance after the AI-enabled high-risk product or service has been put on the market\\nand, where needed, enforcement by relevant competent authorities\\n4 DBG RESPONSE: A combination of ex-ante compliance and ex-post enforcement mechanisms\\n5 Other enforcement system\\n6 No opinion\\x0c14\\nPlease specify any other enforcement system:\\nDBG RESPONSE:\\nHigh-risk AI applications: A combination of ex-ante assessments, based on an external conformity\\nprocedure, as well as ex-post market surveillance would be useful.\\nNon high-risk AI applications: A combination of ex-ante assessments, based on a self-\\nassessment, as well as ex-post market surveillance would be useful. In cases where ex-ante\\nassessments are difficult, more ex-post assessments are needed. Either way, it is crucial that the\\nnecessary capacities are in place to assess the AI, to ensure the efficiency of the assessment-\\nprocess to support the launch of AI products. It is important to allow for innovation. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 19, 'page': 13, '_split_overlap': [{'doc_id': '610023f1c37fb0f36b80171386235ac4', 'range': (0, 794)}, {'doc_id': '568e28137cd51998202849bc9c31cd7c', 'range': (1036, 1253)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3b56301f03a201c492985ca8d96522ec'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: Either way, it is crucial that the\\nnecessary capacities are in place to assess the AI, to ensure the efficiency of the assessment-\\nprocess to support the launch of AI products. It is important to allow for innovation. Ex-ante and\\nex-post assessments by public authorities are cheaper than assessments of external third party\\nproviders (often too costly for start-ups). Assessment requirements need to be therefore\\neconomically feasible (time, costs, efforts, bureaucracy) in order not to hinder innovation.\\nSandboxes are a solution in the technical testing phase, however if the service is offered to\\ncustomers in reality / goes life, rules need to apply (no legal free-ride e.g. with regard to GDPR).\\nImportant steps: every AI provider needs to think about internal processes (models, training of\\ndata, handling of critical situations, handbooks, documentation etc.), the official certification,\\nboth ex-ante and ex-post assessments, later more ex-post than ex-ante assessments, after 5 years\\nrevision of processes, if necessary.\\nExample: market supervision: e.g. volatility-interruptions. In this example the application is\\ntrained on historical data, however the market develops differently in real time. An ex-ante\\nassessment is not easy to tackle. User experience cannot be seen in an ex-ante assessment.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 20, 'page': 14, '_split_overlap': [{'doc_id': '3b56301f03a201c492985ca8d96522ec', 'range': (0, 217)}, {'doc_id': '830a3ef8b6f175f4935a78f47185d161', 'range': (1091, 1309)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '568e28137cd51998202849bc9c31cd7c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: In this example the application is\\ntrained on historical data, however the market develops differently in real time. An ex-ante\\nassessment is not easy to tackle. User experience cannot be seen in an ex-ante assessment.\\nBut one could introduce a “review” after a certain time (e.g. 6 month “trial phase”). This flexibility\\nallows for innovation, improves and better services in the long run, as AI applications are in a\\ndynamic development phase and could increase dramatically. The review of the criteria does not\\nneed to be foreseen in regulation, but rather on guidelines published by supervisory authorities\\nand could be updated on a more regular basis.\\x0c15\\nQuestion 14: Do you have any further suggestion on the assessment of compliance?\\nDBG RESPONSE:\\nWhile designing the compliance assessment process, it is important to keep start-up companies\\nin mind. Therefore, the process should be as efficient as possible, depending on the AI application\\nin question.\\nIn some cases, it might be necessary to focus more on ex-post assessments (e.g. via increased\\nmonitoring), e.g. if ex-ante assessments are only of limited meaningfulness, as the data to train\\nan application will differ from “live” data.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 21, 'page': 14, '_split_overlap': [{'doc_id': '568e28137cd51998202849bc9c31cd7c', 'range': (0, 218)}, {'doc_id': '59b3df53a2bd209b7474d9017a26984d', 'range': (1074, 1198)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '830a3ef8b6f175f4935a78f47185d161'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: if ex-ante assessments are only of limited meaningfulness, as the data to train\\nan application will differ from “live” data.\\nThe list of requirements for (high-risk) AI applications should be reviewed and updated timely\\nand frequently, e.g. without a level 1 change of the regulatory framework, to keep up with\\ntechnological innovation.\\nSection 3 – Safety and liability implications of AI, IoT and robotics\\nThe overall objective of the safety and liability legal frameworks is to ensure that all products and services,\\nincluding those integrating emerging digital technologies, operate safely, reliably and consistently and that\\ndamage having occurred is remedied efficiently.\\nQuestion 15: The current product safety legislation already supports an extended concept of\\nsafety protecting against all kind of risks arising from the product according to its use. However,\\nwhich particular risks stemming from the use of artificial intelligence do you think should be\\nfurther spelled out to provide more legal certainty?\\n1 Cyber risks\\n2 Personal security risks\\n3 Risks related to the loss of connectivity\\n4 Mental health risks\\x0c16\\nQuestion 15a: In your opinion, are there any further risks to be expanded on to provide more\\nlegal certainty?\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 22, 'page': 15, '_split_overlap': [{'doc_id': '830a3ef8b6f175f4935a78f47185d161', 'range': (0, 124)}, {'doc_id': '512388cc24f4bdd355b6a17b6b65fd66', 'range': (1017, 1235)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '59b3df53a2bd209b7474d9017a26984d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: 1 Cyber risks\\n2 Personal security risks\\n3 Risks related to the loss of connectivity\\n4 Mental health risks\\x0c16\\nQuestion 15a: In your opinion, are there any further risks to be expanded on to provide more\\nlegal certainty?\\nDBG RESPONSE:\\nNot relevant for our business, as we do not offer products, which endanger retail customers.\\nQuestion 16: Do you think that the safety legislative framework should consider new risk\\nassessment procedures for products subject to important changes during their lifetime?\\n1 DBG RESPONSE: Yes\\n2 No\\n3 No opinion\\nQuestion 16a: Do you have any further considerations regarding risk assessment procedures?\\nDBG RESPONSE:\\nAs an ex-ante risk assessment is not fully possible for every AI application, a distinction between\\n“self-learning” and “release-based” might be useful. In case of “self-learning” AI applications,\\nagain, a focus on ex-post control mechanisms seems beneficial. Therefore, regular reviews and\\npotential re-training “check-points “might be established in the process, this is especially\\nnecessary for “self-learning” AI applications (see the controversy around the chatter bots in 2016).\\nQuestion 17: Do you think that the current EU legislative framework for liability (Product\\nLiability Directive) should be amended to better cover the risks engendered by certain AI\\napplications?\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 23, 'page': 15, '_split_overlap': [{'doc_id': '59b3df53a2bd209b7474d9017a26984d', 'range': (0, 218)}, {'doc_id': '8a64526446308e4ad676d9c991b4081', 'range': (1130, 1324)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '512388cc24f4bdd355b6a17b6b65fd66'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Deutsche Börse Group, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: Germany, document_date: 10-06-2020 11:13, language: English, \\n\\nPassage: Question 17: Do you think that the current EU legislative framework for liability (Product\\nLiability Directive) should be amended to better cover the risks engendered by certain AI\\napplications?\\n1 Yes\\n2 No\\n3 No opinion\\x0c17\\nQuestion 17a: Do you have any further considerations regarding the question above?\\nDBG RESPONSE:\\nIn general, it might be useful to ask whether a completely “new”, and therefore unregulated, task\\nis performed by an AI application in contrast to an already “known”, and therefore regulated task.\\nIn the latter case, adjustments to the existing framework might be sufficient. For example, if a\\ncompany can prove that it fulfilled all requirements, it should not be held liable because of\\n“negligence”. Notwithstanding a human or an AI application caused the accident.\\nQuestion 18: Do you think that the current national liability rules should be adapted for the\\noperation of AI to better ensure proper compensation for damage and a fair allocation of\\nliability?\\n1 Yes, for all AI applications\\n2 Yes, for specific AI applications\\n3 No\\n4 No opinion\\nPlease specify the AI applications:\\nDBG RESPONSE:\\nSee above.\\nQuestion 19: Do you have any further considerations regarding the question above?', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', 'stakeholder_name': 'Deutsche Börse Group', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '10-06-2020 11:13', 'language': 'English', 'document_reference': 'F530517', 'document_name': 'F530517-20200610_EC_AI_whitepaper_DBG_response.pdf', '_split_id': 24, 'page': 16, '_split_overlap': [{'doc_id': '512388cc24f4bdd355b6a17b6b65fd66', 'range': (0, 194)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8a64526446308e4ad676d9c991b4081'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: P R O P U E S T A P A R A E L L I B R O B L A N C O S O B R E L A\\nI N T E L I G E N C I A A R T I F I C I A L :\\nUn enfoque europeo orientado\\na la excelencia y la confianza\\nBEATRIZ ALEGRE VILLARROYA\\nGraduada en el Programa Conjunto\\nDerecho - Administración y Dirección de Empresas\\nUniversidad de Zaragoza, España (2014-2020)\\nbeatrizalegrevillarroya@gmail.com\\nhttps://www.linkedin.com/in/beatriz-alegre-\\nvillarroya/\\nRef. Ares(2020)3354989 - 26/06/2020\\x0cRESUMEN\\nLa adopción de la inteligencia artificial plantea nuevos retos para los que la legislación actual no\\nestá preparada. Esta propuesta para el Libro Blanco sobre IA enfatiza algunos de los riesgos de\\nesta tecnología, tratando de aportar desde una perspectiva práctica posibles soluciones para los\\nmismos. Sobre la base de lo sugerido por la Comisión Europea, se recogen recomendaciones para\\nla adaptación y la elaboración de normativa en materia de propiedad intelectual e industrial,\\ntransporte terrestre, protección de datos, derecho de consumo, seguros y, finalmente, sobre el\\nrégimen de responsabilidad por daños causados por sistemas de IA. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': 'f24a82b238ba7b4025a69ab9cdc5a8a', 'range': (760, 1100)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f416e1c30d9dd169374cafa21885f31b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Sobre la base de lo sugerido por la Comisión Europea, se recogen recomendaciones para\\nla adaptación y la elaboración de normativa en materia de propiedad intelectual e industrial,\\ntransporte terrestre, protección de datos, derecho de consumo, seguros y, finalmente, sobre el\\nrégimen de responsabilidad por daños causados por sistemas de IA. Las medidas planteadas deben\\nser entendidas como una contribución a la futura regulación de la IA, poniendo relevancia en\\nalgunos aspectos que pueden ser matizados o desarrollados en mayor profundidad.\\nABSTRACT\\nThe adoption of artificial intelligence raises new challenges for which current legislation is not\\nprepared. This proposal for the White Paper on AI emphasizes some of the risks of this\\ntechnology, trying to provide possible solutions for them from a practical perspective. Based on\\nthe suggestions of the European Commission, recommendations are collected for the adaptation\\nand drafting of regulation on intellectual and industrial property, land transportation, data\\nprotection, consumer law, insurance, and, finally, on the liability for damage caused by AI\\nsystems. The proposed measures must be understood as a contribution to the future regulation of\\nAI, putting relevance in some aspects that can be nuanced or developed in greater depth.\\x0cÍNDICE\\n1. Introducción ............................................................................................................. 2\\n2. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 1, 'page': 2, '_split_overlap': [{'doc_id': 'f416e1c30d9dd169374cafa21885f31b', 'range': (0, 340)}, {'doc_id': '399ee52b95e7d1290193e2b9c1f140db', 'range': (1123, 1436)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f24a82b238ba7b4025a69ab9cdc5a8a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: The proposed measures must be understood as a contribution to the future regulation of\\nAI, putting relevance in some aspects that can be nuanced or developed in greater depth.\\x0cÍNDICE\\n1. Introducción ............................................................................................................. 2\\n2. Concepto de inteligencia artificial ......................................................................... 2\\n3. Adopción de la inteligencia artificial ..................................................................... 5\\n3.1. Riesgos de la IA ................................................................................................ 6\\n3.2. Privacidad y la Protección de Datos ............................................................... 9\\n3.3. Seguridad del sistema de IA .......................................................................... 12\\n3.4. Principio de no discriminación ..................................................................... 17\\n3.5. Responsabilidad por daños y perjuicios causados por la IA ..................... 23\\n4. Regulación de la inteligencia artificial ................................................................ 25\\n4.1. Posibles adaptaciones del marco legislativo europeo a la IA ..................... 25\\n4.1.1. Derecho de Propiedad Intelectual e Industrial .......................................... 25\\n4.1.2. Derecho de Transporte Terrestre .............................................................. 27\\n4.1.3. Derecho de Protección de Datos ............................................................... 29\\n4.1.4. Derecho de Consumo y Responsabilidad por Productos Defectuosos ..... 30\\n4.1.5. Derecho de Seguros .................................................................................. 33\\n4.2. Elaboración de nuevas normas sobre IA ..................................................... 34\\n4.2.1. Directrices Éticas para una IA fiable ........................................................ 34\\n4.2.2. Reglamento sobre Responsabilidad por los sistemas de IA ..................... 34\\n5. Conclusión .............................................................................................................. 43\\n6. Bibliografía ............................................................................................................ 44\\n7. Documentación ...................................................................................................... 46\\x0c2\\n1. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 2, 'page': 2, '_split_overlap': [{'doc_id': 'f24a82b238ba7b4025a69ab9cdc5a8a', 'range': (0, 313)}, {'doc_id': 'b0dac9ed4cdc2e98f323fb8cc36f6d43', 'range': (1990, 2454)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '399ee52b95e7d1290193e2b9c1f140db'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Reglamento sobre Responsabilidad por los sistemas de IA ..................... 34\\n5. Conclusión .............................................................................................................. 43\\n6. Bibliografía ............................................................................................................ 44\\n7. Documentación ...................................................................................................... 46\\x0c2\\n1. Introducción\\nLa inteligencia artificial está desarrollándose rápidamente, siendo implementada de forma\\ntransversal en diversos campos, como el económico o el biomédico. Su adopción trae\\nconsigo grandes oportunidades dada la eficiencia y objetividad característica de los\\nsistemas de IA, pero también presenta riesgos que pueden derivar potencialmente en la\\nvulneración de derechos fundamentales como la protección de datos personales y la\\nprivacidad o la no discriminación a través de decisiones parciales.\\nEl doble objetivo planteado por la Comisión Europea es promover la adopción de la IA y\\nabordar los riesgos asociados con ciertos usos de esta nueva tecnología, siendo el\\npropósito del Libro Blanco1 establecer posibles políticas sobre cómo lograr estas metas.\\nSin un marco regulatorio claro, la línea de actuación para prevenir, corregir y, en última\\ninstancia, determinar la responsabilidad es incierta. Es necesario proporcionar a los\\nEstados Miembros una guía con medidas específicas que, más allá del establecimiento de\\nunos principios éticos básicos para el diseño y utilización de la IA, ayuden a concretar los\\nproblemas que pueden surgir y las soluciones a los mismos.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 3, 'page': 3, '_split_overlap': [{'doc_id': '399ee52b95e7d1290193e2b9c1f140db', 'range': (0, 464)}, {'doc_id': '1977bdca2996c36cec488eafd28358b7', 'range': (1376, 1646)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b0dac9ed4cdc2e98f323fb8cc36f6d43'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Es necesario proporcionar a los\\nEstados Miembros una guía con medidas específicas que, más allá del establecimiento de\\nunos principios éticos básicos para el diseño y utilización de la IA, ayuden a concretar los\\nproblemas que pueden surgir y las soluciones a los mismos.\\nLa presente propuesta trata de contribuir a la adaptación y elaboración legislativa sobre\\ninteligencia artificial a nivel de la Unión Europea, profundizando especialmente en la\\nidentificación de riesgos de los sistemas de IA y la consideración de aspectos técnicos,\\néticos y jurídicos para mitigar los mismos.\\n2. Concepto de inteligencia artificial\\nEl 8 de abril de 2019 fue propuesta por el Grupo de Expertos de Alto Nivel sobre IA una\\nDefinición de inteligencia artificial2, señalando sus principales capacidades y disciplinas\\ncientíficas. Se parte de un concepto de sistemas de inteligencia artificial como «sistemas\\nde software (y posiblemente también de hardware) diseñados por humanos que, con un\\nobjetivo complejo, actúan […] interpretando los datos estructurados o no estructurados\\n1 COMISIÓN EUROPEA, White Paper on Artificial Intelligence: a European approach to excellence and\\ntrust, 19 de febrero de 2020, disponible en <https://ec.europa.eu/info/publications/white-paper-artificial-\\nintelligence-european-approach-excellence-and-trust_en>. Fecha de consulta: 21 de marzo de 2020.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 4, 'page': 4, '_split_overlap': [{'doc_id': 'b0dac9ed4cdc2e98f323fb8cc36f6d43', 'range': (0, 270)}, {'doc_id': '289245ccafd46a45241c72e537f62af9', 'range': (813, 1363)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1977bdca2996c36cec488eafd28358b7'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Se parte de un concepto de sistemas de inteligencia artificial como «sistemas\\nde software (y posiblemente también de hardware) diseñados por humanos que, con un\\nobjetivo complejo, actúan […] interpretando los datos estructurados o no estructurados\\n1 COMISIÓN EUROPEA, White Paper on Artificial Intelligence: a European approach to excellence and\\ntrust, 19 de febrero de 2020, disponible en <https://ec.europa.eu/info/publications/white-paper-artificial-\\nintelligence-european-approach-excellence-and-trust_en>. Fecha de consulta: 21 de marzo de 2020.\\n2 GRUPO DE EXPERTOS DE ALTO NIVEL EN IA DE LA COMISIÓN EUROPEA (a), A Definition Of\\nAI: Main Capabilities And Disciplines, 8 de abril de 2019, disponible en <https://ec.europa.eu/digital-\\nsingle-market/en/news/definition-artificial-intelligence-main-capabilities-and-scientific-disciplines>.\\nFecha de consulta: 22 de marzo de 2019.\\x0c3\\nrecopilados, razonando sobre el conocimiento, o el procesamiento de la información,\\nderivado de estos datos y la decisión de las mejores acciones para lograr el objetivo dado».\\nDesde la perspectiva de la disciplina científica, se parte de la idea abstracta de sistemas\\nde IA descrita en el párrafo anterior y se propone una clasificación en tres grupos, con\\ncarácter general y sin perjuicio de la existencia de otras técnicas y disciplinas:\\nrazonamiento y toma de decisiones, aprendizaje y robótica. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 5, 'page': 4, '_split_overlap': [{'doc_id': '1977bdca2996c36cec488eafd28358b7', 'range': (0, 550)}, {'doc_id': '7dcdfd0dc6a5a3f0922ece2384508fc1', 'range': (1062, 1384)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '289245ccafd46a45241c72e537f62af9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Desde la perspectiva de la disciplina científica, se parte de la idea abstracta de sistemas\\nde IA descrita en el párrafo anterior y se propone una clasificación en tres grupos, con\\ncarácter general y sin perjuicio de la existencia de otras técnicas y disciplinas:\\nrazonamiento y toma de decisiones, aprendizaje y robótica. El primer grupo comprende\\nlos sistemas más complejos que, a través de la aplicación y combinación de diversas\\ntécnicas, tienen como objetivo la optimización de una solución ante un problema\\nconcreto. Los sistemas de IA referidos al aprendizaje incluyen machine learning o deep\\nlearning, redes neuronales, árboles de decisiones y otras técnicas que permiten al sistema\\naprender a resolver problemas que no pueden especificarse de forma precisa o cuya\\nsolución no puede ser descrita mediante reglas simbólicas de razonamiento. El\\naprendizaje de estos sistemas puede asimismo clasificarse en términos generales como\\nsupervisado, no supervisado o reforzado. Dicha distinción dependerá de si el algoritmo\\nde optimización del problema es modificado o no al recibir nuevos datos del entorno en\\nel que la IA está funcionando, es decir, si el sistema de IA continúa aprendiendo durante\\nsu funcionamiento o se mantiene inmutable desde su entrenamiento bajo supervisión.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 6, 'page': 5, '_split_overlap': [{'doc_id': '289245ccafd46a45241c72e537f62af9', 'range': (0, 322)}, {'doc_id': '8c6833276e68f4a991908d86dc431963', 'range': (977, 1282)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7dcdfd0dc6a5a3f0922ece2384508fc1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Dicha distinción dependerá de si el algoritmo\\nde optimización del problema es modificado o no al recibir nuevos datos del entorno en\\nel que la IA está funcionando, es decir, si el sistema de IA continúa aprendiendo durante\\nsu funcionamiento o se mantiene inmutable desde su entrenamiento bajo supervisión.\\nFinalmente, la robótica consiste en la actuación de la IA a través de una máquina\\nfísicamente tangible, lo que comúnmente se conoce como robot.\\nLa definición de IA propuesta por la Comisión Europea, centrada en los datos y los\\nalgoritmos como sus principales elementos, es a priori amplia y flexible para poder\\nacomodarse al progreso tecnológico, pero a su vez precisa para contribuir a la creación\\nde un ámbito objetivo de las normas que perdure en el tiempo. Es importante que la\\nnormativa que sea elaborada o vaya a ser adaptada parta de un concepto de IA con esas\\ncaracterísticas, tratando de prevenir que el ámbito objetivo de la norma quede obsoleto\\nante los avances tecnológicos futuros.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 7, 'page': 5, '_split_overlap': [{'doc_id': '7dcdfd0dc6a5a3f0922ece2384508fc1', 'range': (0, 305)}, {'doc_id': '90b993e7099daa99457d699640bfb84f', 'range': (767, 1000)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8c6833276e68f4a991908d86dc431963'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Es importante que la\\nnormativa que sea elaborada o vaya a ser adaptada parta de un concepto de IA con esas\\ncaracterísticas, tratando de prevenir que el ámbito objetivo de la norma quede obsoleto\\nante los avances tecnológicos futuros.\\nSi bien es cierto que el concepto de inteligencia artificial del que se parte en las Directrices\\nÉticas para una IA fiable3 es consistente con el anteriormente referido, podría generarse\\ncierta confusión con respecto al carácter determinista de los algoritmos. Que un algoritmo\\nsea determinista implica que, para una misma entrada de datos, la IA proporcionará en\\n3 GRUPO DE EXPERTOS DE ALTO NIVEL EN IA DE LA COMISIÓN EUROPEA (b), Ethics\\nGuidelines for Trustworthy AI, 8 de abril de 2019, disponible en <https://ec.europa.eu/digital-single-\\nmarket/en/news/ethics-guidelines-trustworthy-ai>. Fecha de consulta: 17 de noviembre de 2019.\\x0c4\\ntodos los casos la misma salida. A pesar de no estar dotada de cognoscencia propia, la IA\\nse basa en el aprendizaje autónomo, lo que genera semejanza con la inteligencia humana4.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 8, 'page': 5, '_split_overlap': [{'doc_id': '8c6833276e68f4a991908d86dc431963', 'range': (0, 233)}, {'doc_id': 'c461e5271e10b738064a40679646840e', 'range': (905, 1050)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '90b993e7099daa99457d699640bfb84f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: A pesar de no estar dotada de cognoscencia propia, la IA\\nse basa en el aprendizaje autónomo, lo que genera semejanza con la inteligencia humana4.\\nEn este punto reside el principal problema de distorsión en cuanto a su entendimiento,\\npuesto que, si bien es asimilable su forma de procesar información a la de una persona,\\nesto no significa que exista la posibilidad de que desarrolle ideas por sí misma. La\\ninteligencia artificial trabaja dentro de las relaciones lógicas que establece el algoritmo\\nfruto de su entrenamiento, por lo que no debe ser entendida como un ente pensante, sino\\ncomo una herramienta matemática como lo es una ecuación, sólo que con un\\nfuncionamiento mucho más sofisticado.\\nUna variación en el output o resultado obtenido por el sistema de IA responde a una\\nmodificación del input. La opacidad de los sistemas de inteligencia artificial puede\\ndificultar el entendimiento de esa relación en sistemas de aprendizaje continuo no\\nsupervisado, ya que como previamente se ha expuesto, estos sistemas modifican su\\nalgoritmo en función del éxito de sus resultados. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 9, 'page': 6, '_split_overlap': [{'doc_id': '90b993e7099daa99457d699640bfb84f', 'range': (0, 145)}, {'doc_id': '4f4b102ca48f9c2286d33b81c1b8b6d', 'range': (805, 1079)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c461e5271e10b738064a40679646840e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: La opacidad de los sistemas de inteligencia artificial puede\\ndificultar el entendimiento de esa relación en sistemas de aprendizaje continuo no\\nsupervisado, ya que como previamente se ha expuesto, estos sistemas modifican su\\nalgoritmo en función del éxito de sus resultados. Ello no quiere decir, en ningún caso, que\\nla naturaleza del sistema de IA devenga no determinista, puesto que no existe arbitrio en\\nla toma de decisiones, sino un dinamismo que se materializa en la aparición de diferentes\\ndecisiones para problemas idénticos, pero siempre respaldado por un cambio de\\ncircunstancias reflejado en los datos proporcionados para el entrenamiento de la IA5.\\nSi se parte de un concepto de IA que refleje una naturaleza no determinista, podría\\nentenderse que la generación de resultados distintos se debe a la arbitrariedad del sistema.\\nPor el contrario, si se parte de un aprendizaje dinámico, toda decisión está basada en datos\\ny criterios que, con mayor o menor dificultad, podrían ser explicables. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 10, 'page': 6, '_split_overlap': [{'doc_id': 'c461e5271e10b738064a40679646840e', 'range': (0, 274)}, {'doc_id': 'fa734968040a638bd7b24a3fa7de94e6', 'range': (838, 1002)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4f4b102ca48f9c2286d33b81c1b8b6d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Por el contrario, si se parte de un aprendizaje dinámico, toda decisión está basada en datos\\ny criterios que, con mayor o menor dificultad, podrían ser explicables. Este extremo es\\nrelevante para la determinación de un régimen de responsabilidad, puesto que,\\npresuponiendo una imposibilidad de control del sistema por esa supuesta arbitrariedad,\\npodría llegar a plantearse la exoneración de la responsabilidad en el caso de decisiones o\\nactuaciones del sistema no explicables. Sin embargo, el carácter determinista del\\nalgoritmo excluye esa arbitrariedad, debiendo orientarse el régimen de responsabilidad\\n4 VAN GERVEN, M. y BOHTE. S., Artificial Neural Networks as Models of Neural Information\\nProcessing, Frontiers in Computational Neuroscience 11:114, 2017, pp. 1-2. DOI:\\n10.3389/fncom.2017.00114.\\n5 ELDRED, C., ZYSMAN, J. y NITZBERG, M., AI and Domain Knowledge: Implications of the Limits of\\nStatistical Inference, BRIE / WITS Technology Briefing, Berkeley, 2019, pp. 1-11, disponible en\\n<https://ssrn.com/abstract=3479479>. Fecha de consulta: 18 de mayo de 2020.\\x0c5\\nhacia la observación de las relaciones establecidas por el algoritmo, velando por su\\ntransparencia y explicabilidad y forzando a quienes diseñen los sistemas de IA a reducir\\nen la medida de lo posible la opacidad.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 11, 'page': 6, '_split_overlap': [{'doc_id': '4f4b102ca48f9c2286d33b81c1b8b6d', 'range': (0, 164)}, {'doc_id': '3194817087acc5c71261e37a0025cba5', 'range': (1069, 1284)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fa734968040a638bd7b24a3fa7de94e6'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: 5\\nhacia la observación de las relaciones establecidas por el algoritmo, velando por su\\ntransparencia y explicabilidad y forzando a quienes diseñen los sistemas de IA a reducir\\nen la medida de lo posible la opacidad.\\nPor todo ello, la definición de IA de la cual debe partir la elaboración o adaptación de la\\nnormativa debe ser suficientemente amplia, para procurar que perdure en un futuro a corto\\ny medio plazo a pesar de los avances tecnológicos, y al mismo tiempo precisa, atendiendo\\na las características de esta tecnología que singularizan su comportamiento. La seguridad\\nde los sistemas de IA y la salvaguarda de los derechos fundamentales que pueden verse\\ncomprometidos por sus decisiones y actuaciones sólo puede conseguirse a través de una\\ncomprensión íntegra de la inteligencia artificial y de la continua revisión de los progresos\\ny evoluciones de la misma.\\n3. Adopción de la inteligencia artificial\\nEl desarrollo y aplicación de la inteligencia artificial está siendo impulsado a gran\\nvelocidad. En este contexto, es difícil que la legislación y la aplicación e interpretación\\nde las normas evolucionen conforme lo hace la tecnología. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 12, 'page': 7, '_split_overlap': [{'doc_id': 'fa734968040a638bd7b24a3fa7de94e6', 'range': (0, 215)}, {'doc_id': 'edff639f70a9f3d3f3ca6e6d82449a12', 'range': (1008, 1146)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3194817087acc5c71261e37a0025cba5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: En este contexto, es difícil que la legislación y la aplicación e interpretación\\nde las normas evolucionen conforme lo hace la tecnología. Esta disparidad de ritmos\\npuede generar incertidumbre, temor y, desde una perspectiva más práctica, lagunas\\njurídicas que antes no existían. Es por ello por lo que debe adoptarse una postura de\\nconocimiento de la situación actual y anticipación a los nuevos retos. Solamente\\nconociendo el potencial de la IA, desde el punto de vista positivo y negativo, podrán\\nestablecerse normas que verdaderamente se adapten a esta nueva realidad y solucionen\\nlos conflictos jurídicos que la misma trae consigo sin poner en peligro el desarrollo y la\\ninnovación.\\nLos sistemas de IA presentan grandes ventajas por la propia naturaleza de los algoritmos,\\nsiendo el alto nivel de precisión de los resultados obtenidos una de las principales. El\\nelevado volumen de datos analizados permite que a través de la IA pueda optimizarse la\\nseguridad de los productos, la eficiencia en la toma de decisiones o el acierto de los\\nmodelos de predicción. Además, dichos resultados no están influidos por el punto de vista\\ndel decisor, lo que permite que los mismos sean más objetivos. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 13, 'page': 7, '_split_overlap': [{'doc_id': '3194817087acc5c71261e37a0025cba5', 'range': (0, 138)}, {'doc_id': '3ec7fd8f19d45a4355bfba04602c5435', 'range': (1064, 1193)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'edff639f70a9f3d3f3ca6e6d82449a12'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Además, dichos resultados no están influidos por el punto de vista\\ndel decisor, lo que permite que los mismos sean más objetivos. Por otra parte, el proceso\\nde clasificación y predicción con IA es considerablemente más rápido en comparación\\ncon el que lleva a cabo un ser humano y, además, exige un menor nivel de recursos en\\ncuanto a tiempo y personal invertidos.\\x0c6\\nEl aprendizaje automático y, en particular, su aplicación a sistemas autónomos de toma\\nde decisiones se ha extendido a campos tan diversos como el diagnóstico de\\nenfermedades, la predicción de delitos y la evaluación de seguros6. Estos sistemas de\\ntoma de decisiones estarían englobados en el primer grupo de sistemas de IA que se\\ndescriben en la Definición que aporta el Grupo de Expertos de Alto Nivel7,\\ncorrespondiendo a los sistemas de razonamiento a través de los cuales trata de optimizarse\\nun problema concreto.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 14, 'page': 7, '_split_overlap': [{'doc_id': 'edff639f70a9f3d3f3ca6e6d82449a12', 'range': (0, 129)}, {'doc_id': '3bd7b0eb68d19e7cfa52c452a56b8a4b', 'range': (597, 885)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3ec7fd8f19d45a4355bfba04602c5435'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Estos sistemas de\\ntoma de decisiones estarían englobados en el primer grupo de sistemas de IA que se\\ndescriben en la Definición que aporta el Grupo de Expertos de Alto Nivel7,\\ncorrespondiendo a los sistemas de razonamiento a través de los cuales trata de optimizarse\\nun problema concreto.\\nLas decisiones en estas áreas pueden tener implicaciones éticas o legales, por lo que es\\nnecesario que el sistema sea utilizado bajo una perspectiva que vaya más allá del objetivo\\nde maximizar la precisión de la predicción, debiendo considerar y ponderar, en su caso,\\nel impacto que pueden tener las decisiones generadas para la sociedad8. En este sentido,\\ndebe priorizarse la seguridad de los modelos de IA y la salvaguarda de los derechos\\nfundamentales que pueden verse afectados por los mismos.\\n3.1. Riesgos de la IA\\nLos riesgos potenciales inherentes a los sistemas de IA pueden tener distinta magnitud,\\nen función de diversos aspectos o criterios. Todo parece indicar que, con el objetivo de\\natender y mitigar estos riesgos, va a optarse por una clasificación dual: sistemas de alto\\nriesgo y sistemas de bajo riesgo. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 15, 'page': 8, '_split_overlap': [{'doc_id': '3ec7fd8f19d45a4355bfba04602c5435', 'range': (0, 288)}, {'doc_id': 'b8b924f5196d2d9e6c66da09b6d4b7d', 'range': (942, 1110)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3bd7b0eb68d19e7cfa52c452a56b8a4b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Todo parece indicar que, con el objetivo de\\natender y mitigar estos riesgos, va a optarse por una clasificación dual: sistemas de alto\\nriesgo y sistemas de bajo riesgo. Una diferenciación en dos grupos limita las posibilidades\\nde crear medidas adecuadas y suficientemente adaptadas para los sistemas de IA, puesto\\nque, al no existir categorías más específicas, habrá una amplia diversidad de sistemas\\ndentro de cada uno de los conjuntos. La división en más grupos o, al menos, en subgrupos,\\nposibilitaría una mayor concreción de los criterios de inclusión o pertenencia y de las\\nestrategias de mitigación. No obstante, dejando a un lado el debate sobre si el\\nplanteamiento de una clasificación dual es el más adecuado, debe atenderse a la aplicación\\npráctica de esta distinción.\\nPrecisar qué sistemas de IA serán considerados de alto riesgo o bajo riesgo supone una\\nclasificación muy importante, dado que las medidas de prevención de daños, control del\\n6 TAN, Z., YEOM, S., FREDRIKSON, M. y TALWALKAR, A., Learning Fair Representations for Kernel\\nModels,ArXiv preprint, arXiv:1906.11813, 2019, pp. 1-15.\\n7 GRUPO DE EXPERTOS DE ALTO NIVEL EN IA DE LA COMISIÓN EUROPEA (a), A Definition Of\\nAI…cit.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 16, 'page': 8, '_split_overlap': [{'doc_id': '3bd7b0eb68d19e7cfa52c452a56b8a4b', 'range': (0, 168)}, {'doc_id': '8da9d5650b5faf4986960ec80d84386d', 'range': (779, 1195)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b8b924f5196d2d9e6c66da09b6d4b7d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Precisar qué sistemas de IA serán considerados de alto riesgo o bajo riesgo supone una\\nclasificación muy importante, dado que las medidas de prevención de daños, control del\\n6 TAN, Z., YEOM, S., FREDRIKSON, M. y TALWALKAR, A., Learning Fair Representations for Kernel\\nModels,ArXiv preprint, arXiv:1906.11813, 2019, pp. 1-15.\\n7 GRUPO DE EXPERTOS DE ALTO NIVEL EN IA DE LA COMISIÓN EUROPEA (a), A Definition Of\\nAI…cit.\\n8 KLEINBERG, J., LUDWIG, J., MULLAINATHAN, S. y SUNSTEIN, C.S., «Discrimination in the Age\\nof Algorithms», Journal of Legal Analysis, Vol. 10, 2018, pp. 113-174. DOI: 10.1093/jla/laz001.\\x0c7\\nsistema, corrección de deficiencias y el régimen de responsabilidad serán distintas para\\ncada grupo. Además, es importante tener presente que esa diferenciación debe hacerse\\natendiendo a criterios claros y concretos, pero suficientemente amplios para dar cabida a\\nlos avances que puedan darse en los sistemas de IA y las nuevas tecnologías que puedan\\nsurgir. La indeterminación o la ausencia de unas reglas de clasificación concisas puede\\nocasionar que determinados sistemas de IA se encuentren entre los límites de estos dos\\ngrupos.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 17, 'page': 8, '_split_overlap': [{'doc_id': 'b8b924f5196d2d9e6c66da09b6d4b7d', 'range': (0, 416)}, {'doc_id': 'c7dc874050dc5de14d142d30140929d1', 'range': (965, 1139)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8da9d5650b5faf4986960ec80d84386d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: La indeterminación o la ausencia de unas reglas de clasificación concisas puede\\nocasionar que determinados sistemas de IA se encuentren entre los límites de estos dos\\ngrupos.\\nEn el Proyecto de Informe que lleva a cabo la Comisión de Asuntos Jurídicos del\\nParlamento Europeo sobre el régimen de responsabilidad civil en materia de IA9, que se\\nexaminará en mayor profundidad más adelante, se aporta una definición de sistema de IA\\nde alto riesgo. Se entiende como tal aquel cuyo funcionamiento autónomo conlleva «un\\npotencial y significativo riesgo de causar un perjuicio a una o más personas, de forma\\naleatoria o imposible de predecir; dependiendo la magnitud del riesgo de la relación entre\\nla gravedad del posible perjuicio, la probabilidad de que el riesgo se materialice y el modo\\nen que se utiliza el sistema de IA».\\nEsta definición resulta poco precisa, lo que conlleva que existan algunos inconvenientes\\na la hora de su aplicación práctica. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 18, 'page': 9, '_split_overlap': [{'doc_id': '8da9d5650b5faf4986960ec80d84386d', 'range': (0, 174)}, {'doc_id': '26b6e679ded9773910e7527443f6b9f2', 'range': (445, 947)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c7dc874050dc5de14d142d30140929d1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Se entiende como tal aquel cuyo funcionamiento autónomo conlleva «un\\npotencial y significativo riesgo de causar un perjuicio a una o más personas, de forma\\naleatoria o imposible de predecir; dependiendo la magnitud del riesgo de la relación entre\\nla gravedad del posible perjuicio, la probabilidad de que el riesgo se materialice y el modo\\nen que se utiliza el sistema de IA».\\nEsta definición resulta poco precisa, lo que conlleva que existan algunos inconvenientes\\na la hora de su aplicación práctica. En primer lugar, parece extraerse de la misma que\\núnicamente es un sistema de IA de alto riesgo aquel que puede causar un perjuicio de\\nforma aleatoria o imposible de predecir, cuando en realidad los sistemas de IA son\\ndeterministas, si bien pueden producirse resultados no esperados o difíciles de explicar\\npor la opacidad o complejidad del sistema. Además, los sistemas que no sean opacos y\\nque funcionen correctamente pueden presentar también alto riesgo en determinadas\\ncircunstancias, cuando por ejemplo afectan a derechos fundamentales como la vida o la\\nsalud. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 19, 'page': 9, '_split_overlap': [{'doc_id': 'c7dc874050dc5de14d142d30140929d1', 'range': (0, 502)}, {'doc_id': '1ce6cc47bf72de06dd15406b3f558b67', 'range': (853, 1068)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '26b6e679ded9773910e7527443f6b9f2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Además, los sistemas que no sean opacos y\\nque funcionen correctamente pueden presentar también alto riesgo en determinadas\\ncircunstancias, cuando por ejemplo afectan a derechos fundamentales como la vida o la\\nsalud. En el caso de una máquina que a través de IA puede llevar a cabo operaciones\\nquirúrgicas, a pesar de que el sistema puede estar bien calibrado y tener un margen de\\nerror mínimo, debe considerarse la conveniencia de que sea calificado como sistema de\\nalto riesgo dada la función que realiza, para que el nivel de prevención, control, corrección\\ny responsabilidad sea el máximo posible.\\n9 COMISIÓN DE ASUNTOS JURÍDICOS DEL PARLAMENTO EUROPEO, Proyecto de Informe con\\nrecomendaciones destinadas a la Comisión sobre un régimen de responsabilidad civil en materia de\\ninteligencia artificial (2020/2014 (INL)), disponible en\\n<https://www.europarl.europa.eu/doceo/document/JURI-PR-650556_ES.pdf>.\\x0c8\\nLa gravedad del posible perjuicio, la probabilidad de materialización del riesgo y el modo\\nde utilización de la IA son criterios que, por el contrario, pueden ser más adecuados para\\nhacer esta clasificación. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 20, 'page': 9, '_split_overlap': [{'doc_id': '26b6e679ded9773910e7527443f6b9f2', 'range': (0, 215)}, {'doc_id': '4468fa2e87d288f7637a6735cb7d2a9c', 'range': (906, 1115)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1ce6cc47bf72de06dd15406b3f558b67'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: 8\\nLa gravedad del posible perjuicio, la probabilidad de materialización del riesgo y el modo\\nde utilización de la IA son criterios que, por el contrario, pueden ser más adecuados para\\nhacer esta clasificación. Se dice en el Informe que «el grado de gravedad debe\\ndeterminarse sobre la base de la magnitud del daño potencial resultante del\\nfuncionamiento, el número de personas afectadas, el valor total del posible perjuicio y el\\ndaño a la sociedad en su conjunto». Parece entenderse de lo anterior que se valorará este\\ncriterio en función de cómo y por qué cuantía puedan afectar los potenciales daños a la\\nesfera del perjudicado, incluyendo menoscabos materiales y personales, a cuántas\\npersonas puedan afectar dichos daños y la relevancia de estos para la sociedad.\\nSobre la probabilidad de materialización del riesgo, uno de los factores más importantes\\na tener en cuenta, se dice que «debe determinarse sobre la base del papel de los cálculos\\nalgorítmicos en el proceso de toma de decisiones, la complejidad de la decisión y la\\nreversibilidad de los efectos». ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 21, 'page': 10, '_split_overlap': [{'doc_id': '1ce6cc47bf72de06dd15406b3f558b67', 'range': (0, 209)}, {'doc_id': '360dc77f8caf291f368f3f7ca8b55e22', 'range': (769, 1064)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4468fa2e87d288f7637a6735cb7d2a9c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Sobre la probabilidad de materialización del riesgo, uno de los factores más importantes\\na tener en cuenta, se dice que «debe determinarse sobre la base del papel de los cálculos\\nalgorítmicos en el proceso de toma de decisiones, la complejidad de la decisión y la\\nreversibilidad de los efectos». La abstracción de esta afirmación, especialmente cuando\\nse refiere al «papel de los cálculos algorítmicos en el proceso de toma de decisiones»,\\nrequiere de una aclaración o concreción. Lo anterior, sumado a la subjetividad que implica\\nmedir la complejidad de la decisión o la dificultad que puede suponer determinar si los\\ndaños causados son reversibles y hasta qué punto lo son, hace que resulte cuestionable la\\nutilización de estas características para medir el nivel riesgo de la IA. Un criterio que\\npermite determinar esa probabilidad de materialización del riesgo de forma más objetiva\\nes el margen de error de un sistema de IA, en el sentido de permitir el funcionamiento de\\nlos sistemas que tengan un porcentaje de éxito mínimo en sus resultados.\\nEstablecer un límite máximo en el margen de error puede ser la solución para evitar que\\nsean utilizados sistemas de IA deficientes que arrojen resultados incorrectos. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 22, 'page': 10, '_split_overlap': [{'doc_id': '4468fa2e87d288f7637a6735cb7d2a9c', 'range': (0, 295)}, {'doc_id': 'bcfc8c13a25705d7e7ef0ec26ff1a838', 'range': (1050, 1216)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '360dc77f8caf291f368f3f7ca8b55e22'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Establecer un límite máximo en el margen de error puede ser la solución para evitar que\\nsean utilizados sistemas de IA deficientes que arrojen resultados incorrectos. Sin\\nembargo, no es suficiente con determinar el margen de error que es permisible, puesto\\nque para que esta medida sea útil debe acompañarse del menor nivel de incertidumbre\\nposible. La incertidumbre de una IA mide la previsibilidad del comportamiento de la IA,\\nde manera que, a mayor nivel de incertidumbre, menor es la certeza sobre el margen de\\nerror. Un sistema de IA que no esté bien calibrado y, por tanto, tenga un nivel de\\nincertidumbre elevado, puede presentar un margen de error inexacto, de manera que la\\nprobabilidad de comportamientos fuera de lo esperado sea superior a la que el sistema\\nindica.\\nEs por ello por lo que, para asegurar que la probabilidad de materialización del riesgo se\\nminimiza, primero debe requerirse un nivel de incertidumbre de los sistemas de IA que\\x0c9\\npermita aproximar con suficiente exactitud el margen de error. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 23, 'page': 10, '_split_overlap': [{'doc_id': '360dc77f8caf291f368f3f7ca8b55e22', 'range': (0, 166)}, {'doc_id': 'c3545e3739fcdf1fc200ce5da195b6b2', 'range': (777, 1018)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bcfc8c13a25705d7e7ef0ec26ff1a838'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Es por ello por lo que, para asegurar que la probabilidad de materialización del riesgo se\\nminimiza, primero debe requerirse un nivel de incertidumbre de los sistemas de IA que\\x0c9\\npermita aproximar con suficiente exactitud el margen de error. El segundo paso, una vez\\nse ha calculado de forma precisa dicho margen, es concretar a partir de qué nivel el\\nsistema de IA no es aceptable por tener un porcentaje insuficiente de resultados\\nsatisfactorios.\\nPor último, el denominado modo de utilización de la inteligencia artificial se refiere «al\\nsector en el que opera el sistema de IA, si puede tener efectos jurídicos o reales sobre\\nderechos importantes de la persona afectada protegidos desde el punto de vista jurídico y\\nsi los efectos pueden evitarse razonablemente». Cabe suponer, siguiendo lo anterior, que\\nel nivel de riesgo será mayor si las acciones de la IA afectan a personas especialmente\\nvulnerables o actúan en áreas que requieren especial protección, como podrían ser la\\nsanidad, el medio ambiente o la educación.\\nUna valoración y ponderación de estos tres factores puede ayudar a identificar el nivel de\\nriesgo para cada sistema de IA. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 24, 'page': 10, '_split_overlap': [{'doc_id': 'bcfc8c13a25705d7e7ef0ec26ff1a838', 'range': (0, 241)}, {'doc_id': 'cb45778a8bc45acf565823ce02ae61e', 'range': (1024, 1146)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c3545e3739fcdf1fc200ce5da195b6b2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Una valoración y ponderación de estos tres factores puede ayudar a identificar el nivel de\\nriesgo para cada sistema de IA. Por otra parte, debe estudiarse si puede ser interesante\\nintroducir algunos ejemplos concretos que sirvan como referencia para los sistemas de\\ndifícil identificación. En este sentido, el Parlamento Europeo recomienda en su Informe\\nque todos los sistemas de IA de alto riesgo figuren en un anexo de la propuesta de\\nReglamento que sea sometida a una revisión periódica cada seis meses. Sin embargo,\\ndebe ampliarse la explicación con respecto a esta lista de sistemas de alto riesgo,\\nconcretando si es una lista orientativa o una lista cerrada, qué criterios de inclusión o\\npermanencia se seguirían o si dentro de la misma hay distintos niveles o todos se acogerán\\nal mismo tipo de régimen de responsabilidad y medidas preventivas.\\nPara que la clasificación de sistemas de IA en función de su riesgo sea adecuada, debe\\natenderse a los principios de no discriminación y de privacidad y protección de datos,\\ndado que son dos de los aspectos que más protección requieren dada la situación y el\\nestado actual de avance de esta tecnología. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 25, 'page': 11, '_split_overlap': [{'doc_id': 'c3545e3739fcdf1fc200ce5da195b6b2', 'range': (0, 122)}, {'doc_id': '985d2c4847bee0367b2917e58205837a', 'range': (852, 1154)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'cb45778a8bc45acf565823ce02ae61e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Para que la clasificación de sistemas de IA en función de su riesgo sea adecuada, debe\\natenderse a los principios de no discriminación y de privacidad y protección de datos,\\ndado que son dos de los aspectos que más protección requieren dada la situación y el\\nestado actual de avance de esta tecnología. A continuación, se exponen algunos de los\\nriesgos concretos que existen respecto a estos derechos, aportándose posteriormente una\\nlínea de actuación para mitigar los mismos.\\n3.2. Privacidad y la Protección de Datos\\nLa inteligencia artificial tiene un gran potencial para procesar y analizar datos a gran\\nescala. Si bien la intención que se persigue con su adopción es el buen uso de dicha\\ncapacidad para asistir y ayudar a la sociedad, una incorrecta utilización de esta tecnología\\npuede suponer una amenaza hacia la privacidad e intimidad de las personas. Los datos\\x0c10\\nprocesados, la forma en que se diseñan las aplicaciones y el alcance de la intervención\\nhumana pueden afectar los derechos de libertad de expresión, la protección de datos\\npersonales, la privacidad y las libertades políticas.\\nLa privacidad puede verse afectada no sólo por aquellos datos sensibles que\\nmanifiestamente se contengan en el big data. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 26, 'page': 11, '_split_overlap': [{'doc_id': 'cb45778a8bc45acf565823ce02ae61e', 'range': (0, 302)}, {'doc_id': '956415d117a526131da89e92ea58bf22', 'range': (860, 1219)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '985d2c4847bee0367b2917e58205837a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Los datos\\x0c10\\nprocesados, la forma en que se diseñan las aplicaciones y el alcance de la intervención\\nhumana pueden afectar los derechos de libertad de expresión, la protección de datos\\npersonales, la privacidad y las libertades políticas.\\nLa privacidad puede verse afectada no sólo por aquellos datos sensibles que\\nmanifiestamente se contengan en el big data. Dada la capacidad de inferencia estadística\\nde la IA, existe riesgo de extracción de datos sensibles a través del algoritmo. La\\ninferencia de datos sensibles consiste en la inducción de características concretas del\\nindividuo, como pueden ser la orientación sexual, edad, opiniones políticas o religiosas,\\ngénero o raza. Esto es posible a través del proceso inductivo por el cual el algoritmo,\\ndurante su entrenamiento a base de prueba y error, lleva a cabo simplificaciones de las\\nvariables recogidas en la base de datos que tienen relación entre sí e infiere una nueva\\nvariable10. Esta nueva variable es la que puede representar una característica del individuo\\nque la propia persona no haya querido revelar. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 27, 'page': 11, '_split_overlap': [{'doc_id': '985d2c4847bee0367b2917e58205837a', 'range': (0, 359)}, {'doc_id': '792f21a3ef0f5677d2ffe7b53e23c5d2', 'range': (943, 1070)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '956415d117a526131da89e92ea58bf22'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Esta nueva variable es la que puede representar una característica del individuo\\nque la propia persona no haya querido revelar. Por ejemplo, si una persona proporciona\\ndatos como los estudios cursados, el tipo de productos o servicios consumidos o sus\\naficiones o intereses, es posible que pueda inferirse estadísticamente su género.\\nEl uso potencial de la información necesaria para usar los sistemas de IA o generada por\\nestos mismos puede causar cierta inquietud con respecto a la utilización de la\\ninformación. En ocasiones, las características que pueden inferirse a través de la IA son\\ndatos que pertenecen a la esfera privada de la persona. De esta forma, sin necesidad de\\npreguntar de forma directa al individuo, que en su caso mostraría su conformidad o\\ndesacuerdo con proporcionar ciertos datos, puede llegar a conocerse información\\npersonal.\\nOtra preocupación importante con respecto al impacto de la IA en la privacidad de la\\ninformación es si debe haber límites a las sugerencias personalizadas gracias a los\\nsistemas de IA. Las recomendaciones que llegan al individuo, desde un anuncio\\npublicitario a una lista de reproducción automática, se crean basándose en una\\nconstrucción de la propia concepción de la identidad de la persona. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 28, 'page': 12, '_split_overlap': [{'doc_id': '956415d117a526131da89e92ea58bf22', 'range': (0, 127)}, {'doc_id': 'aa374ea29086dd971e7a835a199671ee', 'range': (1038, 1246)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '792f21a3ef0f5677d2ffe7b53e23c5d2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Las recomendaciones que llegan al individuo, desde un anuncio\\npublicitario a una lista de reproducción automática, se crean basándose en una\\nconstrucción de la propia concepción de la identidad de la persona. Si bien en principio\\nla personalización de contenido en función de las preferencias puede tener un impacto\\npositivo, existen ciertos riesgos asociados a esta actividad.\\n10 COLE, G.W. y WILLIAMSON, S.A., Avoiding Resentment Via Monotonic Fairness, ArXiv preprint,\\narXiv:1909.01251v1, 2019, pp. 1-16.\\x0c11\\nCuando se muestra contenido personalizado a un individuo, se está dejando de mostrar el\\ncontenido que no queda registrado entre las preferencias del usuario. Si pensamos en\\npublicidad u ofertas de bienes y servicios, esto puede tener sentido y beneficiar a\\ncomprador y vendedor, ya que el primero encuentra más rápido cosas que le gustan y el\\nsegundo maximiza el beneficio de su inversión en publicidad al dirigirla al público\\nobjetivo. Sin embargo, en el caso de las sugerencias de contenido en las noticias o en\\nprensa, puede ocurrir que una persona comience a recibir únicamente el contenido que es\\nafín a su opinión. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 29, 'page': 12, '_split_overlap': [{'doc_id': '792f21a3ef0f5677d2ffe7b53e23c5d2', 'range': (0, 208)}, {'doc_id': '66dfaa5f413d47a91e0d0ae3ca891936', 'range': (948, 1131)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'aa374ea29086dd971e7a835a199671ee'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Sin embargo, en el caso de las sugerencias de contenido en las noticias o en\\nprensa, puede ocurrir que una persona comience a recibir únicamente el contenido que es\\nafín a su opinión. En este caso, el derecho a la información se vería puesto en peligro, ya\\nque el lector no tiene acceso por igual a toda la información y su criterio puede verse\\nparcializado por las recomendaciones personalizadas que retroalimentan sus preferencias\\niniciales. Para evitar problemas de esta índole, podría establecerse un sistema de\\nactivación o desactivación de la personalización de contenido por parte del individuo, de\\nmanera que pudiese dar su consentimiento expreso a esta función al activarla, siendo\\nconsciente de que está recibiendo información acorde a sus preferencias. Si, de forma\\nvoluntaria, prefiere omitirse la personalización, podría desactivarse la función en\\ncualquier momento.\\nEn relación con lo anterior, la elección de prestar o no consentimiento para el tratamiento\\nde datos puede causar otros problemas. No todos los usuarios prestan consentimiento, de\\nmanera que la información de una facción importante de población no se incluye en los\\ndatos que entrenan la IA. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 30, 'page': 13, '_split_overlap': [{'doc_id': 'aa374ea29086dd971e7a835a199671ee', 'range': (0, 183)}, {'doc_id': '797548a639bac3e32ba68823efaa357f', 'range': (1011, 1171)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '66dfaa5f413d47a91e0d0ae3ca891936'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: No todos los usuarios prestan consentimiento, de\\nmanera que la información de una facción importante de población no se incluye en los\\ndatos que entrenan la IA. En determinadas circunstancias puede suceder que esta situación\\nse extreme, existiendo un riesgo potencial de que la IA no pueda generalizarse bien. Si\\nesto ocurre, probablemente el margen de error de la IA sea más elevado, puesto que\\ndurante su entrenamiento no ha tenido acceso a todos los datos posibles para optimizar su\\nfuncionamiento en el mundo real. Una posible solución técnica para este inconveniente\\nes la eliminación de la línea de aprendizaje que incorpora los datos no consensuales o el\\nreentrenamiento de los modelos de IA utilizando conjuntos de datos modificados.\\nLa garantía y salvaguarda de la protección de la privacidad individual podría estar\\namenazada por la adopción de la IA11, infringiéndose el respeto de la confidencialidad en\\nel uso de los datos, la protección de su integridad y el acceso a los mismos. Es por ello\\nimprescindible que las prácticas con IA se supervisen desde esta perspectiva, evitando la\\n11 NELSON, G.S., «Bias in artificial intelligence», North Carolina Medical Journal, Vol. 80(4), 2019, pp.\\n220-222. DOI: 10.18043/ncm.80.4.220.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 31, 'page': 13, '_split_overlap': [{'doc_id': '66dfaa5f413d47a91e0d0ae3ca891936', 'range': (0, 160)}, {'doc_id': '2088b95c070591416368cfdb2859961c', 'range': (994, 1238)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '797548a639bac3e32ba68823efaa357f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Es por ello\\nimprescindible que las prácticas con IA se supervisen desde esta perspectiva, evitando la\\n11 NELSON, G.S., «Bias in artificial intelligence», North Carolina Medical Journal, Vol. 80(4), 2019, pp.\\n220-222. DOI: 10.18043/ncm.80.4.220.\\x0c12\\nvulneración de estos derechos y cuidando que se cumpla lo dispuesto en la normativa de\\nprotección de datos12.\\n3.3. Seguridad del sistema de IA\\nLa utilización de sistemas de IA para determinadas funciones puede ocasionar la\\npresencia de nuevos riesgos para la seguridad, como un accidente de tráfico causado por\\nun error de un vehículo autónomo o una dosis farmacológica inadecuada para un paciente\\ncalculada o administrada por un robot médico. Estos problemas pueden derivar de un fallo\\nen el diseño de la IA, la insuficiencia de cantidad o cualidad de datos utilizados en su\\nentrenamiento u otras razones propias del aprendizaje automático. En cualquier caso, los\\nposibles riesgos que puedan aparecer deben ser mitigados para evitar potenciales daños o\\ndesconfianza en la adopción de la IA, lo que podría causar finalmente un rechazo hacia\\nesta tecnología y por consiguiente una pérdida de competitividad de las empresas\\nresidentes en la UE.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 32, 'page': 13, '_split_overlap': [{'doc_id': '797548a639bac3e32ba68823efaa357f', 'range': (0, 244)}, {'doc_id': '6d83b98f33ec3001c7cb0e15452a0b4d', 'range': (890, 1190)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2088b95c070591416368cfdb2859961c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: En cualquier caso, los\\nposibles riesgos que puedan aparecer deben ser mitigados para evitar potenciales daños o\\ndesconfianza en la adopción de la IA, lo que podría causar finalmente un rechazo hacia\\nesta tecnología y por consiguiente una pérdida de competitividad de las empresas\\nresidentes en la UE.\\nCon el objetivo de reducir el impacto de los riesgos en seguridad de sistemas de IA, puede\\nresultar conveniente establecer una línea de actuación que contenga medidas en tres\\ndirecciones: robustez técnica, transparencia y explicabilidad del sistema de IA y dirección\\ny supervisión humana.\\nPara asegurar la robustez técnica de un sistema de IA es imprescindible que los datos\\nutilizados para su entrenamiento sean suficientes y de calidad y que se minimice el nivel\\nde incertidumbre y el margen de error. En cuanto a los aspectos que deben revisarse\\nrelativos a los datos, en primer lugar, debe controlarse que su obtención y finalidad es\\nconforme a la normativa de privacidad y protección de datos. La información recogida\\ndebe ser amplia, en número y casuística, para cubrir todos los escenarios relevantes y\\nevitar que haya situaciones peligrosas para las que no se haya entrenado la IA.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 33, 'page': 14, '_split_overlap': [{'doc_id': '2088b95c070591416368cfdb2859961c', 'range': (0, 300)}, {'doc_id': '135184e8058903d9a04ff37daf3e1232', 'range': (1000, 1190)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6d83b98f33ec3001c7cb0e15452a0b4d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: La información recogida\\ndebe ser amplia, en número y casuística, para cubrir todos los escenarios relevantes y\\nevitar que haya situaciones peligrosas para las que no se haya entrenado la IA.\\nFinalmente, es importante que los datos sean representativos en cuanto a género, raza o\\ncualquier otro motivo que pueda resultar discriminatorio.\\nEl nivel de incertidumbre representa con qué probabilidad no existe certeza sobre un\\nresultado, de manera que no se sabe con exactitud qué margen de error tiene el sistema\\nde IA. La determinación del nivel de incertidumbre que hay en estos sistemas se\\n12 Reglamento (UE) 2016/679 del Parlamento Europeo y del Consejo de 27 de abril de 2016 relativo a la\\nprotección de las personas físicas en lo que respecta al tratamiento de datos personales y a la libre\\ncirculación de estos datos y por el que se deroga la Directiva 95/46/CE.\\x0c13\\ndetermina a través de su calibración. Un sistema bien calibrado será capaz de expresar\\ncon gran exactitud la incertidumbre en cada decisión, lo que permite conocer en qué\\nmedida la misma es o no confiable, en función de si existe o no certeza sobre que dicha\\ndecisión sea correcta13.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 34, 'page': 14, '_split_overlap': [{'doc_id': '6d83b98f33ec3001c7cb0e15452a0b4d', 'range': (0, 190)}, {'doc_id': '8ea26161be9826550ca431471ae41f06', 'range': (907, 1152)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '135184e8058903d9a04ff37daf3e1232'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Un sistema bien calibrado será capaz de expresar\\ncon gran exactitud la incertidumbre en cada decisión, lo que permite conocer en qué\\nmedida la misma es o no confiable, en función de si existe o no certeza sobre que dicha\\ndecisión sea correcta13.\\nPor tanto, antes de estudiar las medidas de reducción del margen de error de un sistema\\nde IA, debe comprobarse que su nivel de incertidumbre es mínimo. De lo contrario, podría\\npensarse que el margen de error es elevado cuando en realidad no lo es o viceversa,\\nhaciendo que las medidas impuestas traten de dar solución a un problema que no ha sido\\nbien concretado. Cuando un sistema de IA presenta un nivel de incertidumbre superior al\\naceptable, debe recalibrarse el sistema hasta que se alcance el nivel deseado. Una vez ha\\nsido recalibrado, el margen de error que arroje será más preciso, de manera que puede\\nentonces pasarse a una segunda etapa donde se examine si ese margen de error es\\nadecuado.\\nEl margen de error es un indicador que muestra el número aproximado de veces que la\\nIA no consigue los resultados esperados. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 35, 'page': 15, '_split_overlap': [{'doc_id': '135184e8058903d9a04ff37daf3e1232', 'range': (0, 245)}, {'doc_id': 'e731421e6b38891c6ed1cadfab5a888', 'range': (948, 1072)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8ea26161be9826550ca431471ae41f06'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: El margen de error es un indicador que muestra el número aproximado de veces que la\\nIA no consigue los resultados esperados. El funcionamiento de la IA se basa en el uso de\\ndatos para la optimización de un problema, de manera que es prácticamente imposible\\nque no exista margen de error. Lo anterior implicaría que todos los datos posibles han\\nsido utilizados para su entrenamiento, de manera que no exista ningún elemento o\\nescenario nuevo al que pueda enfrentarse el sistema. A pesar de que esto no puede\\nlograrse en su totalidad, sí debe intentarse que ese margen de error que representa las\\nsituaciones para las que la IA no ha sido entrenada sea el menor posible. Para minimizarlo,\\ndebe procurarse que los datos de entrenamiento sean suficientes y variados, de manera\\nque se recoja en los mismos la mayor casuística posible.\\nEste no es un aspecto que perdure en el tiempo en todos los casos, por lo que debe\\nrevisarse durante la vida de la IA que la misma funciona correctamente y que su margen\\nde error se mantiene bajo. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 36, 'page': 15, '_split_overlap': [{'doc_id': '8ea26161be9826550ca431471ae41f06', 'range': (0, 124)}, {'doc_id': 'b684f5a2b5f085107c6d3964090002ad', 'range': (830, 1026)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e731421e6b38891c6ed1cadfab5a888'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Este no es un aspecto que perdure en el tiempo en todos los casos, por lo que debe\\nrevisarse durante la vida de la IA que la misma funciona correctamente y que su margen\\nde error se mantiene bajo. Cuando no sea así, el sistema deberá volver a ser entrenado\\npara adecuarse a las nuevas circunstancias, y tendrá que repetirse este proceso tantas\\nveces como sea necesario. Por ejemplo, un vehículo puede ser entrenado de forma que su\\nsistema de conducción autónoma tenga un margen de error muy reducido. Sin embargo,\\nsi no se actualiza el sistema, en el momento en el que una nueva señal sea introducida\\n13 ANTORÁN CABISCOL, J., Understanding Uncertainty in Bayesian Neural Networks, Departamento\\nde Ingeniería de la Universidad de Cambridge, 2019, Pro manuscript, pp. 1-94.\\x0c14\\ncabe la posibilidad de que el sistema no reconozca la misma y no pueda interpretarla. En\\nfunción de la IA y de su entrenamiento –supervisado, no supervisado o reforzado–, el\\nsistema requerirá un mayor o menor control del margen de error y actualización.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 37, 'page': 15, '_split_overlap': [{'doc_id': 'e731421e6b38891c6ed1cadfab5a888', 'range': (0, 196)}, {'doc_id': '2e327cc4eb04a82f6f5e0d673f8930aa', 'range': (861, 1028)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b684f5a2b5f085107c6d3964090002ad'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: En\\nfunción de la IA y de su entrenamiento –supervisado, no supervisado o reforzado–, el\\nsistema requerirá un mayor o menor control del margen de error y actualización.\\nEn el Libro Blanco de IA14, cuando se hace referencia a la robustez técnica del sistema,\\nse dice que uno de los elementos a considerar es que los sistemas de IA pueden lidiar con\\nerrores o inconsistencias durante todas sus fases de vida. Si bien pueden existir diversas\\ninterpretaciones sobre esta afirmación, una de las principales causas de la existencia de\\ndefectos funcionales es el alto nivel de incertidumbre y el elevado margen de error. Para\\ncumplir con el requisito de robustez técnica de que la IA actúe de forma exacta durante\\ntodas las fases de su ciclo, es necesario limitar el uso de sistemas con estas características.\\nEn la futura regulación sobre IA debe concretarse el origen de esos «errores o\\ninconsistencias» y tenerse en cuenta los dos aspectos mencionados en la búsqueda de una\\nsolución para la optimización del comportamiento robusto de los sistemas de IA.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 38, 'page': 16, '_split_overlap': [{'doc_id': 'b684f5a2b5f085107c6d3964090002ad', 'range': (0, 167)}, {'doc_id': '4f55ef2bd938dcdfc4c094e9e4f3146d', 'range': (802, 1048)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2e327cc4eb04a82f6f5e0d673f8930aa'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: En la futura regulación sobre IA debe concretarse el origen de esos «errores o\\ninconsistencias» y tenerse en cuenta los dos aspectos mencionados en la búsqueda de una\\nsolución para la optimización del comportamiento robusto de los sistemas de IA.\\nPor último, otra consideración importante de la robustez técnica es la seguridad per se de\\nlos sistemas de IA, en el sentido de que los mismos sean resistentes a ataques o intentos\\nde manipulación de los datos o algoritmos. Para ello deben emplearse técnicas adecuadas\\nde protección, de manera que no se pueda tener acceso al sistema de IA ni extraer los\\ndatos de entrenamiento. Además, en caso de que los mismos ocurran, deben haber sido\\nprevistas medidas suficientes de mitigación o corrección del daño causado.\\nUna característica que debe acompañar a la robustez técnica y seguridad del sistema de\\nIA es la transparencia y explicabilidad. La robustez persigue procurar que la IA funcione\\nde forma adecuada, tratando de evitar los errores o imprevistos. No obstante, cuando\\ntienen lugar fallos a pesar de los intentos de hacer seguro el sistema, la transparencia y\\nexplicabilidad se hacen necesarias. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 39, 'page': 16, '_split_overlap': [{'doc_id': '2e327cc4eb04a82f6f5e0d673f8930aa', 'range': (0, 246)}, {'doc_id': '9f5ee6f0d77703939861f03f1fb3f886', 'range': (1003, 1149)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4f55ef2bd938dcdfc4c094e9e4f3146d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: No obstante, cuando\\ntienen lugar fallos a pesar de los intentos de hacer seguro el sistema, la transparencia y\\nexplicabilidad se hacen necesarias. Estas cualidades son esenciales para que el sistema,\\nademás de ser seguro, se perciba como tal.\\nConforme a lo expuesto en el Libro Blanco15, la transparencia implica que se informe de\\nforma clara a quienes apliquen el sistema, a las autoridades competentes e incluso a las\\npartes afectadas sobre las capacidades y limitaciones de la IA, su propósito específico y\\nsu probabilidad de éxito al funcionar. La información proporcionada debe ser objetiva,\\n14 COMISIÓN EUROPEA, White Paper on Artificial Intelligence: a European approach to excellence and\\ntrust…cit.\\n15 COMISIÓN EUROPEA, White Paper on Artificial Intelligence: a European approach to excellence and\\ntrust…cit.\\x0c15\\nconcisa y fácilmente entendible para las personas a las que va dirigida. Además, en\\nalgunos casos se plantea que no sea necesario advertir del uso de la IA si resulta obvio o\\nmanifiesto.\\nSi bien el planteamiento que hace la Comisión Europea sobre la transparencia parte de\\nideas concretas, es conveniente introducir algunos matices. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 40, 'page': 16, '_split_overlap': [{'doc_id': '4f55ef2bd938dcdfc4c094e9e4f3146d', 'range': (0, 146)}, {'doc_id': '960fed4b7d0c60439bc851d7481679ec', 'range': (1007, 1152)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9f5ee6f0d77703939861f03f1fb3f886'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Si bien el planteamiento que hace la Comisión Europea sobre la transparencia parte de\\nideas concretas, es conveniente introducir algunos matices. En primer lugar, no se\\nestablece de forma clara si la información se hará siempre accesible para el usuario final\\nde la IA. De hecho, parece interpretarse que esta posibilidad sólo se dará en algunos casos\\ncuando se habla de informar «incluso a las partes afectadas». Tampoco se precisa hasta\\nqué extremo se entenderá que resulta obvia la utilización de la IA, lo cual puede generar\\ndudas para el implementador y cierto temor o inseguridad por parte del usuario expuesto.\\nLa transparencia posibilita el conocimiento y la comprensión del funcionamiento de la\\ninteligencia artificial, un presupuesto básico para la confianza en esta tecnología.\\nEstablecer que el sistema de IA sea transparente como un requisito de carácter obligatorio\\nenfatiza la responsabilidad de quienes emplean inteligencia artificial y, por extensión, de\\nquien diseña el sistema. Estos agentes se ven en la obligación de explicar el conjunto de\\ndatos concreto que ha servido de entrenamiento a la red neuronal y el algoritmo resultante,\\nlo que permite inferir qué decisiones fueron tomadas y cuál fue el fundamento de las\\nmismas16.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 41, 'page': 17, '_split_overlap': [{'doc_id': '9f5ee6f0d77703939861f03f1fb3f886', 'range': (0, 145)}, {'doc_id': '348c204bb2fa2acd67ba96a2af50069e', 'range': (997, 1248)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '960fed4b7d0c60439bc851d7481679ec'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Estos agentes se ven en la obligación de explicar el conjunto de\\ndatos concreto que ha servido de entrenamiento a la red neuronal y el algoritmo resultante,\\nlo que permite inferir qué decisiones fueron tomadas y cuál fue el fundamento de las\\nmismas16.\\nEl problema de la «caja negra» es un desafío que a menudo plantea problemas para\\nquienes han utilizado sistemas inteligentes asistiendo sus decisiones. Ante el\\nrequerimiento de las personas afectadas por las mismas, se encuentran en una situación\\nque exige justificar determinadas decisiones y, por tanto, deben buscar información sobre\\nla actividad de la IA. El conflicto surge con algunas técnicas de aprendizaje automático,\\nque a pesar de tener éxito en lo relativo al nivel de precisión, son opacas en términos de\\nexplicación de resultados17. La noción de IA de caja negra se refiere a tales escenarios,\\ndonde no es posible rastrear la justificación que existe detrás de ciertas decisiones18, lo\\nque puede incluso poner en duda su imparcialidad.\\n16 NELSON, G.S., «Bias in artificial intelligence»…cit.\\n17 COECKELBERGH, M., «Ethics of artificial intelligence: Some ethical issues and regulatory\\nchallenges», Technology and Regulation, 2019, pp. 31-34. DOI: 10.26116/techreg.2019.003.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 42, 'page': 17, '_split_overlap': [{'doc_id': '960fed4b7d0c60439bc851d7481679ec', 'range': (0, 251)}, {'doc_id': 'b859fcfaeaed2aef7136ba44797a6628', 'range': (1058, 1238)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '348c204bb2fa2acd67ba96a2af50069e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: 17 COECKELBERGH, M., «Ethics of artificial intelligence: Some ethical issues and regulatory\\nchallenges», Technology and Regulation, 2019, pp. 31-34. DOI: 10.26116/techreg.2019.003.\\n18 GRUPO DE EXPERTOS DE ALTO NIVEL EN IA DE LA COMISIÓN EUROPEA (a), A Definition\\nOf AI…cit.\\x0c16\\nLa explicabilidad es la solución a este problema de opacidad, puesto que, si se logra\\nentender el mecanismo subyacente del sistema y encontrar soluciones para los errores\\ncometidos, desaparece la incertidumbre en cuanto a su funcionamiento. Es por ello por lo\\nque uno de los campos de investigación más vanguardistas en inteligencia artificial es lo\\nque se conoce como XAI o Explainable Artificial Intelligence, que consiste en el\\ndesarrollo de técnicas y métodos orientados a la explicación del algoritmo de IA.\\nUna de las medidas propuestas que podría contribuir a mejorar la explicabilidad del\\nsistema de IA es registrar la base de datos de entrenamiento incluyendo una descripción\\nde razones de elección de los datos utilizados, la información sobre el algoritmo y los\\nobjetivos establecidos para el sistema. Asimismo, otra de las sugerencias es conseguir\\nque los resultados sean reproducibles, de manera que repitiendo la situación objeto de\\nestudio se observe el funcionamiento de la IA al obtener un resultado. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 43, 'page': 17, '_split_overlap': [{'doc_id': '348c204bb2fa2acd67ba96a2af50069e', 'range': (0, 180)}, {'doc_id': 'afeeb30c653e26f9697084cc6cda3d26', 'range': (1090, 1294)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b859fcfaeaed2aef7136ba44797a6628'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Asimismo, otra de las sugerencias es conseguir\\nque los resultados sean reproducibles, de manera que repitiendo la situación objeto de\\nestudio se observe el funcionamiento de la IA al obtener un resultado. Sin embargo, debe\\ntenerse en cuenta que esto puede ser válido en el caso de sistemas que actúan bajo\\nsupervisión, pero no necesariamente en sistemas no supervisados o reforzados. Estos\\nsistemas de IA se caracterizan por estar sujetos a un entrenamiento continuo, por lo que,\\nsi el algoritmo se ha modificado como consecuencia de haber obtenido nuevos datos, el\\nresultado que se obtiene para la misma situación podría ser distinto.\\nLa dirección y supervisión humana deviene necesaria en aquellos casos en los que el\\nsistema de IA no es suficientemente robusto técnicamente, transparente o explicable. De\\nesta forma, las deficiencias que pueda presentar la IA pueden ser corregidas por la\\nintervención de un ser humano. Existen diferentes niveles de actuación por parte de la\\npersona, proponiéndose cuatro rangos en el Libro Blanco19. El primer nivel supone que\\nlos resultados no sean válidos sin la revisión de un ser humano. El segundo, que los\\nresultados sean válidos sin esa revisión, pero que la persona pueda intervenir para\\nmodificarlos. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 44, 'page': 18, '_split_overlap': [{'doc_id': 'b859fcfaeaed2aef7136ba44797a6628', 'range': (0, 204)}, {'doc_id': '4ff786597d883ad9cb64568d1a6dde57', 'range': (1038, 1247)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'afeeb30c653e26f9697084cc6cda3d26'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: El primer nivel supone que\\nlos resultados no sean válidos sin la revisión de un ser humano. El segundo, que los\\nresultados sean válidos sin esa revisión, pero que la persona pueda intervenir para\\nmodificarlos. En tercer lugar, que exista la posibilidad de que la persona intervenga en\\ntiempo real y monotorice el sistema de IA. Y, por último, que sean impuestas en la fase\\nde diseño de la IA ciertas restricciones que determinen su funcionamiento desde un\\nprincipio. Podría incluso plantearse para los sistemas de más alto riesgo la opción de\\nimpedir su utilización si no se presta conformidad con anterioridad a su lanzamiento al\\n19 COMISIÓN EUROPEA, White Paper on Artificial Intelligence: a European approach to excellence and\\ntrust...cit.\\x0c17\\npúblico, tras haberse comprobado el algoritmo resultante o incluso la base de datos con\\nla que ha sido entrenado.\\nFinalmente, diseñar sistemas de normalización y certificación, entendidos como métodos\\nde acreditación que valoren la calidad del sistema de IA, puede ser una buena medida\\nque, aunque no incrementa la seguridad del sistema, sí ayuda a la transparencia del\\nmismo. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 45, 'page': 18, '_split_overlap': [{'doc_id': 'afeeb30c653e26f9697084cc6cda3d26', 'range': (0, 209)}, {'doc_id': '632415708897e73e09e8d33debde03d0', 'range': (860, 1122)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4ff786597d883ad9cb64568d1a6dde57'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Finalmente, diseñar sistemas de normalización y certificación, entendidos como métodos\\nde acreditación que valoren la calidad del sistema de IA, puede ser una buena medida\\nque, aunque no incrementa la seguridad del sistema, sí ayuda a la transparencia del\\nmismo. Esta opción permitiría a los usuarios tener conocimiento certificado de que el\\nsistema funciona correctamente, en el sentido de esté bien calibrado. A pesar de no poder\\nofrecer una solución en todo caso para la seguridad, de esta forma se consigue que las\\npersonas afectadas por la utilización de la inteligencia artificial sean conscientes de su\\nnivel de incertidumbre y margen de error. La persona puede entonces, con una mayor\\ninformación, optar o no por utilizar el sistema de IA, recibir productos o servicios que lo\\nintegren o incluso decidir qué grado de intervención humana quiere aplicarse.\\nEl Libro Blanco sugiere el etiquetado voluntario para aplicaciones de IA que no son de\\nalto riesgo. Sin embargo, considerando que esta medida no es demasiado gravosa y\\ncontribuye a hacer los sistemas de IA más transparentes en cuanto a su seguridad, sería\\nconveniente que no únicamente los sistemas de bajo riesgo sigan un régimen de\\ncertificación. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 46, 'page': 19, '_split_overlap': [{'doc_id': '4ff786597d883ad9cb64568d1a6dde57', 'range': (0, 262)}, {'doc_id': 'f68eed93409b51105f1ba1713c8ccde8', 'range': (963, 1211)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '632415708897e73e09e8d33debde03d0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Sin embargo, considerando que esta medida no es demasiado gravosa y\\ncontribuye a hacer los sistemas de IA más transparentes en cuanto a su seguridad, sería\\nconveniente que no únicamente los sistemas de bajo riesgo sigan un régimen de\\ncertificación. Etiquetar los sistemas de alto riesgo para visibilizar el nivel de seguridad o\\nrobustez técnica es incluso más necesario que en los de riesgo medio o bajo. Por tanto, el\\netiquetado debería ser incluso obligatorio en estos casos, quizá dando la opción de\\netiquetar voluntariamente para los sistemas de bajo riesgo.\\nPara conseguir la seguridad de un sistema de IA deben aplicarse medidas que aseguren\\nsu robustez técnica, transparencia y explicabilidad. De forma preventiva, la dirección y\\nsupervisión humana con distintos grados de intervención permite reducir los riesgos\\ninherentes a esta tecnología. Debe adoptarse una postura que combine estos aspectos para\\npriorizar el objetivo de crear sistemas seguros de forma coherente y responsable.\\n3.4. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 47, 'page': 19, '_split_overlap': [{'doc_id': '632415708897e73e09e8d33debde03d0', 'range': (0, 248)}, {'doc_id': '491358c8f635b0bb3f0e9f987b68a32', 'range': (851, 996)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f68eed93409b51105f1ba1713c8ccde8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Debe adoptarse una postura que combine estos aspectos para\\npriorizar el objetivo de crear sistemas seguros de forma coherente y responsable.\\n3.4. Principio de no discriminación\\nLos datos empleados en el entrenamiento de la IA pueden presentar ciertos sesgos por\\nprejuicios históricos u otros factores fuera del control del proveedor de los datos o el\\ndesarrollador, de manera que, si los datos no son suficientemente equilibrados o\\ninclusivos, la inteligencia artificial entrenada con los mismos no puede generalizarse bien.\\nEn el caso de los sistemas de IA dedicados a la toma de decisiones, estas podrían resultar\\nparciales, favoreciendo a algunos grupos sobre otros por razón de raza, género u\\x0c18\\norientación sexual, entre otras 20. Ante esta situación, es necesario que los modelos de\\naprendizaje automático encaminados a la toma de decisiones sean diseñados previniendo\\nla interpretación o la práctica discriminatoria21.\\nSi bien a priori no parece plantear inconvenientes la eliminación de este tipo de sesgos en\\nlas bases de datos, la solución no resulta sencilla por la capacidad de análisis de la IA. La\\ncomplejidad de este asunto reside en el doble origen de esta parcialidad, que finalmente\\nda lugar a una decisión sesgada. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 48, 'page': 19, '_split_overlap': [{'doc_id': 'f68eed93409b51105f1ba1713c8ccde8', 'range': (0, 145)}, {'doc_id': '52b4fb7346cfe433d0cb9e14f95a153c', 'range': (1109, 1233)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '491358c8f635b0bb3f0e9f987b68a32'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: La\\ncomplejidad de este asunto reside en el doble origen de esta parcialidad, que finalmente\\nda lugar a una decisión sesgada. Por un lado, es evidente que, si en el conjunto\\nestructurado de datos se incluye una variable discriminatoria, la decisión resultante estará\\nbasada en las correlaciones que se hayan creado entre dicha variable y otras que no lo\\nson, por lo que la casuística puede dar lugar a resultados discriminatorios. Sin embargo,\\ndicha parcialidad puede aparecer incluso en situaciones en las que esa variable, a pesar\\nde no haberse incluido de forma expresa, pueda inferirse por métodos estadísticos.\\nMediante inferencia estadística la IA es capaz de inducir características concretas del\\nindividuo susceptibles de causar decisiones discriminatorias que afecten al mismo, como\\nla orientación sexual, edad, opiniones políticas o religiosas, género o raza22. Cuando\\ndebido a estas correlaciones se acaba reconociendo una característica que cumple con la\\nfunción de optimización y funciona correctamente en términos probabilísticos, la red\\nneuronal se basará en la misma para tomar sus decisiones. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 49, 'page': 20, '_split_overlap': [{'doc_id': '491358c8f635b0bb3f0e9f987b68a32', 'range': (0, 124)}, {'doc_id': '69f41f57a943266e7dbc8fb47c231340', 'range': (871, 1108)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '52b4fb7346cfe433d0cb9e14f95a153c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Cuando\\ndebido a estas correlaciones se acaba reconociendo una característica que cumple con la\\nfunción de optimización y funciona correctamente en términos probabilísticos, la red\\nneuronal se basará en la misma para tomar sus decisiones. Ese rasgo que se infiere del\\nresto de variables y que deviene determinante en el proceso de toma de decisiones, a pesar\\nde no llevar el nombre de la característica a la que representa, causa el mismo resultado\\nque si dicha cualidad existiese desde un principio. Es por ello por lo que, en estos casos,\\na pesar de no estar presentes dichas variables sensibles en el conjunto de datos de\\nentrenamiento, a través de otras características que están altamente correlacionadas con\\nlas que sí se contienen, las decisiones pueden tornarse sesgadas23.\\n20 MAYSON, S.G., «Bias in, Bias out», Yale Law Journal 128, 2019, pp. 1-84, ¿disponible en\\n<https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3257004>. Fecha de consulta: 3 de enero de 2020;\\nDOSHI-VELEZ, F., KORTZ, M., BUDISH, R., BAVITZ, C., GERSHMAN, S., O’BRIEN, D.,\\nSCHIEBER, S., WALDO, J., WEINBERGER, D. y WOOD. A., Accountability of AI under the law: The\\nrole of explanation. ArXiv preprint, arXiv:1711.01134, 2017, pp. 1-15.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 50, 'page': 20, '_split_overlap': [{'doc_id': '52b4fb7346cfe433d0cb9e14f95a153c', 'range': (0, 237)}, {'doc_id': '844f3119d4f55f4a1119603940ef0c1a', 'range': (935, 1215)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '69f41f57a943266e7dbc8fb47c231340'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Fecha de consulta: 3 de enero de 2020;\\nDOSHI-VELEZ, F., KORTZ, M., BUDISH, R., BAVITZ, C., GERSHMAN, S., O’BRIEN, D.,\\nSCHIEBER, S., WALDO, J., WEINBERGER, D. y WOOD. A., Accountability of AI under the law: The\\nrole of explanation. ArXiv preprint, arXiv:1711.01134, 2017, pp. 1-15.\\n21 KUSNE, M., LOFTUS, J., RUSSELL, C. y SILVA, R., Counterfactual Fairness, ArXiv preprint,\\narXiv:1703.06856v3, 8 de marzo de 2018, pp. 1-18; KLEINBERG, J., LUDWIG, J., MULLAINATHAN,\\nS. y SUNSTEIN, C.S., «Discrimination in the Age of Algorithms»…cit.\\n22 COLE, G.W. y WILLIAMSON, S.A., Avoiding Resentment Via Monotonic Fairness…cit.\\n23 TAN, Z., YEOM, S., FREDRIKSON, M. y TALWALKAR, A., Learning Fair Representations… cit.\\x0c19\\nPóngase el caso de una red neuronal que clasifica a un grupo de posibles prestatarios\\ncomo aptos o no aptos, cuya base de entrenamiento contiene únicamente las variables\\nrenta, estudios, contrato de trabajo y lugar de residencia. Si la red neuronal infiere por la\\ninformación contenida en dichas características la existencia de una nueva variable que\\npermite simplificar en el mayor de los casos el proceso de decisión, la incluirá en sus\\ncálculos para obtener los resultados. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 51, 'page': 20, '_split_overlap': [{'doc_id': '69f41f57a943266e7dbc8fb47c231340', 'range': (0, 280)}, {'doc_id': '39d153efdec9796cc08691223bce241b', 'range': (937, 1184)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '844f3119d4f55f4a1119603940ef0c1a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Si la red neuronal infiere por la\\ninformación contenida en dichas características la existencia de una nueva variable que\\npermite simplificar en el mayor de los casos el proceso de decisión, la incluirá en sus\\ncálculos para obtener los resultados. Así, si en la mayor parte de los casos la persona con\\nmenos solvencia está situada en un rango de 25 a 30 años, tiene un nivel de estudios bajo,\\ntrabaja en el sector del textil y vive en un gueto camboyano, dichas características pueden\\nser abstraídas por la red en una sola que las hace coincidir con base en la estadística: una\\npersona media en España procedente de Camboya. A pesar de las generalizaciones –en\\ntodo caso irreales y únicamente al efecto de poner el ejemplo– y la extrema simplificación\\ndel caso ilustrativo, la idea subyacente es que el análisis de la inteligencia artificial va\\nmás allá de un simple cálculo matemático, puesto que mediante el uso de métodos\\nestadísticos utiliza razonamientos lógicos complejos para la toma de decisiones.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 52, 'page': 21, '_split_overlap': [{'doc_id': '844f3119d4f55f4a1119603940ef0c1a', 'range': (0, 247)}, {'doc_id': 'ded8a63415a216bed4524498e61f951b', 'range': (625, 1005)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '39d153efdec9796cc08691223bce241b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: A pesar de las generalizaciones –en\\ntodo caso irreales y únicamente al efecto de poner el ejemplo– y la extrema simplificación\\ndel caso ilustrativo, la idea subyacente es que el análisis de la inteligencia artificial va\\nmás allá de un simple cálculo matemático, puesto que mediante el uso de métodos\\nestadísticos utiliza razonamientos lógicos complejos para la toma de decisiones.\\nLa consecuencia de lo anterior es que, en determinados casos, existe el riesgo de que las\\npersonas puedan aprovecharse del uso de la IA y, por extensión, de la estadística, para\\ntomar decisiones que sean discriminatorias en última instancia. Para ello, bastaría con\\nencontrar cualidades concretas que presenten alta correlación con el rasgo que se pretende\\nexcluir de la selección e incluirlas, de manera que de forma encubierta se obtengan\\ndecisiones sesgadas a través de un procedimiento que aparentemente no lo es.\\nBuena parte de la doctrina científica24 ha criticado duramente esta posibilidad,\\nconcluyendo que, si es posible inferir a través de un algoritmo la característica sensible\\nen cuestión, el uso de dicho algoritmo no debería permitirse. Sin embargo, podría optarse\\npor una posición más moderada y que transige el uso de inteligencia artificial sin imponer\\nexcesivas restricciones. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 53, 'page': 21, '_split_overlap': [{'doc_id': '39d153efdec9796cc08691223bce241b', 'range': (0, 380)}, {'doc_id': '394317f654fe94da714690c2c80c36d1', 'range': (1133, 1276)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ded8a63415a216bed4524498e61f951b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Sin embargo, podría optarse\\npor una posición más moderada y que transige el uso de inteligencia artificial sin imponer\\nexcesivas restricciones. Si en lugar de excluir todos aquellos algoritmos de los cuales\\npuede inferirse una característica concreta –algo que no resulta extraño teniendo en cuenta\\nque puede darse por probabilidad esta casuística, sin que ello conlleve necesariamente\\nuna pretensión discriminatoria encubierta–, se lleva a cabo un control exhaustivo de las\\n24 YEOM, S., DATTA, A. y FREDRIKSON, M., «Hunting for discriminatory proxies in linear regression\\nmodels», Advances in Neural Information Processing Systems, 2018, pp. 4568-4578, disponible en\\n<http://papers.nips.cc/paper/7708-hunting-for-discriminatory-proxies-in-linear-regression-models.pdf>.\\nFecha de consulta: 14 de abril de 2020; TAN, Z., YEOM, S., FREDRIKSON, M. y TALWALKAR, A.,\\nLearning Fair Representations… cit.\\x0c20\\nvariables que se contienen en la base de datos, la decisión que se obtiene finalmente no\\ntiene por qué ser discriminatoria, a pesar de que por cifras pueda parecerlo.\\nEstablecer restricciones que traten de eliminar la discriminación supone, en primer lugar,\\ndecidir qué definición de equidad o justicia es la más adecuada para la tarea en cuestión.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 54, 'page': 21, '_split_overlap': [{'doc_id': 'ded8a63415a216bed4524498e61f951b', 'range': (0, 143)}, {'doc_id': 'b56361f716052355f52270fe302b9c89', 'range': (1068, 1249)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '394317f654fe94da714690c2c80c36d1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Establecer restricciones que traten de eliminar la discriminación supone, en primer lugar,\\ndecidir qué definición de equidad o justicia es la más adecuada para la tarea en cuestión.\\nUn estudio llevado a cabo por investigadores estadounidenses y británicos25 demuestra\\nque, dependiendo de la relación entre un atributo protegido y los datos, ciertas\\ndefiniciones de equidad pueden incluso aumentar la discriminación. Sobre la base de esa\\ncontradicción, se plantea una definición de equidad, denominada counterfactual fairness.\\nSegún dicha definición, una decisión es justa hacia un individuo si es la misma en dos\\nescenarios, tanto en el mundo real, como en un mundo contrafactual, que es aquel en el\\nque el individuo pertenecería a un grupo demográfico diferente. Esta definición de\\nequidad señala la necesaria causalidad de las diferentes actuaciones por parte del\\nalgoritmo, conocidas como local explanations, de manera que analiza si cada una de esas\\ndecisiones locales ha sido justa éticamente26. Si la decisión final está basada en\\ncaracterísticas cuya justificación de pertenencia en la base de datos no es discriminatoria,\\nla misma no debe entenderse como tal27.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 55, 'page': 22, '_split_overlap': [{'doc_id': '394317f654fe94da714690c2c80c36d1', 'range': (0, 181)}, {'doc_id': '559647894770573a0652ddae41c79413', 'range': (1001, 1169)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b56361f716052355f52270fe302b9c89'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Si la decisión final está basada en\\ncaracterísticas cuya justificación de pertenencia en la base de datos no es discriminatoria,\\nla misma no debe entenderse como tal27.\\nEn la línea del ejemplo anterior, si la persona que selecciona qué variables deben\\nincorporarse en la base de datos es capaz de justificar por qué es conveniente que sean\\ntenidas en cuenta las mismas, el algoritmo no debe entenderse como discriminatorio. La\\nrenta, el nivel estudios, el tipo de contrato de trabajo e incluso el lugar de residencia son\\nvariables que pueden tener relación con la solvencia de una persona. En consecuencia, no\\nson variables discriminatorias y el algoritmo creado con base en las mismas tampoco debe\\nser considerado como tal.\\nAunque el resultado de la selección de prestatarios pueda dar lugar a la calificación de\\naptos del 90 por ciento de los españoles y no aptos del 70 por ciento de los camboyanos,\\nello no significa per se que la decisión haya sido discriminatoria. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 56, 'page': 22, '_split_overlap': [{'doc_id': 'b56361f716052355f52270fe302b9c89', 'range': (0, 168)}, {'doc_id': '7c3aa904785fdc0bf1bc7e8e4d8bc97f', 'range': (725, 970)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '559647894770573a0652ddae41c79413'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Aunque el resultado de la selección de prestatarios pueda dar lugar a la calificación de\\naptos del 90 por ciento de los españoles y no aptos del 70 por ciento de los camboyanos,\\nello no significa per se que la decisión haya sido discriminatoria. Con base en los criterios\\nque se tienen en cuenta, si el año siguiente se incrementa la población inmigrante\\ncamboyana en España altamente cualificada, con un contrato de trabajo con una\\nremuneración elevada que les permita vivir en el centro de la ciudad, las decisiones\\n25 KUSNE, M., LOFTUS, J., RUSSELL, C. y SILVA, R., Counterfactual Fairness… cit. pp. 1-2.\\n26 DOSHI-VELEZ, F., KORTZ, M., BUDISH, R. et al., Accountability of AI under the law… cit.\\n27 KLEINBERG, J., LUDWIG, J., MULLAINATHAN, S. y SUNSTEIN, C.S., «Discrimination in the Age\\nof Algorithms»...cit.\\x0c21\\nadoptadas cambiarán drásticamente, pudiendo ocurrir que se consideren como aptos el 80\\npor ciento de los potenciales prestatarios camboyanos.\\nEn conclusión, la existencia de discriminación debe tenerse en cuenta desde un punto de\\nvista objetivo, de manera que únicamente se consideren sesgadas aquellas decisiones que,\\nefectivamente, se basen en criterios que no sean imparciales28. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 57, 'page': 22, '_split_overlap': [{'doc_id': '559647894770573a0652ddae41c79413', 'range': (0, 245)}, {'doc_id': '8b0fea59fa66abc3969e17bb2dd665ac', 'range': (958, 1198)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7c3aa904785fdc0bf1bc7e8e4d8bc97f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: En conclusión, la existencia de discriminación debe tenerse en cuenta desde un punto de\\nvista objetivo, de manera que únicamente se consideren sesgadas aquellas decisiones que,\\nefectivamente, se basen en criterios que no sean imparciales28. Asimismo, los datos que\\nsirven de entrenamiento a la IA deben revisarse y actualizarse, de manera que el algoritmo\\nse modifique conforme lo hace la información que contienen las variables no\\ndiscriminatorias. De esa manera, la variable que ha surgido por inferencia estadística\\ndesaparecerá o cambiará en función de las nuevas circunstancias. Con ello se asegura el\\nprincipio de igualdad entre las personas, puesto que las decisiones no estarán basadas en\\nvariables discriminatorias, sino en razonamiento lógico y estadística.\\nEspecial relevancia adquiere dicha distinción en Derecho de Consumo, ya que en muchas\\nocasiones tiene lugar la selección de clientes en cuanto a la proposición u oferta de\\nproductos o servicios29. El consumidor, en los casos en los que crea vulnerado el principio\\nde igualdad o no discriminación, tiene el derecho de conocer la justificación del rechazo\\nde una empresa a prestarle servicios o venderle productos. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 58, 'page': 23, '_split_overlap': [{'doc_id': '7c3aa904785fdc0bf1bc7e8e4d8bc97f', 'range': (0, 240)}, {'doc_id': '9ade19697e293d0644567e6dab6906e9', 'range': (965, 1180)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8b0fea59fa66abc3969e17bb2dd665ac'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: El consumidor, en los casos en los que crea vulnerado el principio\\nde igualdad o no discriminación, tiene el derecho de conocer la justificación del rechazo\\nde una empresa a prestarle servicios o venderle productos. Ante la falta de una explicación\\npertinente, podrá accionar contra el mismo por considerar que existe una infracción del\\nprincipio de no discriminación, recogido no sólo en la legislación del Estado en el que se\\nencuentre, sino también de forma general en el artículo 21 de la Carta Europea de los\\nDerechos Fundamentales30.\\nComienzan a ser numerosos los casos que plantean dudas acerca de la legalidad de la\\nutilización de la IA. Uno de los más conocidos, relacionado con el riesgo de parcialidad\\ny discriminación expuesto es el de la tarjeta de crédito Apple, lanzada en colaboración\\ncon Goldman Sachs y Mastercard para los usuarios estadounidenses en agosto de 201931.\\nLa tarjeta Apple es una tarjeta de crédito que proporciona una línea de crédito a los\\nusuarios y utiliza machine learning para ayudarles en la gestión y control de gastos. En\\n28 MAYSON, S.G., «Bias in, Bias out»…cit.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 59, 'page': 23, '_split_overlap': [{'doc_id': '8b0fea59fa66abc3969e17bb2dd665ac', 'range': (0, 215)}, {'doc_id': '7fcb69feffe77f0896bc16445fd8451e', 'range': (887, 1103)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9ade19697e293d0644567e6dab6906e9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: La tarjeta Apple es una tarjeta de crédito que proporciona una línea de crédito a los\\nusuarios y utiliza machine learning para ayudarles en la gestión y control de gastos. En\\n28 MAYSON, S.G., «Bias in, Bias out»…cit.\\n29 PERC, M., OZER, M. y HOJNIK, J., «Social and juristic challenges of artificial intelligence», Palgrave\\nCommunications, 5:61, 2019, pp. 1-7. DOI: 10.1057/s41599-019-0278-x.\\n30 Carta de los Derechos Fundamentales de la Unión Europea, 2000, C 364/01, disponible en\\n<https://www.europarl.europa.eu/charter/pdf/text_es.pdf>. Fecha de consulta: 18 de mayo de 2020.\\n31 APPLE, «Apple Card launches today for all US customers», Apple Newsroom, 2019, disponible en\\n<https://www.apple.com/newsroom/2019/08/apple-card-launches-today-for-all-us-customers/>. Fecha de\\nconsulta: 6 de abril de 2020.\\x0c22\\nnoviembre de 2019 un usuario manifestó públicamente a través de Twitter que el límite\\nde crédito para su mujer era veinte veces inferior al suyo, estando ambos casados y\\nhabiendo proporcionado la misma información con respecto a sus activos, e incluso\\npresentando la mujer una mejor puntuación crediticia. Al ser compartidas situaciones\\nsimilares por otros clientes, el Departamento de Servicios Financieros del Estado de\\nNueva York inició una investigación todavía en curso para determinar si los criterios\\nutilizados por la tarjeta Apple podían ser considerados discriminatorios32.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 60, 'page': 23, '_split_overlap': [{'doc_id': '9ade19697e293d0644567e6dab6906e9', 'range': (0, 216)}, {'doc_id': '1a1c8f9a8e424cb923e990cf00cf44d2', 'range': (1113, 1390)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7fcb69feffe77f0896bc16445fd8451e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Al ser compartidas situaciones\\nsimilares por otros clientes, el Departamento de Servicios Financieros del Estado de\\nNueva York inició una investigación todavía en curso para determinar si los criterios\\nutilizados por la tarjeta Apple podían ser considerados discriminatorios32.\\nEn un comunicado a CNN Business33, Goldman Sachs explicó que los clientes de la\\ntarjeta Apple no comparten una línea de crédito bajo la cuenta de un familiar u otra\\npersona al obtener una tarjeta complementaria. Las solicitudes se evalúan de forma\\nindependiente, teniendo en cuenta los ingresos del individuo y el nivel de solvencia,\\nconsiderando para ello la puntuación crediticia, el volumen de deuda y cómo se ha\\ngestionado esa deuda. Esto podría justificar que se asignen a dos miembros de la misma\\nfamilia límites de crédito significativamente diferentes.\\nCon independencia de los resultados que arroje la investigación, cabe la posibilidad de\\nque éste sea un ejemplo ilustrativo de parcialidad con respecto a la variable género por\\ninferencia estadística. Sin un fundamento sólido que justifique las decisiones del sistema\\nautónomo de toma de decisiones que determina el límite de crédito de los usuarios, podría\\nconsiderarse que este sistema de IA actúa de forma parcial o discriminatoria.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 61, 'page': 24, '_split_overlap': [{'doc_id': '7fcb69feffe77f0896bc16445fd8451e', 'range': (0, 277)}, {'doc_id': '5fa1ac0cae632b5a119705c88c8ad966', 'range': (1040, 1274)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1a1c8f9a8e424cb923e990cf00cf44d2'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Sin un fundamento sólido que justifique las decisiones del sistema\\nautónomo de toma de decisiones que determina el límite de crédito de los usuarios, podría\\nconsiderarse que este sistema de IA actúa de forma parcial o discriminatoria.\\nPor otro lado, el derecho de los consumidores a la igualdad de trato podría verse\\ncuestionado por la nueva estrategia de precios de Uber, que está estudiando la posibilidad\\nde fijar el precio del trayecto en función de la predisposición al gasto del usuario o de su\\ncomportamiento34. En un principio, Uber establecía sus precios a través de un mecanismo\\nde oferta y demanda, siendo el precio igual para todos los usuarios del servicio que\\nsolicitaban el mismo trayecto. Implementando este mecanismo alternativo, los precios\\npodrían incrementarse para los consumidores que tengan una capacidad económica\\n32 VIGDOR, N., «Apple Card Investigated After Gender Discrimination Complaints», The New York Times\\nBusiness, 2019, disponible en <https://www.nytimes.com/2019/11/10/business/Apple-credit-card-\\ninvestigation.html>. Fecha de consulta: 6 de abril de 2020.\\n33 NEDLUND, E., «Apple Card is accused of gender bias. Here's how that can happen», CNN Business,\\n2019, disponible en <https://edition.cnn.com/2019/11/12/business/apple-card-gender-bias/index.html>.\\nFecha de consulta: 6 de abril de 2020.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 62, 'page': 24, '_split_overlap': [{'doc_id': '1a1c8f9a8e424cb923e990cf00cf44d2', 'range': (0, 234)}, {'doc_id': '19a34c35acc9a85397e4694dd05998d0', 'range': (1092, 1329)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5fa1ac0cae632b5a119705c88c8ad966'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: 33 NEDLUND, E., «Apple Card is accused of gender bias. Here's how that can happen», CNN Business,\\n2019, disponible en <https://edition.cnn.com/2019/11/12/business/apple-card-gender-bias/index.html>.\\nFecha de consulta: 6 de abril de 2020.\\n34 NEWCOMER, E., Uber Yield Management: Uber Starts Charging What It Thinks You’re Willing to Pay,\\nBloomberg, 2017, disponible en <https://www.bloomberg.com/news/articles/2017-05-19/uber-s-future-\\nmay-rely-on-predicting-how-much-you-re-willing-to-pay>. Fecha de consulta: 20 de mayo de 2020.\\x0c23\\nsuperior, por ejemplo, haciendo que los trayectos reiterados desde las zonas residenciales\\nmás ricas sean más caros. Otro de los aspectos que pueden considerarse en la\\ndeterminación del precio es la vida restante de la batería, de manera que el precio sea más\\nelevado si el teléfono va a apagarse en poco tiempo35.\\nAmbos casos han tenido por el momento una mayor incidencia en Estados Unidos, pero\\nse trata de multinacionales que operan en todo el mundo y que también ponen en riesgo\\nlos derechos de los ciudadanos de la Unión Europea. Es necesario un control constante,\\nsi bien no excesivo, para evitar que se produzcan situaciones de amenaza a los principios\\néticos básicos que están establecidos por la UE. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 63, 'page': 24, '_split_overlap': [{'doc_id': '5fa1ac0cae632b5a119705c88c8ad966', 'range': (0, 237)}, {'doc_id': '5e0beda8955398ea38768ad91b88375d', 'range': (1069, 1242)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '19a34c35acc9a85397e4694dd05998d0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Es necesario un control constante,\\nsi bien no excesivo, para evitar que se produzcan situaciones de amenaza a los principios\\néticos básicos que están establecidos por la UE. La transparencia y explicabilidad del\\nalgoritmo deviene en este tipo de supuestos necesaria a fin de proteger a los consumidores\\ny salvaguardar sus derechos.\\n3.5. Responsabilidad por daños y perjuicios causados por la IA\\nEl régimen de responsabilidad aplicable a la inteligencia artificial es uno de los puntos\\nmás controvertidos. Debe reflexionarse acerca de quiénes serán los sujetos sobre los que\\npuede recaer la responsabilidad, qué tipo de responsabilidad en cada caso y en qué medida\\nexiste responsabilidad subsidiaria. Además, una de las novedades que deriva de las\\ncaracterísticas particulares de la IA es la inversión de la carga de la prueba.\\nEl Grupo Experto en Responsabilidad y Nuevas Tecnologías de la Comisión Europea\\npublicó en 2019 un informe sobre Responsabilidad para la IA y otras tecnologías\\nEmergentes36, en el que se recoge la distinción entre dos tipos de operadores a la hora de\\nasignar la responsabilidad: el operador frontal y el operador de backend. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 64, 'page': 25, '_split_overlap': [{'doc_id': '19a34c35acc9a85397e4694dd05998d0', 'range': (0, 173)}, {'doc_id': '5b6aed9785476225900fa4b53426f3a9', 'range': (827, 1151)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5e0beda8955398ea38768ad91b88375d'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: El Grupo Experto en Responsabilidad y Nuevas Tecnologías de la Comisión Europea\\npublicó en 2019 un informe sobre Responsabilidad para la IA y otras tecnologías\\nEmergentes36, en el que se recoge la distinción entre dos tipos de operadores a la hora de\\nasignar la responsabilidad: el operador frontal y el operador de backend. El operador\\nfrontal representa a aquellos que «principalmente» deciden y se benefician del uso de la\\ntecnología, mientras que el operador de backend se refiere a quienes «continuamente»\\ndefinen las características de «la tecnología relevante» y proporcionan soporte de backend\\nesencial y continuo. Esta última categoría podría incluir a los fabricantes que ofrecen\\nactualizaciones continuas de software y servicios de backend, entendiendo los mismos\\ncomo la instrumentación de recursos informáticos entre el marco de deep learning y la\\ninfraestructura de la nube con la que trabaja la IA. Este informe apunta, además, que\\n35 MARTIN, N., Uber Charges More If They Think You're Willing To Pay More, Forbes, 2019, disponible\\nen <https://www.forbes.com/sites/nicolemartin1/2019/03/30/uber-charges-more-if-they-think-youre-\\nwilling-to-pay-more/#1825e1747365>. Fecha de consulta: 21 de mayo de 2020.\\n36 GRUPO EXPERTO EN RESPONSABILIDAD Y NUEVAS TECNOLOGÍAS DE LA COMISIÓN\\nEUROPEA, Liability for Artificial Intelligence and other emerging digital technologies, 2019, pp. 1-70.\\nDOI:10.2838/573689.\\x0c\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 65, 'page': 25, '_split_overlap': [{'doc_id': '5e0beda8955398ea38768ad91b88375d', 'range': (0, 324)}, {'doc_id': '78b06bca4304faff0b757ef2ea964b83', 'range': (1219, 1414)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5b6aed9785476225900fa4b53426f3a9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: 36 GRUPO EXPERTO EN RESPONSABILIDAD Y NUEVAS TECNOLOGÍAS DE LA COMISIÓN\\nEUROPEA, Liability for Artificial Intelligence and other emerging digital technologies, 2019, pp. 1-70.\\nDOI:10.2838/573689.\\x0c24\\ncuando dos operadores coexisten, la responsabilidad estricta «debe recaer en el que tiene\\nmás control sobre los riesgos de operación».\\nEn cuanto a la responsabilidad del fabricante o productor, se sugiere en este informe se\\nimpute estrictamente la responsabilidad por los defectos en productos o contenido digital\\nque incorporen tecnología digital emergente –entre los cuales se incluirían aquellos que\\nfuncionen con IA–, incluso si «el defecto apareció después de que el producto se puso en\\ncirculación». Se considera que el riesgo soportado en la fase de desarrollo no debería\\nrecaer sobre los fabricantes en los casos en que fuese predecible que pudieran ocurrir\\ndesarrollos o comportamientos imprevistos.\\nDebido a la dificultad para las víctimas a la hora de demostrar la existencia de dichos\\ndefectos o la determinación de la responsabilidad por los mismos, el Grupo de Expertos\\npropone invertir la carga de la prueba, de manera que corresponda al fabricante probar\\nque el defecto no existía, no era predecible o se encuentra fuera de su ámbito de\\nresponsabilidad. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 66, 'page': 25, '_split_overlap': [{'doc_id': '5b6aed9785476225900fa4b53426f3a9', 'range': (0, 195)}, {'doc_id': '30aedfeebc82f94d739e8d7c179acefe', 'range': (908, 1268)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '78b06bca4304faff0b757ef2ea964b83'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Debido a la dificultad para las víctimas a la hora de demostrar la existencia de dichos\\ndefectos o la determinación de la responsabilidad por los mismos, el Grupo de Expertos\\npropone invertir la carga de la prueba, de manera que corresponda al fabricante probar\\nque el defecto no existía, no era predecible o se encuentra fuera de su ámbito de\\nresponsabilidad. Estas nuevas tecnologías son en esencia complejas, dinámicas e\\ninterconectadas, lo que puede conllevar que resulte especialmente difícil establecer un\\nnexo de causalidad entre el origen del defecto y el daño ocasionado. Para proteger al\\nusuario en este tipo de situaciones, se considera proporcional esa inversión probatoria, de\\nforma que sea el operador o la persona a la que se dirija la reclamación por el defecto\\nquien demuestre que no existía la deficiencia o el nexo causal que permite que le sea\\nimputada la responsabilidad por el mismo.\\nAdemás de cuestionar la responsabilidad objetiva por productos con IA defectuosos,\\ntambién debe plantearse la conveniencia de una posible alteración normativa con respecto\\na la responsabilidad subsidiaria. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 67, 'page': 26, '_split_overlap': [{'doc_id': '78b06bca4304faff0b757ef2ea964b83', 'range': (0, 360)}, {'doc_id': '35f466b243f1f3c7131390e72cbea420', 'range': (906, 1111)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '30aedfeebc82f94d739e8d7c179acefe'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Además de cuestionar la responsabilidad objetiva por productos con IA defectuosos,\\ntambién debe plantearse la conveniencia de una posible alteración normativa con respecto\\na la responsabilidad subsidiaria. En concreto, se suscita la posibilidad de expandir el\\nrégimen de responsabilidad indirecta a los daños causados por la tecnología autónoma\\npara los casos en que existe equivalencia funcional. Dicha equivalencia responde a una\\nsituación en la que el uso de una tecnología autónoma que causa daños pueda dar lugar a\\nla responsabilidad indirecta del operador, si su uso es equivalente al empleo de auxiliares\\nhumanos, es decir, que la tarea ejecutada por una IA pudiese haber sido realizada por un\\nser humano.\\nLas anteriores cuestiones acerca de los riesgos sobre la responsabilidad serán tratadas en\\nmayor profundidad junto a algunas aportaciones personales en el apartado donde se revisa\\x0c25\\nel régimen propuesto en el proyecto del Reglamento sobre Responsabilidad por el\\nfuncionamiento de los sistemas de Inteligencia Artificial37.\\n4. Regulación de la inteligencia artificial\\nLa implementación de sistemas de IA se ha extendido a campos tan diversos como el\\ndiagnóstico de enfermedades, la predicción de delitos y la evaluación de seguros38.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 68, 'page': 26, '_split_overlap': [{'doc_id': '30aedfeebc82f94d739e8d7c179acefe', 'range': (0, 205)}, {'doc_id': '893254698949a0c995a698304091c402', 'range': (1040, 1246)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '35f466b243f1f3c7131390e72cbea420'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Regulación de la inteligencia artificial\\nLa implementación de sistemas de IA se ha extendido a campos tan diversos como el\\ndiagnóstico de enfermedades, la predicción de delitos y la evaluación de seguros38.\\nConsiderando los riesgos previamente descritos, y conforme a lo apuntado por la\\nComisión Europea, existe una necesidad imperante de examinar si la legislación actual es\\nsuficiente para dar respuesta a los riesgos de la IA y si puede ser efectivamente aplicada.\\nSi no lo es, debe considerarse si procede hacer adaptaciones de la actual legislación o, si\\nesto fuese insuficiente, elaborar nuevas normas.\\nEn la línea de lo anterior, es razonable la conclusión que se alcanza ante la incertidumbre\\ncausada por la ausencia de un marco regulatorio claro. Si no se proporciona un enfoque\\nlegislativo a escala de la UE, existe un riesgo real de fragmentación en el mercado interior,\\nlo que socavaría los objetivos de confianza, seguridad jurídica y aceptación del mercado.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 69, 'page': 27, '_split_overlap': [{'doc_id': '35f466b243f1f3c7131390e72cbea420', 'range': (0, 206)}, {'doc_id': '20ab881aaebed6d24820fd0f1c29316c', 'range': (756, 971)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '893254698949a0c995a698304091c402'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Si no se proporciona un enfoque\\nlegislativo a escala de la UE, existe un riesgo real de fragmentación en el mercado interior,\\nlo que socavaría los objetivos de confianza, seguridad jurídica y aceptación del mercado.\\nPara armonizar la legislación de los Estados Miembros y anticipar una respuesta para las\\nsituaciones de riesgo o amenaza causadas por sistemas de IA, es necesario que se lleve a\\ncabo una adaptación de la legislación existente o la elaboración de nuevas normas en el\\námbito europeo. Más allá de las Directrices Éticas para una IA fiable39, deben concretarse\\nlos riesgos que existen en las distintas áreas del Derecho y proponerse medidas concretas\\npara dar una solución eficaz a los mismos. Esto proporciona un punto de partida para los\\ndiferentes Estados, que deben regular la IA con sus propias normas, pero ajustándose a\\nlos principios establecidos por la UE.\\n4.1. Posibles adaptaciones del marco legislativo europeo a la IA\\n4.1.1. Derecho de Propiedad Intelectual e Industrial\\nLa inteligencia artificial puede llevar a cabo creaciones literarias y artísticas, como\\npueden ser canciones, cuadros o poemas. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 70, 'page': 27, '_split_overlap': [{'doc_id': '893254698949a0c995a698304091c402', 'range': (0, 215)}, {'doc_id': 'b8b884d12f68ec364c1ad62d037b836e', 'range': (950, 1123)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '20ab881aaebed6d24820fd0f1c29316c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Derecho de Propiedad Intelectual e Industrial\\nLa inteligencia artificial puede llevar a cabo creaciones literarias y artísticas, como\\npueden ser canciones, cuadros o poemas. En Europa, mientras que algunos países han\\n37 COMISIÓN DE ASUNTOS JURÍDICOS DEL PARLAMENTO EUROPEO, Proyecto de Informe con\\nrecomendaciones destinadas a la Comisión sobre un régimen de responsabilidad civil en materia de\\ninteligencia artificial…cit.\\n38 TAN, Z., YEOM, S., FREDRIKSON, M. y TALWALKAR, A., Learning Fair Representations for\\nKernel Models,ArXiv preprint, arXiv:1906.11813, 2019, pp. 1-15.\\n39 GRUPO DE EXPERTOS DE ALTO NIVEL EN IA DE LA COMISIÓN EUROPEA (b), Ethics\\nGuidelines for Trustworthy AI…cit.\\x0c26\\noptado por la protección de las obras creadas por una tecnología, otros se posicionan en\\ncontra de atribuir una autoría a este tipo de trabajos, considerando que dichas obras deben\\npertenecer a dominio público.\\nLa Ley de Derechos de Autor de Reino Unido 40 da una definición de obras generadas por\\nordenador y establece su autoría, los derechos morales que corresponden a dichas obras\\ny el periodo de duración de dicha protección. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 71, 'page': 27, '_split_overlap': [{'doc_id': '20ab881aaebed6d24820fd0f1c29316c', 'range': (0, 173)}, {'doc_id': 'a92a136ee3ae215d1745838b3ec3819c', 'range': (901, 1120)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b8b884d12f68ec364c1ad62d037b836e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: La Ley de Derechos de Autor de Reino Unido 40 da una definición de obras generadas por\\nordenador y establece su autoría, los derechos morales que corresponden a dichas obras\\ny el periodo de duración de dicha protección. Se entiende como «trabajo generado por un\\nordenador» aquel que es creado por un ordenador sin la intervención de un autor humano\\ny se considera que el autor es la persona por quien se toman las medidas necesarias para\\nla creación de la obra. En la misma línea, la Ley de Derechos de Autor de Irlanda41\\nestablece un periodo de duración del copyright para obras generadas por ordenador de\\nsetenta años. Sin embargo, en la mayoría de los países europeos se tiende a no reconocer\\nderechos de autor sobre las obras generadas por ordenador.\\nEs momento de establecer de forma clara cuál es el criterio que la UE comparte, para que\\nasí los Estados miembros adopten una postura de aceptación o rechazo sobre la existencia\\nde una autoría para este tipo de trabajos. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 72, 'page': 28, '_split_overlap': [{'doc_id': 'b8b884d12f68ec364c1ad62d037b836e', 'range': (0, 219)}, {'doc_id': 'f046fea2c868e4a71ff1025a2b1f8861', 'range': (755, 975)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a92a136ee3ae215d1745838b3ec3819c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Es momento de establecer de forma clara cuál es el criterio que la UE comparte, para que\\nasí los Estados miembros adopten una postura de aceptación o rechazo sobre la existencia\\nde una autoría para este tipo de trabajos. En el caso de reconocer a los trabajos creados\\npor IA derechos de autor, debe determinarse a quién corresponden los mismos, mientras\\nque, de rechazarse esta idea, habría que clasificar estas creaciones como obras de dominio\\npúblico.\\nLos escritores y periodistas ahora pueden utilizar software de procesamiento de textos\\npara escribir artículos periodísticos y libros. Los diseñadores gráficos pueden crear\\ncarteles y cuadros. Los compositores pueden ajustar su música y crear nuevas canciones.\\nLa IA, al igual que el ordenador, pero de forma más sofisticada y desarrollada, es una\\nherramienta que sirve de ayuda o asistencia para los autores humanos. La pregunta que\\ndebe plantearse llegado este punto no es si debe reconocerse o no derechos de autor sobre\\nlas obras creadas por la IA, sino a quién corresponden esos derechos.\\nLa IA no tiene consciencia de sí misma ni de su obra, ni personalidad jurídica a la que\\npueda ser atribuida una autoría. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 73, 'page': 28, '_split_overlap': [{'doc_id': 'a92a136ee3ae215d1745838b3ec3819c', 'range': (0, 220)}, {'doc_id': '589e6ea3cd1cc596ac55f15e225869ca', 'range': (1048, 1168)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f046fea2c868e4a71ff1025a2b1f8861'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: La IA no tiene consciencia de sí misma ni de su obra, ni personalidad jurídica a la que\\npueda ser atribuida una autoría. El autor en este tipo de supuestos debe ser quien ha\\ndiseñado la tecnología que finalmente ha dado lugar a la obra, como en el caso de que\\n40 Copyright, Designs and Patents Act, Reino Unido, 1988, disponible en\\n<http://www.legislation.gov.uk/ukpga/1988/48/part/I/chapter/I/crossheading/authorship-and-ownership-\\nof-copyright>.\\n41 Copyright and Related Rights Act, Irlanda, 2000, disponible en\\n<http://www.irishstatutebook.ie/eli/2000/act/28/enacted/en/print>.\\x0c27\\nuna persona desarrolle y entrene una red neuronal que cree cuadros o canciones. Podría\\ntambién plantearse el escenario en el que se adjudiquen los derechos de autor al\\npropietario de la tecnología, por ejemplo, en el caso de una editorial que haya adquirido\\nuna IA y la utilice para redactar libros o artículos.\\nBuena parte de los expertos en inteligencia artificial42 consideran que la negativa al\\notorgamiento de derechos de autor sobre las obras generadas por ordenador supondría un\\ndesincentivo económico, puesto que, al pertenecer la obra creada al dominio público, el\\ndiseñador de la IA que ha creado la obra no podría lucrarse. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 74, 'page': 28, '_split_overlap': [{'doc_id': 'f046fea2c868e4a71ff1025a2b1f8861', 'range': (0, 120)}, {'doc_id': '7f94674fcf85393d3cb336a56129202c', 'range': (896, 1218)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '589e6ea3cd1cc596ac55f15e225869ca'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Buena parte de los expertos en inteligencia artificial42 consideran que la negativa al\\notorgamiento de derechos de autor sobre las obras generadas por ordenador supondría un\\ndesincentivo económico, puesto que, al pertenecer la obra creada al dominio público, el\\ndiseñador de la IA que ha creado la obra no podría lucrarse. Uno de los objetivos\\nplanteados por la Comisión Europea responde al impulso del desarrollo de la inteligencia\\nartificial, para lo cual se necesita dotar de incentivos a quienes la diseñan. En este sentido,\\nla desprotección de las obras literarias y artísticas supondría posiblemente un freno al\\nprogreso y avance tecnológicos a causa de la falta de incentivos económicos.\\nEs por ello por lo que el debate en cuanto a los derechos de propiedad intelectual e\\nindustrial debe abordarse desde la perspectiva de la tecnología como herramienta\\nutilizada por el ser humano, existiendo una autoría detrás de la obra creada por IA. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 75, 'page': 29, '_split_overlap': [{'doc_id': '589e6ea3cd1cc596ac55f15e225869ca', 'range': (0, 322)}, {'doc_id': '66742e04065c77020d175273817181ac', 'range': (695, 945)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7f94674fcf85393d3cb336a56129202c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Es por ello por lo que el debate en cuanto a los derechos de propiedad intelectual e\\nindustrial debe abordarse desde la perspectiva de la tecnología como herramienta\\nutilizada por el ser humano, existiendo una autoría detrás de la obra creada por IA. La\\ntarea pendiente es revisar el concepto de autor, dar cabida a la existencia de obras\\ngeneradas por tecnologías –dentro de las cuales se incluye la IA–, establecer el periodo\\nde duración de la protección y examinar los posibles escenarios para determinar a quién\\ncorresponde la autoría en función de las circunstancias concretas.\\n4.1.2. Derecho de Transporte Terrestre\\nLas tecnologías de IA integradas en productos o aplicadas a prestaciones de servicios\\npueden presentar nuevos riesgos de seguridad para los usuarios en el área del transporte\\nterrestre. Un error en el reconocimiento de objetos por parte de un automóvil autónomo\\npuede causar un accidente con lesiones físicas y daños materiales. Estos riesgos pueden\\nser causados por defectos en el diseño de la IA, por una insuficiente disponibilidad o\\ncalidad de los datos o debido a otros problemas derivados del aprendizaje automático.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 76, 'page': 29, '_split_overlap': [{'doc_id': '7f94674fcf85393d3cb336a56129202c', 'range': (0, 250)}, {'doc_id': '941ae23e2c243b4a8ea6fdaec4ae3a7c', 'range': (951, 1144)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '66742e04065c77020d175273817181ac'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Estos riesgos pueden\\nser causados por defectos en el diseño de la IA, por una insuficiente disponibilidad o\\ncalidad de los datos o debido a otros problemas derivados del aprendizaje automático.\\nDos convenios internacionales de tráfico por carretera, a saber, el Convenio de Ginebra\\nsobre el tráfico por carretera de 194943 y el Convenio de Viena sobre el tráfico por\\n42 HRISTOV, K., Artificial Intelligence and the Copyright Dilemma. The Journal of the Franklin Pierce\\nCenter for Intellectual Property, Vol. 57, 3 (438), disponible en <https://law.unh.edu/about/unh-law-\\npublications/idea-journal-franklin-pierce-center-intellectual-property>. Fecha de consulta: 15 de mayo de\\n2020.\\n43 Convención de Ginebra, de 19 de septiembre de 1949, sobre la circulación vial.\\x0c28\\ncarretera de 196844, son la base sobre la que se asientan la mayor parte de las leyes\\nnacionales de tráfico de los Estados miembros. Las normas de tráfico que se recogen en\\nestas convenciones fueron elaboradas bajo el paradigma de conducción de un vehículo\\npor una persona humana. La aparición de vehículos de conducción autónoma que pueden\\noperar sin interferencia humana actualmente no es compatible con este planteamiento.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 77, 'page': 29, '_split_overlap': [{'doc_id': '66742e04065c77020d175273817181ac', 'range': (0, 193)}, {'doc_id': '6ca7ce98435abb877d1623d5d38a6419', 'range': (1049, 1193)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '941ae23e2c243b4a8ea6fdaec4ae3a7c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: La aparición de vehículos de conducción autónoma que pueden\\noperar sin interferencia humana actualmente no es compatible con este planteamiento.\\nPor lo tanto, un vehículo totalmente automatizado, en el sentido de la Convención de\\nGinebra y la Convención de Viena, no tiene conductor.\\nPara dar solución a esta situación, debe revisarse el planteamiento de la normativa de\\ntráfico terrestre, dando cabida a los supuestos de vehículos autónomos, en los que no hay\\nuna persona que intervenga en la conducción. El sistema de IA dirige la conducción del\\nvehículo, por lo que la figura del conductor que se recoge en la Convención de Ginebra y\\nla Convención de Viena queda superada. La responsabilidad por la conducta del vehículo\\nrecae en su caso sobre el sistema de IA instalado en el automóvil, pero al carecer de\\npersonalidad jurídica esto crea una laguna.\\nUna posibilidad para colmar la misma es desviar la responsabilidad hacia la parte que\\ntiene más influencia sobre la conducta que ha generado el sistema de IA. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 78, 'page': 30, '_split_overlap': [{'doc_id': '941ae23e2c243b4a8ea6fdaec4ae3a7c', 'range': (0, 144)}, {'doc_id': '72873fcfc62856445d3ae43cc3110e7c', 'range': (854, 1012)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6ca7ce98435abb877d1623d5d38a6419'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Una posibilidad para colmar la misma es desviar la responsabilidad hacia la parte que\\ntiene más influencia sobre la conducta que ha generado el sistema de IA. Dependiendo de\\nlas circunstancias, el responsable podría ser el fabricante del vehículo, que es quien decide\\nsobre el hardware y el software del mismo; el diseñador de la IA, que establece los\\nobjetivos y entrena las redes neuronales; el proveedor de los datos que sirven de base a\\nese entrenamiento o incluso la persona que haya conseguido hackear el sistema de IA y\\ncontrolarlo a distancia. El propietario también podría ser responsable, por ejemplo, si la\\nconducta ha tenido lugar como consecuencia de que se hayan ignorado las instrucciones\\npara instalar una actualización de software o, en el caso de vehículos semiautónomos, se\\nhayan desoído las advertencias del sistema en las que se requiere su intervención en la\\nconducción.\\nDebe, por tanto, revisarse la legislación de la Unión Europea en materia de tráfico\\nterrestre, integrando el concepto de vehículo autónomo y semiautónomo en la normativa\\nvigente. Es posible que surjan nuevas obligaciones y derechos para el fabricante del\\ntransporte, el conductor y el pasajero. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 79, 'page': 30, '_split_overlap': [{'doc_id': '6ca7ce98435abb877d1623d5d38a6419', 'range': (0, 158)}, {'doc_id': 'de8a7ce0d39fc2a4150b805bd1799416', 'range': (893, 1187)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '72873fcfc62856445d3ae43cc3110e7c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Debe, por tanto, revisarse la legislación de la Unión Europea en materia de tráfico\\nterrestre, integrando el concepto de vehículo autónomo y semiautónomo en la normativa\\nvigente. Es posible que surjan nuevas obligaciones y derechos para el fabricante del\\ntransporte, el conductor y el pasajero. Asimismo, el régimen de responsabilidad en el caso\\n44 Convención de Viena, de 8 de noviembre de 1968, sobre la circulación vial.\\x0c29\\nde accidentes puede verse alterado por esta inclusión, de manera que también debe\\nadaptarse la respuesta que se ofrece en este tipo de supuestos.\\n4.1.3. Derecho de Protección de Datos\\nEl Reglamento General de Protección de Datos45 no aborda específicamente la IA. A\\npesar de que se han tenido en cuenta los avances y los riesgos de los entornos digitales en\\nla regulación de la protección de datos, la Unión Europea ha optado por lo que podría\\ndenominarse como «legislación independiente de la tecnología»46. Las reglas y principios\\ndel RGPD son suficientemente flexibles para cubrir futuros cambios tecnológicos y\\nperdurar en el tiempo. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 80, 'page': 30, '_split_overlap': [{'doc_id': '72873fcfc62856445d3ae43cc3110e7c', 'range': (0, 294)}, {'doc_id': '6cab4ff519b0f7e1acd95f0c3e175752', 'range': (691, 1064)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'de8a7ce0d39fc2a4150b805bd1799416'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: A\\npesar de que se han tenido en cuenta los avances y los riesgos de los entornos digitales en\\nla regulación de la protección de datos, la Unión Europea ha optado por lo que podría\\ndenominarse como «legislación independiente de la tecnología»46. Las reglas y principios\\ndel RGPD son suficientemente flexibles para cubrir futuros cambios tecnológicos y\\nperdurar en el tiempo. No obstante, la consecuencia de un exceso de generalidad que\\nprocure la inclusión de nuevos avances puede dar lugar a grandes divergencias en la\\ninterpretación de la ley y, en consecuencia, generar cierta incertidumbre jurídica.\\nEl artículo 4 del RGPD incluye una serie de definiciones como «datos personales»,\\n«elaboración de perfiles» o «tratamiento» que, a priori, son válidas y aplicables a la IA.\\nAsimismo, lo previsto en cuanto a las obligaciones de los implementadores de sistemas\\nde IA coincide con lo establecido en la disposición 24 del Reglamento. Se sugiere que,\\nindependientemente de la ubicación del establecimiento y de la pertenencia a la UE, todo\\nactor esté sujeto a la legislación de protección de datos si se realiza oferta de bienes o\\nservicios a los interesados en el territorio de la Unión.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 81, 'page': 31, '_split_overlap': [{'doc_id': 'de8a7ce0d39fc2a4150b805bd1799416', 'range': (0, 373)}, {'doc_id': 'c40c94f7a3cf7baa01614998099b38fb', 'range': (933, 1186)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6cab4ff519b0f7e1acd95f0c3e175752'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Se sugiere que,\\nindependientemente de la ubicación del establecimiento y de la pertenencia a la UE, todo\\nactor esté sujeto a la legislación de protección de datos si se realiza oferta de bienes o\\nservicios a los interesados en el territorio de la Unión.\\nSin embargo, el principio de limitación de la finalidad y el principio de minimización de\\ndatos, señalados ambos en el artículo 5.1 apartados b) y c), respectivamente, podría ser\\ndemasiado acotado teniendo en cuenta las capacidades de procesamiento de IA. El uso de\\nalgoritmos y la utilidad del aprendizaje automático se basa en la tendencia a recopilar la\\nmayor cantidad de datos posible y la generación de nuevos datos. De hecho, la\\nreutilización de la información es una característica principal de las aplicaciones de IA en\\nrelación con el análisis de big data. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 82, 'page': 31, '_split_overlap': [{'doc_id': '6cab4ff519b0f7e1acd95f0c3e175752', 'range': (0, 253)}, {'doc_id': '6adc1c80ef3a406d13bd12555237fd8b', 'range': (676, 819)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c40c94f7a3cf7baa01614998099b38fb'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: De hecho, la\\nreutilización de la información es una característica principal de las aplicaciones de IA en\\nrelación con el análisis de big data. Aunque a priori podría entenderse que estos principios\\nactúan como una restricción o impedimento para el desarrollo de los sistemas de IA por\\n45 Reglamento (UE) 2016/679 del Parlamento Europeo y del Consejo de 27 de abril de 2016 relativo a la\\nprotección de las personas físicas en lo que respecta al tratamiento de datos personales y a la libre\\ncirculación de estos datos y por el que se deroga la Directiva 95/46/CE.\\n46 MITROU, L., Data Protection, Artificial Intelligence and Cognitive Services is the General Data\\nProtection Regulation (GDPR) “Artificial Intelligence-Proof”?, 2019, pp. 1-90, disponible en\\n<https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE2PdYu>. Fecha de consulta: 19 de mayo\\nde 2020.\\x0c30\\nla prohibición de reutilización de datos y limitación de su uso, una interpretación\\nadecuada de este artículo puede solventar este inconveniente47.\\nUn desarrollador o implementador de IA está sujeto a los principios de protección de\\ndatos que se recogen en el RGPD, debiendo respetar todos los preceptos de dicha norma\\nque puedan aplicarse a su situación. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 83, 'page': 31, '_split_overlap': [{'doc_id': 'c40c94f7a3cf7baa01614998099b38fb', 'range': (0, 143)}, {'doc_id': '226a68e314815a1ea50a011eec295326', 'range': (1014, 1221)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6adc1c80ef3a406d13bd12555237fd8b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Un desarrollador o implementador de IA está sujeto a los principios de protección de\\ndatos que se recogen en el RGPD, debiendo respetar todos los preceptos de dicha norma\\nque puedan aplicarse a su situación. Para contribuir a esta adaptación normativa, dos son\\nlos retos que los desarrolladores e implementadores de la IA deben afrontar. Por una parte,\\ndeben definir de forma suficiente los fines perseguidos en la utilización de los datos\\nempleados en el entrenamiento del sistema de IA. Por otro lado, sería conveniente que al\\nrecoger datos se cerciorasen de seleccionar cuáles son relevantes para el entrenamiento\\ndel sistema de IA, de manera que trate de respetarse el principio de minimización de datos\\ndescrito en el párrafo anterior.\\nAdoptando esta perspectiva, el Reglamento de Protección de Datos puede ser\\ndirectamente aplicable a la IA, si bien es conveniente que se interprete parte de su\\ncontenido de forma más detallada o extensiva, como puede ser el caso de los principios\\nreferidos.\\n4.1.4. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 84, 'page': 32, '_split_overlap': [{'doc_id': '6adc1c80ef3a406d13bd12555237fd8b', 'range': (0, 207)}, {'doc_id': 'b2f1dd7fe213543274ed14c00b14521b', 'range': (741, 1005)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '226a68e314815a1ea50a011eec295326'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Adoptando esta perspectiva, el Reglamento de Protección de Datos puede ser\\ndirectamente aplicable a la IA, si bien es conveniente que se interprete parte de su\\ncontenido de forma más detallada o extensiva, como puede ser el caso de los principios\\nreferidos.\\n4.1.4. Derecho de Consumo y Responsabilidad por Productos Defectuosos\\nLas recomendaciones sobre responsabilidad por defectos en productos que incorporen IA\\nque se recogen en el informe de la Comisión Europea48 podrían implicar la modificación\\nde la Directiva de Responsabilidad del Producto49. Teniendo en cuenta la participación\\nde diferentes agentes en el diseño, desarrollo, utilización y aplicación de los sistemas de\\nIA, debe ampliarse el concepto de operador que determina el ámbito objetivo de la norma.\\nPara ello, deben considerarse no sólo las formas de inteligencia artificial actualmente\\nexistentes, sino que es preciso redefinir el concepto de operador, producto defectuoso y\\ndefecto, de forma que tengan cabida las nuevas tecnologías que surjan en los próximos\\naños, sean o no consecuencia de una evolución de la IA.\\n47 MITROU, L., Data Protection, Artificial Intelligence and Cognitive Services is the General Data\\nProtection Regulation (GDPR) “Artificial Intelligence-Proof”?...cit.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 85, 'page': 32, '_split_overlap': [{'doc_id': '226a68e314815a1ea50a011eec295326', 'range': (0, 264)}, {'doc_id': 'aa557b8e3864e0c72bf5bcc0d14361d6', 'range': (769, 1255)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b2f1dd7fe213543274ed14c00b14521b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Para ello, deben considerarse no sólo las formas de inteligencia artificial actualmente\\nexistentes, sino que es preciso redefinir el concepto de operador, producto defectuoso y\\ndefecto, de forma que tengan cabida las nuevas tecnologías que surjan en los próximos\\naños, sean o no consecuencia de una evolución de la IA.\\n47 MITROU, L., Data Protection, Artificial Intelligence and Cognitive Services is the General Data\\nProtection Regulation (GDPR) “Artificial Intelligence-Proof”?...cit.\\n48 GRUPO EXPERTO EN RESPONSABILIDAD Y NUEVAS TECNOLOGÍAS DE LA COMISIÓN\\nEUROPEA, Liability for Artificial Intelligence…cit.\\n49 CONSEJO DE LAS COMUNIDADES EUROPEAS, Directiva del Consejo, de 25 de julio de 1985,\\nrelativa a la aproximación de las disposiciones legales, reglamentarias y administrativas de los Estados\\nmiembros en materia de responsabilidad por los daños causados por productos defectuosos (85/374/CEE),\\nDiario Oficial de las Comunidades Europeas, 13(19) disponible en <https://eur-lex.europa.eu/legal-\\ncontent/ES/TXT/PDF/?uri=CELEX:31985L0374&from=EN>.\\x0c31\\nLa aceptación de la clasificación de operadores sugerida en el informe sobre\\nResponsabilidad por la IA50 debe ir acompañada del establecimiento de obligaciones\\nespecíficas para el operador frontal y el operador de backend, así como un marco de\\nresponsabilidad diferenciado para cada operador por el incumplimiento de lo que se haya\\nprevisto. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 86, 'page': 32, '_split_overlap': [{'doc_id': 'b2f1dd7fe213543274ed14c00b14521b', 'range': (0, 486)}, {'doc_id': '333c395c7ad7ede0cbfed8f603d1a6f4', 'range': (1055, 1399)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'aa557b8e3864e0c72bf5bcc0d14361d6'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: 31\\nLa aceptación de la clasificación de operadores sugerida en el informe sobre\\nResponsabilidad por la IA50 debe ir acompañada del establecimiento de obligaciones\\nespecíficas para el operador frontal y el operador de backend, así como un marco de\\nresponsabilidad diferenciado para cada operador por el incumplimiento de lo que se haya\\nprevisto. A pesar de que la opacidad y la autonomía de los sistemas de IA puedan suponer\\nun obstáculo o incluso imposibilitar en la práctica la prueba de la existencia o el origen\\ndel defecto, esta limitación puede superarse haciendo responsables a las personas que\\ncrean, mantienen o controlan los riesgos asociados al sistema de inteligencia artificial. De\\nahí la importancia de definir el término operador e incluir dentro de esta acepción no sólo\\nal fabricante, sino también al proveedor de los datos, el desarrollador y el implementador\\n–quien en última instancia utiliza la IA–, para el caso de que estos agentes sean diferentes\\npersonas.\\nEl proveedor de datos es la persona que recoge y/o entrega o proporciona los datos a quien\\ndesarrollará la inteligencia artificial, pudiendo existir una diferenciación entre quien\\nrecoge en un principio los datos y quien los estructura posteriormente para su utilización.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 87, 'page': 33, '_split_overlap': [{'doc_id': 'aa557b8e3864e0c72bf5bcc0d14361d6', 'range': (0, 344)}, {'doc_id': 'd3ada75693a2492504ea9339261fd95c', 'range': (980, 1251)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '333c395c7ad7ede0cbfed8f603d1a6f4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: El proveedor de datos es la persona que recoge y/o entrega o proporciona los datos a quien\\ndesarrollará la inteligencia artificial, pudiendo existir una diferenciación entre quien\\nrecoge en un principio los datos y quien los estructura posteriormente para su utilización.\\nPodría entenderse el desarrollador como la persona que diseña la inteligencia artificial\\nusando los datos proporcionados por el proveedor para su entrenamiento y fijando los\\nobjetivos que condicionan la actuación de la IA y la creación del algoritmo.\\nEl fabricante o productor puede coincidir con el desarrollador o no, según la función de\\nla IA y su posible integración en un objeto o máquina. Por ejemplo, en el caso de los\\nvehículos autónomos podría darse la situación de que el fabricante del automóvil\\nexternalizase la función de diseño del sistema de conducción autónoma y se encargarse\\núnicamente del montaje del transporte integrando el sistema de IA en el mismo.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 88, 'page': 33, '_split_overlap': [{'doc_id': '333c395c7ad7ede0cbfed8f603d1a6f4', 'range': (0, 271)}, {'doc_id': '2f5bed6300d4e70d200f519932faa432', 'range': (667, 943)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd3ada75693a2492504ea9339261fd95c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Por ejemplo, en el caso de los\\nvehículos autónomos podría darse la situación de que el fabricante del automóvil\\nexternalizase la función de diseño del sistema de conducción autónoma y se encargarse\\núnicamente del montaje del transporte integrando el sistema de IA en el mismo.\\nFinalmente, el implementador podría definirse como la persona que decide sobre el uso\\ndel sistema de IA, ejerce control sobre el riesgo y se beneficia de su funcionamiento;\\nentendiendo por ejercicio del control cualquier acción del implementador que afecte al\\nmodo de funcionamiento de la IA o que altere funciones o procesos del sistema.\\n50 GRUPO EXPERTO EN RESPONSABILIDAD Y NUEVAS TECNOLOGÍAS DE LA COMISIÓN\\nEUROPEA, Liability for Artificial Intelligence…cit.\\x0c32\\nEn la línea de lo previsto en la Directiva sobre Responsabilidad de Productos\\nDefectuosos51, la existencia de un defecto implica que el resultado del producto o servicio\\nno es exactamente lo que se esperaba, sin que ello suponga necesariamente que el\\nproducto o servicio no funciona. Por producto o servicio defectuoso debe entenderse\\naquel que no ofrezca la seguridad que cabría legítimamente esperar teniendo en cuenta\\ntodas las circunstancias y, especialmente, el uso que razonablemente se prevé del mismo.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 89, 'page': 33, '_split_overlap': [{'doc_id': 'd3ada75693a2492504ea9339261fd95c', 'range': (0, 276)}, {'doc_id': 'b6b119314005ee0eaf8a1dca1c5503eb', 'range': (1027, 1252)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2f5bed6300d4e70d200f519932faa432'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Por producto o servicio defectuoso debe entenderse\\naquel que no ofrezca la seguridad que cabría legítimamente esperar teniendo en cuenta\\ntodas las circunstancias y, especialmente, el uso que razonablemente se prevé del mismo.\\nLa responsabilidad debería abarcar todas las operaciones de los sistemas de IA,\\nindependientemente del lugar donde se realice la operación o que la misma sea física o\\nvirtual. De esta forma se evita que la localización de los operadores o la tangibilidad de\\nsus acciones desprotejan a los usuarios que pueden verse perjudicados por los potenciales\\ndaños y perjuicios causados por la inteligencia artificial.\\nEn el caso de que coexistan diferentes acciones o comportamientos entre los agentes\\nresponsables que hayan dado lugar al riesgo o defecto, si la responsabilidad es objetiva\\ndebería entenderse como solidaria, facilitando así la posibilidad del sujeto afectado de\\ndirigirse contra uno, algunos o todos los agentes implicados. En el ámbito de la\\nresponsabilidad subsidiaria, sería necesario delimitar la extensión de dicha\\nresponsabilidad, tanto desde el punto de vista de los actores que pasarían a ser\\nresponsables subsidiarios, como para determinar los defectos o riesgos por los cuales debe\\nsurgir esta responsabilidad.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 90, 'page': 34, '_split_overlap': [{'doc_id': '2f5bed6300d4e70d200f519932faa432', 'range': (0, 225)}, {'doc_id': '969ff4888dbe3a22e4114178000dbfc0', 'range': (958, 1254)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b6b119314005ee0eaf8a1dca1c5503eb'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: En el ámbito de la\\nresponsabilidad subsidiaria, sería necesario delimitar la extensión de dicha\\nresponsabilidad, tanto desde el punto de vista de los actores que pasarían a ser\\nresponsables subsidiarios, como para determinar los defectos o riesgos por los cuales debe\\nsurgir esta responsabilidad.\\nPor último, la inversión de la carga de la prueba habría de ser recogida como excepción\\na la regla general de prueba por parte del usuario que reclama la responsabilidad del\\noperador por defectos en el producto o servicio que ha adquirido. El informe de la\\nComisión Europea52 hace alusión a esta inversión de la carga de la prueba en los casos en\\nlos que pueda entenderse que existe presunción de culpa por parte del operador. Dicha\\npresunción podría devenir del incumplimiento de las normas de registro o seguridad que\\nsean establecidas para los sistemas de IA e impuestas a los operadores. Se sugiere, como\\nuna de las posibilidades, que las tecnologías de IA incorporen algún tipo de sistema de\\nregistro que permita identificar la fuente del mal funcionamiento que causó el daño. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 91, 'page': 34, '_split_overlap': [{'doc_id': 'b6b119314005ee0eaf8a1dca1c5503eb', 'range': (0, 296)}, {'doc_id': '262dbfd2f2809d09b1aa705883fa8a8c', 'range': (889, 1078)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '969ff4888dbe3a22e4114178000dbfc0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Se sugiere, como\\nuna de las posibilidades, que las tecnologías de IA incorporen algún tipo de sistema de\\nregistro que permita identificar la fuente del mal funcionamiento que causó el daño. La\\n51 CONSEJO DE LAS COMUNIDADES EUROPEAS, Directiva del Consejo, de 25 de julio de 1985,\\nrelativa a la aproximación de las disposiciones legales, reglamentarias y administrativas de los Estados\\nmiembros en materia de responsabilidad por los daños causados por productos defectuosos…cit.\\n52 GRUPO EXPERTO EN RESPONSABILIDAD Y NUEVAS TECNOLOGÍAS DE LA COMISIÓN\\nEUROPEA, Liability for Artificial Intelligence…cit.\\x0c33\\ninexistencia de este sistema de registro o seguridad podría constituir una presunción\\nrefutable de responsabilidad, pudiendo probarse la improcedencia de dicha acusación con\\nla aportación de la información que explique el funcionamiento del sistema de IA o el\\norigen del defecto.\\nFinalmente, la Directiva de Maquinaria53 y la Directiva de Seguridad General del\\nProducto54 deben asimismo revisarse y actualizarse, de forma que ambas estén adaptadas\\na la IA y en concordancia con el resto de normativa europea que sea modificada,\\nespecialmente en lo referente al régimen de responsabilidad por daños y perjuicios.\\n4.1.5. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 92, 'page': 34, '_split_overlap': [{'doc_id': '969ff4888dbe3a22e4114178000dbfc0', 'range': (0, 189)}, {'doc_id': 'f6b0f19e98723b2240e0e4f524327e2c', 'range': (885, 1223)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '262dbfd2f2809d09b1aa705883fa8a8c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Finalmente, la Directiva de Maquinaria53 y la Directiva de Seguridad General del\\nProducto54 deben asimismo revisarse y actualizarse, de forma que ambas estén adaptadas\\na la IA y en concordancia con el resto de normativa europea que sea modificada,\\nespecialmente en lo referente al régimen de responsabilidad por daños y perjuicios.\\n4.1.5. Derecho de Seguros\\nConsiderando la existencia de riesgos potenciales de los sistemas de IA y en previsión de\\nminimizar los daños que pueden ocasionar los mismos a la víctima o al responsable por\\nlos mismos, debe estudiarse la posibilidad de exigir un seguro obligatorio de terceros para\\nciertas tecnologías emergentes, entre las cuales debe incluirse la IA. Una cobertura\\nadecuada de los riesgos es además necesaria para garantizar la confianza de los\\nciudadanos en esta tecnología. Estos seguros podrían ayudar a las víctimas de manera\\nmás fácil o fructífera a reclamar una indemnización por daños, sin que se prejuzgue el\\nderecho de la aseguradora a recurrir contra los responsables de actos de responsabilidad\\ncivil.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 93, 'page': 35, '_split_overlap': [{'doc_id': '262dbfd2f2809d09b1aa705883fa8a8c', 'range': (0, 338)}, {'doc_id': '2172d9611bd2cd49c9725f0aecec5589', 'range': (822, 1058)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f6b0f19e98723b2240e0e4f524327e2c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Estos seguros podrían ayudar a las víctimas de manera\\nmás fácil o fructífera a reclamar una indemnización por daños, sin que se prejuzgue el\\nderecho de la aseguradora a recurrir contra los responsables de actos de responsabilidad\\ncivil.\\nUna posibilidad es obligar a los implementadores de la IA a contar con un seguro para\\nsus sistemas de alto riesgo, o quizá para todos ellos, aunque haciendo una diferenciación\\nen la cobertura en función del riesgo que tenga el sistema. El mercado de los seguros\\npodría adaptar los productos existentes o crear un nuevo seguro para los numerosos\\nsectores y las diferentes tecnologías, productos y servicios que conllevan los sistemas de\\nIA. Otra opción es que se establezcan fondos de compensación para las víctimas que no\\npodrían reclamar efectivamente una indemnización debido a las dificultades para\\n53 PARLAMENTO EUROPEO y CONSEJO DE LA UNIÓN EUROPEA, Directiva del Parlamento\\nEuropeo y del Consejo, de 17 de mayo de 2006, relativa a la maquinaria (2006/42/EC), Diario Oficial de\\nla Unión Europea, L157/24, disponible en <https://eur-\\nlex.europa.eu/LexUriServ/LexUriServ.do?uri=OJ:L:2006:157:0024:0086:EN:PDF>.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 94, 'page': 35, '_split_overlap': [{'doc_id': 'f6b0f19e98723b2240e0e4f524327e2c', 'range': (0, 236)}, {'doc_id': '4265ea538aeffc7dbdc88bdacdae9103', 'range': (677, 1150)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2172d9611bd2cd49c9725f0aecec5589'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Otra opción es que se establezcan fondos de compensación para las víctimas que no\\npodrían reclamar efectivamente una indemnización debido a las dificultades para\\n53 PARLAMENTO EUROPEO y CONSEJO DE LA UNIÓN EUROPEA, Directiva del Parlamento\\nEuropeo y del Consejo, de 17 de mayo de 2006, relativa a la maquinaria (2006/42/EC), Diario Oficial de\\nla Unión Europea, L157/24, disponible en <https://eur-\\nlex.europa.eu/LexUriServ/LexUriServ.do?uri=OJ:L:2006:157:0024:0086:EN:PDF>.\\n54 PARLAMENTO EUROPEO y CONSEJO DE LA UNIÓN EUROPEA, Directiva del Parlamento\\nEuropeo y del Consejo, de 3 de diciembre de 2001, relativa a la seguridad general de los productos\\n(2001/95/EC), Diario Oficial de la Unión Europea, L11/4, disponible en <https://eur-lex.europa.eu/legal-\\ncontent/ES/TXT/PDF/?uri=CELEX:32001L0095&from=EN>.\\x0c34\\nidentificar al responsable por los daños ocasionados o en el caso de que la tecnología no\\nesté asegurada.\\n4.2. Elaboración de nuevas normas sobre IA\\n4.2.1. Directrices Éticas para una IA fiable\\nEl 8 de abril de 2019 la Comisión publicó las Directrices Éticas para una IA fiable55,\\nprimer instrumento orientativo europeo acerca de los pasos a seguir en los conflictos\\nsurgidos por la utilización de esta nueva tecnología. El objetivo de este instrumento pasa\\npor maximizar los beneficios y minimizar los riesgos que surgen por la adopción de la\\ninteligencia artificial. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 95, 'page': 35, '_split_overlap': [{'doc_id': '2172d9611bd2cd49c9725f0aecec5589', 'range': (0, 473)}, {'doc_id': '933fa8cb931ca43c75e09dd702398a12', 'range': (1231, 1378)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4265ea538aeffc7dbdc88bdacdae9103'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: El objetivo de este instrumento pasa\\npor maximizar los beneficios y minimizar los riesgos que surgen por la adopción de la\\ninteligencia artificial. Para cumplir esta misión, se considera que el punto de partida es\\npromover la fiabilidad de la IA en el sentido de extender la confianza en la misma, lo cual\\nse pretende consiguiendo que esta tecnología sea lícita, ética y robusta, técnica y\\nsocialmente. Se trata de que estos tres componentes sean considerados de forma conjunta\\ny simultánea, estableciéndose un marco de fiabilidad para la protección de los Derechos\\nFundamentales recogidos en la Carta de la UE.\\nLas Directrices Éticas superan el plano abstracto de la enunciación de principios\\ngenerales, haciendo referencia a medidas concretas que deberían ser objeto de un estudio\\npormenorizado. No obstante, más allá de los principios éticos que recoge es necesaria una\\nmayor profundización y concreción en algunos aspectos, especialmente respecto a las\\nmedidas que pueden adoptarse para mitigar los riesgos de la IA.\\n4.2.2. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 96, 'page': 36, '_split_overlap': [{'doc_id': '4265ea538aeffc7dbdc88bdacdae9103', 'range': (0, 147)}, {'doc_id': '25fbaca216dbcc72426498f7eda349e8', 'range': (798, 1027)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '933fa8cb931ca43c75e09dd702398a12'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: No obstante, más allá de los principios éticos que recoge es necesaria una\\nmayor profundización y concreción en algunos aspectos, especialmente respecto a las\\nmedidas que pueden adoptarse para mitigar los riesgos de la IA.\\n4.2.2. Reglamento sobre Responsabilidad por los sistemas de IA\\nEl 27 de abril de 2020 fue publicado el Proyecto de Informe con recomendaciones\\ndestinadas a la Comisión sobre un régimen de responsabilidad civil en materia de\\ninteligencia artificial incluyendo la propuesta del Parlamento Europeo para el Reglamento\\nsobre Responsabilidad por el funcionamiento de los sistemas de Inteligencia Artificial56.\\nEn este documento, el Parlamento Europeo apuesta por la creación de un marco jurídico\\nhorizontal basado en principios comunes con el fin de establecer una igualdad de normas\\nen toda la Unión y proteger eficazmente nuestros valores europeos. Considera que las\\nnuevas normas comunes para los sistemas de IA deben recogerse en un reglamento,\\n55 GRUPO DE EXPERTOS DE ALTO NIVEL EN IA DE LA COMISIÓN EUROPEA (b), Ethics\\nGuidelines for Trustworthy AI…cit.\\n56 COMISIÓN DE ASUNTOS JURÍDICOS DEL PARLAMENTO EUROPEO, Proyecto de Informe con\\nrecomendaciones destinadas a la Comisión sobre un régimen de responsabilidad civil en materia de\\ninteligencia artificial…cit.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 97, 'page': 36, '_split_overlap': [{'doc_id': '933fa8cb931ca43c75e09dd702398a12', 'range': (0, 229)}, {'doc_id': '5c375a0414aa3da7931e5b916f7cd4c9', 'range': (1077, 1283)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '25fbaca216dbcc72426498f7eda349e8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: 56 COMISIÓN DE ASUNTOS JURÍDICOS DEL PARLAMENTO EUROPEO, Proyecto de Informe con\\nrecomendaciones destinadas a la Comisión sobre un régimen de responsabilidad civil en materia de\\ninteligencia artificial…cit.\\x0c35\\nhaciendo especial alusión a la cuestión de la responsabilidad civil en caso de daño o\\nperjuicio causado por la IA.\\nTeniendo en cuenta lo anterior, parece que la regulación de la IA se llevará a cabo no\\nsolamente a través de adaptaciones de normativas ya existentes, sino mediante la creación\\nde nuevos instrumentos, como las Directrices Éticas o este futuro Reglamento sobre\\nResponsabilidad por el funcionamiento de los sistemas de inteligencia artificial.\\nEn materia de responsabilidad, la adaptación de la Directiva de Responsabilidad por\\nProductos Defectuosos57 podría llegar a resultar insuficiente. El Parlamento Europeo\\napunta en su Informe que, de conformidad con los sistemas de responsabilidad estricta de\\nlos Estados miembros, el Reglamento propuesto solo debe cubrir los daños que afecten a\\nla vida, la salud, la integridad física y la propiedad, y debe establecer las cantidades y el\\nalcance de la indemnización, así como el plazo de prescripción para las reclamar dichos\\ndaños. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 98, 'page': 36, '_split_overlap': [{'doc_id': '25fbaca216dbcc72426498f7eda349e8', 'range': (0, 206)}, {'doc_id': '37749dcd67dc7d0ba938c77ee37cd16a', 'range': (814, 1200)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5c375a0414aa3da7931e5b916f7cd4c9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: El Parlamento Europeo\\napunta en su Informe que, de conformidad con los sistemas de responsabilidad estricta de\\nlos Estados miembros, el Reglamento propuesto solo debe cubrir los daños que afecten a\\nla vida, la salud, la integridad física y la propiedad, y debe establecer las cantidades y el\\nalcance de la indemnización, así como el plazo de prescripción para las reclamar dichos\\ndaños. Esto permite dotar a los Estados miembros de un punto de partida común para los\\nderechos fundamentales más importantes, dejando un margen de libertad con respecto a\\notros derechos, para que los países regulen las particularidades del régimen de\\nresponsabilidad de la forma que más se adecúe a su ordenamiento jurídico.\\nEl proyecto del Reglamento comienza presentando en su artículo 3 ciertas definiciones.\\nSin embargo, hay ciertos conceptos que deberían ser incluidos y otros que conviene\\nmatizar. El sistema de IA de alto riesgo es una clasificación que necesita una descripción\\nmás detallada, prescindiendo de la mención sobre la aleatoriedad y atendiendo a los\\ndiferentes criterios que determinan si, efectivamente, el riesgo es elevado y el sistema\\nrequiere de mayor protección. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 99, 'page': 37, '_split_overlap': [{'doc_id': '5c375a0414aa3da7931e5b916f7cd4c9', 'range': (0, 386)}, {'doc_id': '354f0382ca36d2d7b647708cf3cc13cc', 'range': (885, 1169)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '37749dcd67dc7d0ba938c77ee37cd16a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: El sistema de IA de alto riesgo es una clasificación que necesita una descripción\\nmás detallada, prescindiendo de la mención sobre la aleatoriedad y atendiendo a los\\ndiferentes criterios que determinan si, efectivamente, el riesgo es elevado y el sistema\\nrequiere de mayor protección. Recapitulando lo expuesto anteriormente, un sistema de\\nIA debería ser calificado de alto riesgo en función de tres criterios: la gravedad del posible\\nperjuicio, la probabilidad de que el riesgo se materialice y el modo en que se utiliza el\\nsistema.\\nPor otra parte, la existencia de un anexo donde se recojan los sistemas de IA de alto riesgo\\npuede generar más incertidumbre que seguridad. Debe cuestionarse si resulta más eficaz\\na efectos de su aplicación en la práctica la creación de una lista cerrada, aunque revisable,\\nde sistemas de riesgo o el examen caso por caso del sistema en función de unos criterios\\nconcretos. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 100, 'page': 37, '_split_overlap': [{'doc_id': '37749dcd67dc7d0ba938c77ee37cd16a', 'range': (0, 284)}, {'doc_id': '9c7a9993ad6b9c2898afc5d918d3d2a4', 'range': (674, 907)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '354f0382ca36d2d7b647708cf3cc13cc'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Debe cuestionarse si resulta más eficaz\\na efectos de su aplicación en la práctica la creación de una lista cerrada, aunque revisable,\\nde sistemas de riesgo o el examen caso por caso del sistema en función de unos criterios\\nconcretos. Si bien es cierto que una lista puede dar una sensación de mayor concreción,\\n57 CONSEJO DE LAS COMUNIDADES EUROPEAS, Directiva del Consejo, de 25 de julio de 1985,\\nrelativa a la aproximación de las disposiciones legales, reglamentarias y administrativas de los Estados\\nmiembros en materia de responsabilidad por los daños causados por productos defectuosos…cit.\\x0c36\\nexiste el riesgo de que determinados sistemas no se encuentren identificados en la misma\\ny queden fuera del marco de protección, además de la posibilidad de que sean causados\\ndaños y no se aplique el régimen de responsabilidad o medidas para sistemas de alto\\nriesgo hasta su inclusión. De aceptarse el método de enumeración en el anexo de los\\nsistemas de alto riesgo, debe estudiarse el efecto retroactivo de las medidas de prevención,\\nanálisis y corrección, así como de la aplicación del régimen de responsabilidad.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 101, 'page': 37, '_split_overlap': [{'doc_id': '354f0382ca36d2d7b647708cf3cc13cc', 'range': (0, 233)}, {'doc_id': '238ac0eb6cbb0116d91ee37a2bf9d562', 'range': (885, 1115)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9c7a9993ad6b9c2898afc5d918d3d2a4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: De aceptarse el método de enumeración en el anexo de los\\nsistemas de alto riesgo, debe estudiarse el efecto retroactivo de las medidas de prevención,\\nanálisis y corrección, así como de la aplicación del régimen de responsabilidad.\\nEn el anexo del Proyecto de Reglamento se recogen cinco sistemas de IA calificados de\\nalto riesgo: aeronave no tripulada, vehículos con niveles de automatización 4 y 5, sistemas\\nautónomos de gestión del tráfico, robots autónomos y dispositivos autónomos de limpieza\\nde lugares públicos. Sin perjuicio de los posibles matices que puedan ser añadidos a estos\\nsistemas, la categoría de robots autónomos presenta sin duda cierta problemática. Un\\nrobot autónomo es una máquina inteligente capaz de realizar tareas en el mundo por sí\\nmisma, sin control humano explícito58. Por tanto, cuando se habla de robots autónomos\\nse hace referencia desde un robot que lleva a cabo operaciones quirúrgicas hasta un robot\\naspirador. Sin embargo, es evidente que el nivel de riesgo en estos dos ejemplos es muy\\ndiferente, tanto atendiendo a la magnitud de los daños que puede generar como al impacto\\nde los mismos en la esfera personal y social. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 102, 'page': 38, '_split_overlap': [{'doc_id': '9c7a9993ad6b9c2898afc5d918d3d2a4', 'range': (0, 230)}, {'doc_id': '250c3472a2c22dc51ed2223836363bd5', 'range': (946, 1157)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '238ac0eb6cbb0116d91ee37a2bf9d562'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Sin embargo, es evidente que el nivel de riesgo en estos dos ejemplos es muy\\ndiferente, tanto atendiendo a la magnitud de los daños que puede generar como al impacto\\nde los mismos en la esfera personal y social. Si se mantiene la creación de este anexo,\\nprocede crear categorías más específicas, a salvo de que el objetivo en un principio sea\\nclasificar por lo general los sistemas como de alto riesgo.\\nPor otra parte, existen sistemas de IA que no pertenecen a las anteriores categorías y que,\\nsin embargo, pueden tener alto riesgo. En concreto, no se reflejan los sistemas de decisión\\nautónomos más allá de los integrados en vehículos dedicados a la conducción autónoma.\\nSin embargo, pueden existir sistemas autónomos de toma de decisiones que tengan alto\\nriesgo, como por ejemplo un sistema que determine la medicación o dieta que debe seguir\\nun paciente. Si bien es cierto que, por el momento, estos sistemas todavía no están muy\\nextendidos y requieren de mayor desarrollo, en un futuro cercano la IA se implementará\\nde forma prolífera en sectores más allá de la conducción y el tráfico.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 103, 'page': 38, '_split_overlap': [{'doc_id': '238ac0eb6cbb0116d91ee37a2bf9d562', 'range': (0, 211)}, {'doc_id': 'c8d277eb72d2341f50866cbecdb9787a', 'range': (859, 1091)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '250c3472a2c22dc51ed2223836363bd5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Si bien es cierto que, por el momento, estos sistemas todavía no están muy\\nextendidos y requieren de mayor desarrollo, en un futuro cercano la IA se implementará\\nde forma prolífera en sectores más allá de la conducción y el tráfico.\\nEn cuanto a las definiciones que se refieren a los sujetos afectados por este Reglamento,\\nes importante incluir a todos los actores que puedan ser potencialmente responsables de\\n58 BEKEY, G.A., Autonomous Robots: From Biological Inspiration to Implementation and Control, 2017,\\ndisponible en <https://mitpress.mit.edu/books/autonomous-robots>. Fecha de consulta: 17 de mayo de\\n2020.\\x0c37\\ndaños causados por la inteligencia artificial. No sólo el implementador puede ser\\nresponsable, sino también el productor, el desarrollador o el proveedor de los datos.\\nSe entiende que implementador es quien ejerce en mayor medida el control sobre los\\nriesgos asociados y se beneficia de las operaciones del sistema de IA. Esto genera grandes\\ndudas en cuanto a quién es el implementador, puesto que todos los agentes ejercen en\\nparte control sobre los riesgos asociados, siendo mayor o menor en cada fase en función\\nde las características del sistema. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 104, 'page': 38, '_split_overlap': [{'doc_id': '250c3472a2c22dc51ed2223836363bd5', 'range': (0, 232)}, {'doc_id': '361bf5f8515fcd7a5cc3c00c8d34b0c9', 'range': (941, 1169)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c8d277eb72d2341f50866cbecdb9787a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Esto genera grandes\\ndudas en cuanto a quién es el implementador, puesto que todos los agentes ejercen en\\nparte control sobre los riesgos asociados, siendo mayor o menor en cada fase en función\\nde las características del sistema. Para un sistema de IA supervisado, el mayor riesgo\\npuede estar en la calidad de los datos que han entrenado el sistema, mientras que, en un\\nsistema no supervisado, el riesgo puede venir dado de la exposición del sistema a nuevos\\ndatos que modifican su comportamiento. Por tanto, atendiendo al control del riesgo, el\\nimplementador podría ser en cada caso un sujeto diferente, en función del tipo de sistema\\nde IA y la fase donde se ha originado el defecto. Por otra parte, se conjuga este elemento\\nde control de riesgo con el criterio de beneficio obtenido por el uso del sistema. Con\\nrespecto a este segundo aspecto, parece que quien generalmente obtendría beneficios de\\nsu utilización es la persona que pone a disposición del usuario el producto o servicio en\\nel cual se ha integrado la IA, lo cual también puede identificarse con el operador final.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 105, 'page': 39, '_split_overlap': [{'doc_id': 'c8d277eb72d2341f50866cbecdb9787a', 'range': (0, 228)}, {'doc_id': '2a5c0b43c5f665bc96f04ec5e9f2bd23', 'range': (809, 1079)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '361bf5f8515fcd7a5cc3c00c8d34b0c9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Con\\nrespecto a este segundo aspecto, parece que quien generalmente obtendría beneficios de\\nsu utilización es la persona que pone a disposición del usuario el producto o servicio en\\nel cual se ha integrado la IA, lo cual también puede identificarse con el operador final.\\nLa definición de productor tampoco es exacta, puesto que el productor puede ser quien\\ndesarrolla el sistema, pero también quien simplemente lo integra cuando un tercero lo ha\\ndiseñado. Asimismo, el productor no tiene por qué coincidir con el operador final, que\\nserá quien finalmente ponga a disposición del usuario el sistema de IA.\\nEl ejemplo ya mencionado sobre los vehículos autónomos puede ilustrar con claridad lo\\nanterior. El proveedor de datos es la persona que pondría a disposición los datos de\\nentrenamiento de la IA. El desarrollador, una vez recibidos dichos datos, es el encargado\\nde fijar los objetivos y añadir las restricciones al sistema de IA según proceda, llevar a\\ncabo el entrenamiento de la IA minimizando el margen de error y recalibrando el sistema\\npara reducir el nivel de incertidumbre. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 106, 'page': 39, '_split_overlap': [{'doc_id': '361bf5f8515fcd7a5cc3c00c8d34b0c9', 'range': (0, 270)}, {'doc_id': '24ed3da5f904f88c61679f41c67679e7', 'range': (800, 1084)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2a5c0b43c5f665bc96f04ec5e9f2bd23'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: El desarrollador, una vez recibidos dichos datos, es el encargado\\nde fijar los objetivos y añadir las restricciones al sistema de IA según proceda, llevar a\\ncabo el entrenamiento de la IA minimizando el margen de error y recalibrando el sistema\\npara reducir el nivel de incertidumbre. Una vez la IA funcione correctamente, podría\\nponerse a disposición del productor o fabricante del vehículo, quien ensambla las piezas\\ny realiza el montaje del automóvil, integrando el sistema de IA cuya función es la\\nconducción autónoma. Finalmente, este productor, que puede ser o no el operador final,\\nvenderá el vehículo ya terminado a los clientes finales.\\nPara que el régimen de responsabilidad funcione correctamente, es importante conocer\\nlas diferentes etapas del desarrollo de un sistema de IA y examinar cuáles son las tareas,\\nobligaciones y riesgos concretos que recaen sobre cada uno de los actores. Por tanto, una\\x0c38\\nrevisión de los sujetos definidos en este precepto ayudaría a una mejor comprensión de\\neste proceso completo y aportaría una mayor claridad a la hora de determinar la\\nresponsabilidad. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 107, 'page': 39, '_split_overlap': [{'doc_id': '2a5c0b43c5f665bc96f04ec5e9f2bd23', 'range': (0, 284)}, {'doc_id': '48210a06d579854bfedafaf99afde225', 'range': (897, 1098)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '24ed3da5f904f88c61679f41c67679e7'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Por tanto, una\\x0c38\\nrevisión de los sujetos definidos en este precepto ayudaría a una mejor comprensión de\\neste proceso completo y aportaría una mayor claridad a la hora de determinar la\\nresponsabilidad. De las definiciones mencionadas parece extraerse que el implementador\\nes quien oferta el producto o servicio con IA al usuario final, mientras que el productor\\nsería, en su caso, el desarrollador.\\nEn el artículo 4 se establece la responsabilidad objetiva del implementador, exonerando\\nal mismo de responsabilidad solamente en el caso de que exista fuerza mayor. Teniendo\\nen cuenta la naturaleza y funcionamiento de estos sistemas, debe concretarse qué se\\nentiende por fuerza mayor en el caso de la IA. En ocasiones es evidente que ciertos daños\\ncausados por el sistema no podían haberse previsto, como en el caso de que un vehículo\\nautónomo no reconozca un objeto o cuerpo cuya aparición sea nueva y del cual no se\\ntenían datos hasta el momento. Sin embargo, otros escenarios pueden dar lugar a mayor\\nconfusión, por ejemplo, un comportamiento imprevisto cometido dentro del margen de\\nerror del sistema que había superado los requisitos de seguridad y calidad establecidos.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 108, 'page': 39, '_split_overlap': [{'doc_id': '24ed3da5f904f88c61679f41c67679e7', 'range': (0, 201)}, {'doc_id': 'dc040c1d6d3b8d2d7f84f02a1a86ef1e', 'range': (948, 1174)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '48210a06d579854bfedafaf99afde225'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Sin embargo, otros escenarios pueden dar lugar a mayor\\nconfusión, por ejemplo, un comportamiento imprevisto cometido dentro del margen de\\nerror del sistema que había superado los requisitos de seguridad y calidad establecidos.\\nLa utilización de sistemas de IA implica que, dentro del funcionamiento normal, hay\\nciertas posibilidades de resultados erróneos o anormales. Debe determinarse si dichos\\nresultados serán considerados como fuerza mayor o, por el contrario, dan lugar a una\\nresponsabilidad objetiva incluso cuando el agente responsable realizó su trabajo con la\\nmáxima diligencia debida.\\nPor su parte, el artículo 8 prevé la responsabilidad subjetiva del implementador para los\\nsistemas de IA que no sean de alto riesgo. La responsabilidad objetiva para los sistemas\\nde alto riesgo y subjetiva para los sistemas de bajo riesgo, dándose en ambos casos la\\ninversión de la carga de la prueba, puede llegar a resultar excesivamente gravosa para el\\nimplementador. Es cierto que debe facilitarse para el usuario la posibilidad de reclamar\\nlos daños y defectos que hayan sido ocasionados y, en caso de que sea difícil probar el\\norigen de los mismos, la inversión de la carga de la prueba puede ser conveniente. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 109, 'page': 40, '_split_overlap': [{'doc_id': '48210a06d579854bfedafaf99afde225', 'range': (0, 226)}, {'doc_id': '8a2d53455b00004a1db8b47e3db92406', 'range': (967, 1211)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'dc040c1d6d3b8d2d7f84f02a1a86ef1e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Es cierto que debe facilitarse para el usuario la posibilidad de reclamar\\nlos daños y defectos que hayan sido ocasionados y, en caso de que sea difícil probar el\\norigen de los mismos, la inversión de la carga de la prueba puede ser conveniente. Sin\\nembargo, los fallos del sistema de IA pueden darse en diversas etapas en las que el\\nimplementador no ha tenido intervención alguna, por lo que debe regularse el régimen de\\nresponsabilidad teniendo en cuenta todas las posibilidades.\\nExistiendo inversión de la carga de la prueba, la responsabilidad subjetiva para sistemas\\nde IA tanto de alto riesgo como de bajo de riesgo no limita las posibilidades de accionar\\ncontra la persona afectada. Permite que dicha persona pueda dirigirse hacia el\\nimplementador y que, si este demuestra que el daño no le es imputable, se redirija la\\x0c39\\nreclamación contra el verdadero responsable. Esta solución facilita que el cliente final no\\nse vea perjudicado y que el implementador no soporte una carga excesiva por esa\\nresponsabilidad objetiva. De lo contrario, podría darse una situación de desincentivo por\\ntemor a las graves consecuencias en caso de producirse daños, disminuyendo así la\\nimplementación y utilización de sistemas de IA. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 110, 'page': 40, '_split_overlap': [{'doc_id': 'dc040c1d6d3b8d2d7f84f02a1a86ef1e', 'range': (0, 244)}, {'doc_id': 'e9165e10835190e576904726d6b42c14', 'range': (1027, 1220)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8a2d53455b00004a1db8b47e3db92406'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: De lo contrario, podría darse una situación de desincentivo por\\ntemor a las graves consecuencias en caso de producirse daños, disminuyendo así la\\nimplementación y utilización de sistemas de IA. Esto frustraría en parte el objetivo de\\npromover la adopción de la inteligencia artificial en la Unión Europea y conseguir una\\nposición fuerte en este campo en el panorama internacional.\\nEn la misma línea, el artículo 10 prevé como supuesto de negligencia concurrente\\núnicamente el caso en el que el daño se haya debido a las actuaciones del implementador\\ny la persona afectada en conjunto. Considerando el régimen de responsabilidad\\nestablecido para el implementador, una vía que ofrece una solución menos gravosa podría\\nser la previsión de negligencia concurrente con otros actores como el productor o el\\nproveedor de datos en el caso de que sus actuaciones hayan sido el origen del daño o\\nperjuicio. De esta forma se alivia la carga soportada por el implementador en los casos en\\nlos que su intervención, más allá de poner a disposición del usuario final el producto o\\nservicio, no ha causado el daño. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 111, 'page': 41, '_split_overlap': [{'doc_id': '8a2d53455b00004a1db8b47e3db92406', 'range': (0, 193)}, {'doc_id': '5a102c45475a056ab40e12be6fdb2a8e', 'range': (897, 1098)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e9165e10835190e576904726d6b42c14'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: De esta forma se alivia la carga soportada por el implementador en los casos en\\nlos que su intervención, más allá de poner a disposición del usuario final el producto o\\nservicio, no ha causado el daño. Esta opción permite que, sin desproteger al usuario, se\\ndirima la responsabilidad de una forma más justa desde el inicio del procedimiento de\\nreclamación, evitando la dilación que puede suponer un procedimiento posterior de\\nrepetición por parte del implementador contra el verdadero responsable.\\nEse procedimiento de repetición o recurso de indemnización se contiene en el artículo 12\\ndel Reglamento. Sin embargo, una revisión de dicha disposición podría resultar\\nbeneficiosa tanto para el implementador como para la persona afectada. La imposibilidad\\nde iniciar la reclamación de indemnización por parte del implementador antes de finalizar\\níntegramente el pago a la persona perjudicada presenta desventajas para ambas partes.\\nPor un lado, el implementador se ve privado de la acción de repetición hasta que finalice\\nun proceso en el que se le imputa responsabilidad objetiva sin opción de desviar incluso\\ncon prueba la responsabilidad hacia otra persona. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 112, 'page': 41, '_split_overlap': [{'doc_id': 'e9165e10835190e576904726d6b42c14', 'range': (0, 201)}, {'doc_id': 'f673728473cb5ac751264d656eafa62e', 'range': (930, 1158)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5a102c45475a056ab40e12be6fdb2a8e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Por un lado, el implementador se ve privado de la acción de repetición hasta que finalice\\nun proceso en el que se le imputa responsabilidad objetiva sin opción de desviar incluso\\ncon prueba la responsabilidad hacia otra persona. Debe tenerse en cuenta, a estos efectos,\\nque las indemnizaciones previstas en los artículos 5 y 6, a las que se hará mención más\\nadelante, alcanzan cuantías considerablemente elevadas. Ello implica que el\\nimplementador, sin importar lo diligente que haya sido su actuación, debe responder por\\ntoda indemnización que se le reclame sin posibilidad de reclamar al responsable hasta el\\nabono. Esto supone una carga excesiva y desproporcionada hacia esta figura, que incluso\\nen el supuesto de contar con un seguro o un fondo para este tipo de contingencias, podría\\x0c40\\ntener dificultades para hacer frente al pago de todas las indemnizaciones que le sean\\nreclamadas. Con esta observación no se trata de desviar o disminuir la responsabilidad\\ndel implementador, puesto que, en caso de ser responsable por el daño, respondería\\nabonando la indemnización correspondiente. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 113, 'page': 41, '_split_overlap': [{'doc_id': '5a102c45475a056ab40e12be6fdb2a8e', 'range': (0, 228)}, {'doc_id': 'c69319019ad0941a5bc7c865dc01bdec', 'range': (890, 1090)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f673728473cb5ac751264d656eafa62e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Con esta observación no se trata de desviar o disminuir la responsabilidad\\ndel implementador, puesto que, en caso de ser responsable por el daño, respondería\\nabonando la indemnización correspondiente. Simplemente se trata de facilitar el\\nprocedimiento de reclamación y dar la posibilidad de que el mismo sea más directo, de\\nforma que el implementador, si consigue probar que la responsabilidad recae sobre otra\\npersona, no deba responder por el daño y sea la persona responsable quien haga frente a\\nesa indemnización.\\nEsta solución no beneficia únicamente al implementador, que puede liberarse de la\\nresponsabilidad objetiva si consigue probar la responsabilidad de otro actor, sino que\\nfacilita el cobro de la indemnización por la persona afectada. Esto es así en tanto en cuanto\\nun cúmulo de reclamaciones hacia una única persona puede llegar a saturar o sobrecargar\\nel sistema de compensaciones que se haya previsto, de forma que no sólo se perjudique\\nla situación económica de un agente que quizá no sea responsable de daño alguno, sino\\nque además frustre el cobro de parte de las indemnizaciones solicitadas.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 114, 'page': 42, '_split_overlap': [{'doc_id': 'f673728473cb5ac751264d656eafa62e', 'range': (0, 200)}, {'doc_id': '7d546cb84b87b5719395e489f647626f', 'range': (750, 1113)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c69319019ad0941a5bc7c865dc01bdec'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Esto es así en tanto en cuanto\\nun cúmulo de reclamaciones hacia una única persona puede llegar a saturar o sobrecargar\\nel sistema de compensaciones que se haya previsto, de forma que no sólo se perjudique\\nla situación económica de un agente que quizá no sea responsable de daño alguno, sino\\nque además frustre el cobro de parte de las indemnizaciones solicitadas.\\nLa responsabilidad objetiva tiene sentido en el caso de que solo esa persona pueda ser\\nresponsable sobre la actuación del objeto o ser que causa el daño, como puede ocurrir con\\nun animal. Sin embargo, la IA debe ser tratada como cualquier otro objeto en cuyo\\nmontaje o desarrollo intervienen varias personas. El daño puede haber sido causado por\\ndiferentes agentes y se debe dar la posibilidad a la persona afectada de reclamar individual\\no conjuntamente contra todos ellos, así como facilitar que la persona que ha puesto a\\ndisposición del perjudicado el bien o servicio pueda probar la ausencia de\\nresponsabilidad.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 115, 'page': 42, '_split_overlap': [{'doc_id': 'c69319019ad0941a5bc7c865dc01bdec', 'range': (0, 363)}, {'doc_id': '4780a20428f5310faa5b80e8d8f4857f', 'range': (673, 980)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7d546cb84b87b5719395e489f647626f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: El daño puede haber sido causado por\\ndiferentes agentes y se debe dar la posibilidad a la persona afectada de reclamar individual\\no conjuntamente contra todos ellos, así como facilitar que la persona que ha puesto a\\ndisposición del perjudicado el bien o servicio pueda probar la ausencia de\\nresponsabilidad.\\nEn el caso de que el usuario final sea un consumidor, es razonable que se siga un régimen\\nde responsabilidad similar al establecido para productos defectuosos, de forma que se\\nreclame contra el productor o fabricante el daño causado por el producto o servicio\\ndefectuoso. Sin embargo, el artículo 7 f) la Directiva de Responsabilidad por Productos\\nDefectuosos59 prevé la posibilidad de que el productor no sea responsable cuando el\\ndefecto proceda de una parte integrante del producto cuya fabricación corresponda a un\\n59 CONSEJO DE LAS COMUNIDADES EUROPEAS, Directiva del Consejo, de 25 de julio de 1985,\\nrelativa a la aproximación de las disposiciones legales, reglamentarias y administrativas de los Estados\\nmiembros en materia de responsabilidad por los daños causados por productos defectuosos… cit.\\x0c41\\ntercero. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 116, 'page': 42, '_split_overlap': [{'doc_id': '7d546cb84b87b5719395e489f647626f', 'range': (0, 307)}, {'doc_id': '52c7e954a28d5cda07761eccaa33df83', 'range': (580, 1124)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4780a20428f5310faa5b80e8d8f4857f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Sin embargo, el artículo 7 f) la Directiva de Responsabilidad por Productos\\nDefectuosos59 prevé la posibilidad de que el productor no sea responsable cuando el\\ndefecto proceda de una parte integrante del producto cuya fabricación corresponda a un\\n59 CONSEJO DE LAS COMUNIDADES EUROPEAS, Directiva del Consejo, de 25 de julio de 1985,\\nrelativa a la aproximación de las disposiciones legales, reglamentarias y administrativas de los Estados\\nmiembros en materia de responsabilidad por los daños causados por productos defectuosos… cit.\\x0c41\\ntercero. Este sería el caso de un fabricante de vehículos autónomos que no ha diseñado el\\nsistema de IA, pero lo ha adquirido de un tercero para integrarlo en el automóvil.\\nExiste cierto temor a que la persona afectada, en el caso de existir el régimen de\\nresponsabilidad descrito, se encuentre en una posición de vulnerabilidad en la cual no\\npueda reclamar a ninguna persona. Sin embargo, el único supuesto en el que no habría\\nlugar a la indemnización es el de fuerza mayor. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 117, 'page': 42, '_split_overlap': [{'doc_id': '4780a20428f5310faa5b80e8d8f4857f', 'range': (0, 544)}, {'doc_id': '8ec8795c9b2b905ab69e131a9a0832a6', 'range': (709, 1011)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '52c7e954a28d5cda07761eccaa33df83'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Existe cierto temor a que la persona afectada, en el caso de existir el régimen de\\nresponsabilidad descrito, se encuentre en una posición de vulnerabilidad en la cual no\\npueda reclamar a ninguna persona. Sin embargo, el único supuesto en el que no habría\\nlugar a la indemnización es el de fuerza mayor. Existiendo la inversión de carga de la\\nprueba, en caso de que sea difícil o imposible observar el funcionamiento de la IA por\\nfalta de trasparencia y, por tanto, determinar dónde se originó el daño y quién responde\\npor el mismo, no habría exoneración o liberación de responsabilidad.\\nUna de las obligaciones establecidas para los desarrolladores de la IA debe ser la\\ntransparencia y explicabilidad del sistema, por lo que, en los casos en los que no se pueda\\ndeterminar el origen del daño y, por tanto, no se pueda probar que no hubo\\nresponsabilidad, esta podría recaer sobre el desarrollador e incluso el implementador. El\\ndesarrollador debe asegurarse de que el sistema de IA que diseña y vende es\\nsuficientemente transparente y explicable, por lo que si no se puede determinar el origen\\ndel daño es responsable por haber faltado a dicha obligación.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 118, 'page': 43, '_split_overlap': [{'doc_id': '52c7e954a28d5cda07761eccaa33df83', 'range': (0, 302)}, {'doc_id': 'd8a2a8a1e25a8975f70023015845d99d', 'range': (924, 1154)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8ec8795c9b2b905ab69e131a9a0832a6'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: El\\ndesarrollador debe asegurarse de que el sistema de IA que diseña y vende es\\nsuficientemente transparente y explicable, por lo que si no se puede determinar el origen\\ndel daño es responsable por haber faltado a dicha obligación.\\nLa tarea del implementador que no participa en el desarrollo de la IA es entregar el\\nproducto terminado o servicio al usuario. En el proceso de compra de la inteligencia\\nartificial e integración de la misma en el producto o servicio, tiene el deber de tratar de\\nverificar por todos los medios a su alcance que el sistema de IA cumple con los requisitos\\nlegalmente establecidos. Por tanto, la responsabilidad del implementador tendrá lugar\\ncuando incurra en dolo, culpa, falta de diligencia o negligencia al utilizar un sistema de\\nIA que no sea suficientemente robusto, transparente o explicable en su producto o\\nservicio. Sólo procedería la liberación de responsabilidad si, habiendo tomado todas las\\ncautelas posibles y empleando toda la diligencia debida, no pudo conocer que el sistema\\nde IA no cumplía con los estándares de calidad previstos.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 119, 'page': 43, '_split_overlap': [{'doc_id': '8ec8795c9b2b905ab69e131a9a0832a6', 'range': (0, 230)}, {'doc_id': '363dd9fbedceae93552015b665035785', 'range': (853, 1077)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd8a2a8a1e25a8975f70023015845d99d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Sólo procedería la liberación de responsabilidad si, habiendo tomado todas las\\ncautelas posibles y empleando toda la diligencia debida, no pudo conocer que el sistema\\nde IA no cumplía con los estándares de calidad previstos.\\nAsimismo, posiblemente un mayor desarrollo del artículo 11 sobre la responsabilidad\\nsolidaria y conjunta facilitaría la tarea de determinar la responsabilidad entre los distintos\\nactores desde un principio. Solamente se recogen dos supuestos: la responsabilidad de\\nvarios implementadores o la responsabilidad del implementador y el productor. Dado que\\nampliar la definición de implementador a otras figuras supondría una mayor\\nincertidumbre a la hora de la aplicación práctica del Reglamento, posiblemente la opción\\x0c42\\nmás factible sea añadir otros supuestos en los que existan varios responsables de forma\\nsolidaria y conjunta, como los expuestos previamente.\\nEn el artículo 5 y 6 se establece el importe y el alcance de la indemnización que procede\\npor los daños y perjuicios causados por sistemas de IA. De nuevo, esta disposición hace\\núnicamente referencia al supuesto del implementador como responsable, no haciendo\\nmención alguna acerca del proveedor de los datos, el desarrollador o el productor o\\nfabricante. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 120, 'page': 43, '_split_overlap': [{'doc_id': 'd8a2a8a1e25a8975f70023015845d99d', 'range': (0, 224)}, {'doc_id': '4a313ce24f731c44f16374b1424259fc', 'range': (1032, 1241)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '363dd9fbedceae93552015b665035785'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: De nuevo, esta disposición hace\\núnicamente referencia al supuesto del implementador como responsable, no haciendo\\nmención alguna acerca del proveedor de los datos, el desarrollador o el productor o\\nfabricante. Dado que las cuantías tanto por daños materiales como personales son\\nelevadas, debe revisarse lo señalado en cuanto al régimen de responsabilidad del\\nimplementador. Por otra parte, la concreción de la cuantía indemnizatoria parece quedar\\na discrecionalidad del juez o tribunal que conozca del procedimiento. Teniendo en cuenta\\nel amplio rango de la indemnización, y para evitar que existan resoluciones\\ncontradictorias o muy diferentes, podría ser conveniente establecer ciertos criterios de\\nmoderación de la cuantía compensatoria. Esto no supone una limitación de la\\ndiscrecionalidad del juez, sino una orientación para procurar que la indemnización se\\ndetermine siguiendo unos criterios uniformes en todos los Estados miembros.\\nFinalmente, el plazo de prescripción especial recogido en el artículo 7 es de diez o treinta\\naños, en función del supuesto. Este término debe ponerse en contexto con los plazos de\\nprescripción generalmente establecidos para delitos que pueden causar daños similares.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 121, 'page': 44, '_split_overlap': [{'doc_id': '363dd9fbedceae93552015b665035785', 'range': (0, 209)}, {'doc_id': '72e2381ee15688c17738e468d41bc13b', 'range': (1064, 1206)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4a313ce24f731c44f16374b1424259fc'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Este término debe ponerse en contexto con los plazos de\\nprescripción generalmente establecidos para delitos que pueden causar daños similares.\\nLa prescripción para delitos como el homicidio o las lesiones se regula de forma\\nconsiderablemente distinta en los países europeos, por lo que este plazo de prescripción\\nespecial podría llegar a resultar controvertido si carece de una justificación.\\nDice la Exposición de Motivos del Reglamento que «cualquier marco en materia de\\nresponsabilidad civil orientado al futuro debe aspirar a lograr un equilibrio entre la\\nprotección eficaz de las potenciales víctimas de daños y, al mismo tiempo, ofrecer un\\nmargen de maniobra suficiente para posibilitar el desarrollo de nuevas tecnologías,\\nproductos o servicios». Sin embargo, el estricto régimen de responsabilidad que se hace\\nrecaer en exclusiva sobre el implementador puede suponer un gran desincentivo para las\\nempresas dispuestas a apostar por la adopción de sistemas de IA. El objetivo de protección\\nde las personas afectadas puede perseguirse desde una óptica más amplia, donde se de\\ncabida a otros actores potencialmente responsables. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 122, 'page': 44, '_split_overlap': [{'doc_id': '4a313ce24f731c44f16374b1424259fc', 'range': (0, 142)}, {'doc_id': '4273530edbfc20b6e66a70fa8866d37a', 'range': (970, 1132)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '72e2381ee15688c17738e468d41bc13b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: El objetivo de protección\\nde las personas afectadas puede perseguirse desde una óptica más amplia, donde se de\\ncabida a otros actores potencialmente responsables. Pueden ofrecerse las mismas o\\nincluso más posibilidades de reclamación al usuario perjudicado haciendo la situación del\\nimplementador menos gravosa, para los casos en los que la responsabilidad no recaiga\\nsobre su actuación, sino sobre otros sujetos.\\x0c43\\n5. Conclusión\\nLa adaptación de la legislación vigente y la elaboración de nueva normativa sobre\\ninteligencia artificial es un proceso complejo que requiere de un conocimiento de la\\nmateria en profundidad y un diseño de medidas de previsión, control, corrección y\\nresponsabilidad adecuadas a la naturaleza y funcionamiento de esta tecnología. Dada la\\ndificultad que puede entrañar anticipar los riesgos de la IA en todos sus ámbitos de\\naplicación, las recomendaciones y sugerencias planteadas desde diferentes puntos de vista\\ny disciplinas científicas es posiblemente la vía que permite una mejor comprensión de los\\nproblemas existentes.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 123, 'page': 44, '_split_overlap': [{'doc_id': '72e2381ee15688c17738e468d41bc13b', 'range': (0, 162)}, {'doc_id': 'c6752291fe48d604b029a1698e59be19', 'range': (759, 1053)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4273530edbfc20b6e66a70fa8866d37a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Dada la\\ndificultad que puede entrañar anticipar los riesgos de la IA en todos sus ámbitos de\\naplicación, las recomendaciones y sugerencias planteadas desde diferentes puntos de vista\\ny disciplinas científicas es posiblemente la vía que permite una mejor comprensión de los\\nproblemas existentes.\\nLa Comisión Europea ha comenzado un gran trabajo en el camino hacia la regulación de\\nla IA, optando por la adaptación de la normativa existente en la mayor parte de los\\námbitos, pero dando paso a la creación de un nuevo Reglamento que recoja el régimen de\\nResponsabilidad por los daños causados por la inteligencia artificial. Si bien esta\\nperspectiva puede ser acertada, algunos de los aspectos que responden a estos cambios o\\nnovedades pueden resultar controvertidos, por lo que conviene que se lleve a cabo una\\nrevisión o matización de los mismos.\\nSin perjuicio de las recomendaciones y medidas propuestas, el planteamiento general de\\nla responsabilidad en materia de IA es especialmente relevante. Encontrar el equilibrio\\nentre la seguridad del marco de responsabilidad y la protección del desarrollo tecnológico\\ny la innovación es un doble objetivo fundamental para la Unión Europea. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 124, 'page': 45, '_split_overlap': [{'doc_id': '4273530edbfc20b6e66a70fa8866d37a', 'range': (0, 294)}, {'doc_id': 'e8b184a1a6f46adf0f7b64932de6447e', 'range': (997, 1183)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c6752291fe48d604b029a1698e59be19'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Encontrar el equilibrio\\nentre la seguridad del marco de responsabilidad y la protección del desarrollo tecnológico\\ny la innovación es un doble objetivo fundamental para la Unión Europea. En este sentido,\\ndebe ponerse especial cuidado en la determinación de los posibles sujetos responsables,\\nel carácter de la responsabilidad que se pretende atribuir y los supuestos en los que la\\nmisma procede. Un marco de responsabilidad demasiado amplio o restringido puede\\nocasionar que uno de los objetivos mencionados pueda verse perjudicado, con el impacto\\nnegativo que ello conlleva para la protección de los usuarios de la IA, en el caso del\\nprimero, o para el papel de la UE como impulsor de la adopción de esta tecnología, si se\\natiende al segundo.\\nEsta propuesta no es una guía de la futura regulación de la IA, pero sí ha sido elaborada\\ncon el objetivo de apoyar ese esfuerzo legislativo. El debate es el motor del avance, por\\nlo que las cuestiones que en este documento se tratan deben ser interpretadas como puntos\\ncontrovertidos y aportaciones constructivas. La inteligencia artificial y, por extensión, su\\nregulación, nos afecta a todos. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 125, 'page': 45, '_split_overlap': [{'doc_id': 'c6752291fe48d604b029a1698e59be19', 'range': (0, 186)}, {'doc_id': 'a38664b06b3a789f91c90f359a61e091', 'range': (886, 1138)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e8b184a1a6f46adf0f7b64932de6447e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: El debate es el motor del avance, por\\nlo que las cuestiones que en este documento se tratan deben ser interpretadas como puntos\\ncontrovertidos y aportaciones constructivas. La inteligencia artificial y, por extensión, su\\nregulación, nos afecta a todos. Es momento de colaborar para intentar que, teniendo en\\x0c44\\ncuenta todas las contribuciones posibles, la normativa de IA permita cumplir ese doble\\nobjetivo de la Unión Europea: proporcionar seguridad, estimulando el progreso.\\n6. Bibliografía\\nANTORÁN CABISCOL, J., Understanding Uncertainty in Bayesian Neural Networks,\\nDepartamento de Ingeniería de la Universidad de Cambridge, 2019, Pro manuscript, pp.\\n1-94.\\nAPPLE, «Apple Card launches today for all US customers», Apple Newsroom, 2019,\\ndisponible en <https://www.apple.com/newsroom/2019/08/apple-card-launches-today-\\nfor-all-us-customers/>. Fecha de consulta: 6 de abril de 2020.\\nBEKEY, G.A., Autonomous Robots: From Biological Inspiration to Implementation and\\nControl, 2017, disponible en <https://mitpress.mit.edu/books/autonomous-robots>.\\nFecha de consulta: 17 de mayo de 2020.\\nCOECKELBERGH, M., «Ethics of artificial intelligence: Some ethical issues and\\nregulatory challenges», Technology and Regulation, 2019, pp. 31-34. DOI:\\n10.26116/techreg.2019.003.\\nCOLE, G.W. y WILLIAMSON, S.A., Avoiding Resentment Via Monotonic Fairness,\\nArXiv preprint, arXiv:1909.01251v1, 2019, pp. 1-16.\\nDOSHI-VELEZ, F., KORTZ, M., BUDISH, R., BAVITZ, C., GERSHMAN, S.,\\nO’BRIEN, D., SCHIEBER, S., WALDO, J., WEINBERGER, D. y WOOD. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 126, 'page': 45, '_split_overlap': [{'doc_id': 'e8b184a1a6f46adf0f7b64932de6447e', 'range': (0, 252)}, {'doc_id': '10ba2cb476ad4fd3beb2de14ab30c123', 'range': (1391, 1517)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a38664b06b3a789f91c90f359a61e091'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: DOSHI-VELEZ, F., KORTZ, M., BUDISH, R., BAVITZ, C., GERSHMAN, S.,\\nO’BRIEN, D., SCHIEBER, S., WALDO, J., WEINBERGER, D. y WOOD. A.,\\nAccountability of AI under the law: The role of explanation. ArXiv preprint,\\narXiv:1711.01134, 2017, pp. 1-15.\\nELDRED, C., ZYSMAN, J. y NITZBERG, M., AI and Domain Knowledge: Implications\\nof the Limits of Statistical Inference, BRIE / WITS Technology Briefing, Berkeley, 2019,\\npp. 1-11, disponible en <https://ssrn.com/abstract=3479479>. Fecha de consulta: 18 de\\nmayo de 2020.\\nHRISTOV, K., Artificial Intelligence and the Copyright Dilemma. The Journal of the\\nFranklin Pierce Center for Intellectual Property, Vol. 57, 3 (438), disponible en\\n<https://law.unh.edu/about/unh-law-publications/idea-journal-franklin-pierce-center-\\nintellectual-property>. Fecha de consulta: 15 de mayo de 2020.\\x0c45\\nKLEINBERG, J., LUDWIG, J., MULLAINATHAN, S. y SUNSTEIN, C.S.,\\n«Discrimination in the Age of Algorithms», Journal of Legal Analysis, Vol. 10, 2018, pp.\\n113-174. DOI: 10.1093/jla/laz001.\\nKUSNE, M., LOFTUS, J., RUSSELL, C. y SILVA, R., Counterfactual Fairness, ArXiv\\npreprint, arXiv:1703.06856v3, 8 de marzo de 2018, pp. 1-18.\\nMARTIN, N., Uber Charges More If They Think You're Willing To Pay More, Forbes,\\n2019, disponible en <https://www.forbes.com/sites/nicolemartin1/2019/03/30/uber-\\ncharges-more-if-they-think-youre-willing-to-pay-more/#1825e1747365>. Fecha de\\nconsulta: 21 de mayo de 2020.\\nMAYSON, S.G., «Bias in, Bias out», Yale Law Journal 128, 2019, pp. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 127, 'page': 46, '_split_overlap': [{'doc_id': 'a38664b06b3a789f91c90f359a61e091', 'range': (0, 126)}, {'doc_id': '9257705797436c39a70d22908a913d0c', 'range': (1378, 1483)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '10ba2cb476ad4fd3beb2de14ab30c123'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: Fecha de\\nconsulta: 21 de mayo de 2020.\\nMAYSON, S.G., «Bias in, Bias out», Yale Law Journal 128, 2019, pp. 1-84, ¿disponible\\nen <https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3257004>. Fecha de consulta:\\n3 de abril de 2020.\\nMITROU, L., Data Protection, Artificial Intelligence and Cognitive Services is the\\nGeneral Data Protection Regulation (GDPR) “Artificial Intelligence-Proof”?, 2019, pp.\\n1-90, disponible en\\n<https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE2PdYu>. Fecha de\\nconsulta: 19 de mayo de 2020.\\nNEDLUND, E., «Apple Card is accused of gender bias. Here's how that can happen»,\\nCNN Business, 2019, disponible en <https://edition.cnn.com/2019/11/12/business/apple-\\ncard-gender-bias/index.html>. Fecha de consulta: 6 de abril de 2020.\\nNELSON, G.S., «Bias in artificial intelligence», North Carolina Medical Journal, Vol.\\n80(4), 2019, pp. 220-222. DOI: 10.18043/ncm.80.4.220.\\nNEWCOMER, E., Uber Yield Management: Uber Starts Charging What It Thinks You’re\\nWilling to Pay, Bloomberg, 2017, disponible en\\n<https://www.bloomberg.com/news/articles/2017-05-19/uber-s-future-may-rely-on-\\npredicting-how-much-you-re-willing-to-pay>. Fecha de consulta: 20 de mayo de 2020.\\nPERC, M., OZER, M. y HOJNIK, J., «Social and juristic challenges of artificial\\nintelligence», Palgrave Communications, 5:61, 2019, pp. 1-7. DOI: 10.1057/s41599-019-\\n0278-x.\\nTAN, Z., YEOM, S., FREDRIKSON, M. y TALWALKAR, A., Learning Fair\\nRepresentations for Kernel Models,ArXiv preprint, arXiv:1906.11813, 2019, pp. 1-15.\\x0c46\\nVAN GERVEN, M. y BOHTE. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 128, 'page': 47, '_split_overlap': [{'doc_id': '10ba2cb476ad4fd3beb2de14ab30c123', 'range': (0, 105)}, {'doc_id': '732d3e8693eb78e32fd56d6b257fd7b5', 'range': (1364, 1539)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9257705797436c39a70d22908a913d0c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: TAN, Z., YEOM, S., FREDRIKSON, M. y TALWALKAR, A., Learning Fair\\nRepresentations for Kernel Models,ArXiv preprint, arXiv:1906.11813, 2019, pp. 1-15.\\x0c46\\nVAN GERVEN, M. y BOHTE. S., Artificial Neural Networks as Models of Neural\\nInformation Processing, Frontiers in Computational Neuroscience 11:114, 2017, pp. 1-2.\\nDOI: 10.3389/fncom.2017.00114.\\nVIGDOR, N., «Apple Card Investigated After Gender Discrimination Complaints», The\\nNew York Times Business, 2019, disponible en\\n<https://www.nytimes.com/2019/11/10/business/Apple-credit-card-investigation.html>.\\nFecha de consulta: 6 de abril de 2020.\\nYEOM, S., DATTA, A. y FREDRIKSON, M., «Hunting for discriminatory proxies in\\nlinear regression models», Advances in Neural Information Processing Systems, 2018,\\npp. 4568-4578, disponible en <http://papers.nips.cc/paper/7708-hunting-for-\\ndiscriminatory-proxies-in-linear-regression-models.pdf>. Fecha de consulta: 14 de abril\\nde 2020.\\n7. Documentación\\nCarta de los Derechos Fundamentales de la Unión Europea, 2000, C 364/01, disponible\\nen <https://www.europarl.europa.eu/charter/pdf/text_es.pdf>. Fecha de consulta: 18 de\\nmayo de 2020.\\nCOMISIÓN DE ASUNTOS JURÍDICOS DEL PARLAMENTO EUROPEO, Proyecto\\nde Informe con recomendaciones destinadas a la Comisión sobre un régimen de\\nresponsabilidad civil en materia de inteligencia artificial (2020/2014 (INL)), disponible\\nen <https://www.europarl.europa.eu/doceo/document/JURI-PR-650556_ES.pdf>.\\nCOMISIÓN EUROPEA, White Paper on Artificial Intelligence: a European approach to\\nexcellence and trust, 19 de febrero de 2020, disponible en\\n<https://ec.europa.eu/info/publications/white-paper-artificial-intelligence-european-\\napproach-excellence-and-trust_en>. Fecha de consulta: 21 de marzo de 2020.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 129, 'page': 47, '_split_overlap': [{'doc_id': '9257705797436c39a70d22908a913d0c', 'range': (0, 175)}, {'doc_id': 'b1501bd2b6c7320138e9823a85c3aacf', 'range': (1433, 1733)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '732d3e8693eb78e32fd56d6b257fd7b5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: COMISIÓN EUROPEA, White Paper on Artificial Intelligence: a European approach to\\nexcellence and trust, 19 de febrero de 2020, disponible en\\n<https://ec.europa.eu/info/publications/white-paper-artificial-intelligence-european-\\napproach-excellence-and-trust_en>. Fecha de consulta: 21 de marzo de 2020.\\nCONSEJO DE LAS COMUNIDADES EUROPEAS, Directiva del Consejo, de 25 de\\njulio de 1985, relativa a la aproximación de las disposiciones legales, reglamentarias y\\nadministrativas de los Estados miembros en materia de responsabilidad por los daños\\ncausados por productos defectuosos (85/374/CEE), Diario Oficial de las Comunidades\\nEuropeas, 13(19) disponible en <https://eur-lex.europa.eu/legal-\\ncontent/ES/TXT/PDF/?uri=CELEX:31985L0374&from=EN>.\\nConvención de Ginebra, de 19 de septiembre de 1949, sobre la circulación vial.\\x0c47\\nConvención de Viena, de 8 de noviembre de 1968, sobre la circulación vial.\\nCopyright, Designs and Patents Act, Reino Unido, 1988, disponible en\\n<http://www.legislation.gov.uk/ukpga/1988/48/part/I/chapter/I/crossheading/authorship-\\nand-ownership-of-copyright>.\\nCopyright and Related Rights Act, Irlanda, 2000, disponible en\\n<http://www.irishstatutebook.ie/eli/2000/act/28/enacted/en/print>.\\nGRUPO DE EXPERTOS DE ALTO NIVEL EN IA DE LA COMISIÓN EUROPEA (a),\\nA Definition Of AI: Main Capabilities And Disciplines, 8 de abril de 2019, disponible en\\n<https://ec.europa.eu/digital-single-market/en/news/definition-artificial-intelligence-\\nmain-capabilities-and-scientific-disciplines>. Fecha de consulta: 22 de marzo de 2019.\\nGRUPO DE EXPERTOS DE ALTO NIVEL EN IA DE LA COMISIÓN EUROPEA (b),\\nEthics Guidelines for Trustworthy AI, 8 de abril de 2019, disponible en\\n<https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai>.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 130, 'page': 48, '_split_overlap': [{'doc_id': '732d3e8693eb78e32fd56d6b257fd7b5', 'range': (0, 300)}, {'doc_id': '85df3e904cfa92c41b9dbeb2d2644f8d', 'range': (1544, 1768)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b1501bd2b6c7320138e9823a85c3aacf'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 28-05-2020 17:51, language: Spanish, \\n\\nPassage: GRUPO DE EXPERTOS DE ALTO NIVEL EN IA DE LA COMISIÓN EUROPEA (b),\\nEthics Guidelines for Trustworthy AI, 8 de abril de 2019, disponible en\\n<https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai>.\\nFecha de consulta: 17 de noviembre de 2019.\\nGRUPO EXPERTO EN RESPONSABILIDAD Y NUEVAS TECNOLOGÍAS DE LA\\nCOMISIÓN EUROPEA, Liability for Artificial Intelligence and other emerging digital\\ntechnologies, 2019, pp. 1-70. DOI:10.2838/573689.\\nReglamento (UE) 2016/679 del Parlamento Europeo y del Consejo de 27 de abril de 2016\\nrelativo a la protección de las personas físicas en lo que respecta al tratamiento de datos\\npersonales y a la libre circulación de estos datos y por el que se deroga la Directiva\\n95/46/CE.\\nPARLAMENTO EUROPEO y CONSEJO DE LA UNIÓN EUROPEA, Directiva del\\nParlamento Europeo y del Consejo, de 17 de mayo de 2006, relativa a la maquinaria\\n(2006/42/EC), Diario Oficial de la Unión Europea, L157/24, disponible en <https://eur-\\nlex.europa.eu/LexUriServ/LexUriServ.do?uri=OJ:L:2006:157:0024:0086:EN:PDF>.\\nPARLAMENTO EUROPEO y CONSEJO DE LA UNIÓN EUROPEA, Directiva del\\nParlamento Europeo y del Consejo, de 3 de diciembre de 2001, relativa a la seguridad\\ngeneral de los productos (2001/95/EC), Diario Oficial de la Unión Europea, L11/4,\\ndisponible en <https://eur-lex.europa.eu/legal-\\ncontent/ES/TXT/PDF/?uri=CELEX:32001L0095&from=EN>.', 'content_type': 'text', 'score': None, 'meta': {'name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '28-05-2020 17:51', 'language': 'Spanish', 'document_reference': 'F528947', 'document_name': 'F528947-Beatriz_Alegre_Villarroya_Propuesta_Libro_Blanco_UE.pdf', '_split_id': 131, 'page': 49, '_split_overlap': [{'doc_id': 'b1501bd2b6c7320138e9823a85c3aacf', 'range': (0, 224)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '85df3e904cfa92c41b9dbeb2d2644f8d'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Asssociation Française Transhumaniste - Technoprog, stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 14-06-2020 19:47, language: French, \\n\\nPassage: Réponse de l'association française transhumaniste - Technoprog\\nConsultation on the White Paper on Artificial Intelligence - A European Approach\\nL'Union européenne est la région du monde avec le plus de pratiques démocratiques. C'est\\naussi probablement la région du monde avec le plus de financements publics de la\\nrecherche dans le domaine de l'intelligence artificielle.\\nCe qui manque principalement dans le document qu'il est demandé de commenter, c'est la\\ndéfinition des priorités relatives à l'intelligence artificielle.\\nPour l'association française transhumaniste-Technoprog, ces priorités doivent s'inscrire dans\\nune optique mondiale. L'objectif n'est pas de favoriser l'Union européenne, mais de\\npermettre à l'Union européenne d'être utile à tous les citoyens du monde.\\nPour cela, l'I.A. doit servir à :\\nDévelopper des recherches et des tâches dans tous les domaines de la santé humaine.\\nAujourd'hui, vu la pandémie que nous traversions, nous pensons bien sûr à la lutte contre\\nles maladies infectieuses. Mais l'I.A. doit permettre de développer tout ce qui permet une\\nlongévité accrue des hommes et des femmes, donc lutter contre toutes les maladies liées au\\nvieillissement (la Covid-19 étant d'ailleurs elle-même une maladie liée au vieillissement).\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F530365-R_ponse_AFT__Technoprog_Consultation_on_the_White_Paper_on_Artificial_Intelligence_-_A_European_Approach.pdf', 'stakeholder_name': 'Asssociation Française Transhumaniste - Technoprog', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:47', 'language': 'French', 'document_reference': 'F530365', 'document_name': 'F530365-R_ponse_AFT__Technoprog_Consultation_on_the_White_Paper_on_Artificial_Intelligence_-_A_European_Approach.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': 'a5c44089da7d0e4fe763fe877b59352e', 'range': (1024, 1258)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b03d54bd73a8fa5ad6e4d1adc2f00cc9'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Asssociation Française Transhumaniste - Technoprog, stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 14-06-2020 19:47, language: French, \\n\\nPassage: doit permettre de développer tout ce qui permet une\\nlongévité accrue des hommes et des femmes, donc lutter contre toutes les maladies liées au\\nvieillissement (la Covid-19 étant d'ailleurs elle-même une maladie liée au vieillissement).\\nDévelopper des recherches et des tâches dans tous les domaines du développement\\ndurable: énergies renouvelables, recyclages et réutilisations.\\nEnfin, l'I.A. doit servir également aux recherches et aux tâches utiles pour diminuer les\\nrisques dans tous les domaines.\\nAttention, l'I.A. en elle-même et plus particulièrement l'intelligence artificielle générale, dans\\nun futur indéterminé, mais pas nécessairement lointain, pourrait être elle-même un facteur\\nde risque auquel il faudra être attentif. Etre attentif ne signifie pas nécessairement freiner les\\ndéveloppements. Cela peut signifier accélérer les recherches les plus bénéficiaires à la\\ncollectivité et s'assurer que les financements (publics et privés) s'orientent dans ces\\ndirections.\\nRef. Ares(2020)3359934 - 26/06/2020\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F530365-R_ponse_AFT__Technoprog_Consultation_on_the_White_Paper_on_Artificial_Intelligence_-_A_European_Approach.pdf', 'stakeholder_name': 'Asssociation Française Transhumaniste - Technoprog', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:47', 'language': 'French', 'document_reference': 'F530365', 'document_name': 'F530365-R_ponse_AFT__Technoprog_Consultation_on_the_White_Paper_on_Artificial_Intelligence_-_A_European_Approach.pdf', '_split_id': 1, 'page': 1, '_split_overlap': [{'doc_id': 'b03d54bd73a8fa5ad6e4d1adc2f00cc9', 'range': (0, 234)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a5c44089da7d0e4fe763fe877b59352e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: CEC European Managers, stakeholder_type: Trade Union, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 13-06-2020 19:47, language: English, \\n\\nPassage: Dear Madam, dear Sir,\\nWe would like to take this occasion to bring to your attention two documents for download.\\nWe unfortunately have not been able to include them in the on-line consultation, due to the\\nlimited upload space.\\n1. CEC European Managers : Guidelines for Managing the Digital Transformation\\nhttps://www.cec-managers.org/wp-content/uploads/2020/02/CEC-Guidelines-Managing-the-\\nDigital-Transformation.pdf\\n2. CFE-CGC Charte Lab RH\\nhttps://fr.calameo.com/read/003664566071549f23d87\\nRef. Ares(2020)3359988 - 26/06/2020', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530249-AI_letter.pdf', 'stakeholder_name': 'CEC European Managers', 'stakeholder_type': 'Trade Union', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '13-06-2020 19:47', 'language': 'English', 'document_reference': 'F530249', 'document_name': 'F530249-AI_letter.pdf', '_split_id': 0, 'page': 1, '_split_overlap': []}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8b2807fbbd77d59bdf1a3960d5153a0'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Numereco, Ireland, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Ireland, document_date: 14-06-2020 23:35, language: English, \\n\\nPassage: Numereco.eu AI Submission to the EU consultation\\nNumereco.eu Page 1\\nSubmission to the EU consultation\\n14/June/2020\\nWe do appreciate the opportunity to share our view in your consultation.\\nWe would like to submit the following results of our numerical model.\\nWe assumed that branches are going to be using more advanced AI applications in\\nindustries such as Financial services, Health care and medical, IT, Business services,\\nTelecommunications.\\nWe also assumed that AI applications cause a significant improvement in productivity and\\nthat the increasing profit will be shared in-between stakeholders including industries on the\\ndemand side.\\nWe also assume a competitive market.\\nNumerical modelling was done based on the data of Ireland; the model obviously works with\\nany other country.\\nParts of the results regard to\\n- industries without the use of AI (in the model),\\n- industries with the use of AI;\\n- and the government's partnership with the private sector.\\n1. Industries without the use of AI\\n(1) In the short-term industries benefit even without the use of AI (while other industries use\\nAI).\\nReceiving benefits has preconditions.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F530415-Numereco_submission_1.pdf', 'stakeholder_name': 'Numereco, Ireland', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Ireland', 'stakeholder_scope': nan, 'document_date': '14-06-2020 23:35', 'language': 'English', 'document_reference': 'F530415', 'document_name': 'F530415-Numereco_submission_1.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': '92f9fb5dfb777cae19318e8a1e345eb1', 'range': (965, 1136)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b42f8ff0b6a712194cf4f8a4578243cc'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Numereco, Ireland, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Ireland, document_date: 14-06-2020 23:35, language: English, \\n\\nPassage: Industries without the use of AI\\n(1) In the short-term industries benefit even without the use of AI (while other industries use\\nAI).\\nReceiving benefits has preconditions.\\nBenefits can be realized if\\ni) industries that are applying AI lower their prices due to the productivity\\nincreasement;\\nii) the buyer industries are price sensitive (negative price elasticity;\\nRef. Ares(2020)3359940 - 26/06/2020\\x0cNumereco.eu AI Submission to the EU consultation\\nNumereco.eu Page 2\\niii) there are no  more inputs from every other supplier (including\\nindustries that are not applying AI) in the short- term (i.e. there is no change in the\\ntechnology).\\nOn the long-term these companies may see a decrease in the amount of orders if they don't\\nincrease their productivity (e.g. via the use of AI).\\n(3) Industries without the use of AI can realize an increase in both in the return on capital\\nand wages, without any structural changes, the increase happens on the 'business as usual'\\nmanner.\\n2. Industries with the use of AI\\n(4) The industries with the use of AI will realise their benefits in cost reduction. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F530415-Numereco_submission_1.pdf', 'stakeholder_name': 'Numereco, Ireland', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Ireland', 'stakeholder_scope': nan, 'document_date': '14-06-2020 23:35', 'language': 'English', 'document_reference': 'F530415', 'document_name': 'F530415-Numereco_submission_1.pdf', '_split_id': 1, 'page': 1, '_split_overlap': [{'doc_id': 'b42f8ff0b6a712194cf4f8a4578243cc', 'range': (0, 171)}, {'doc_id': '89e9cd69728cbd13e8a8dd05d5b064e0', 'range': (978, 1092)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '92f9fb5dfb777cae19318e8a1e345eb1'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Numereco, Ireland, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Ireland, document_date: 14-06-2020 23:35, language: English, \\n\\nPassage: Industries with the use of AI\\n(4) The industries with the use of AI will realise their benefits in cost reduction. The\\nincreased productivity makes it possible to maintain their revenue while reducing the unit\\nprice and increasing wages, however the application of AI results in staff reduction. (NB: Of\\ncourse, it is possible to assume unchanged staff numbers, in this case, the level of orders\\nmust increase correspondingly. These two cases are identical, we chose the first option in\\nour numerical model for the comparison).\\n(5) The industries with the use of AI see a significant increase in profit due to the application\\nof AI. The increase rate depends on a number of factors (such as material costs, labour cost,\\nallocation of productivity enhanc use of AI results in a positive long-term effect. Enhances short-term profit makes it a\\npossibility for a vertical integration.\\x0cNumereco.eu AI Submission to the EU consultation\\nNumereco.eu Page 3\\n3. Partnership with the private sector\\n(7) As the application of AI is a world-wide trend in many areas, it is creating challenges to\\nEU countries' businesses and governments.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F530415-Numereco_submission_1.pdf', 'stakeholder_name': 'Numereco, Ireland', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Ireland', 'stakeholder_scope': nan, 'document_date': '14-06-2020 23:35', 'language': 'English', 'document_reference': 'F530415', 'document_name': 'F530415-Numereco_submission_1.pdf', '_split_id': 2, 'page': 2, '_split_overlap': [{'doc_id': '92f9fb5dfb777cae19318e8a1e345eb1', 'range': (0, 114)}, {'doc_id': 'cd056423424e2872d869ad84662fb0c8', 'range': (953, 1125)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '89e9cd69728cbd13e8a8dd05d5b064e0'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Numereco, Ireland, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Ireland, document_date: 14-06-2020 23:35, language: English, \\n\\nPassage: Partnership with the private sector\\n(7) As the application of AI is a world-wide trend in many areas, it is creating challenges to\\nEU countries' businesses and governments.\\nTherefor the application of AI is unavoidable, but it does make a change in the labour\\nmarket. It causes structural changes within industries and between industries.\\nOur model reports it on a general level but it is clear that there will be jobs that are not going\\nto be needed any more, and others that are going to require an extended knowledge in a\\ncertain field.\\n(8) It means educational and training challenges to both the government and private sectors.\\nFurthermore, mobility on the labour market is necessary both in geographical terms and in-\\nbetween professions. Co-operation in between the government and private sectors may\\nreduce the overall cost.\\n(9) Since there will be industry branches and worker groups that are on the losing side of\\nthese changes (and since they are also tax-payers) the government's actions shall focus on\\nsupporting these groups on a sustainable matter: re-trainings, providing career possibilities\\n(even in a co-operation in between government and businesses).\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F530415-Numereco_submission_1.pdf', 'stakeholder_name': 'Numereco, Ireland', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Ireland', 'stakeholder_scope': nan, 'document_date': '14-06-2020 23:35', 'language': 'English', 'document_reference': 'F530415', 'document_name': 'F530415-Numereco_submission_1.pdf', '_split_id': 3, 'page': 3, '_split_overlap': [{'doc_id': '89e9cd69728cbd13e8a8dd05d5b064e0', 'range': (0, 172)}, {'doc_id': 'f269a08cffe93c2b630758f337c191ff', 'range': (833, 1171)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'cd056423424e2872d869ad84662fb0c8'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Numereco, Ireland, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Ireland, document_date: 14-06-2020 23:35, language: English, \\n\\nPassage: (9) Since there will be industry branches and worker groups that are on the losing side of\\nthese changes (and since they are also tax-payers) the government's actions shall focus on\\nsupporting these groups on a sustainable matter: re-trainings, providing career possibilities\\n(even in a co-operation in between government and businesses).\\nIt is a strong requirement that these programmes must be self-sustained solutions in\\nfinancial terms.\\nOnce again, we do appreciate the opportunity to share our view in your consultation.\\nTibor Toth\\nnumereco.eu\\nIreland\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F530415-Numereco_submission_1.pdf', 'stakeholder_name': 'Numereco, Ireland', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Ireland', 'stakeholder_scope': nan, 'document_date': '14-06-2020 23:35', 'language': 'English', 'document_reference': 'F530415', 'document_name': 'F530415-Numereco_submission_1.pdf', '_split_id': 4, 'page': 3, '_split_overlap': [{'doc_id': 'cd056423424e2872d869ad84662fb0c8', 'range': (0, 338)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f269a08cffe93c2b630758f337c191ff'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: World Federalist Movement - Institute for Global Policy  Transnational Working Group on the Global Governance of AI and Disruptive Technologies, stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 13-06-2020 22:18, language: English, \\n\\nPassage: 1\\nEuropean Commission White Paper\\nOn Artificial Intelligence – A European approach to excellence and trust\\nCOM(2020) 65 final\\nComments from the\\nWorld Federalist Movement – Institute of Global Policy (WFM-IGP)\\nTrans-national Working Group on\\nGlobal Governance of AI and Disruptive Technologies (TWG on AI)\\nThe World Federalist Movement’s Transnational Working Group on AI has reviewed\\nthe White Paper and is broadly supportive, subject to the following comments:\\n1. Global regulation: There is little mention of a global regulatory framework.\\nThis should however be the urgent goal as AI has tremendous power both to\\nsupport and destroy humanity. The sooner this power is under responsible\\nand effective global regulation the better. This should be an explicit goal for\\nthe European Union, CAHAI and the United Nations. Such matters should\\nstart to be discussed in global fora as a prelude to the negotiation of an initial\\nGlobal Treaty on AI. Such a goal should be clearly stated.\\n2. CAHAI: How will the timing of any emerging European Commission Directive\\nrelate to the output of the Council for Europe’s Ad Hoc Committee on Artificial\\nIntelligence (CAHAI)? There would seem to be major overlap in scope. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530261-WFM_TWG_AI_EC_White_Paper_050620.pdf', 'stakeholder_name': 'World Federalist Movement - Institute for Global Policy  Transnational Working Group on the Global Governance of AI and Disruptive Technologies', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '13-06-2020 22:18', 'language': 'English', 'document_reference': 'F530261', 'document_name': 'F530261-WFM_TWG_AI_EC_White_Paper_050620.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': 'ee2d942086a87cd0b1847c307b6137c8', 'range': (984, 1205)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ae5c8a52d2dd303c58622dd0e94484b6'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: World Federalist Movement - Institute for Global Policy  Transnational Working Group on the Global Governance of AI and Disruptive Technologies, stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 13-06-2020 22:18, language: English, \\n\\nPassage: CAHAI: How will the timing of any emerging European Commission Directive\\nrelate to the output of the Council for Europe’s Ad Hoc Committee on Artificial\\nIntelligence (CAHAI)? There would seem to be major overlap in scope. If the\\nEC is completely clear as to the way forward, then one could expect that it\\ncould publish first. On the other hand, this issue is of major global concern.\\nGlobal regulation is needed as soon as possible. Playing a very active role in\\nthe decision making within CAHAI whilst waiting for the results before\\npublishing its own regulatory framework would seem to be the best way\\nforward.\\n3. Benefits of AI: The potential benefits that AI can bring are well known. The\\nWhite Paper sets out a series of steps that will help support the development\\nof AI within Europe. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530261-WFM_TWG_AI_EC_White_Paper_050620.pdf', 'stakeholder_name': 'World Federalist Movement - Institute for Global Policy  Transnational Working Group on the Global Governance of AI and Disruptive Technologies', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '13-06-2020 22:18', 'language': 'English', 'document_reference': 'F530261', 'document_name': 'F530261-WFM_TWG_AI_EC_White_Paper_050620.pdf', '_split_id': 1, 'page': 1, '_split_overlap': [{'doc_id': 'ae5c8a52d2dd303c58622dd0e94484b6', 'range': (0, 221)}, {'doc_id': 'c105c82facfdd193e83b59211fec403f', 'range': (616, 791)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ee2d942086a87cd0b1847c307b6137c8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: World Federalist Movement - Institute for Global Policy  Transnational Working Group on the Global Governance of AI and Disruptive Technologies, stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 13-06-2020 22:18, language: English, \\n\\nPassage: Benefits of AI: The potential benefits that AI can bring are well known. The\\nWhite Paper sets out a series of steps that will help support the development\\nof AI within Europe. It is notable however that efforts to introduce AI are not\\nevenly spread and that there are sectors in the realm of public goods where\\nthe introduction of AI would benefit from greater encouragement and support.1\\nThe identification of priority areas and initiatives to be supported, based on\\ntheir benefits to the EU and humanity as a whole, should be an explicit\\nresponsibility of any EU body dedicated to AI.\\n4. Risks of AI: In addition to the multiple benefits that can arise from the\\nintroduction of AI, there are also categories of risk that will need serious action\\nto address. The European Commission paper should explicitly acknowledge\\nthis and propose initial steps towards their resolution. Three main areas of\\nrisk are:\\n1 https://ec.europa.eu/digital-singl-market/en/news/communication-artificial-intelligence-europe\\nRef. Ares(2020)3359928 - 26/06/2020\\x0c2\\na. Weapons Systems: Implementation of a moratorium on R&D that passes\\nlimits, including R&D on Lethal Autonomous Weapons Systems (LAWS,\\naka Killer Robots). In particular2:\\nI. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530261-WFM_TWG_AI_EC_White_Paper_050620.pdf', 'stakeholder_name': 'World Federalist Movement - Institute for Global Policy  Transnational Working Group on the Global Governance of AI and Disruptive Technologies', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '13-06-2020 22:18', 'language': 'English', 'document_reference': 'F530261', 'document_name': 'F530261-WFM_TWG_AI_EC_White_Paper_050620.pdf', '_split_id': 2, 'page': 1, '_split_overlap': [{'doc_id': 'ee2d942086a87cd0b1847c307b6137c8', 'range': (0, 175)}, {'doc_id': 'e6ef31d2abbc08801c20fe96391372c4', 'range': (1045, 1216)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c105c82facfdd193e83b59211fec403f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: World Federalist Movement - Institute for Global Policy  Transnational Working Group on the Global Governance of AI and Disruptive Technologies, stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 13-06-2020 22:18, language: English, \\n\\nPassage: Weapons Systems: Implementation of a moratorium on R&D that passes\\nlimits, including R&D on Lethal Autonomous Weapons Systems (LAWS,\\naka Killer Robots). In particular2:\\nI. A moratorium on the development, deployment, transfer, and use of\\nanti-personnel lethal autonomous weapon systems.\\nII. Define guiding principles for human involvement in the use of force.\\nIII. Develop protocols and/or technological means to mitigate the risk of\\nunintentional escalation due to autonomous systems.\\nIV. Develop strategies for preventing proliferation to illicit uses, such as\\nby criminals, terrorists, or rogue states.\\nV. Conduct research to improve technologies and human-machine\\nsystems to reduce non-combatant harm and ensure International\\nHuman Rights Law compliance in the use of future weapons.\\nb. Negative Impact on labour: AI is expected to have a dramatic impact on\\nthe labour - force, reducing demand for labour in an unprecedented\\nmanner. This in itself is not a disaster if, and only if, sufficient account of\\nthis transformation is taken both economically and socially in the work\\nplace.\\nI. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530261-WFM_TWG_AI_EC_White_Paper_050620.pdf', 'stakeholder_name': 'World Federalist Movement - Institute for Global Policy  Transnational Working Group on the Global Governance of AI and Disruptive Technologies', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '13-06-2020 22:18', 'language': 'English', 'document_reference': 'F530261', 'document_name': 'F530261-WFM_TWG_AI_EC_White_Paper_050620.pdf', '_split_id': 3, 'page': 2, '_split_overlap': [{'doc_id': 'c105c82facfdd193e83b59211fec403f', 'range': (0, 171)}, {'doc_id': '7a4c40befad079abda6516f02cfc27a4', 'range': (937, 1090)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e6ef31d2abbc08801c20fe96391372c4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: World Federalist Movement - Institute for Global Policy  Transnational Working Group on the Global Governance of AI and Disruptive Technologies, stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 13-06-2020 22:18, language: English, \\n\\nPassage: This in itself is not a disaster if, and only if, sufficient account of\\nthis transformation is taken both economically and socially in the work\\nplace.\\nI. Economically some form of Universal Basic Income might be\\nrequired, funded through taxation of the wealth generated by the AI,\\nwhether through general taxation or via a specific tax relating to the\\ndeployment of AI in the businesses concerned.\\nII. Socially, people have often found a sense of identity and purpose in\\ntheir lives through the work that they perform and their role in society.\\nIf this role is to be diminished (less working time), or cease altogether\\n(unemployment), people will need to be helped to find a new source\\nof identity and purpose in their lives and new pathways to flourishing.\\nIt is essential that the planning required to address these two issues takes\\nplace hand in hand with the encouragement of AI in this White Paper.\\nc. Control: Multiple teams of brilliant scientists around the world are carrying\\nout AI related research and developing AI systems. Very rapid progress is\\nbeing made and is projected to continue to be made over the coming\\ndecades. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530261-WFM_TWG_AI_EC_White_Paper_050620.pdf', 'stakeholder_name': 'World Federalist Movement - Institute for Global Policy  Transnational Working Group on the Global Governance of AI and Disruptive Technologies', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '13-06-2020 22:18', 'language': 'English', 'document_reference': 'F530261', 'document_name': 'F530261-WFM_TWG_AI_EC_White_Paper_050620.pdf', '_split_id': 4, 'page': 2, '_split_overlap': [{'doc_id': 'e6ef31d2abbc08801c20fe96391372c4', 'range': (0, 153)}, {'doc_id': '6ebb3921d24c3fd51a72646b5427f05f', 'range': (904, 1134)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7a4c40befad079abda6516f02cfc27a4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: World Federalist Movement - Institute for Global Policy  Transnational Working Group on the Global Governance of AI and Disruptive Technologies, stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 13-06-2020 22:18, language: English, \\n\\nPassage: c. Control: Multiple teams of brilliant scientists around the world are carrying\\nout AI related research and developing AI systems. Very rapid progress is\\nbeing made and is projected to continue to be made over the coming\\ndecades. The competitive nature between countries, companies and\\nteams is such that the drive to progress appears at times unstoppable.\\nWithout a change of direction, this drive can only lead to the development\\nof Artificial entities with a General Intelligence greater than that of humans\\n– and soon much, much greater. Down that path lies the risk of the end of\\nhumanity. The length of the path is contentious – but many see it as only\\na few decades long.\\nAs with the shorter-term impact on labour, a Regulatory Framework for the\\ndevelopment and deployment of AI systems should address the problem\\noutlined above. It is unlikely to encompass a totally reliable solution at the\\noutset, but it should acknowledge the problem and be promoting and\\nsupporting the development of the means to reliably resolve the problem.\\n2 Edited version of https://spectrum.ieee.org/automaton/robotics/artificial-intelligence/a-path-towards-\\nreasonable-autonomous-weapons-regulation', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530261-WFM_TWG_AI_EC_White_Paper_050620.pdf', 'stakeholder_name': 'World Federalist Movement - Institute for Global Policy  Transnational Working Group on the Global Governance of AI and Disruptive Technologies', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '13-06-2020 22:18', 'language': 'English', 'document_reference': 'F530261', 'document_name': 'F530261-WFM_TWG_AI_EC_White_Paper_050620.pdf', '_split_id': 5, 'page': 2, '_split_overlap': [{'doc_id': '7a4c40befad079abda6516f02cfc27a4', 'range': (0, 230)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6ebb3921d24c3fd51a72646b5427f05f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: El CERMI se crea para ser la plataforma unitaria de incidencia política que aporta valor añadido al movimiento social de la discapacidad. Orienta su actuación bajo el principio de unidad y cohesión de la discapacidad organizada. www.cermi.es, stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Spain, document_date: 18-05-2020 09:40, language: Spanish, \\n\\nPassage: 1\\nDocumento de contribución del CERMI a la Consulta Pública sobre\\nel Libro Blanco sobre la Inteligencia Artificial\\nInteligencia Artificial y Personas con Discapacidad desde una\\nvisión exigente de derechos humanos\\nAprobado por el Comité Ejecutivo del CERMI Estatal\\nen su reunión del 14 de mayo de 2020\\n1) La Inteligencia Artificial (IA) permite desarrollar sistemas\\ninformáticos capaces de emular y realizar actividades propias\\nde los seres humanos, tales como percibir, razonar, aprender\\ny resolver problemas.1 El objetivo de un sistema de IA es\\nrealizar tareas o resolver problemas con resultados similares o\\nsuperiores a los obtenidos por una persona;2\\n2) El uso y aplicación de sistemas de IA ha pasado, en muy poco\\ntiempo, a convertirse en una realidad en la vida diaria de la\\ninmensa mayoría de las personas;3\\n3) A pesar de ello, cada vez más voces autorizadas manifiestan\\npreocupaciones derivadas del uso de sistemas de IA en\\nnuestras sociedades hipertecnologizadas, en especial en el\\ngoce y ejercicio de los derechos humanos;4\\n4) Los informes preliminares sobre riesgos del uso de sistema de\\nIA revelan discriminaciones en perjuicio de grupos sociales\\nmás expuestos a ver vulnerados sus derechos tales como\\ngénero, raza o situación migratoria.5 Recientes estudios,\\nevidencian que las personas con discapacidad, mujeres y\\nhombres, no son ajenas a este fenómeno, muy a menudo a\\ntravés de discriminaciones múltiples e interseccionales;6\\n5) Las personas con discapacidad, como grupo colocado en\\nsituación de fragilidad social, se encuentran ante un mayor\\nRef. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529148-Contribuci_n_CERMI_consulta_p_blica_europea_sobre_IA.pdf', 'stakeholder_name': 'El CERMI se crea para ser la plataforma unitaria de incidencia política que aporta valor añadido al movimiento social de la discapacidad. Orienta su actuación bajo el principio de unidad y cohesión de la discapacidad organizada. www.cermi.es', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '18-05-2020 09:40', 'language': 'Spanish', 'document_reference': 'F529148', 'document_name': 'F529148-Contribuci_n_CERMI_consulta_p_blica_europea_sobre_IA.pdf', '_split_id': 0, 'page': 1, '_split_overlap': []}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'cc47ebf5fd3668ced635c94757dae675'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: El CERMI se crea para ser la plataforma unitaria de incidencia política que aporta valor añadido al movimiento social de la discapacidad. Orienta su actuación bajo el principio de unidad y cohesión de la discapacidad organizada. www.cermi.es, stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Spain, document_date: 18-05-2020 09:40, language: Spanish, \\n\\nPassage: Ares(2020)3355452 - 26/06/2020\\x0c2\\nriesgo de vulneración de sus derechos y libertades\\nfundamentales, lo que justifica que se adopten enfoques\\nespecíficos basados en el principio de igualdad y no\\ndiscriminación;7 además de tomar en consideración los\\nprincipios de diseño para todas las personas y accesibilidad\\nuniversal.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529148-Contribuci_n_CERMI_consulta_p_blica_europea_sobre_IA.pdf', 'stakeholder_name': 'El CERMI se crea para ser la plataforma unitaria de incidencia política que aporta valor añadido al movimiento social de la discapacidad. Orienta su actuación bajo el principio de unidad y cohesión de la discapacidad organizada. www.cermi.es', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '18-05-2020 09:40', 'language': 'Spanish', 'document_reference': 'F529148', 'document_name': 'F529148-Contribuci_n_CERMI_consulta_p_blica_europea_sobre_IA.pdf', '_split_id': 1, 'page': 1, '_split_overlap': []}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '74de65bd1e7d9828454074b665f064d3'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: El CERMI se crea para ser la plataforma unitaria de incidencia política que aporta valor añadido al movimiento social de la discapacidad. Orienta su actuación bajo el principio de unidad y cohesión de la discapacidad organizada. www.cermi.es, stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Spain, document_date: 18-05-2020 09:40, language: Spanish, \\n\\nPassage: 6) Las reglas y principios desarrollados en los planos\\ninternacional y regional deben servir de base frente al uso de\\nsistemas de IA que pongan en riesgo o vulneren derechos\\nhumanos de las personas con discapacidad en igualdad de\\ncondiciones con los demás;8\\n7) Los órganos internacionales de derechos humanos deben\\nabordar en sus mecanismos de seguimiento los riesgos en el\\nuso de la IA en los derechos humanos, en especial respecto\\nde los grupos en especial situación de exposición y\\nvulnerabilidad;\\n8) Desde un enfoque específico de derechos humanos de las\\npersonas con discapacidad, los sistemas de IA representan,\\nde entrada, tanto riesgos como beneficios para el goce y\\nejercicio de los mismos;\\n9) Entre los principales riesgos se pueden señalar los siguientes:\\na) El uso de sistemas de IA para justificar la selección\\ngenética de personas sin discapacidad; b) El uso de sistemas\\nde IA para identificar y eventualmente discriminar a personas\\ncon discapacidad; c) La creación de sistemas de IA basados\\nen modelos de normalización que excluyan o no tengan en\\ncuenta la las necesidades, la opinión y diversidad de las\\npersonas con discapacidad; d) El diseño de sistemas de IA\\nque se basen o nutran de datos que incluyan estereotipos,\\nsesgos y prejuicios respecto de la discapacidad; e) El uso de\\nsistemas de IA que no permitan la participación o toma de\\ndecisiones de personas con discapacidad, por sí mismas o a\\ntravés de sus organizaciones representativas; f) La creación\\nde sistemas IA dirigidos a las personas con discapacidad que\\nno sean probados y validados para su uso por las propias\\npersonas con discapacidad.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529148-Contribuci_n_CERMI_consulta_p_blica_europea_sobre_IA.pdf', 'stakeholder_name': 'El CERMI se crea para ser la plataforma unitaria de incidencia política que aporta valor añadido al movimiento social de la discapacidad. Orienta su actuación bajo el principio de unidad y cohesión de la discapacidad organizada. www.cermi.es', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '18-05-2020 09:40', 'language': 'Spanish', 'document_reference': 'F529148', 'document_name': 'F529148-Contribuci_n_CERMI_consulta_p_blica_europea_sobre_IA.pdf', '_split_id': 2, 'page': 2, '_split_overlap': []}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '15fffbbaabd568695be03cd3f63ed970'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: El CERMI se crea para ser la plataforma unitaria de incidencia política que aporta valor añadido al movimiento social de la discapacidad. Orienta su actuación bajo el principio de unidad y cohesión de la discapacidad organizada. www.cermi.es, stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Spain, document_date: 18-05-2020 09:40, language: Spanish, \\n\\nPassage: 3\\n10) Entre los principales beneficios se podrían destacar los\\nsiguientes: a) Sistemas de IA que facilitan el acceso a la\\ninformación y a la propia comunicación en todos los medios y\\nformatos; b) Sistemas de IA que facilitan la toma de\\ndecisiones; c) Sistemas de IA que facilitan la accesibilidad en\\nel entorno y los ajustes razonables; d) Sistemas de IA\\nincluidos en robots (androides) que facilitan la asistencia\\npersonal; e) Sistemas de IA de automoción que facilitan el\\ndiseño universal; o f) Sistemas de IA que facilitan la atención\\nsanitaria y los servicios de habilitación y rehabilitación; por\\ncitar solo algunas de los potenciales usos.\\n11) El debate ético y social que irremediablemente impone\\nel uso generalizado de sistemas de IA a la luz de las reglas\\nuniversales y regionales de derechos humanos no puede\\nprescindir ni omitir a las personas con discapacidad y tampoco\\npuede eludir el enfoque específico de este grupo;\\n12) El enfoque específico respecto de los riesgos y\\nbeneficios del uso de sistemas de IA para los derechos\\nhumanos de las personas con discapacidad debe ser\\nprioritariamente abordado por el propio grupo social de las\\npersonas con discapacidad y sus familias. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529148-Contribuci_n_CERMI_consulta_p_blica_europea_sobre_IA.pdf', 'stakeholder_name': 'El CERMI se crea para ser la plataforma unitaria de incidencia política que aporta valor añadido al movimiento social de la discapacidad. Orienta su actuación bajo el principio de unidad y cohesión de la discapacidad organizada. www.cermi.es', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '18-05-2020 09:40', 'language': 'Spanish', 'document_reference': 'F529148', 'document_name': 'F529148-Contribuci_n_CERMI_consulta_p_blica_europea_sobre_IA.pdf', '_split_id': 3, 'page': 3, '_split_overlap': [{'doc_id': '6882369ba09de598605c9708ead86512', 'range': (646, 1190)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9291e06ccaf2b9ee21398ebd6fc31bdc'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: El CERMI se crea para ser la plataforma unitaria de incidencia política que aporta valor añadido al movimiento social de la discapacidad. Orienta su actuación bajo el principio de unidad y cohesión de la discapacidad organizada. www.cermi.es, stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Spain, document_date: 18-05-2020 09:40, language: Spanish, \\n\\nPassage: 11) El debate ético y social que irremediablemente impone\\nel uso generalizado de sistemas de IA a la luz de las reglas\\nuniversales y regionales de derechos humanos no puede\\nprescindir ni omitir a las personas con discapacidad y tampoco\\npuede eludir el enfoque específico de este grupo;\\n12) El enfoque específico respecto de los riesgos y\\nbeneficios del uso de sistemas de IA para los derechos\\nhumanos de las personas con discapacidad debe ser\\nprioritariamente abordado por el propio grupo social de las\\npersonas con discapacidad y sus familias. A dichos fines, es\\npreciso asignarle la prioridad y los recursos necesarios tales\\ncomo el apoyo de investigaciones, promoción de debates\\npúblicos o la intervención activa en foros y espacios de\\nparticipación política y social;\\n13) El despliegue y gestión de la IA ha de estar sometido a\\nprocedimientos democráticos de gobernanza, que garanticen\\nla transparencia, la rendición de cuentas y la participación de\\ntodos los grupos de interés en la toma de decisiones y en la\\nvalidación de soluciones. Las personas con discapacidad son\\nun grupo de interés legítimo de la IA que ha de tener\\nasegurado un rol en el gobierno de estos sistemas.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529148-Contribuci_n_CERMI_consulta_p_blica_europea_sobre_IA.pdf', 'stakeholder_name': 'El CERMI se crea para ser la plataforma unitaria de incidencia política que aporta valor añadido al movimiento social de la discapacidad. Orienta su actuación bajo el principio de unidad y cohesión de la discapacidad organizada. www.cermi.es', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '18-05-2020 09:40', 'language': 'Spanish', 'document_reference': 'F529148', 'document_name': 'F529148-Contribuci_n_CERMI_consulta_p_blica_europea_sobre_IA.pdf', '_split_id': 4, 'page': 3, '_split_overlap': [{'doc_id': '9291e06ccaf2b9ee21398ebd6fc31bdc', 'range': (0, 544)}, {'doc_id': '372a696ae0bdc370f3dec8c556d8d8dc', 'range': (1041, 1179)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6882369ba09de598605c9708ead86512'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: El CERMI se crea para ser la plataforma unitaria de incidencia política que aporta valor añadido al movimiento social de la discapacidad. Orienta su actuación bajo el principio de unidad y cohesión de la discapacidad organizada. www.cermi.es, stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Spain, document_date: 18-05-2020 09:40, language: Spanish, \\n\\nPassage: Las personas con discapacidad son\\nun grupo de interés legítimo de la IA que ha de tener\\nasegurado un rol en el gobierno de estos sistemas.\\n14) Los principios, valores y mandatos de la Convención\\nInternacional sobre los Derechos de las Personas con\\nDiscapacidad de 2006 y los Objetivos de Desarrollo\\nSostenible/Agenda 2030 de Naciones Unidas han de constituir\\x0c4\\nen todo caso el marco referencial y de prescripición de la IA\\nen relación con las personas con discapacidad.\\n15) Visibilizar la discapacidad e incluirla en el desarrollo de\\nreglas uniformes y principios éticos sobre el uso de sistemas\\nde IA contribuye a pensar en un marco de protección y\\nrespeto de derechos humanos mucho más amplio y ajustado\\na la realidad de la diversidad humana, cuyas distintas\\nexpresiones son todas ellas valiosas y dignas de promoción y\\nprotección.\\n14 de mayo de 2020.\\n1 Una definición de la inteligencia artificial: Principales capacidades y disciplinas científicas (2018).\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529148-Contribuci_n_CERMI_consulta_p_blica_europea_sobre_IA.pdf', 'stakeholder_name': 'El CERMI se crea para ser la plataforma unitaria de incidencia política que aporta valor añadido al movimiento social de la discapacidad. Orienta su actuación bajo el principio de unidad y cohesión de la discapacidad organizada. www.cermi.es', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '18-05-2020 09:40', 'language': 'Spanish', 'document_reference': 'F529148', 'document_name': 'F529148-Contribuci_n_CERMI_consulta_p_blica_europea_sobre_IA.pdf', '_split_id': 5, 'page': 3, '_split_overlap': [{'doc_id': '6882369ba09de598605c9708ead86512', 'range': (0, 138)}, {'doc_id': 'bfe1e04dbe5611489874f0e618f4f9a4', 'range': (470, 959)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '372a696ae0bdc370f3dec8c556d8d8dc'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: El CERMI se crea para ser la plataforma unitaria de incidencia política que aporta valor añadido al movimiento social de la discapacidad. Orienta su actuación bajo el principio de unidad y cohesión de la discapacidad organizada. www.cermi.es, stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Spain, document_date: 18-05-2020 09:40, language: Spanish, \\n\\nPassage: 15) Visibilizar la discapacidad e incluirla en el desarrollo de\\nreglas uniformes y principios éticos sobre el uso de sistemas\\nde IA contribuye a pensar en un marco de protección y\\nrespeto de derechos humanos mucho más amplio y ajustado\\na la realidad de la diversidad humana, cuyas distintas\\nexpresiones son todas ellas valiosas y dignas de promoción y\\nprotección.\\n14 de mayo de 2020.\\n1 Una definición de la inteligencia artificial: Principales capacidades y disciplinas científicas (2018).\\nGrupo de expertos de alto nivel sobre inteligencia artificial de la Unión Europea\\n(https://ec.europa.eu/newsroom/dae/document.cfm?doc_id=60656)\\n2 Desde aspectos sociales como resolver conflictos jurídicos, operar el sistema financiero, hacer\\nvigilancia de actividad humana, o conducir automóviles, buques o aeronaves, a aspectos\\nindividuales como consejos de administración financiera o selección de música, películas o videos,\\nlos sistemas de IA que conviven en nuestras sociedades pueden llevar a cabo diferentes tareas o\\nfunciones que otrora eran llevadas a cabo exclusivamente por personas.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529148-Contribuci_n_CERMI_consulta_p_blica_europea_sobre_IA.pdf', 'stakeholder_name': 'El CERMI se crea para ser la plataforma unitaria de incidencia política que aporta valor añadido al movimiento social de la discapacidad. Orienta su actuación bajo el principio de unidad y cohesión de la discapacidad organizada. www.cermi.es', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '18-05-2020 09:40', 'language': 'Spanish', 'document_reference': 'F529148', 'document_name': 'F529148-Contribuci_n_CERMI_consulta_p_blica_europea_sobre_IA.pdf', '_split_id': 6, 'page': 4, '_split_overlap': [{'doc_id': '372a696ae0bdc370f3dec8c556d8d8dc', 'range': (0, 489)}, {'doc_id': 'd5f277679a0b19933075aa1f6ca60794', 'range': (490, 1084)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bfe1e04dbe5611489874f0e618f4f9a4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: El CERMI se crea para ser la plataforma unitaria de incidencia política que aporta valor añadido al movimiento social de la discapacidad. Orienta su actuación bajo el principio de unidad y cohesión de la discapacidad organizada. www.cermi.es, stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Spain, document_date: 18-05-2020 09:40, language: Spanish, \\n\\nPassage: Grupo de expertos de alto nivel sobre inteligencia artificial de la Unión Europea\\n(https://ec.europa.eu/newsroom/dae/document.cfm?doc_id=60656)\\n2 Desde aspectos sociales como resolver conflictos jurídicos, operar el sistema financiero, hacer\\nvigilancia de actividad humana, o conducir automóviles, buques o aeronaves, a aspectos\\nindividuales como consejos de administración financiera o selección de música, películas o videos,\\nlos sistemas de IA que conviven en nuestras sociedades pueden llevar a cabo diferentes tareas o\\nfunciones que otrora eran llevadas a cabo exclusivamente por personas.\\n3 Muchos creen que la IA no les afecta en su vida diaria pero lo cierto es que si uno busca un empleo,\\nsolicita acceso a educación especializada, o contrata un seguro médico, de vida o de responsabilidad\\ncivil, muy probablemente la decisión sea influenciada o determinada por un sistema de IA sin que\\njamás lo sepa.\\n4 DERTECNIA: Derechos Humanos, Diversidad y Tecnología, Universidad Carlos III de Madrid\\n(https://dertecnia.com/); Raso, F. A., Hilligoss, A., et. al. (2018). Artificial Intelligence & Human\\nRights: Opportunities & Risks, Center for Internet & Society, Harvard (http://nrs.harvard.edu/urn-\\n3:HUL.InstRepos:38021439); Unboxing Artificial Intelligence: 10 steps to protect Human Rights\\n(2019). Consejo de Europa (https://rm.coe.int/unboxing-artificial-intelligence-10-steps-to-protect-\\nhuman-rights-reco/1680946e64)\\n5 Vid. West, S.M., Whittaker, M. and Crawford, K. (2019). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529148-Contribuci_n_CERMI_consulta_p_blica_europea_sobre_IA.pdf', 'stakeholder_name': 'El CERMI se crea para ser la plataforma unitaria de incidencia política que aporta valor añadido al movimiento social de la discapacidad. Orienta su actuación bajo el principio de unidad y cohesión de la discapacidad organizada. www.cermi.es', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '18-05-2020 09:40', 'language': 'Spanish', 'document_reference': 'F529148', 'document_name': 'F529148-Contribuci_n_CERMI_consulta_p_blica_europea_sobre_IA.pdf', '_split_id': 7, 'page': 4, '_split_overlap': [{'doc_id': 'bfe1e04dbe5611489874f0e618f4f9a4', 'range': (0, 594)}, {'doc_id': 'c584db9fbab6101cec7d4ac36121b1ba', 'range': (1070, 1482)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd5f277679a0b19933075aa1f6ca60794'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: El CERMI se crea para ser la plataforma unitaria de incidencia política que aporta valor añadido al movimiento social de la discapacidad. Orienta su actuación bajo el principio de unidad y cohesión de la discapacidad organizada. www.cermi.es, stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Spain, document_date: 18-05-2020 09:40, language: Spanish, \\n\\nPassage: Artificial Intelligence & Human\\nRights: Opportunities & Risks, Center for Internet & Society, Harvard (http://nrs.harvard.edu/urn-\\n3:HUL.InstRepos:38021439); Unboxing Artificial Intelligence: 10 steps to protect Human Rights\\n(2019). Consejo de Europa (https://rm.coe.int/unboxing-artificial-intelligence-10-steps-to-protect-\\nhuman-rights-reco/1680946e64)\\n5 Vid. West, S.M., Whittaker, M. and Crawford, K. (2019). Discriminating Systems: Gender, Race and\\nPower in AI. AI Now Institute. Retrieved from\\nhttps://ainowinstitute.org/discriminatingsystems.html\\n6 Vid. Whittaker, M., Alper, M., et. al. (2019). Disability, Bias, and AI. AI Now Institute. Retrieved from\\nhttps://ainowinstitute.org/disabilitybiasai-2019.pdf; Rafael de Asís Roig (2019). Discapacidad e\\nInteligencia Artificial, accessible en: https://pasocero243055203.com/\\n7 Informe de la Relatora Especial sobre los derechos de las personas con discapacidad sobre\\nBioética y Discapacidad, A/HRC/43/41, 17 de diciembre de 2019.\\n8 Directrices Éticas para una IA Fiable (2018). Grupo de expertos de alto nivel sobre inteligencia\\nartificial de la Unión Europea\\n(https://ec.europa.eu/newsroom/dae/document.cfm?doc_id=60423); Carta Ética Europea sobre el\\nuso de inteligencia artificial en los sistemas judiciales (2018), Consejo de Europa\\n(https://rm.coe.int/ethical-charter-en-for-publication-4-december-2018/16808f699c); Principios\\nde la OCDE sobre Inteligencia Artificial (2019). Organización para la Cooperación y el Desarrollo\\nEconómico (http://www.oecd.org/going-digital/ai/principles/)\\nEl CERMI y Fundación CERMI Mujeres agradecen al Profesor Doctor Francisco Bariffi sus\\nvaliosas contribuciones para la elaboración de este Manifiesto.', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529148-Contribuci_n_CERMI_consulta_p_blica_europea_sobre_IA.pdf', 'stakeholder_name': 'El CERMI se crea para ser la plataforma unitaria de incidencia política que aporta valor añadido al movimiento social de la discapacidad. Orienta su actuación bajo el principio de unidad y cohesión de la discapacidad organizada. www.cermi.es', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '18-05-2020 09:40', 'language': 'Spanish', 'document_reference': 'F529148', 'document_name': 'F529148-Contribuci_n_CERMI_consulta_p_blica_europea_sobre_IA.pdf', '_split_id': 8, 'page': 4, '_split_overlap': [{'doc_id': 'd5f277679a0b19933075aa1f6ca60794', 'range': (0, 412)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c584db9fbab6101cec7d4ac36121b1ba'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: National, stakeholder_size: nan, stakeholder_country: nan, document_date: 19-06-2020 13:57, language: English, \\n\\nPassage: NOTAT\\nThe Danish Government’s response to the public consultation on the\\nwhite paper “On Artificial Intelligence – A European approach to ex-\\ncellence and trust”\\nGeneral comments\\nThe Danish Government welcomes the European Commission’s (Commis-\\nsion) white paper on artificial intelligence (AI) and supports the ambition\\nfor a European approach to promote the development and uptake of AI in\\na responsible and trustworthy manner. AI is one of the pivotal technologies\\nthat can underpin the EU's competitiveness, prosperity, strategic autonomy\\nand climate-neutral transition as well as public administration and welfare.\\nIts vast potential has furthermore become evident by the current COVID-\\n19 crisis which has highlighted the technology’s contribution to tackling\\nthe pandemic. At the same time, the increasing application of AI and its\\npotential to solve the challenges of tomorrow has reinforced the important\\nobjective of ensuring trustworthy, ethical, safe and secure application of\\nAI.\\nIn certain situations, the usage of AI may involve serious risks to individ-\\nuals and society which must be addressed in a proportionate and risk-based\\nregulatory framework at the European level. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529882-DK_General_Comments_on_the_AI-White_Paper.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'National', 'document_date': '19-06-2020 13:57', 'language': 'English', 'document_reference': 'F529882', 'document_name': 'F529882-DK_General_Comments_on_the_AI-White_Paper.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': '45fc166826799f26d392f49a9ea7a8d3', 'range': (993, 1188)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7fbe9599468403d52bda0ce43b1d49db'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: National, stakeholder_size: nan, stakeholder_country: nan, document_date: 19-06-2020 13:57, language: English, \\n\\nPassage: In certain situations, the usage of AI may involve serious risks to individ-\\nuals and society which must be addressed in a proportionate and risk-based\\nregulatory framework at the European level. A European framework must\\nbe clear and operable in order to ensure trust among citizens and increase\\nthe protection in society as well as ensuring legal certainty for business and\\npublic authorities. The aim should be to pave the way towards a true Single\\nMarket for AI, where developers and deployers of AI are able to innovate\\nand scale up across the EU.\\nAI will likewise be one of the key enablers for rebooting the European\\neconomy after COVID-19. Therefore, a strengthened focus on fostering AI\\necosystems and capacities in the EU is needed in order to improve Europe’s\\nfuture competitiveness and resilience as well as for achieving the objec-\\ntives set out in the European Green Deal. The EU must continue to strate-\\ngically build on its strengths and reduce its weaknesses in order to improve\\nits abilities to develop and deploy responsible, ethical, safe and secure AI,\\nthereby making this a trademark for the EU.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529882-DK_General_Comments_on_the_AI-White_Paper.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'National', 'document_date': '19-06-2020 13:57', 'language': 'English', 'document_reference': 'F529882', 'document_name': 'F529882-DK_General_Comments_on_the_AI-White_Paper.pdf', '_split_id': 1, 'page': 1, '_split_overlap': [{'doc_id': '7fbe9599468403d52bda0ce43b1d49db', 'range': (0, 195)}, {'doc_id': '64302f986bf7e2d036663a6ac0c9ca15', 'range': (887, 1117)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '45fc166826799f26d392f49a9ea7a8d3'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: National, stakeholder_size: nan, stakeholder_country: nan, document_date: 19-06-2020 13:57, language: English, \\n\\nPassage: The EU must continue to strate-\\ngically build on its strengths and reduce its weaknesses in order to improve\\nits abilities to develop and deploy responsible, ethical, safe and secure AI,\\nthereby making this a trademark for the EU.\\nIt is important to have in mind that certain usage of AI in sectors critical\\nfor our society can involve risks of societal significance. Consequently, a\\nstrengthened focus on fostering AI ecosystems and capacities in the EU\\nshould also seek to reduce technological dependency on third country de-\\nliveries in key value chains and infrastructure of critical importance for our\\nRef. Ares(2020)3360021 - 26/06/2020\\x0c2\\nsociety and security, thereby strengthening the EU’s autonomy as well as\\nenabling the EU to define the European way on digitalisation.\\nThe overarching aim must be to ensure that AI and the digital economy in\\nthe EU is characterized by a high degree of trust, safety and security as\\nwell as a strong competitiveness based on framework conditions which\\npromote innovation, are technology neutral and do not create unnecessary\\nburdens and barriers.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529882-DK_General_Comments_on_the_AI-White_Paper.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'National', 'document_date': '19-06-2020 13:57', 'language': 'English', 'document_reference': 'F529882', 'document_name': 'F529882-DK_General_Comments_on_the_AI-White_Paper.pdf', '_split_id': 2, 'page': 1, '_split_overlap': [{'doc_id': '45fc166826799f26d392f49a9ea7a8d3', 'range': (0, 230)}, {'doc_id': 'dc6c5cf6445f644c12110b78ca095977', 'range': (780, 1090)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '64302f986bf7e2d036663a6ac0c9ca15'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: National, stakeholder_size: nan, stakeholder_country: nan, document_date: 19-06-2020 13:57, language: English, \\n\\nPassage: The overarching aim must be to ensure that AI and the digital economy in\\nthe EU is characterized by a high degree of trust, safety and security as\\nwell as a strong competitiveness based on framework conditions which\\npromote innovation, are technology neutral and do not create unnecessary\\nburdens and barriers.\\nThe Danish Government is looking forward to the further discussions and\\nwork on the initiatives announced in the white paper and will form a posi-\\ntion on the specific legislative initiatives, as these are presented by the\\nCommission. It should be noted that the Danish Government finds it im-\\nportant that the coming discussions does not in any way prejudge the ne-\\ngotiations on the future Multiannual Financial Framework nor fail to re-\\nspect the common understandings on the Digital Europe Programme and\\nthe Horizon Europe Programme reached between the European Parliament\\nand the Council.\\nSpecific remarks to the different elements in the white paper can be found\\nin the attached document “Annex: Specific comments from the Danish\\nGovernment’s on the white paper on artificial intelligence”.', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529882-DK_General_Comments_on_the_AI-White_Paper.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'National', 'document_date': '19-06-2020 13:57', 'language': 'English', 'document_reference': 'F529882', 'document_name': 'F529882-DK_General_Comments_on_the_AI-White_Paper.pdf', '_split_id': 3, 'page': 2, '_split_overlap': [{'doc_id': '64302f986bf7e2d036663a6ac0c9ca15', 'range': (0, 310)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'dc6c5cf6445f644c12110b78ca095977'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Introduction\\nLe Comité national pilote d’éthique du numérique (CNPEN) a été mis en place en décembre 2019\\nsous l’égide du Comité consultatif national d’éthique (CCNE) à la demande du Premier ministre de\\nla République Française. Il est constitué de 27 personnes d’horizons différents, issues du monde\\nacadémique et politique, des entreprises ou de la société civile, pour aborder de manière globale les\\nenjeux éthiques du numérique et donc de l’IA en particulier. Son rôle est à la fois d’élaborer des avis\\nsur les saisines qui lui sont adressées et d’effectuer un travail de veille pour éclairer les prises de\\ndécision individuelles et collectives.\\nLes trois saisines initiales du gouvernement portent sur les agents conversationnels, le véhicule\\nautonome, et le diagnostic médical à l’ère de l’intelligence artificielle. Mais la crise sanitaire de la\\nCovid-19 a entraîné une réflexion, des communiqués et des avis sur les usages massifs du\\nnumérique dans un contexte de confinement et sur l’utilisation du numérique dans une stratégie de\\ndéconfinement.\\nLe CNPEN souhaite collaborer étroitement avec d’autres comités éthiques de pays européens pour\\ncontribuer à une approche européenne des enjeux éthiques du numérique. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': 'd99d901001e580e36295435ebf1e6231', 'range': (1054, 1219)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '71615e490f873ff8baab68924fc35cc6'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Le CNPEN souhaite collaborer étroitement avec d’autres comités éthiques de pays européens pour\\ncontribuer à une approche européenne des enjeux éthiques du numérique. Il est donc\\nparticulièrement soucieux que l’approche proposée par Le Livre Blanc soit conforme à des valeurs\\npartagées mais aussi à des conditions de vies partagées par le plus grand nombre.\\nLa réponse du CNPEN à cette consultation porte sur les enjeux éthiques de l’IA comprise comme la\\npartie des sciences et technologies du numérique intégrant tout particulièrement l’apprentissage\\nmachine (cf. la caractérisation proposée dans le livre blanc).\\nConsultation sur le Livre blanc sur l’intelligence artificielle\\nUne approche européenne\\nContribution du\\nComité National Pilote d’Éthique du Numérique (CNPEN, France)\\n14 Juin 2020\\nRef. Ares(2020)3356817 - 26/06/2020\\x0c2\\nSection 1 – Un écosystème d’excellence\\nAfin de construire un écosystème d’excellence capable de soutenir le développement et de favoriser l’adoption de l’IA dans\\ntous les secteurs économiques de l’UE, le Livre blanc propose une série d’actions.\\nSelon vous, quelle est l’importance des six actions proposées à la section 4 du Livre\\nblanc sur l’IA (de 1 à 5: 1 n’est pas important du tout, 5 est très important)?\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 1, 'page': 1, '_split_overlap': [{'doc_id': '71615e490f873ff8baab68924fc35cc6', 'range': (0, 165)}, {'doc_id': '502a353f83ddf912f7131bcf887ffeb6', 'range': (1076, 1241)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd99d901001e580e36295435ebf1e6231'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Selon vous, quelle est l’importance des six actions proposées à la section 4 du Livre\\nblanc sur l’IA (de 1 à 5: 1 n’est pas important du tout, 5 est très important)?\\n1 - Pas\\nimportant\\ndu tout\\n2 - Pas\\nimportant\\n3 -\\nNeutre\\n4 -\\nImportant\\n5 -Très\\nimportant\\nSans avis\\nCoopération avec les États\\nmembres X\\nCibler les efforts de la\\ncommunauté de la\\nrecherche et de l’innovation\\nX\\nCompétences\\nX\\nAccorder une place de choix\\naux PME X\\nPartenariat avec le secteur\\nprivé X\\nEncourager le secteur\\npublic à adopter l’IA X\\nA. Coopération avec les Etats Membres (5) : Le CNPEN comprend de nombreuses\\npersonnes appartenant à la communauté de la recherche et de l’innovation dans le domaine\\nde l’IA en particulier. Elles proviennent principalement d’universités et d’institutions du\\nsecteur public mais sont souvent engagées dans des partenariats avec le secteur privé aux\\nniveaux français, européen et international. De ce point de vue le CNPEN considère qu’il est\\ntrès important de cibler les efforts de la communauté de la recherche et de l’innovation\\ndans le cadre d’une coopération privilégiée entre États membres de l’UE.\\nB. Cibler les efforts (5) : Voir la réponse précédente.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 2, 'page': 2, '_split_overlap': [{'doc_id': 'd99d901001e580e36295435ebf1e6231', 'range': (0, 165)}, {'doc_id': '5e05869d3723795224d4dbd509ab4502', 'range': (899, 1164)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '502a353f83ddf912f7131bcf887ffeb6'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: De ce point de vue le CNPEN considère qu’il est\\ntrès important de cibler les efforts de la communauté de la recherche et de l’innovation\\ndans le cadre d’une coopération privilégiée entre États membres de l’UE.\\nB. Cibler les efforts (5) : Voir la réponse précédente.\\nC. Compétences (5) : La question du développement des compétences en IA est\\nimportante. Même si les États membres ont déjà des compétences académiques et des\\nformations de qualité et reconnues internationalement il faut renforcer les compétences\\nacadémiques et les centres interdisciplinaires pour mieux gérer les applications en IA\\nD. Accorder une place de choix aux PME (5) : Il est aussi crucial d’accorder une place\\nde choix aux PME pour les aider à maîtriser et adopter les outils de l’IA dans leurs\\ndomaines d’activités tout en veillant à ce que l’accès au financement via Invest EU\\nprenne en compte des critères d’usage de l’IA en conformité avec les enjeux éthiques et\\nsociétaux dans le cadre de la transition écologique et solidaire pour l’UE.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 3, 'page': 2, '_split_overlap': [{'doc_id': '502a353f83ddf912f7131bcf887ffeb6', 'range': (0, 265)}, {'doc_id': '2d84abbffaedee492a1a6caaf47c2003', 'range': (354, 1018)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5e05869d3723795224d4dbd509ab4502'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Même si les États membres ont déjà des compétences académiques et des\\nformations de qualité et reconnues internationalement il faut renforcer les compétences\\nacadémiques et les centres interdisciplinaires pour mieux gérer les applications en IA\\nD. Accorder une place de choix aux PME (5) : Il est aussi crucial d’accorder une place\\nde choix aux PME pour les aider à maîtriser et adopter les outils de l’IA dans leurs\\ndomaines d’activités tout en veillant à ce que l’accès au financement via Invest EU\\nprenne en compte des critères d’usage de l’IA en conformité avec les enjeux éthiques et\\nsociétaux dans le cadre de la transition écologique et solidaire pour l’UE.\\nE. Partenariat avec le secteur privé (5) : Concernant le partenariat avec le secteur privé,\\nle CNPEN est attentif aux enjeux de souveraineté nationale et européenne (voir aussi le\\nrapport1 de la CERNA) et au risque d’érosion du patrimoine que constituent les données\\npubliques si elles sont accessibles au secteur privé sans garanties suffisantes contre\\n1 https://www.allistene.fr/files/2018/10/55708_AvisSouverainete-CERNA-2018.pdf\\x0c3\\nd’éventuels usages détournés. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 4, 'page': 2, '_split_overlap': [{'doc_id': '5e05869d3723795224d4dbd509ab4502', 'range': (0, 664)}, {'doc_id': '3afb198b5b5d0cab3151f9842695411a', 'range': (665, 1129)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2d84abbffaedee492a1a6caaf47c2003'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: E. Partenariat avec le secteur privé (5) : Concernant le partenariat avec le secteur privé,\\nle CNPEN est attentif aux enjeux de souveraineté nationale et européenne (voir aussi le\\nrapport1 de la CERNA) et au risque d’érosion du patrimoine que constituent les données\\npubliques si elles sont accessibles au secteur privé sans garanties suffisantes contre\\n1 https://www.allistene.fr/files/2018/10/55708_AvisSouverainete-CERNA-2018.pdf\\x0c3\\nd’éventuels usages détournés. On pense en particulier aux données de santé, mais cela peut\\nconcerner d’autres corpus de données par exemple sur la mobilité des personnes et des\\nbiens, l’habitat et plus généralement toutes les ressources vitales. Il est donc indispensable\\nd’assortir ces partenariats public-privé de règles de transparence, de contrôle et de\\nréversibilité, voire de réciprocité d’accès à d’autres données.\\nF. Encourager le secteur public à adopter l’IA (5) : Enfin le CNPEN considère qu’il est\\neffectivement souhaitable d’encourager le secteur public à adopter l’IA. Il existe plusieurs\\navantages à cette adoption : tout d’abord, l’acquisition de compétences en IA par\\nl’administration, puis l’acculturation de nos concitoyens grâce à la multiplication des\\ninteractions avec l’IA. Enfin, l’adoption de la technologie par l’administration stimulera\\nl’innovation et la commande publique en matière d’IA, qui dynamisera potentiellement le\\nsecteur des start-ups. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 5, 'page': 2, '_split_overlap': [{'doc_id': '2d84abbffaedee492a1a6caaf47c2003', 'range': (0, 464)}, {'doc_id': '46f90a56ecfdd28d863b7afda943c16', 'range': (1232, 1409)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3afb198b5b5d0cab3151f9842695411a'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Enfin, l’adoption de la technologie par l’administration stimulera\\nl’innovation et la commande publique en matière d’IA, qui dynamisera potentiellement le\\nsecteur des start-ups. Cependant, l’IA devra être un outil d’amélioration du service et non un\\nremplacement des personnes qui le fournissent, et l’interaction humaine devrait rester la\\nnorme en particulier pour les usagers qui en auraient besoin dont les personnes isolées ou\\nvulnérables ou ayant des difficultés d’accès aux interfaces numériques ou de maîtrise des\\noutils numériques.\\nD’autres actions devraient-elles être envisagées?\\nLe CNPEN considère que l’Europe a un rôle particulier à jouer dans la coopération internationale\\nexterne à l’Union Européenne, en particulier avec les pays ACP (Afrique-Caraibes-Pacifique), pour\\nle développement d’une IA de confiance et conforme aux valeurs éthiques partagées par les États\\nmembres et mentionnées dans le Livre Blanc (section 4 – H aspects internationaux). Pour mieux\\npeser dans les négociations dans les grandes institutions internationales (ONU, G7, G20, OCDE,\\nUNESCO, OMC, UIT etc.) il faudrait que les États membres de l’UE y parlent d’une même voix en\\nse coordonnant au préalable.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 6, 'page': 3, '_split_overlap': [{'doc_id': '3afb198b5b5d0cab3151f9842695411a', 'range': (0, 177)}, {'doc_id': '34426069f8e76ff2ca267deb5cb5133e', 'range': (964, 1192)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '46f90a56ecfdd28d863b7afda943c16'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Pour mieux\\npeser dans les négociations dans les grandes institutions internationales (ONU, G7, G20, OCDE,\\nUNESCO, OMC, UIT etc.) il faudrait que les États membres de l’UE y parlent d’une même voix en\\nse coordonnant au préalable.\\nUne révision du plan coordonné dans le domaine de l’IA (action 1)\\nEn tenant compte des résultats de la consultation publique sur le Livre blanc, la Commission proposera aux États membres\\nune révision du plan coordonné en vue d’une adoption d’ici à la fin 2020\\nSelon vous, dans quelle mesure est-il important, dans chacun de ces domaines,\\nd’aligner les politiques et de renforcer la coordination, comme décrit à la section 4.A\\ndu Livre blanc (de 1 à 5: 1 n’est pas important du tout, 5 est très important) ?\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 7, 'page': 3, '_split_overlap': [{'doc_id': '46f90a56ecfdd28d863b7afda943c16', 'range': (0, 228)}, {'doc_id': '1603116119ee29f05ff52fb0e62f52ae', 'range': (229, 735)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '34426069f8e76ff2ca267deb5cb5133e'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Une révision du plan coordonné dans le domaine de l’IA (action 1)\\nEn tenant compte des résultats de la consultation publique sur le Livre blanc, la Commission proposera aux États membres\\nune révision du plan coordonné en vue d’une adoption d’ici à la fin 2020\\nSelon vous, dans quelle mesure est-il important, dans chacun de ces domaines,\\nd’aligner les politiques et de renforcer la coordination, comme décrit à la section 4.A\\ndu Livre blanc (de 1 à 5: 1 n’est pas important du tout, 5 est très important) ?\\n1 - Pas\\nimportant\\ndu tout\\n2 – Pas\\nimportant\\n3 –\\nNeutre\\n4 -\\nImportant\\n5 – Très\\nimportant\\nSans\\navis\\nRenforcer l’excellence dans la\\nrecherche X\\nÉtablir des centres d’essai\\nconstituant une référence\\nmondiale pour l’IA\\nX\\nEncourager le secteur public à\\nadopter l’IA X\\nAccroître le financement des\\nstart-ups innovantes dans le\\ndomaine de l’IA\\nX\\nDévelopper les compétences en\\nmatière d’IA et adapter les\\nprogrammes de formation\\nexistants\\nX\\x0c4\\nConstruire l’espace\\neuropéen des données X\\nEn cohérence avec ses réponses aux questions précédentes, le CNPEN considère qu’il est très\\nimportant de renforcer l’excellence dans la recherche, d’établir des centres d’essai constituant\\nune référence mondiale pour l’IA, d’encourager le secteur public à adopter l’IA et d’accroître le\\nfinancement des start-ups innovantes dans le domaine de l’IA,\\nDe même le développement des compétences en matière d’IA et l’adaptation des programmes\\nde formation IA sont jugés très important non seulement pour renforcer les compétences\\nacadémiques, mais aussi pour favoriser l’adoption de l’IA à bon escient par les entreprises, en\\nparticulier les PME, et par le secteur public, et surtout pour permettre l’acculturation des\\npopulations ayant des difficultés de maîtrise des outils numériques.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 8, 'page': 3, '_split_overlap': [{'doc_id': '34426069f8e76ff2ca267deb5cb5133e', 'range': (0, 506)}, {'doc_id': 'b12cf79b97908406696626a48aa40429', 'range': (507, 1765)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1603116119ee29f05ff52fb0e62f52ae'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: 1 - Pas\\nimportant\\ndu tout\\n2 – Pas\\nimportant\\n3 –\\nNeutre\\n4 -\\nImportant\\n5 – Très\\nimportant\\nSans\\navis\\nRenforcer l’excellence dans la\\nrecherche X\\nÉtablir des centres d’essai\\nconstituant une référence\\nmondiale pour l’IA\\nX\\nEncourager le secteur public à\\nadopter l’IA X\\nAccroître le financement des\\nstart-ups innovantes dans le\\ndomaine de l’IA\\nX\\nDévelopper les compétences en\\nmatière d’IA et adapter les\\nprogrammes de formation\\nexistants\\nX\\x0c4\\nConstruire l’espace\\neuropéen des données X\\nEn cohérence avec ses réponses aux questions précédentes, le CNPEN considère qu’il est très\\nimportant de renforcer l’excellence dans la recherche, d’établir des centres d’essai constituant\\nune référence mondiale pour l’IA, d’encourager le secteur public à adopter l’IA et d’accroître le\\nfinancement des start-ups innovantes dans le domaine de l’IA,\\nDe même le développement des compétences en matière d’IA et l’adaptation des programmes\\nde formation IA sont jugés très important non seulement pour renforcer les compétences\\nacadémiques, mais aussi pour favoriser l’adoption de l’IA à bon escient par les entreprises, en\\nparticulier les PME, et par le secteur public, et surtout pour permettre l’acculturation des\\npopulations ayant des difficultés de maîtrise des outils numériques.\\nQuant à encourager le secteur public à adopter l’IA, le CNPEN émet la même réserve que\\nprécédemment, c’est-à-dire que cette adoption soit justifiée et maintienne une relation humaine\\nentre l’administration et les citoyens, en particulier les personnes isolées ou vulnérables et ayant\\ndes difficultés d’accès aux interfaces numériques ou de maîtrise des outils numériques.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 9, 'page': 3, '_split_overlap': [{'doc_id': '1603116119ee29f05ff52fb0e62f52ae', 'range': (0, 1258)}, {'doc_id': 'f19a55acade671689a6558dbf7fb14c2', 'range': (1259, 1630)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b12cf79b97908406696626a48aa40429'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Quant à encourager le secteur public à adopter l’IA, le CNPEN émet la même réserve que\\nprécédemment, c’est-à-dire que cette adoption soit justifiée et maintienne une relation humaine\\nentre l’administration et les citoyens, en particulier les personnes isolées ou vulnérables et ayant\\ndes difficultés d’accès aux interfaces numériques ou de maîtrise des outils numériques.\\nEnfin la construction d’un espace européen des données est très importante pour i) éviter la\\nfragmentation des systèmes nationaux, ii) élaborer un standard européen pour le format des\\ndonnées, facteur d’interopérabilité et de rayonnement international, et iii) présenter un front commun\\nplus fort dans la capacité de négociation de l’UE avec de grands acteurs privés extra-européens.\\nCet espace européen des données devra être soumis au contrôle démocratique du Parlement\\nEuropéen, au contrôle des organes de supervision et aux avis consultatifs d’autres instances\\neuropéennes telles que le Comité Economique et Social Européen (CESE).\\nD’autres domaines devraient-ils être envisagés?\\nLe CNPEN souhaiterait que les pays membres de l’UE se dotent de comités consultatifs nationaux\\nd’éthique du numérique et de l’IA et que ceux-ci se coordonnent au sein d’un comité consultatif\\neuropéen.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 10, 'page': 4, '_split_overlap': [{'doc_id': 'b12cf79b97908406696626a48aa40429', 'range': (0, 371)}, {'doc_id': 'f6102cf1fac47f65f5e25424be0ce76a', 'range': (1056, 1256)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f19a55acade671689a6558dbf7fb14c2'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Le CNPEN souhaiterait que les pays membres de l’UE se dotent de comités consultatifs nationaux\\nd’éthique du numérique et de l’IA et que ceux-ci se coordonnent au sein d’un comité consultatif\\neuropéen.\\nUne communauté de la recherche et de l’innovation unie et renforcée qui vise\\nl’excellence\\nIl sera essentiel d’unir les forces à tous les niveaux, de la recherche fondamentale jusqu’au déploiement, afin de surmonter\\nla fragmentation et de créer des synergies entre les réseaux d’excellence existants.\\nSelon vous, quelle est l’importance des trois actions proposées dans les sections\\n4.B, 4.C et 4.E du Livre blanc sur l’IA (de 1 à 5: 1 n’est pas important du tout, 5 est\\ntrès important)?\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 11, 'page': 4, '_split_overlap': [{'doc_id': 'f19a55acade671689a6558dbf7fb14c2', 'range': (0, 200)}, {'doc_id': '98c05214dd0f4a97632b80bde329923e', 'range': (501, 687)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f6102cf1fac47f65f5e25424be0ce76a'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Selon vous, quelle est l’importance des trois actions proposées dans les sections\\n4.B, 4.C et 4.E du Livre blanc sur l’IA (de 1 à 5: 1 n’est pas important du tout, 5 est\\ntrès important)?\\n1 - Pas\\nimporta\\nnt du\\ntout\\n2 - Pas\\nimportant\\n3 -\\nNeutre\\n4 -\\nImporta\\nnt\\n5 -\\nTrès\\nimportant\\nSans\\navis\\nSoutenir l’établissement\\nd’un centre «phare» pour la\\nrecherche, qui soit de\\ncalibre mondial et capable\\nd’attirer les cerveaux les\\nplus brillants\\nX\\nCréer un réseau des\\ncentres d’excellence\\nexistants dans le domaine\\nde la recherche en IA\\nX\\x0c5\\nMettre en place un\\npartenariat public-privé\\npour la recherche\\nindustrielle\\nX\\nA. Soutenir l’établissement d’un centre «phare» (3) : Le CNPEN est réservé sur la création\\nd’un seul « centre phare » européen sur l’IA qui devrait coordonner les divers centres de\\ncompétence actuels. Plusieurs instituts de recherche européens en IA ont déjà une masse\\ncritique et pourraient constituer autant de « centres phares » interdisciplinaires européens\\nde calibre mondial sur l’IA.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 12, 'page': 4, '_split_overlap': [{'doc_id': 'f6102cf1fac47f65f5e25424be0ce76a', 'range': (0, 186)}, {'doc_id': 'adf417e6aa283c0b16d5e543838d6ab8', 'range': (805, 994)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '98c05214dd0f4a97632b80bde329923e'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Plusieurs instituts de recherche européens en IA ont déjà une masse\\ncritique et pourraient constituer autant de « centres phares » interdisciplinaires européens\\nde calibre mondial sur l’IA.\\nB. Créer un réseau des centres d’excellence (5) : En revanche il paraît très important, plus\\nopérationnel et efficace de créer un réseau des centres d’excellence existants dans le\\ndomaine de la recherche en IA.\\nC. Mettre en place un partenariat public-privé (5) : La mise en place d’un partenariat\\npublic-privé pour la recherche industrielle est jugée importante pourvu que les relations\\nétablies avec les grands groupes privés internationaux soient suivies et auditées pour\\ns’assurer que la recherche industrielle menée en Europe soit bien au service d’une\\nsouveraineté européenne.\\nD’autres actions visant à renforcer la communauté de la recherche et de l’innovation\\ndevraient-elles se voir accorder une priorité?\\nLe CNPEN encourage les programmes de recherche collaborative, multidisciplinaires et à long\\nterme, et pas uniquement les projets individuels ou des projets ciblés à court terme.\\nUne attention particulière pour les petites et moyennes entreprise (PME)\\nLa Commission collaborera avec les États membres pour faire en sorte qu’au moins un pôle d’innovation numérique par\\nÉtat membre ait un niveau élevé de spécialisation en IA.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 13, 'page': 5, '_split_overlap': [{'doc_id': '98c05214dd0f4a97632b80bde329923e', 'range': (0, 189)}, {'doc_id': 'f5901e1ebe98cf09976972e174ac0349', 'range': (1083, 1328)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'adf417e6aa283c0b16d5e543838d6ab8'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Une attention particulière pour les petites et moyennes entreprise (PME)\\nLa Commission collaborera avec les États membres pour faire en sorte qu’au moins un pôle d’innovation numérique par\\nÉtat membre ait un niveau élevé de spécialisation en IA.\\nSelon vous, quelle est l’importance de chacune de ces missions des pôles\\nd’innovation numérique spécialisés mentionnés à la section 4.D du Livre blanc en ce\\nqui concerne les PME (de 1 à 5: 1 n’est pas important du tout, 5 est très important)?\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 14, 'page': 5, '_split_overlap': [{'doc_id': 'adf417e6aa283c0b16d5e543838d6ab8', 'range': (0, 245)}, {'doc_id': 'dad57c3e6922c0abf329fe5562a39807', 'range': (246, 488)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f5901e1ebe98cf09976972e174ac0349'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Selon vous, quelle est l’importance de chacune de ces missions des pôles\\nd’innovation numérique spécialisés mentionnés à la section 4.D du Livre blanc en ce\\nqui concerne les PME (de 1 à 5: 1 n’est pas important du tout, 5 est très important)?\\n1 - Pas\\nimporta\\nnt du\\ntout\\n2 -Pas\\nimportant\\n3 -\\nNeutre\\n4 -\\nImporta\\nnt\\n5 -\\nTrès\\nimportant\\nSans\\navis\\nContribuer à sensibiliser\\nles PME aux avantages\\npotentiels de l’IA\\nX\\nDonner accès aux centres\\nd’essai et de référence X\\nPromouvoir le transfert de\\nconnaissances et soutenir\\nle développement de\\nl’expertise en matière d’IA\\npour les PME\\nX\\x0c6\\nSoutenir des partenariats\\nentre les PME, les\\ngrandes entreprises et les\\nuniversités autour de\\nprojets d’IA\\nX\\nFournir des informations\\nsur le financement en\\nfonds propres pour les\\nstart-ups dans le domaine\\nde l’IA\\nX\\nLe CNPEN souligne l’importance de sensibiliser les PME non seulement aux avantages potentiels\\nde l’IA, mais aussi aux risques liés à l’IA, aux aspects éthiques et juridiques de la conception et de\\nl’usage des outils numériques et des algorithmes d’IA et à leurs impacts sociétaux. L’IA n’est pas\\ntoujours la solution la plus appropriée. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 15, 'page': 5, '_split_overlap': [{'doc_id': 'f5901e1ebe98cf09976972e174ac0349', 'range': (0, 242)}, {'doc_id': 'ff2ae112572bb6a971d739723c7a45fb', 'range': (243, 1131)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'dad57c3e6922c0abf329fe5562a39807'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: 1 - Pas\\nimporta\\nnt du\\ntout\\n2 -Pas\\nimportant\\n3 -\\nNeutre\\n4 -\\nImporta\\nnt\\n5 -\\nTrès\\nimportant\\nSans\\navis\\nContribuer à sensibiliser\\nles PME aux avantages\\npotentiels de l’IA\\nX\\nDonner accès aux centres\\nd’essai et de référence X\\nPromouvoir le transfert de\\nconnaissances et soutenir\\nle développement de\\nl’expertise en matière d’IA\\npour les PME\\nX\\x0c6\\nSoutenir des partenariats\\nentre les PME, les\\ngrandes entreprises et les\\nuniversités autour de\\nprojets d’IA\\nX\\nFournir des informations\\nsur le financement en\\nfonds propres pour les\\nstart-ups dans le domaine\\nde l’IA\\nX\\nLe CNPEN souligne l’importance de sensibiliser les PME non seulement aux avantages potentiels\\nde l’IA, mais aussi aux risques liés à l’IA, aux aspects éthiques et juridiques de la conception et de\\nl’usage des outils numériques et des algorithmes d’IA et à leurs impacts sociétaux. L’IA n’est pas\\ntoujours la solution la plus appropriée. Ceci implique en particulier de développer et proposer des\\nformations spécifiques.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 16, 'page': 5, '_split_overlap': [{'doc_id': 'dad57c3e6922c0abf329fe5562a39807', 'range': (0, 888)}, {'doc_id': '8ee5a0054f32bb807c7cd696746b673f', 'range': (833, 971)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ff2ae112572bb6a971d739723c7a45fb'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: L’IA n’est pas\\ntoujours la solution la plus appropriée. Ceci implique en particulier de développer et proposer des\\nformations spécifiques.\\nUne expertise interne aux PME en matière d’IA étant difficile à entretenir et capitaliser le CNPEN\\nconsidère que l’accès direct des PME aux centres d’essai et de référence leur permettrait d’une\\npart d’expérimenter et d’autre part d’interagir avec les innovations élaborées par d’autres.\\nLes partenariats entre PME, grandes entreprises et universités autour de projets d’IA sont\\nfondamentaux pour le transfert de connaissances et le développement d’expertises et de\\nconseils en matière d’IA qui puissent être mis à disposition des PME.\\nSection 2 – Un écosystème de confiance\\nLe chapitre 5 du Livre blanc définit des options en vue d’un cadre réglementaire pour l’IA.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 17, 'page': 6, '_split_overlap': [{'doc_id': 'ff2ae112572bb6a971d739723c7a45fb', 'range': (0, 138)}, {'doc_id': '5397f912e707548bc4bcdce285af5368', 'range': (675, 805)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8ee5a0054f32bb807c7cd696746b673f'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Section 2 – Un écosystème de confiance\\nLe chapitre 5 du Livre blanc définit des options en vue d’un cadre réglementaire pour l’IA.\\nSelon vous, quelle est l’importance des préoccupations suivantes concernant l’IA (de\\n1 à 5 : 1 n’est pas important du tout, 5 est très important)\\n1 - Pas\\nimporta\\nnt du\\ntout\\n2 - Pas\\nimportant\\n3 -\\nNeutre\\n4 -\\nImporta\\nnt\\n5 -\\nTrès\\nimportant\\nSans\\navis\\nL’IA peut compromettre\\nla sécurité X\\nL’IA peut porter atteinte aux\\ndroits fondamentaux\\n(comme la dignité humaine,\\nle respect de la vie privée,\\nla protection des données,\\nla liberté d’ expression, les\\ndroits des travailleurs, etc.)\\nX\\nL’utilisation de l’IA\\npeut entraîner des\\nrésultats\\ndiscriminatoires\\nX\\nL’IA peut prendre des\\nmesures dont les motifs\\nne peuvent pas être\\nexpliqués\\nX\\x0c7\\nIl peut être plus difficile\\npour les personnes ayant\\nsubi un préjudice du fait\\nde l'utilisation de l’IA\\nd'obtenir réparation\\nX\\nL’IA n’est pas toujours exacte\\nX\\nA. L’IA peut compromettre la sécurité (5) : La relation entre l’IA et la sécurité est\\nambivalente.\\nD’un côté les technologies de l'IA peuvent présenter de nouveaux risques pour la sécurité. Au-\\ndelà des exemples bien connus (par ex. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 18, 'page': 6, '_split_overlap': [{'doc_id': '8ee5a0054f32bb807c7cd696746b673f', 'range': (0, 130)}, {'doc_id': '99b0fb3532245585ddfcb6cd73750c7e', 'range': (1019, 1152)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5397f912e707548bc4bcdce285af5368'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: D’un côté les technologies de l'IA peuvent présenter de nouveaux risques pour la sécurité. Au-\\ndelà des exemples bien connus (par ex. un accident lié au dysfonctionnement d’un véhicule\\nautonome) on peut citer aussi le risque que l’IA puisse être utilisée par des pirates pour\\ncompromettre la sécurité en repérant, à partir de données, les habitudes des usagers, par\\nexemple les mots de passe qu’ils ont l’habitude d’utiliser, etc. L’IA peut aussi être utilisée pour\\npasser au crible des défenses informatiques et trouver des failles. Une IA digne de confiance\\nnécessite des systèmes et algorithmes suffisamment sûrs, fiables et robustes pour répondre à\\ndes exigences de cybersécurité élevés en résistant aux attaques directes et aux tentatives plus\\nsubtiles de manipulation des données ou des algorithmes proprement dits. Ils doivent être\\nfondés sur des mécanismes de « safety by design » et adopter les précautions nécessaires\\ncontre les risques de mésusages.\\nDe l’autre côté, et de façon plus positive, l’IA peut contribuer à renforcer la sécurité dans un\\ncertain nombre de domaines. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 19, 'page': 7, '_split_overlap': [{'doc_id': '5397f912e707548bc4bcdce285af5368', 'range': (0, 133)}, {'doc_id': 'b8b56de838416aad81ec6d44a896a260', 'range': (962, 1086)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '99b0fb3532245585ddfcb6cd73750c7e'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: De l’autre côté, et de façon plus positive, l’IA peut contribuer à renforcer la sécurité dans un\\ncertain nombre de domaines. À titre d’exemple des systèmes d’identité numérique, à condition\\nqu’ils soient fiables et déployés sans biais liés au genre, au handicap, aux caractéristiques\\nphysiques ou l’origine ethnique, pourraient grandement améliorer la sécurité d’authentification,\\nde connexion et de transactions. Par ailleurs, l’IA permet d’analyser tous les événements et de\\ndistinguer, parmi ceux-ci, les tentatives pour faire une brèche dans la sécurité des systèmes.\\nB. L’IA peut porter atteinte aux droits fondamentaux (5) : La mauvaise utilisation de l’IA\\npourrait porter atteinte à plusieurs droits fondamentaux. Le déploiement de certains\\nsystèmes de « reconnaissance émotionnelle », sans bases scientifiques solides et à des\\nfins diverses, ou la mise en place de systèmes de surveillance sophistiqués fondés sur des\\ntechniques de reconnaissance faciale, illustrent certains risques pour les droits\\nfondamentaux. Le scandale de Cambridge Analytica a par ailleurs montré qu’une mauvaise\\nutilisation des données et de l’IA pourrait déstabiliser les socles démocratiques de nos\\nsociétés européennes et servir à des opérations d’influence. Le CNPEN considère que\\nl’Europe doit prêter la plus grande attention à ces risques.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 20, 'page': 7, '_split_overlap': [{'doc_id': '99b0fb3532245585ddfcb6cd73750c7e', 'range': (0, 124)}, {'doc_id': '7ae61033166daa13330a079f163831f6', 'range': (1022, 1328)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b8b56de838416aad81ec6d44a896a260'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Le scandale de Cambridge Analytica a par ailleurs montré qu’une mauvaise\\nutilisation des données et de l’IA pourrait déstabiliser les socles démocratiques de nos\\nsociétés européennes et servir à des opérations d’influence. Le CNPEN considère que\\nl’Europe doit prêter la plus grande attention à ces risques.\\nC. L’utilisation de l’IA peut entraîner des résultats discriminatoires (5) : Il s’agit ici d’une\\nprolongation du point précédent. Les données utilisées par les systèmes d’IA peuvent être\\nbiaisées par des partis pris ou par des bases de données incomplètes ou reflétant des\\ndiscriminations ou des biais humains. Les biais peuvent être présents à tous les stades de la\\nconception et du déploiement (dont l’usage) des systèmes algorithmiques. De manière\\nsimilaire, la manière dont les systèmes d’IA et les algorithmes sont construits peut\\négalement être entachée de biais ou aboutir à des inégalités de traitement, voire les\\nsystématiser ou les amplifier. Les systèmes de l’IA doivent être fondés sur le respect de la\\ndignité humaine et de l’égalité de traitement, sans discrimination aucune, tout en prêtant\\nune attention particulière à la sous-représentation de certaines catégories de population\\n(femmes, certains groupes sociaux…) et à la situation des personnes vulnérables ainsi qu’aux\\nquestions d’accessibilité. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 21, 'page': 7, '_split_overlap': [{'doc_id': 'b8b56de838416aad81ec6d44a896a260', 'range': (0, 306)}, {'doc_id': 'fba774b2e97cbabe13e5c9885537858', 'range': (960, 1322)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7ae61033166daa13330a079f163831f6'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Les systèmes de l’IA doivent être fondés sur le respect de la\\ndignité humaine et de l’égalité de traitement, sans discrimination aucune, tout en prêtant\\nune attention particulière à la sous-représentation de certaines catégories de population\\n(femmes, certains groupes sociaux…) et à la situation des personnes vulnérables ainsi qu’aux\\nquestions d’accessibilité. En même temps, et de façon plus optimiste, le CNPEN considère\\nque l’utilisation de l’IA peut aussi contribuer à éliminer les biais humains et à améliorer la\\nsituation des personnes handicapées, vulnérables ou à autonomie réduite.\\nD. L’IA peut prendre des mesures dont les motifs ne peuvent pas être expliqués (5) :\\nL’explicabilité est essentielle, surtout quand l’utilisation de l’IA aboutit à des décisions affectant\\ndes personnes et leurs droits. Elle est indispensable, par exemple, pour justifier les décisions\\x0c8\\ncalculées dans les systèmes critiques, les systèmes d’affectation dans l’enseignement, l’aide\\nau recrutement, la justice, etc. L’explicabilité contribuera à construire la confiance des citoyens\\nà l’égard de ces technologies. Actuellement, un champ de recherche émerge afin d’améliorer\\nl’explicabilité et la transparence des systèmes d’apprentissage ainsi que leur adaptation en\\ncontexte et l’adéquation de l’apprentissage à ce qu’en attend l’humain. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 22, 'page': 7, '_split_overlap': [{'doc_id': '7ae61033166daa13330a079f163831f6', 'range': (0, 362)}, {'doc_id': 'c800f4a1ca16b84a2c551e1323ada5d2', 'range': (1105, 1329)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fba774b2e97cbabe13e5c9885537858'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Actuellement, un champ de recherche émerge afin d’améliorer\\nl’explicabilité et la transparence des systèmes d’apprentissage ainsi que leur adaptation en\\ncontexte et l’adéquation de l’apprentissage à ce qu’en attend l’humain. Ainsi, il ne s’agit plus\\nseulement de construire des modèles par apprentissage machine sans comprendre mais bien\\nd’essayer de les expliquer. Voir l’avis de la CERNA, publiée en juin 2017, sur l’Ethique de la\\nrecherche en apprentissage machine2.\\nE. Il peut être plus difficile pour les personnes ayant subi un préjudice du fait de\\nl'utilisation de l’IA d'obtenir réparation (5) : Il s’agit d’une préoccupation importante qui\\nappelle en effet un certain nombre de points d’attention s’agissant de la réparation non\\nseulement du préjudice subi à titre individuel mais également de la réparation du préjudice\\ncollectif. Les règles existantes ne permettent pas nécessairement de signaler les discriminations\\nsubies par un groupe d’individus visé par un traitement algorithmique, au-delà de la somme des\\nindividus. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 23, 'page': 8, '_split_overlap': [{'doc_id': 'fba774b2e97cbabe13e5c9885537858', 'range': (0, 224)}, {'doc_id': '93e488acf4db47e97bd8174361d2e87b', 'range': (841, 1033)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c800f4a1ca16b84a2c551e1323ada5d2'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Les règles existantes ne permettent pas nécessairement de signaler les discriminations\\nsubies par un groupe d’individus visé par un traitement algorithmique, au-delà de la somme des\\nindividus. Comme le soulignent certains rapports (voir par exemple le rapport de la CNIL3 ou le\\nrapport de la mission présidée par Cédric Villani4), plusieurs algorithmes fonctionnent en effet\\nnon à l'échelle de la personne mais à celle du groupe et les données ne sont pas tant granulaires\\nque réticulaires, c'est-à-dire organisées en réseau. Ils peuvent dès lors être exploités afin de\\nproduire des corrélations concernant des segments ou groupes d'individus, potentiellement\\nexposés à certains risques de discrimination. Cela appelle par conséquent une réflexion sur ces\\nenjeux éthiques s’agissant de cette dimension collective et les solutions possibles.\\nF. L’IA n’est pas toujours exacte (5) : Les techniques d’apprentissage machines ne sont en\\ngénéral pas exactes au sens propre, mais peuvent fournir des approximations qui peuvent être\\nintéressantes. Par ailleurs, il va de soi qu’un système qui est systématiquement faux ou\\napproximatif est problématique. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 24, 'page': 8, '_split_overlap': [{'doc_id': 'c800f4a1ca16b84a2c551e1323ada5d2', 'range': (0, 192)}, {'doc_id': '666146ab6d7b73a8bf3f56f01a81b7ef', 'range': (841, 1145)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '93e488acf4db47e97bd8174361d2e87b'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: F. L’IA n’est pas toujours exacte (5) : Les techniques d’apprentissage machines ne sont en\\ngénéral pas exactes au sens propre, mais peuvent fournir des approximations qui peuvent être\\nintéressantes. Par ailleurs, il va de soi qu’un système qui est systématiquement faux ou\\napproximatif est problématique. Il faudrait donc prévoir des méthodes et des critères de\\nvalidation de l’apprentissage machine ainsi que des procédures de maintenance et s’intéresser\\naussi à la question importante de la reproductibilité des résultats.\\nAvez-vous d’autres préoccupations concernant l’IA qui ne sont pas mentionnées ci-\\ndessus? Veuillez préciser:\\nD’autres enjeux éthiques importants sont soulignés dans l’avis de 2017 la CERNA sur l’Ethique de\\nla recherche en apprentissage machine.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 25, 'page': 8, '_split_overlap': [{'doc_id': '93e488acf4db47e97bd8174361d2e87b', 'range': (0, 304)}, {'doc_id': '3a75ee5d597ab2e69671b23755a9185c', 'range': (615, 769)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '666146ab6d7b73a8bf3f56f01a81b7ef'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Veuillez préciser:\\nD’autres enjeux éthiques importants sont soulignés dans l’avis de 2017 la CERNA sur l’Ethique de\\nla recherche en apprentissage machine.\\nTrois problèmes de premier plan provoquent surtout des tensions éthiques : a) la spécification d’un\\nsystème d’IA qui ne peut saisir complètement et correctement la définition d’un concept en langue\\nnaturelle, d’où l’inexactitude inhérente qui induit des erreurs d’interprétation ; b) l’instabilité de\\nl’apprentissage d’un système d’IA qui ne classifiera pas « humainement » ou « correctement » une\\ndonnée qui ne faisait pas partie de son corpus d’apprentissage, provoquant de multiples problèmes\\nde sécurité; c) la vérification d’un système d’IA dont on ne peut prouver que l’apprentissage\\nrespectera un cadre prédéfini en toutes circonstances, ce qui pose des question de responsabilité).\\nPlus largement, et en continuation de la discussion sur l’explicabilité, se pose la question des actions\\n« inhumaines » de la part des systèmes d’IA, des interprétations données à ces actions par les\\nutilisateurs et des changements de comportement des utilisateurs humains qui interagissent avec\\nde tels systèmes.\\nPensez-vous que les préoccupations exprimées ci-dessus peuvent être résolues par\\nla législation européenne applicable? \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 26, 'page': 8, '_split_overlap': [{'doc_id': '666146ab6d7b73a8bf3f56f01a81b7ef', 'range': (0, 154)}, {'doc_id': 'b6fa245314239e8bce612e796aea2433', 'range': (845, 1277)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3a75ee5d597ab2e69671b23755a9185c'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Plus largement, et en continuation de la discussion sur l’explicabilité, se pose la question des actions\\n« inhumaines » de la part des systèmes d’IA, des interprétations données à ces actions par les\\nutilisateurs et des changements de comportement des utilisateurs humains qui interagissent avec\\nde tels systèmes.\\nPensez-vous que les préoccupations exprimées ci-dessus peuvent être résolues par\\nla législation européenne applicable? Dans la négative, estimez- vous qu’il devrait y\\navoir de nouvelles règles spécifiques pour les systèmes d’IA?\\n2 http://cerna-ethics-allistene.org/digitalAssets/53/53991_cerna___thique_apprentissage.pdf\\n3 https://www.cnil.fr/sites/default/files/atoms/files/cnil_rapport_garder_la_main_web.pdf\\n4 https://www.aiforhumanity.fr/pdfs/9782111457089_Rapport_Villani_accessible.pdf\\x0c9\\n• La législation actuelle est amplement suffisante\\n• La législation actuelle peut présenter quelques lacunes\\n• Une nouvelle législation s’impose\\n• Autre Sans avis\\nNous avons aujourd’hui un corpus de règles très important découlant d’instruments divers adoptés\\nau fil du temps au sein de l’Union Européenne (sans parler d’autres règles et standards\\ninternationaux). Ces règles (telles que celles contenues, par exemple, dans le RGPD) sont\\n« technologiquement neutres » (c’est à dire qu’elles ne sont pas spécifiques de technologies\\nparticulières) et restent pleinement applicables en matière d’IA. Elles constituent une bonne base de\\ndépart pour la régulation de l’IA et pour répondre aux risques susmentionnés.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 27, 'page': 8, '_split_overlap': [{'doc_id': '3a75ee5d597ab2e69671b23755a9185c', 'range': (0, 432)}, {'doc_id': '85341658d6ed1517092683091d106109', 'range': (1173, 1518)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b6fa245314239e8bce612e796aea2433'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Ces règles (telles que celles contenues, par exemple, dans le RGPD) sont\\n« technologiquement neutres » (c’est à dire qu’elles ne sont pas spécifiques de technologies\\nparticulières) et restent pleinement applicables en matière d’IA. Elles constituent une bonne base de\\ndépart pour la régulation de l’IA et pour répondre aux risques susmentionnés.\\nNéanmoins, le CNPEN considère que le cadre législatif pourrait être amélioré et ceci pour plusieurs\\nraisons.\\n• Premièrement, en l’état actuel il existe un risque de fragmentation du fait de divergences\\nnationales dans l’application des règles existantes. Il serait donc utile d’assurer\\nprogressivement une interprétation uniforme des règles existantes par les organes de\\ncontrôle, les régulateurs, voire le législateur européen. À titre d’exemple, le Comité Européen\\nde Protection des Données a un rôle important à jouer en ce qui concerne l’application du\\nRGPD en matière d’IA.\\n• Deuxièmement, il est clair que, dans certains domaines, les règles existantes pourraient ne\\npas suffire et que l’on pourrait avoir besoin d’adapter le cadre législatif existant, voire\\nd’adopter des nouvelles règles, pour faire face à un certain nombre de situations et de risques\\n(voir, par exemple, nos commentaires sur la responsabilité dans la Section 3). \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 28, 'page': 9, '_split_overlap': [{'doc_id': 'b6fa245314239e8bce612e796aea2433', 'range': (0, 345)}, {'doc_id': '6b79a6e60f39cddb2eaf725802f6c346', 'range': (925, 1285)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '85341658d6ed1517092683091d106109'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: • Deuxièmement, il est clair que, dans certains domaines, les règles existantes pourraient ne\\npas suffire et que l’on pourrait avoir besoin d’adapter le cadre législatif existant, voire\\nd’adopter des nouvelles règles, pour faire face à un certain nombre de situations et de risques\\n(voir, par exemple, nos commentaires sur la responsabilité dans la Section 3). Ceci pourrait\\nêtre particulièrement utile pour mieux protéger les droits fondamentaux ou pour améliorer le\\nrégime juridique de responsabilité afin de garantir un système plus efficace et équitable\\nd’indemnisation pour les dommages causés par l’utilisation d’IA.\\n• Enfin, le CNPEN considère qu’il est nécessaire de s’assurer que le cadre réglementaire\\nexistant tient suffisamment compte d’une série de principes éthiques nécessaires pour bâtir\\nune IA de confiance.\\nSi vous pensez que de nouvelles règles sont nécessaires pour les systèmes d’IA,\\nêtes-vous d’accord avec le fait que l’introduction d’exigences obligatoires nouvelles\\ndevrait être limitée aux applications à haut risque (dans lesquelles le préjudice\\néventuel causé par le système d’IA est particulièrement élevé)?\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 29, 'page': 9, '_split_overlap': [{'doc_id': '85341658d6ed1517092683091d106109', 'range': (0, 360)}, {'doc_id': 'c01505259ccce36cab0f0ef3c1f90260', 'range': (825, 1136)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6b79a6e60f39cddb2eaf725802f6c346'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Si vous pensez que de nouvelles règles sont nécessaires pour les systèmes d’IA,\\nêtes-vous d’accord avec le fait que l’introduction d’exigences obligatoires nouvelles\\ndevrait être limitée aux applications à haut risque (dans lesquelles le préjudice\\néventuel causé par le système d’IA est particulièrement élevé)?\\n• Oui\\n• Non\\n• Sans Avis\\n• Autre (veuillez préciser):\\nUne approche réglementaire fondée sur une analyse de risques semble justifiée, tout comme la\\npréoccupation de la Commission de ne pas s’engager dans une sur-réglementation européenne qui\\npourrait freiner l’innovation et le déploiement des effets bénéfiques multiples attendus par l’IA.\\nIl est important néanmoins d’évaluer les besoins en matière de régulation au cas par cas. Le critère\\npour l’adoption de règles pourrait ne pas être exclusivement le risque d’un préjudice\\n« particulièrement élevé » mais aussi d’autres critères, y compris un risque important de violation\\ndes principes éthiques. Comme expliqué en introduction, les saisines initiales du CNPEN concernent\\ntrois domaines dont deux seulement (santé et véhicules connectés) semblent répondre à la définition\\nde « haut risque » de la Commission. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 30, 'page': 9, '_split_overlap': [{'doc_id': '6b79a6e60f39cddb2eaf725802f6c346', 'range': (0, 311)}, {'doc_id': '1c4f03d3760b70f03b4e32383ac83ff9', 'range': (962, 1173)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c01505259ccce36cab0f0ef3c1f90260'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Comme expliqué en introduction, les saisines initiales du CNPEN concernent\\ntrois domaines dont deux seulement (santé et véhicules connectés) semblent répondre à la définition\\nde « haut risque » de la Commission. Les agents conversationnels présentent pourtant de « haut\\nrisques » dans certains domaines, par exemple lorsqu'ils sont utilisés avec reconnaissance faciale\\n(et/ou audio) des émotions dans le cadre du recrutement avec des risques élevés de discrimination.\\x0c10\\nCes situations mériteraient considération dans une approche réglementaire. Il serait peu satisfaisant,\\nd’un point de vue éthique, que des dommages subis par des individus ne soient pas indemnisés ou\\npris en considération car d’une part ils se situent dans la « zone grise » de l’arsenal réglementaire\\nexistant et, d’autre part, les institutions européennes n’auraient pas souhaité combler les lacunes\\nexistantes considérant qu’il ne s’agit pas là de domaines « à haut risque ».\\nÊtes-vous d’accord avec l’approche proposée à la section 5.B du Livre blanc afin de\\ndéterminer si une application de l’IA est «à haut risque» ?\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 31, 'page': 9, '_split_overlap': [{'doc_id': 'c01505259ccce36cab0f0ef3c1f90260', 'range': (0, 211)}, {'doc_id': '90ddd2fe6bac0d1c37976939bb8b696e', 'range': (949, 1092)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1c4f03d3760b70f03b4e32383ac83ff9'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Êtes-vous d’accord avec l’approche proposée à la section 5.B du Livre blanc afin de\\ndéterminer si une application de l’IA est «à haut risque» ?\\n• Oui\\n• Non\\n• Sans Avis\\n• Autre (veuillez préciser):\\nL’approche proposée constitue un bon point de départ mais devrait être affinée afin de mieux\\nparvenir à une définition satisfaisante de la notion de « haut risque ». Comme la Commission elle-\\nmême le reconnaît, il peut exister des situations (des cas exceptionnels ?) dans lesquelles, « compte\\ntenu des risques, l'utilisation d'applications d'IA à certaines fins devrait être considérée comme étant\\nà haut risque en soi, c'est-à-dire indépendamment du secteur concerné ». Il en résulte une double\\nincertitude : quant aux situations précises où le secteur n’est plus un critère déterminant ; et quant\\nà la personne qui va procéder à cette évaluation et aux méthodes utilisées. On pourrait craindre\\nque, compte tenu de ces incertitudes, les développeurs et opérateurs de systèmes IA puissent\\nrevendiquer ce pouvoir d’appréciation. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 32, 'page': 10, '_split_overlap': [{'doc_id': '1c4f03d3760b70f03b4e32383ac83ff9', 'range': (0, 143)}, {'doc_id': '1cda54cf5ca611bfc6b386b5031b6e0b', 'range': (873, 1025)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '90ddd2fe6bac0d1c37976939bb8b696e'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: On pourrait craindre\\nque, compte tenu de ces incertitudes, les développeurs et opérateurs de systèmes IA puissent\\nrevendiquer ce pouvoir d’appréciation. Le fait de décider si un système d’IA (et les technologies\\nconnexes) doit être considéré comme étant « à haut risque » devrait toujours découler d’une\\névaluation impartiale, réglementée et externe prenant en compte non seulement l’application elle-\\nmême, mais aussi son intégration dans un système d’information plus global. L’évaluation du risque\\ndoit être fondée non seulement sur la gravité du dommage potentiel mais aussi sur la gravité de la\\nviolation des principes éthiques sous-jacents.\\nSi vous le souhaitez, veuillez indiquer quelle est, de votre point de vue, l’application\\nou l’utilisation de l’IA la plus préoccupante («à haut risque»):\\nSi les systèmes d’armes létaux autonomes viennent immédiatement à l’esprit, d’autres applications\\npourraient aussi susciter des préoccupations éthiques tout aussi fondamentales. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 33, 'page': 10, '_split_overlap': [{'doc_id': '90ddd2fe6bac0d1c37976939bb8b696e', 'range': (0, 152)}, {'doc_id': 'efd0036b5ec98d96198d3a4fea10c1da', 'range': (647, 978)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1cda54cf5ca611bfc6b386b5031b6e0b'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Si vous le souhaitez, veuillez indiquer quelle est, de votre point de vue, l’application\\nou l’utilisation de l’IA la plus préoccupante («à haut risque»):\\nSi les systèmes d’armes létaux autonomes viennent immédiatement à l’esprit, d’autres applications\\npourraient aussi susciter des préoccupations éthiques tout aussi fondamentales. À titre d’exemple\\nles applications suivantes pourraient être très préoccupantes : les systèmes de « notation sociale »\\ndes citoyens d’un pays fondés sur une évaluation de leur comportement et de leur « intégrité\\néthique » ; les systèmes de surveillance de masse fondés sur la reconnaissance biométrique ; ou\\nencore certains systèmes décisionnels fondés sur les réactions émotionnelles comme par exemple\\nla reconnaissance d’émotions faciales ou audio pour le recrutement, la détection du mensonge aux\\nfrontières, la détection de l’attention des élèves à l’école, etc.\\nSelon vous, quelle est l’importance des exigences obligatoires suivantes énoncées\\ndans un éventuel futur cadre réglementaire pour l’IA (section 5.D du Livre blanc) (de\\n1 à 5: 1 n’est pas important du tout, 5 est très important)?\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 34, 'page': 10, '_split_overlap': [{'doc_id': '1cda54cf5ca611bfc6b386b5031b6e0b', 'range': (0, 331)}, {'doc_id': 'f31ead656614dbbb1f194a6cb90a519d', 'range': (899, 1127)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'efd0036b5ec98d96198d3a4fea10c1da'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Selon vous, quelle est l’importance des exigences obligatoires suivantes énoncées\\ndans un éventuel futur cadre réglementaire pour l’IA (section 5.D du Livre blanc) (de\\n1 à 5: 1 n’est pas important du tout, 5 est très important)?\\n1 — Pas\\nimportant\\ndu tout\\n2 - Pas\\nimportant\\n3 -\\nNeutre\\n4 -\\nImporta\\nnt\\n5 -\\nTrès\\nimportant\\nSans\\navis\\nQualité des ensembles de\\ndonnées d’entraînement X\\x0c11\\nConservation des dossiers\\net des données X\\nInformations sur la finalité\\net la nature des systèmes\\nd’IA\\nX\\nRobustesse et précision\\ndes systèmes d’IA X\\nContrôle humain\\nX\\nRègles claires en matière de\\nsécurité et de responsabilité X\\nA. Qualité des ensembles de données d’entraînement (5) : La qualité et l’intégrité des\\ndonnées sont essentielles au bon fonctionnement des systèmes IA.\\nB. Conservation des dossiers et des données (4) : Il convient ici de distinguer deux\\nsituations. D’une part, il est très important d’établir des exigences relatives à la\\nconservation des dossiers de programmation de l’algorithme et des données utilisées pour\\nentraîner les systèmes d’IA. La traçabilité des systèmes d’IA doit en effet être assurée. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 35, 'page': 10, '_split_overlap': [{'doc_id': 'efd0036b5ec98d96198d3a4fea10c1da', 'range': (0, 228)}, {'doc_id': 'f3e1b886599d5fa42514e217660d4033', 'range': (858, 1109)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f31ead656614dbbb1f194a6cb90a519d'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: D’une part, il est très important d’établir des exigences relatives à la\\nconservation des dossiers de programmation de l’algorithme et des données utilisées pour\\nentraîner les systèmes d’IA. La traçabilité des systèmes d’IA doit en effet être assurée. Il est\\ndonc important de pouvoir tracer l’ensemble du processus qui a abouti à la prise d’une\\ndécision et d'enregistrer l’ensemble des décisions prises par les systèmes.\\nEn revanche, la conservation des données elles-mêmes pourrait s’avérer\\nproblématique à trois titres :\\n• Premièrement la conservation de grandes masses de données pourrait\\naugmenter les risques d’atteinte à la vie privée et d’exploitation malveillante.\\n• Deuxièmement la conservation systématique de grandes masses de données a\\nun impact énergétique et environnemental non négligeable. Le CNPEN considère\\nque l’IA doit être développée et utilisée de manière à garantir un respect optimal de\\nl’environnement et à réduire autant que possible son empreinte écologique, afin de\\nsoutenir la réalisation des objectifs fixés en matière de neutralité climatique et\\nd’économie circulaire.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 36, 'page': 11, '_split_overlap': [{'doc_id': 'f31ead656614dbbb1f194a6cb90a519d', 'range': (0, 251)}, {'doc_id': '8acd510fd2db03496983806f58afee59', 'range': (807, 1100)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f3e1b886599d5fa42514e217660d4033'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Le CNPEN considère\\nque l’IA doit être développée et utilisée de manière à garantir un respect optimal de\\nl’environnement et à réduire autant que possible son empreinte écologique, afin de\\nsoutenir la réalisation des objectifs fixés en matière de neutralité climatique et\\nd’économie circulaire.\\n• Troisièmement la conservation des données personnelles doit être conforme\\naux règles en matière de protection des données et de la vie privée qui imposent\\nsouvent aux acteurs privés et publics des délais de rétention courts et/ou des\\nlimitations dans le temps liées à la durée du consentement et au principe de\\nminimisation des données.\\nC. Informations sur la finalité et la nature des systèmes d’IA (5) : L’information sur la\\nfinalité d’un système d’IA (les objectifs poursuivis), ses capacités et ses limites et les\\nconditions dans lesquelles il devrait fonctionner sont importantes non seulement pour les\\nopérateurs et les utilisateurs mais aussi, éventuellement, pour les autorités compétentes. Il\\nest important, de façon générale, de respecter le principe de transparence et d’information.\\nPar ailleurs la Commission souligne avec raison que des informations devraient être\\nclairement fournies aux citoyens lorsqu’ils interagissent avec un système d’IA et non avec\\nun être humain.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 37, 'page': 11, '_split_overlap': [{'doc_id': 'f3e1b886599d5fa42514e217660d4033', 'range': (0, 293)}, {'doc_id': '85decc6d86984a45729b3076727afc5b', 'range': (1091, 1281)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8acd510fd2db03496983806f58afee59'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Par ailleurs la Commission souligne avec raison que des informations devraient être\\nclairement fournies aux citoyens lorsqu’ils interagissent avec un système d’IA et non avec\\nun être humain.\\nD. Robustesse et précision des systèmes d’IA (5) : Comme déjà mentionné, la\\nrobustesse et la fiabilité des systèmes IA ainsi que leur cybersécurité sont des\\nconditions essentielles pour parvenir à une IA de confiance. Les systèmes d’IA devraient\\nêtre fiables et intégrer des mécanismes de sécurité par conception (« safety by design ») et\\x0c12\\nde sûreté. Voir aussi supra nos développements sur « l’exactitude » et le rapport qui y\\nest mentionné.\\nE. Contrôle humain (5) : Le Livre Blanc intègre, à juste raison, la notion d’une Garantie\\nHumaine de l’intelligence artificielle (Human Oversight ou Human Warranty). Ce principe a\\nd’ores et déjà fait l’objet de travaux abondants dans le cadre du processus en cours de\\nrévision de la loi de bioéthique française sous l’égide du CCNE et des démarches initiées\\npar le CNPEN.\\nCette idée d’une Garantie Humaine de l’IA est issue d’un mouvement de propositions\\nacadémiques, citoyennes mais aussi de professionnels de santé. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 38, 'page': 11, '_split_overlap': [{'doc_id': '8acd510fd2db03496983806f58afee59', 'range': (0, 190)}, {'doc_id': 'd4b5068b4ea2269356ed1b63ba3464cc', 'range': (1008, 1153)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '85decc6d86984a45729b3076727afc5b'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Cette idée d’une Garantie Humaine de l’IA est issue d’un mouvement de propositions\\nacadémiques, citoyennes mais aussi de professionnels de santé. Ce principe a été reconnu\\ndans les avis 129 et 130 du CCNE et dans l’article 11 du projet de loi bioéthique en cours\\nd’examen devant le Parlement français. Cette notion a également été portée dans le cadre\\ndes travaux en cours de la task-force sur la régulation de l’IA dans le cadre de l’Organisation\\nMondiale de la Santé.\\nLe concept de « Garantie Humaine » peut paraître abstrait mais il est, en réalité, très\\nopérationnel. Dans le cas de l’IA, l’idée est d’appliquer les principes de régulation de\\nl’intelligence artificielle en amont et en aval de l’algorithme lui-même en établissant des points\\nde supervision humaine. Non pas à chaque étape, sinon l’innovation serait bloquée. Mais sur\\ndes points critiques identifiés dans un dialogue partagé entre les professionnels, les patients\\net les concepteurs d’innovation.\\nDans le domaine de la santé, le CCNE a proposé que cette supervision puisse s’exercer\\navec le déploiement de « collèges de garantie humaine » associant médecins,\\nprofessionnels paramédicaux et représentants des usagers. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 39, 'page': 12, '_split_overlap': [{'doc_id': '85decc6d86984a45729b3076727afc5b', 'range': (0, 145)}, {'doc_id': '2827f029d1d88cc52b891d86332f0c2b', 'range': (967, 1186)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd4b5068b4ea2269356ed1b63ba3464cc'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Dans le domaine de la santé, le CCNE a proposé que cette supervision puisse s’exercer\\navec le déploiement de « collèges de garantie humaine » associant médecins,\\nprofessionnels paramédicaux et représentants des usagers. Leur vocation serait d’assurer a\\nposteriori une révision de dossiers médicaux pour porter un regard humain sur les options\\nthérapeutiques conseillées ou prises par l’algorithme. L’objectif consiste à s’assurer « au fil\\nde l’eau » que l’algorithme reste sur un développement de Machine Learning à la fois efficace\\nmédicalement et responsable éthiquement. Les dossiers à auditer pourraient être définis à\\npartir d’événements indésirables constatés, de critères prédéterminés ou d’une sélection\\naléatoire. Un premier cas pilote de collège de garantie humaine est en phase de déploiement\\nsous l’égide de l’Union française pour la santé bucco-dentaire (UFSBD) : il mettra en œuvre,\\ndans le cadre d’un programme de financements innovants de la Sécurité sociale, une\\nsupervision pour un programme d’IA applicable aux soins dentaires pour 48 EHPAD et mis\\nen œuvre par la start-up française Dental Monitoring. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 40, 'page': 12, '_split_overlap': [{'doc_id': 'd4b5068b4ea2269356ed1b63ba3464cc', 'range': (0, 219)}, {'doc_id': '258639b2129e4c6cddbad8c034a219b3', 'range': (723, 1120)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2827f029d1d88cc52b891d86332f0c2b'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Un premier cas pilote de collège de garantie humaine est en phase de déploiement\\nsous l’égide de l’Union française pour la santé bucco-dentaire (UFSBD) : il mettra en œuvre,\\ndans le cadre d’un programme de financements innovants de la Sécurité sociale, une\\nsupervision pour un programme d’IA applicable aux soins dentaires pour 48 EHPAD et mis\\nen œuvre par la start-up française Dental Monitoring. Cette méthodologie est, en outre,\\nmobilisée dans le cadre des travaux de DRIM France IA, démarche de rassemblement des\\nacteurs de la radiologie française pour le développement responsable de l’IA dans cette\\ndiscipline.\\nCette méthode de supervision humaine au fil de l’eau associant innovateurs en IA, experts\\ntechniques et représentants des bénéficiaires finaux est transposable dans d’autres\\ndomaines économiques et sociaux que la santé.\\nF. Règles claires en matière de sécurité et de responsabilité (5) : Nous n’avons aucun\\ndoute sur le fait que l’existence de règles claires en matière de sécurité et de\\nresponsabilité est indispensable pour assurer la nécessaire sécurité et visibilité\\njuridiques et garantir la protection des consommateurs, la sécurité juridique pour les\\nentreprises et un rôle et des limites clairs pour les régulateurs et les pouvoirs publics.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 41, 'page': 12, '_split_overlap': [{'doc_id': '2827f029d1d88cc52b891d86332f0c2b', 'range': (0, 397)}, {'doc_id': '7916c44f7f841b0cd6f82c93281d32c1', 'range': (837, 1265)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '258639b2129e4c6cddbad8c034a219b3'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: F. Règles claires en matière de sécurité et de responsabilité (5) : Nous n’avons aucun\\ndoute sur le fait que l’existence de règles claires en matière de sécurité et de\\nresponsabilité est indispensable pour assurer la nécessaire sécurité et visibilité\\njuridiques et garantir la protection des consommateurs, la sécurité juridique pour les\\nentreprises et un rôle et des limites clairs pour les régulateurs et les pouvoirs publics.\\nEn plus de la législation existante de l’UE, en particulier le cadre relatif à la protection\\ndes données, et notamment le règlement général sur la protection des données et la\\ndirective en matière de protection des données dans le domaine répressif, ou, le cas\\néchéant, les nouvelles exigences obligatoires éventuellement prévues plus haut\\n(voir la question ci-dessus), estimez-vous que l’utilisation de systèmes\\nd’identification biométrique à distance (par exemple, la reconnaissance faciale) et\\nd’autres technologies susceptibles d’ être utilisées dans les espaces publics doit\\x0c13\\nfaire l’objet d’orientations ou de réglementations supplémentaires au niveau de\\nl’UE?\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 42, 'page': 12, '_split_overlap': [{'doc_id': '258639b2129e4c6cddbad8c034a219b3', 'range': (0, 428)}, {'doc_id': '4ec721858b25d0830c33a3a381447346', 'range': (429, 1097)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7916c44f7f841b0cd6f82c93281d32c1'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: En plus de la législation existante de l’UE, en particulier le cadre relatif à la protection\\ndes données, et notamment le règlement général sur la protection des données et la\\ndirective en matière de protection des données dans le domaine répressif, ou, le cas\\néchéant, les nouvelles exigences obligatoires éventuellement prévues plus haut\\n(voir la question ci-dessus), estimez-vous que l’utilisation de systèmes\\nd’identification biométrique à distance (par exemple, la reconnaissance faciale) et\\nd’autres technologies susceptibles d’ être utilisées dans les espaces publics doit\\x0c13\\nfaire l’objet d’orientations ou de réglementations supplémentaires au niveau de\\nl’UE?\\n• Aucune orientation ou réglementation supplémentaire ne s’impose\\n• Les systèmes d’identification biométrique ne devraient être autorisés dans les espaces\\naccessibles au public que dans certains cas ou si certaines conditions sont remplies\\n(veuillez préciser)\\n• Il faudrait imposer d’autres exigences particulières, en plus de celles mentionnées\\ndans la question ci-dessus (veuillez préciser)\\n• L’utilisation de systèmes d’identification biométrique dans les espaces accessibles au\\npublic, à titre d’exception à l’interdiction générale actuelle, ne devrait être possible qu’après\\nla mise en place d’une orientation ou d’une législation spécifique au niveau de l’UE\\n• Les systèmes d’identification biométrique ne devraient jamais être autorisés dans les\\nespaces accessibles au public\\n• Sans avis\\nVeuillez préciser votre réponse:\\nIl est très satisfaisant qu’en Europe, contrairement à d’autres parties du monde, nous disposions\\ndéjà de règles importantes en matière de cadrage de la reconnaissance faciale. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 43, 'page': 12, '_split_overlap': [{'doc_id': '7916c44f7f841b0cd6f82c93281d32c1', 'range': (0, 668)}, {'doc_id': '69decdcf6d601cd19b8eb98576b4dd09', 'range': (669, 1673)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4ec721858b25d0830c33a3a381447346'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: • Aucune orientation ou réglementation supplémentaire ne s’impose\\n• Les systèmes d’identification biométrique ne devraient être autorisés dans les espaces\\naccessibles au public que dans certains cas ou si certaines conditions sont remplies\\n(veuillez préciser)\\n• Il faudrait imposer d’autres exigences particulières, en plus de celles mentionnées\\ndans la question ci-dessus (veuillez préciser)\\n• L’utilisation de systèmes d’identification biométrique dans les espaces accessibles au\\npublic, à titre d’exception à l’interdiction générale actuelle, ne devrait être possible qu’après\\nla mise en place d’une orientation ou d’une législation spécifique au niveau de l’UE\\n• Les systèmes d’identification biométrique ne devraient jamais être autorisés dans les\\nespaces accessibles au public\\n• Sans avis\\nVeuillez préciser votre réponse:\\nIl est très satisfaisant qu’en Europe, contrairement à d’autres parties du monde, nous disposions\\ndéjà de règles importantes en matière de cadrage de la reconnaissance faciale. Des instruments\\ncomme la Charte des droits fondamentaux de l’UE, la Convention européenne des droits de\\nl’homme, le RGPD ou la directive police-justice posent déjà un cadre réglementaire important pour\\nl’utilisation de techniques de reconnaissance faciale (TRF) par le secteur privé ou le secteur public.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 44, 'page': 13, '_split_overlap': [{'doc_id': '4ec721858b25d0830c33a3a381447346', 'range': (0, 1004)}, {'doc_id': '2d80e10ee7a8216fcb40ffe985a2aa7a', 'range': (1005, 1309)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '69decdcf6d601cd19b8eb98576b4dd09'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Des instruments\\ncomme la Charte des droits fondamentaux de l’UE, la Convention européenne des droits de\\nl’homme, le RGPD ou la directive police-justice posent déjà un cadre réglementaire important pour\\nl’utilisation de techniques de reconnaissance faciale (TRF) par le secteur privé ou le secteur public.\\nNous considérons, néanmoins, que, compte tenu des risques particulièrement importants existant\\ndans ce domaine, les règles devraient être précisées et complétées. Premièrement, il y a un risque\\nimportant d’interprétation divergente des règles existantes par les autorités de régulation et de\\ncontrôle dans les pays européens. Deuxièmement, la transparence en Europe sur les projets\\nd’utilisation des TRF par le privé et le public devrait être assurée. Troisièmement, plutôt que d’entrer\\nde façon aveugle dans une « course » aux TRF avec les États-Unis ou la Chine, l’Europe devrait\\ndonner l’exemple en se focalisant sur les problèmes que la reconnaissance faciale pourrait résoudre\\net en insistant sur les principes de nécessité et de proportionnalité. Quatrièmement, une\\nréglementation claire et homogène au sein de l’EU favoriserait la dynamique de l’innovation et\\nl’acceptabilité des citoyens, en prévenant d’éventuelles dérives. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 45, 'page': 13, '_split_overlap': [{'doc_id': '69decdcf6d601cd19b8eb98576b4dd09', 'range': (0, 304)}, {'doc_id': '384e15d590bfadf6302b0737a6f6bc6a', 'range': (1058, 1237)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2d80e10ee7a8216fcb40ffe985a2aa7a'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Quatrièmement, une\\nréglementation claire et homogène au sein de l’EU favoriserait la dynamique de l’innovation et\\nl’acceptabilité des citoyens, en prévenant d’éventuelles dérives. Des interventions législatives ou\\nréglementaires pourraient s’avérer nécessaires pour fixer les « lignes rouges », aider à établir des\\nlignes directrices là où l’utilisation des TRF se justifie et prévoir des garanties, contrôles et voies de\\nrecours appropriés. De façon plus générale, les TRF dans l’espace public posent des dilemmes\\néthiques particulièrement importants qui devraient d’abord être analysés au niveau politique après\\nun débat démocratique. Le CNPEN espère pouvoir contribuer dans l’avenir à ce débat tant sur le\\nplan national que sur le plan européen.\\nEstimez-vous qu’un système de label non obligatoire (section 5.G du Livre blanc)\\nserait utile pour les systèmes d’IA qui ne sont pas considérés comme étant à haut\\nrisque, en plus de la législation existante?\\n• Extrêmement utile\\n• Très utile\\n• Plutôt inutile\\n• Tout à fait inutile\\n• Sans avis\\nAvez-vous d’autres suggestions sur un système de label non obligatoire?\\x0c14\\nUn système de label non obligatoire peut être utile pour des systèmes d’IA qui ne sont pas\\nconsidérés à haut risque. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 46, 'page': 13, '_split_overlap': [{'doc_id': '2d80e10ee7a8216fcb40ffe985a2aa7a', 'range': (0, 179)}, {'doc_id': 'd86084be12053743c9a87808c4609b13', 'range': (1113, 1232)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '384e15d590bfadf6302b0737a6f6bc6a'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: 14\\nUn système de label non obligatoire peut être utile pour des systèmes d’IA qui ne sont pas\\nconsidérés à haut risque. Mais il faut veiller à ce que ces labels ne soient pas l’apanage de groupes\\nindustriels qui s’auto-labelliseront. En complément, cela nécessite donc la mise en place\\nd’organismes de certification et d’éducation de la population et l’on préconise plutôt le respect de\\nnormes et de standards internationaux précis et auditables.\\nQuel est le moyen de garantir une IA digne de confiance, sûre et respectueuse des\\nrègles et valeurs européennes?\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 47, 'page': 14, '_split_overlap': [{'doc_id': '384e15d590bfadf6302b0737a6f6bc6a', 'range': (0, 119)}, {'doc_id': '40b64e10be32bc986a3dc3e011add179', 'range': (234, 559)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd86084be12053743c9a87808c4609b13'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: En complément, cela nécessite donc la mise en place\\nd’organismes de certification et d’éducation de la population et l’on préconise plutôt le respect de\\nnormes et de standards internationaux précis et auditables.\\nQuel est le moyen de garantir une IA digne de confiance, sûre et respectueuse des\\nrègles et valeurs européennes?\\n• Évaluation préalable de la conformité des applications à haut risque avec les exigences\\nidentifiées (avant de mettre le système sur le marché)\\n• Évaluation a posteriori de la conformité des applications à haut risque au moyen d’une\\nprocédure d’évaluation externe de la conformité\\n• Surveillance a posteriori du marché après la mise sur le marché du produit ou du service à haut\\nrisque reposant sur l’IA et, le cas échéant, contrôle du respect assuré par les autorités\\ncompétentes concernées\\n• Combinaison de mécanismes d’évaluation préalable de la conformité et de contrôle a\\nposteriori du respect\\n• Autre système de contrôle du respect\\n• Sans avis\\nVeuillez préciser tout autre système de contrôle du respect\\nTout système d’IA considéré « à haut risque » devra être soumis une homologation et une\\ncertification de conformité a priori. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 48, 'page': 14, '_split_overlap': [{'doc_id': 'd86084be12053743c9a87808c4609b13', 'range': (0, 325)}, {'doc_id': 'ea0855b56bbc49e3bc0b930170d1231', 'range': (326, 1162)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '40b64e10be32bc986a3dc3e011add179'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: • Évaluation préalable de la conformité des applications à haut risque avec les exigences\\nidentifiées (avant de mettre le système sur le marché)\\n• Évaluation a posteriori de la conformité des applications à haut risque au moyen d’une\\nprocédure d’évaluation externe de la conformité\\n• Surveillance a posteriori du marché après la mise sur le marché du produit ou du service à haut\\nrisque reposant sur l’IA et, le cas échéant, contrôle du respect assuré par les autorités\\ncompétentes concernées\\n• Combinaison de mécanismes d’évaluation préalable de la conformité et de contrôle a\\nposteriori du respect\\n• Autre système de contrôle du respect\\n• Sans avis\\nVeuillez préciser tout autre système de contrôle du respect\\nTout système d’IA considéré « à haut risque » devra être soumis une homologation et une\\ncertification de conformité a priori. De plus, dans la mesure où la réponse d’un algorithme d’IA est\\nsusceptible d’évoluer quand il s’agit d’un apprentissage supervisé ou non supervisé ou par\\nrenforcement, en particulier si l’apprentissage est réalisé en continu et si le domaine d’application\\nest ouvert, il est indispensable de soumettre le système à des tests réguliers et normés pour vérifier\\nque la réponse ne s’écarte pas du cadre de l’homologation. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 49, 'page': 14, '_split_overlap': [{'doc_id': '40b64e10be32bc986a3dc3e011add179', 'range': (0, 836)}, {'doc_id': '228a0a10b45b60e725eb53e0a4543162', 'range': (837, 1254)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ea0855b56bbc49e3bc0b930170d1231'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: De plus, dans la mesure où la réponse d’un algorithme d’IA est\\nsusceptible d’évoluer quand il s’agit d’un apprentissage supervisé ou non supervisé ou par\\nrenforcement, en particulier si l’apprentissage est réalisé en continu et si le domaine d’application\\nest ouvert, il est indispensable de soumettre le système à des tests réguliers et normés pour vérifier\\nque la réponse ne s’écarte pas du cadre de l’homologation. Cela peut passer a minima par des\\ncontrôles techniques réguliers, comme ceux déjà pratiqués pour les automobiles, mais aussi\\nnécessiter des étapes de re-homologation et re-certification des logiciels d’IA.\\nSection 3 – Implications de l’intelligence artificielle, de\\nl’internet des objets et de la robotique en matière de\\nsécurité et de responsabilité\\nL’objectif général des cadres juridiques en matière de sécurité et de responsabilité est de garantir que tous les produits et\\nservices, y compris ceux qui intègrent des technologies numériques émergentes, fonctionnent de manière sûre, fiable et\\ncohérente et que les dommages qui se sont produits soient réparés efficacement.\\nLa législation actuelle sur la sécurité des produits offre déjà une interprétation\\nétendue de la notion de sécurité qui permet de protéger contre tous types de risques\\nliés aux produits en fonction de leur utilisation. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 50, 'page': 14, '_split_overlap': [{'doc_id': 'ea0855b56bbc49e3bc0b930170d1231', 'range': (0, 417)}, {'doc_id': 'd94e567f61b6d3b872f46795943d679b', 'range': (1094, 1312)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '228a0a10b45b60e725eb53e0a4543162'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: La législation actuelle sur la sécurité des produits offre déjà une interprétation\\nétendue de la notion de sécurité qui permet de protéger contre tous types de risques\\nliés aux produits en fonction de leur utilisation. Toutefois, quels risques particuliers\\ndécoulant de l’utilisation de l’IA conviendrait-il, selon vous, de préciser davantage\\nafin d’assurer une plus grande sécurité juridique?\\n• Les risques liés à la cybersécurité\\n• Les risques pour la sécurité des personnes\\n• Les risques liés à la perte de connectivité\\n• Les risques pour la santé mentale\\x0c15\\nLes risques liés à la cybersécurité sont de loin les plus importants car les cyberattaques peuvent\\navoir des conséquences multiples et néfastes. Il est néanmoins rassurant que toutes les parties\\nprenantes ont conscience de ces risques ce qui devrait permettre une prise en compte adéquate de\\nce risque dans le cadre de futures évolutions normatives. D’autres risques, néanmoins, tels que\\nceux relatifs à la santé mentale décrits dans le Livre Blanc, sont très peu pris en considération par\\nles règles existantes. Il serait dès lors utile que les risques pour la santé mentale soient explicitement\\ncouverts par le concept de sécurité des produits dans le cadre législatif.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 51, 'page': 14, '_split_overlap': [{'doc_id': '228a0a10b45b60e725eb53e0a4543162', 'range': (0, 218)}, {'doc_id': '935d46ea143f2890a586a8fc33ad9135', 'range': (1075, 1233)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd94e567f61b6d3b872f46795943d679b'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Il serait dès lors utile que les risques pour la santé mentale soient explicitement\\ncouverts par le concept de sécurité des produits dans le cadre législatif.\\nSelon vous, faut-il élargir à d’autres risques afin d’assurer une plus grande sécurité\\njuridique ?\\nN/A\\nPensez-vous que le cadre législatif relatif à la sécurité devrait envisager de nouvelles\\nprocédures d’évaluation des risques pour les produits faisant l’objet de changements\\nimportants au cours de leur durée de vie?\\n• Oui\\n• Non\\n• Sans avis\\nLe développement des outils numériques et des algorithmes d’IA permettant de rejouer des\\nséquences préalablement enregistrées, ainsi que la simulation numérique de mises en scène\\nréalistes de cas d’usage comportant des risques offrent de grandes possibilités de faire évoluer les\\nprocédures d’évaluation des risques pour les produits faisant l’objet de changements importants au\\ncours de leur durée de vie. Cela offre de nouvelles possibilités de virtualisation des tests\\nd’homologation et de certification par des « jumeaux numériques ». \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 52, 'page': 15, '_split_overlap': [{'doc_id': 'd94e567f61b6d3b872f46795943d679b', 'range': (0, 158)}, {'doc_id': 'e78b1570cd36bccb86cb30d97c75f9f0', 'range': (478, 1040)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '935d46ea143f2890a586a8fc33ad9135'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: • Oui\\n• Non\\n• Sans avis\\nLe développement des outils numériques et des algorithmes d’IA permettant de rejouer des\\nséquences préalablement enregistrées, ainsi que la simulation numérique de mises en scène\\nréalistes de cas d’usage comportant des risques offrent de grandes possibilités de faire évoluer les\\nprocédures d’évaluation des risques pour les produits faisant l’objet de changements importants au\\ncours de leur durée de vie. Cela offre de nouvelles possibilités de virtualisation des tests\\nd’homologation et de certification par des « jumeaux numériques ». De plus, en développant des\\nscénarios (serious games) les outils de simulation peuvent constituer des outils d’aide à la décision\\npour des comités d’évaluation impliquant des représentants des diverses parties prenantes d’un\\ndomaine d’application et d’un écosystème spécifique (mobilité, énergie, santé, défense etc.).\\nAvez-vous d’autres considérations concernant les procédures d’évaluation des\\nrisques?\\nN/A\\nPensez-vous que le cadre législatif actuel de l’UE en matière de responsabilité\\n(directive sur la responsabilité du fait des produits) devrait être modifié afin de mieux\\ncouvrir les risques engendrés par certaines applications de l’IA?\\n• Oui\\n• Non\\n• Sans avis\\nAvez-vous d’autres considérations concernant la question ci-dessus?\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 53, 'page': 15, '_split_overlap': [{'doc_id': '935d46ea143f2890a586a8fc33ad9135', 'range': (0, 562)}, {'doc_id': '72a1e0131269fd8efd3820924f5860fa', 'range': (968, 1299)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e78b1570cd36bccb86cb30d97c75f9f0'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: N/A\\nPensez-vous que le cadre législatif actuel de l’UE en matière de responsabilité\\n(directive sur la responsabilité du fait des produits) devrait être modifié afin de mieux\\ncouvrir les risques engendrés par certaines applications de l’IA?\\n• Oui\\n• Non\\n• Sans avis\\nAvez-vous d’autres considérations concernant la question ci-dessus?\\nComme en matière de régulation en général (supra), le CNPEN n’est pas favorable à une refonte\\ncomplète des régimes de responsabilité existants – et de la directive sur la responsabilité du fait des\\nproduits (directive 85/374/CEE) – qui fonctionnent plutôt bien. Il considère que la mise en place de\\nrègles de responsabilité très lourdes pourrait freiner l’innovation et s’avérer préjudiciable pour le\\ndéveloppement de l’IA en Europe.\\nLe CNPEN note, néanmoins, que la directive sur la responsabilité du fait des produits a été adoptée\\nen 1985, une époque antérieure à la prise en considération des risques associés à l’émergence des\\nnouvelles technologies numériques et, surtout, de l’IA. Certes, les règles de la directive ne sont pas\\nspécifiques à des technologies particulières et s’appliquent dont quelle que soit la technologie\\x0c16\\nutilisée. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 54, 'page': 15, '_split_overlap': [{'doc_id': 'e78b1570cd36bccb86cb30d97c75f9f0', 'range': (0, 331)}, {'doc_id': 'ad819dbdb838d1fecebd86a3c466da7e', 'range': (1020, 1176)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '72a1e0131269fd8efd3820924f5860fa'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Certes, les règles de la directive ne sont pas\\nspécifiques à des technologies particulières et s’appliquent dont quelle que soit la technologie\\x0c16\\nutilisée. Mais elles ne sont pas toujours en mesure de saisir les difficultés qui résultent de la\\ncomplexité, la connectivité, l’opacité, la vulnérabilité et l’autonomie des systèmes d’IA. L’impact\\nsocial d’une incapacité des systèmes juridiques d’apporter des réponses satisfaisantes aux défis\\nposés par les technologies de l’information, y compris et surtout en matière d’indemnisation\\néquitable pour les dommages subis, pourrait rompre la confiance dans l’IA et compromettre les effets\\nbénéfiques attendus. Le CNPEN considère donc que des ajustements spécifiques du cadre législatif\\nactuel pourraient être nécessaires pour éviter que des personnes victimes de préjudices ou dont les\\nbiens sont endommagés se trouvent sans réparation. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 55, 'page': 15, '_split_overlap': [{'doc_id': '72a1e0131269fd8efd3820924f5860fa', 'range': (0, 156)}, {'doc_id': '4999941ef255288b47c72c56246aa9d5', 'range': (657, 883)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ad819dbdb838d1fecebd86a3c466da7e'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Le CNPEN considère donc que des ajustements spécifiques du cadre législatif\\nactuel pourraient être nécessaires pour éviter que des personnes victimes de préjudices ou dont les\\nbiens sont endommagés se trouvent sans réparation. L’attention du législateur pourrait être portée\\nsur des sujets tels que les suivants :\\n- Le fait que la directive repose sur le concept de « produit » (et de ses défauts), perçu\\nessentiellement comme un objet alors que dans les systèmes d’IA les « produits » et les\\n« services » interagissent de façon permanente (comme en témoigne l’exemple de la voiture\\nconnectée) ;\\n- Le fait que le concept de « défaut » d’un produit mériterait d’être précisé dans le cadre des\\ncaractéristiques très spécifiques des systèmes d’IA, voire des logiciels en général.\\nPensez-vous que les règles nationales actuelles en matière de responsabilité\\ndevraient être adaptées en tenant compte du fonctionnement de l’IA afin de mieux\\ngarantir une réparation adéquate des dommages et une répartition équitable des\\nresponsabilités?\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 56, 'page': 16, '_split_overlap': [{'doc_id': 'ad819dbdb838d1fecebd86a3c466da7e', 'range': (0, 226)}, {'doc_id': 'ca120d2e23162270e394c3ee28f28499', 'range': (777, 1030)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4999941ef255288b47c72c56246aa9d5'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Pensez-vous que les règles nationales actuelles en matière de responsabilité\\ndevraient être adaptées en tenant compte du fonctionnement de l’IA afin de mieux\\ngarantir une réparation adéquate des dommages et une répartition équitable des\\nresponsabilités?\\n• Oui, pour toutes les applications de l’IA\\n• Oui, pour des applications de l’IA spécifiques\\n• Non\\n• Sans avis\\nVeuillez préciser les applications de l’IA:\\nLes droits nationaux en matière de responsabilité souffrent de fragmentation et ne comportent\\nsouvent pas de règles spécifiques en matière de responsabilité pour dommages causés par des\\nsystèmes d’IA. Sans énumérer ici les applications de l’IA spécifiques, il nous semble qu’il est\\nnécessaire de procéder à une étude approfondie et secteur par secteur afin de tenir compte des\\néléments suivants :\\n• Les difficultés liées à la définition du dommage et des types de dommages indemnisés par\\nles droits nationaux.\\n• Les difficultés liées à la nécessité pour la victime d’apporter la preuve de l’existence d’un lien\\nde causalité qui pourrait s’avérer une véritable probatio diabolica quand le dommage résulte\\ndu dysfonctionnement d’un système d’IA. Apporter la preuve d’une discrimination résultant\\nd’un traitement algorithmique constitue, par exemple, une difficulté essentielle au regard de\\nl’opacité du système informatique.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 57, 'page': 16, '_split_overlap': [{'doc_id': '4999941ef255288b47c72c56246aa9d5', 'range': (0, 253)}, {'doc_id': '34f8d5330f34451b8f36e01457b6c240', 'range': (1153, 1331)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ca120d2e23162270e394c3ee28f28499'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Apporter la preuve d’une discrimination résultant\\nd’un traitement algorithmique constitue, par exemple, une difficulté essentielle au regard de\\nl’opacité du système informatique.\\n• Ces difficultés probatoires ne se limitent pas d’ailleurs à l’établissement du seul lien de\\ncausalité. Elles portent également sur l’existence de la discrimination per se. En effet,\\ncomment le demandeur peut-il être à même d’établir l’effet discriminatoire d’une pratique,\\nnotamment lorsque les critères fondant la décision prise à l’issue d’un traitement\\nalgorithmique ainsi que leur pondération ne sont pas connus ? A défaut d’information sur ces\\ncritères, seule une analyse statistique des résultats produits par l’algorithme permettrait\\nd’établir de tels faits. Mais une telle analyse ne saurait certainement être menée par le\\ndemandeur seul, s’il s’agit d’un individu contestant une décision prise à son encontre. Il\\nconvient alors de mener une réflexion sur le point de savoir comment remédier à de telles\\ndifficultés.\\n• La nécessité de repenser, en fonction de la situation, la répartition de la responsabilité entre\\nle producteur, le fabricant, le développeur, l’opérateur, et l’utilisateur.\\x0c\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 58, 'page': 16, '_split_overlap': [{'doc_id': 'ca120d2e23162270e394c3ee28f28499', 'range': (0, 178)}, {'doc_id': 'c0104c5abc39edc4d3ecdca8ec2ce60f', 'range': (1006, 1180)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '34f8d5330f34451b8f36e01457b6c240'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: • La nécessité de repenser, en fonction de la situation, la répartition de la responsabilité entre\\nle producteur, le fabricant, le développeur, l’opérateur, et l’utilisateur.\\x0c17\\n• La possibilité de prévoir différentes règles de responsabilité pour différents risques et,\\nsurtout, un système de facilitation de la preuve ou un régime de responsabilité stricte pour\\ndes systèmes d’IA « à haut risque ».\\n• La nécessité de définir si les systèmes d’IA identifiés comme « à haut risque » à des fins de\\nresponsabilité stricte devraient être les mêmes (ou plutôt plus restreints) que les systèmes\\n« à haut risque » à des fins de régulation discutés dans la Section II de ce questionnaire et\\nsur la base de quels critères distinguer les deux catégories.\\n• L’utilité ou non d’envisager un devoir de diligence accrue des développeurs, opérateurs et\\nautres parties prenantes d’un système d’IA leur imposant de sélectionner, d’exploiter, de\\nsurveiller et d’entretenir correctement la technologie utilisée.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 59, 'page': 16, '_split_overlap': [{'doc_id': '34f8d5330f34451b8f36e01457b6c240', 'range': (0, 174)}, {'doc_id': '86d16e99255ffa3b923910fb98c6466b', 'range': (746, 993)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c0104c5abc39edc4d3ecdca8ec2ce60f'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: • L’utilité ou non d’envisager un devoir de diligence accrue des développeurs, opérateurs et\\nautres parties prenantes d’un système d’IA leur imposant de sélectionner, d’exploiter, de\\nsurveiller et d’entretenir correctement la technologie utilisée.\\n• Le principe d’équivalence fonctionnelle qui devrait garantir que les personnes qui ont subi un\\ndommage du fait de l’utilisation d’un système d’IA ne devraient pas être moins indemnisées\\nque si le dommage provenait d’un système analogue déjà couvert par le droit européen ou\\nles droits nationaux.\\nAvez-vous d’autres considérations concernant la question ci-dessus?\\nLe CNPEN souhaite rappeler la polémique suscitée début 2017 quand le Parlement Européen a\\nproposé à la Commission Européenne, « la création d'une personnalité juridique spécifique aux\\nrobots » qui impliquerait que les robots pourraient être tenus pour civilement responsables des\\ndommages qu’ils causeraient, ce qui obligerait leurs fabricants ou propriétaires à contracter des\\npolices d'assurance couvrant les dommages potentiels causés par leurs robots.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 60, 'page': 17, '_split_overlap': [{'doc_id': 'c0104c5abc39edc4d3ecdca8ec2ce60f', 'range': (0, 247)}, {'doc_id': 'aecbc5b22fc8d737f9896cdf456d41c6', 'range': (614, 1069)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '86d16e99255ffa3b923910fb98c6466b'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Le CNPEN souhaite rappeler la polémique suscitée début 2017 quand le Parlement Européen a\\nproposé à la Commission Européenne, « la création d'une personnalité juridique spécifique aux\\nrobots » qui impliquerait que les robots pourraient être tenus pour civilement responsables des\\ndommages qu’ils causeraient, ce qui obligerait leurs fabricants ou propriétaires à contracter des\\npolices d'assurance couvrant les dommages potentiels causés par leurs robots.\\nLe Comité Economique et Social Européen (CESE) s’est opposé formellement à cette\\nproposition pour deux raisons principales : i) « le risque moral inacceptable » que le fabricant\\nn’assume plus sa responsabilité, transférée au robot (ou au système d’IA), au détriment d’une\\néthique de conception, et ii) « le risque d’utilisation impropre et d’abus d’une telle forme juridique »\\nsi les incidents consécutifs à une mauvaise utilisation peuvent être imputés à l’IA ou au robot\\nintelligent par son propriétaire.\\nLe CNPEN considère que ce débat juridique et éthique est de première importance.\\nMerci pour votre contribution à ce questionnaire.\\x0c\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 61, 'page': 17, '_split_overlap': [{'doc_id': '86d16e99255ffa3b923910fb98c6466b', 'range': (0, 455)}, {'doc_id': 'bc37d6de2541ba6d888cdaf881513286', 'range': (963, 1093)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'aecbc5b22fc8d737f9896cdf456d41c6'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Comité national pilote d'éthique du numérique, stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Small (< 50 employees), stakeholder_country: France, document_date: 17-06-2020 16:14, language: French, \\n\\nPassage: Le CNPEN considère que ce débat juridique et éthique est de première importance.\\nMerci pour votre contribution à ce questionnaire.\\x0c18\\nLes membres du Comité national pilote d’éthique du numérique\\nGilles Adda\\nRaja Chatila\\nTheodore Christakis*\\nLaure Coulombel\\nJean-François Delfraissy\\nKarine Lefeuvre\\nLaurence Devillers\\nKarine Dognin-Sauze\\nGilles Dowek\\nValeria Faure-Muntian\\nChristine Froidevaux\\nJean-Gabriel Ganascia\\nEric Germain\\nAlexei Grinbaum\\nDavid Gruson\\nEmmanuel Hirsch\\nJeany Jean-Baptiste\\nClaude Kirchner - directeur\\nAugustin Landler\\nChristophe Lazaro\\nGwendal Le Grand\\nClaire Levallois-Barth\\nCaroline Martin\\nTristan Nitot\\nJérôme Perrin*\\nCatherine Tessier\\nSerena Villata\\nCélia Zolynski\\n*co-rapporteurs de cette contribution\\nContact : camille.darche@ccne.fr\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', 'stakeholder_name': \"Comité national pilote d'éthique du numérique\", 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': 'National', 'document_date': '17-06-2020 16:14', 'language': 'French', 'document_reference': 'F529871', 'document_name': 'F529871-CNPEN-contribution-consultation-IA4EU-2020-06-14.pdf', '_split_id': 62, 'page': 17, '_split_overlap': [{'doc_id': 'aecbc5b22fc8d737f9896cdf456d41c6', 'range': (0, 130)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bc37d6de2541ba6d888cdaf881513286'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Bundesarchitektenkammer e.V - Federal Chamber of German Architects, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Germany, document_date: 20-05-2020 15:48, language: German, \\n\\nPassage: Öffentliche Konsultation der Europäischen Kommission zum\\nVorschlag für ein Weißbuch zur künstlichen Intelligenz,\\nStellungnahme der Bundesarchitektenkammer (BAK),\\nMai 2020\\nDie Bundesarchitektenkammer (BAK) ist ein Zusammenschluss der 16\\nLänderarchitektenkammern in Deutschland, die als Körperschaften des öffentlichen\\nRechts für den Berufsstand zuständig sind. Sie vertritt die Interessen von über\\n135.000 Architekten, Landschaftsarchitekten, Innenarchitekten und Stadtplanern\\ngegenüber Politik und Öffentlichkeit auf nationaler und internationaler Ebene.\\nDie BAK begrüßt die Möglichkeit der Stellungnahme im Rahmen der vorliegenden\\nKonsultation zum Vorschlag der Europäischen Kommission für ein Weißbuch zur\\nKünstlichen Intelligenz (KI). Allgemein weist sie darauf hin, dass KI-Anwendungen\\ndie Planung und gestalterische Arbeit von Architekten aller Fachrichtungen\\nunterstützen können und weitreichende Möglichkeiten neuartiger Arbeitsweisen\\nbieten. Dies betrifft insbesondere den Einsatz von KI-Technologien für ein\\nnachhaltiges und ressourcenschonendes Bauen.\\nHinsichtlich der im Vorschlag für ein Weißbuch zur Künstlichen Intelligenz\\nbehandelten Themen hat die BAK folgende Anmerkungen:\\n1. Zugängliche Datenbanken zur Auswertung von großen Datenmengen:\\nDie Zugänglichkeit von (ggf. EU-finanzierten) Datenbanken ist eine wichtige\\nUnterstützung für kleinere und mittlere Unternehmen (KMU). Große Organisationen\\nhaben einen strukturellen Vorteil, da sie schlichtweg auf einen größeren Datenschatz\\nzugreifen können. Die reine Datenmenge ist Grundlage für qualifiziertes Machine\\nLearning (als Teilbereich der KI). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529032-200520_BAK-Stellungnahme_KI-Konsultation_final.pdf', 'stakeholder_name': 'Bundesarchitektenkammer e.V - Federal Chamber of German Architects', 'stakeholder_type': 'Other', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '20-05-2020 15:48', 'language': 'German', 'document_reference': 'F529032', 'document_name': 'F529032-200520_BAK-Stellungnahme_KI-Konsultation_final.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': '3c103d1171aba559a24e775a2404c2d6', 'range': (1391, 1611)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '527810d8847f4689c9e7511bca243a7f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Bundesarchitektenkammer e.V - Federal Chamber of German Architects, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Germany, document_date: 20-05-2020 15:48, language: German, \\n\\nPassage: Große Organisationen\\nhaben einen strukturellen Vorteil, da sie schlichtweg auf einen größeren Datenschatz\\nzugreifen können. Die reine Datenmenge ist Grundlage für qualifiziertes Machine\\nLearning (als Teilbereich der KI). Um diesen strukturellen Nachteil von KMU, wie den\\nmeisten Architekturbüros in Deutschland, auszugleichen, sind öffentlich zugängliche\\nund öffentlich finanzierte Datenbanken unverzichtbar. Erstrebenswert wäre die\\nAnbindung an öffentlich-rechtliche Institutionen. Dabei könnten sich ggf. auch die\\nArchitektenkammern ins Spiel bringen.\\n2. Datenerfassung im öffentlichen Raum mit KI-Unterstützung:\\nTechnologien zur Datenerfassung können u.a. bei der Qualifizierung der Stadt- und\\nRegionalplanung eingesetzt werden. Aus Sicht der BAK ist eine biometrische\\nErkennung von Personen für die Datenerfassung im Sinne der Stadtplanung nicht\\nerforderlich und sollte grundsätzlich im öffentlichen Raum unterbleiben. Eine\\ntemporäre Erfassung von beispielsweise Verkehrsströmen und Nutzungsfrequenzen\\nim öffentlichen Raum dahingegen sollte unter strengen Auflagen ermöglicht werden.\\n3. Die Kennzeichnung von KI-unterstützten Produkten und Dienstleistungen\\nhinsichtlich Ihrer Konformität mit Datenschutzanforderungen:\\nRef. Ares(2020)3355188 - 26/06/2020\\x0c- 2 -\\nSeite 2 von 2\\nDies betrifft im Gebäudebereich z.B. Smart Home-Anwendungen. Architekten aller\\nFachrichtungen beraten Ihre Auftraggeber bei der Produktauswahl und müssen sich\\ndarauf verlassen können, dass diese den jeweils gewünschten Anforderungen zum\\nSchutz persönlicher Daten entsprechen. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529032-200520_BAK-Stellungnahme_KI-Konsultation_final.pdf', 'stakeholder_name': 'Bundesarchitektenkammer e.V - Federal Chamber of German Architects', 'stakeholder_type': 'Other', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '20-05-2020 15:48', 'language': 'German', 'document_reference': 'F529032', 'document_name': 'F529032-200520_BAK-Stellungnahme_KI-Konsultation_final.pdf', '_split_id': 1, 'page': 1, '_split_overlap': [{'doc_id': '527810d8847f4689c9e7511bca243a7f', 'range': (0, 220)}, {'doc_id': 'e9cf869bd08e98dd6b9d03114592d99', 'range': (1339, 1553)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3c103d1171aba559a24e775a2404c2d6'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Bundesarchitektenkammer e.V - Federal Chamber of German Architects, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Germany, document_date: 20-05-2020 15:48, language: German, \\n\\nPassage: Architekten aller\\nFachrichtungen beraten Ihre Auftraggeber bei der Produktauswahl und müssen sich\\ndarauf verlassen können, dass diese den jeweils gewünschten Anforderungen zum\\nSchutz persönlicher Daten entsprechen. Smart Home-Anwendungen sollten daher\\nals High-Risk-Technologie eingestuft werden und strengen Qualitätsanforderungen\\nund Kennzeichnungspflichten unterliegen. Die High-Risk-Einschätzung betrifft in\\ndiesem Fall die Gefahr des Datenmissbrauchs.\\n4. Souveränität über Daten und Planung beim Architekten:\\nKI-Anwendungen sollten zunächst vor allem Assistenzsysteme sein, damit die\\nEntscheidungshoheit nach wie vor beim Menschen liegt. Dies betrifft zum Beispiel\\nauch die Souveränität des planenden Architekten über seine Daten. Wichtig ist\\nzudem, dass die der KI-Lösung zugrundliegenden Algorithmen transparent sind. Dies\\nkönnte in Zukunft auch Folgen für die Haftung von Berufsangehörigen haben.\\nBundesarchitektenkammer, Berlin/Brüssel, den 7.5.2020\\nAnsprechpartnerin: BAK-Verbindungsbüro Brüssel\\nTelefon: +32 2 219 77 30\\nE-Mail: info@bruessel.bak.de', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529032-200520_BAK-Stellungnahme_KI-Konsultation_final.pdf', 'stakeholder_name': 'Bundesarchitektenkammer e.V - Federal Chamber of German Architects', 'stakeholder_type': 'Other', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Germany', 'stakeholder_scope': nan, 'document_date': '20-05-2020 15:48', 'language': 'German', 'document_reference': 'F529032', 'document_name': 'F529032-200520_BAK-Stellungnahme_KI-Konsultation_final.pdf', '_split_id': 2, 'page': 2, '_split_overlap': [{'doc_id': '3c103d1171aba559a24e775a2404c2d6', 'range': (0, 214)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e9cf869bd08e98dd6b9d03114592d99'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: A VUELTAS CON LA IA\\nY LA RC: ¿DÓNDE\\nCONVERGEN Y QUÉ\\nPROBLEMÁTICA\\nCONLLEVAN?\\nDESCRIPCIÓN\\nBREVE\\nEl presente ejercicio\\nconsta de dos partes.\\nLa primera resume el\\nLibro Blanco sobre la\\nInteligencia Artificial en\\nlas cuestiones\\nrelativas a\\nResponsabilidad Civil.\\nEn la segunda se\\nplantean los\\nproblemas que arroja\\nla aplicación de la\\nlegislación actual en\\nmateria de Inteligencia\\nArtificial,\\nconcretamente en\\nrelación con la\\nResponsabilidad Civil.\\nMacarena\\nAzcárate, Leticia\\nAmorós y David\\nRuiz\\nRef. Ares(2020)3359840 - 26/06/2020\\x0c1\\nÍndice:\\n1. Introducción\\n2. Resumen/análisis del Libro Blanco sobre la Inteligencia Artificial desde el punto de vista de la\\nResponsabilidad Civil\\na. ¿Qué es la IA?\\nb. ¿Qué es la Responsabilidad Civil?\\nc. Definición de los problemas\\nd. Riesgos para la seguridad jurídica y el funcionamiento eficaz del régimen de\\nResponsabilidad Civil\\ne. Destinatarios\\nf. Cumplimiento y ejecución\\ng. Conclusión\\n3. Comentarios y propuestas sobre IA y RC\\na. Introducción al problema\\nb. Fragmentación del mercado único y consecuencias sobre la RC\\nc. Problemas RC\\nd. Riesgos para la seguridad jurídica y el funcionamiento eficaz del régimen de\\nResponsabilidad Civil\\ne. ¿Sobre quién recaería la RC? ¿Cobra sentido una Personalidad Jurídica para la IA?\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': '975af6997501343df20a99464f950572', 'range': (924, 1256)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4e9c2ca7f79a7682a604d5a5ba098aa5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Comentarios y propuestas sobre IA y RC\\na. Introducción al problema\\nb. Fragmentación del mercado único y consecuencias sobre la RC\\nc. Problemas RC\\nd. Riesgos para la seguridad jurídica y el funcionamiento eficaz del régimen de\\nResponsabilidad Civil\\ne. ¿Sobre quién recaería la RC? ¿Cobra sentido una Personalidad Jurídica para la IA?\\nf. Alcance temporal de la responsabilidad\\ng. Seguro de RC obligatorio\\nh. Conclusión\\x0c2\\nA vueltas con la IA y la RC: ¿Dónde convergen y qué problemática conllevan?\\n1. Introducción\\nEs indudable el rápido e imparable desarrollo que está teniendo la IA, pero esta transformación digital\\nen la que estamos inmersos ofrece tantas ventajas como riesgos. El objetivo de la Comisión con este libro\\nblanco es movilizar recursos y crear los incentivos apropiados que aceleren la implantación de la IA,\\ncon un enfoque europeo, coordinando políticas entre los Estados Miembros y la comunidad\\ninvestigadora. Se trata de atraer y retener el talento, creando un marco regulatorio óptimo que aborde\\nlos problemas y los riesgos asociados a determinados usos de esta nueva tecnología y que, además,\\natraiga la inversión pública y privada necesaria para promover su implantación.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 1, 'page': 2, '_split_overlap': [{'doc_id': '4e9c2ca7f79a7682a604d5a5ba098aa5', 'range': (0, 332)}, {'doc_id': '162e22303c6a21f84cc61e9d83ac52d8', 'range': (926, 1191)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '975af6997501343df20a99464f950572'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Se trata de atraer y retener el talento, creando un marco regulatorio óptimo que aborde\\nlos problemas y los riesgos asociados a determinados usos de esta nueva tecnología y que, además,\\natraiga la inversión pública y privada necesaria para promover su implantación.\\nSe debe crear un “ecosistema de excelencia”, un marco político adecuado para establecer medidas que\\narmonicen los esfuerzos a escala regional, nacional y europea, en colaboración con los sectores públicos y\\nprivados, para movilizar recursos y estimular la inversión. Esto solo puede llevarse a cabo dentro de un\\n“ecosistema de confianza” basado en una “regulación adecuada y proporcionada” que evite cualquier\\ntipo de inseguridad jurídica.\\n2. Resumen/análisis Libro Blanco sobre la Inteligencia Artificial desde el punto de vista de la\\nResponsabilidad Civil\\na. ¿Qué es la IA?\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 2, 'page': 3, '_split_overlap': [{'doc_id': '975af6997501343df20a99464f950572', 'range': (0, 265)}, {'doc_id': '2216a586d9b1de43477ca0c38fe3b1ff', 'range': (709, 841)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '162e22303c6a21f84cc61e9d83ac52d8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Resumen/análisis Libro Blanco sobre la Inteligencia Artificial desde el punto de vista de la\\nResponsabilidad Civil\\na. ¿Qué es la IA?\\nEn abril de 2019 el grupo de expertos de alto nivel creado por la Comisión definió los sistemas de IA como\\nprogramas informáticos (y posiblemente también equipos informáticos) diseñados por seres humanos que, dado un\\nobjetivo complejo, actúan en la dimensión física o digital mediante la percepción de su entorno mediante la\\nadquisición de datos, la interpretación de los datos estructurados o no estructurados, el razonamiento sobre el\\nconocimiento o el tratamiento de la información, fruto de esos datos y la decisión de las mejores acciones que se\\nllevarán a cabo para alcanzar el objetivo fijado.”\\nDado que el uso de la IA no solo se traduce en oportunidades sino que conlleva riesgos y amenazas, el\\nlegislador deberá estar atento a estos riesgos y alcanzar una regulación de la IA que permita disfrutar\\nde sus ventajas minimizando los riesgos aparejados a su uso y que a la vez que asegure el respeto de los\\nderechos de las personas y los valores en torno a los cuales se erige la Unión Europea (“UE”) y los\\nEstados Miembros (“EEMM”).\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 3, 'page': 3, '_split_overlap': [{'doc_id': '162e22303c6a21f84cc61e9d83ac52d8', 'range': (0, 132)}, {'doc_id': '238c2fa936380e67f8e579829fcb492e', 'range': (133, 1172)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2216a586d9b1de43477ca0c38fe3b1ff'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: En abril de 2019 el grupo de expertos de alto nivel creado por la Comisión definió los sistemas de IA como\\nprogramas informáticos (y posiblemente también equipos informáticos) diseñados por seres humanos que, dado un\\nobjetivo complejo, actúan en la dimensión física o digital mediante la percepción de su entorno mediante la\\nadquisición de datos, la interpretación de los datos estructurados o no estructurados, el razonamiento sobre el\\nconocimiento o el tratamiento de la información, fruto de esos datos y la decisión de las mejores acciones que se\\nllevarán a cabo para alcanzar el objetivo fijado.”\\nDado que el uso de la IA no solo se traduce en oportunidades sino que conlleva riesgos y amenazas, el\\nlegislador deberá estar atento a estos riesgos y alcanzar una regulación de la IA que permita disfrutar\\nde sus ventajas minimizando los riesgos aparejados a su uso y que a la vez que asegure el respeto de los\\nderechos de las personas y los valores en torno a los cuales se erige la Unión Europea (“UE”) y los\\nEstados Miembros (“EEMM”).\\nUno de los mayores problemas que se refiere es la posible fragmentación en esta materia entre los\\ndistintos EEMM. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 4, 'page': 3, '_split_overlap': [{'doc_id': '2216a586d9b1de43477ca0c38fe3b1ff', 'range': (0, 1039)}, {'doc_id': '4531ba238fedc7320d29cbfaee31b907', 'range': (1040, 1153)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '238c2fa936380e67f8e579829fcb492e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Uno de los mayores problemas que se refiere es la posible fragmentación en esta materia entre los\\ndistintos EEMM. Para evitarlo es imprescindible que esta regulación se acometa principalmente por la\\nUE de forma que las legislaciones de los EEMM sigan la hoja de ruta marcada por la UE en pro del\\nmercado único.\\x0c3\\nb. ¿Qué es la Responsabilidad Civil?\\nLa Responsabilidad Civil (en adelante “RC”), de acuerdo a Díez Picazo, es la sujeción de quien vulnera\\nun deber de conducta en interés de otro sujeto a la obligación de reparar el daño producido. Será RC\\ncontractual cuando surja de la vulneración de un contrato entre las partes y de las obligaciones que\\ngenera entre las mismas o extracontractual (aquiliana) si se causa un daño por un comportamiento\\nculposo o doloso.\\nDentro de la RC extracontractual debemos distinguir si deriva de una acción u omisión culposa\\n(conducta reprochable de la persona fuente de responsabilidad), o si deriva del riesgo (diferenciando\\nentre la responsabilidad civil objetiva y la responsabilidad civil por riesgo.\\nEn los casos complejos que no se pueda determinar a primera vista esta conducta culposa, se deberá\\ndemostrar culpa, teniendo como parte preponderante la diligencia en el actuar. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 5, 'page': 3, '_split_overlap': [{'doc_id': '238c2fa936380e67f8e579829fcb492e', 'range': (0, 113)}, {'doc_id': 'c3715e04a48bf92bff97ac7ad9d6eb54', 'range': (1045, 1222)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4531ba238fedc7320d29cbfaee31b907'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: En los casos complejos que no se pueda determinar a primera vista esta conducta culposa, se deberá\\ndemostrar culpa, teniendo como parte preponderante la diligencia en el actuar. De este modo se\\nprotege al damnificado en mayor medida (salvo excepciones de culpa exclusiva de la víctima o fuerza\\nmayor), debiendo probar estos puntos el agente que haya causado el daño, mientras tanto se entenderá\\nque es responsable. Esto obligará a los agentes a contratar seguros de responsabilidad civil para cubrir\\nestos daños.\\nActualmente, los desarrolladores e implementadores de la IA ya están sujetos a la legislación europea\\nen materia de derechos fundamentales (protección de datos personales, privacidad, no discriminación\\ny otros) de protección de los derechos de los consumidores y normas sobre la seguridad de los\\nproductos y responsabilidad civil y el Acta Europea de Accesibilidad aplicable a partir de 2025 a los\\nbienes y servicios. Sin embargo, estas normas no son específicas para la IA y son previas a la existencia\\nde la misma. Consecuentemente, no son del todo eficientes para cumplir con su finalidad dadas las\\ncaracterísticas de la IA haciendo difícil su aplicación y ejecución.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 6, 'page': 4, '_split_overlap': [{'doc_id': '4531ba238fedc7320d29cbfaee31b907', 'range': (0, 177)}, {'doc_id': '9cdb4665a1d1100f2e73982b73ea9017', 'range': (1030, 1183)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c3715e04a48bf92bff97ac7ad9d6eb54'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Consecuentemente, no son del todo eficientes para cumplir con su finalidad dadas las\\ncaracterísticas de la IA haciendo difícil su aplicación y ejecución.\\nPor ello, hay que estudiar la legislación actual y ver si es necesario legislar Ad hoc para afrontar los retos\\nque plantea la IA, evitando una fragmentación entre las soluciones de los EEMM que, de facto, ya\\nempieza a hacerse patente: a) Alemania propone un sistema de RC según el nivel de riesgo que lleve\\naparejado la aplicación de IA con (5 niveles), b) Dinamarca apuesta por un “sello de ética de los datos”\\npara dar más confianza a los productos y servicios IA a los que se les conceda y c) Malta ofrece una\\ncertificación voluntaria que logra este mismo efecto.\\nc. Definición de los problemas\\nLa aplicación de la IA puede causar tanto daños materiales (para la seguridad y la salud de las personas,\\ncon consecuencias como la muerte y menoscabos al patrimonio) como inmateriales (pérdida de\\nprivacidad, limitaciones al derecho de libertad de expresión, dignidad humana, discriminación en el\\nacceso a empleo, etc…). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 7, 'page': 4, '_split_overlap': [{'doc_id': 'c3715e04a48bf92bff97ac7ad9d6eb54', 'range': (0, 153)}, {'doc_id': '36c117013446c3fa0d4393b1f84d39a2', 'range': (721, 1072)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9cdb4665a1d1100f2e73982b73ea9017'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: c. Definición de los problemas\\nLa aplicación de la IA puede causar tanto daños materiales (para la seguridad y la salud de las personas,\\ncon consecuencias como la muerte y menoscabos al patrimonio) como inmateriales (pérdida de\\nprivacidad, limitaciones al derecho de libertad de expresión, dignidad humana, discriminación en el\\nacceso a empleo, etc…). Estos daños pueden estar vinculados a gran variedad de riesgos, defectos en el\\ndiseño general de los sistemas de IA, por uso de datos sesgado, fallos de ciberseguridad o conectividad\\nen infraestructuras clave, usos malintencionados...\\nDeterminados riesgos afectan principalmente a la protección de los derechos fundamentales\\n(protección de datos personales, privacidad o no discriminación). Los ciudadanos temen quedarse\\nindefensos a la hora de proteger sus derechos y su seguridad frente a los desequilibrios informativos de\\nla toma de decisiones mediante algoritmos.\\x0c4\\nAlgunas de las características de la IA como su opacidad (“efecto caja negra”), su complejidad, su\\nimprevisibilidad y un comportamiento parcialmente autónomo pueden dificultar la tarea de las\\nautoridades a la hora de controlar que se dé un eficaz cumplimiento normativo. La problemática\\nprincipal oscila en encontrar mecanismos fiables de control que evite estos riesgos y el funcionamiento\\neficaz del régimen de RC.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 8, 'page': 4, '_split_overlap': [{'doc_id': '9cdb4665a1d1100f2e73982b73ea9017', 'range': (0, 351)}, {'doc_id': 'b81ee320face95e8594df7d8a981271d', 'range': (1194, 1339)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '36c117013446c3fa0d4393b1f84d39a2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: La problemática\\nprincipal oscila en encontrar mecanismos fiables de control que evite estos riesgos y el funcionamiento\\neficaz del régimen de RC.\\nd. Riesgos para la seguridad jurídica y el funcionamiento eficaz del régimen de Responsabilidad\\nCivil\\nLa falta de disposiciones claras en materia de seguridad y algunas características de las tecnologías de\\nla IA puede crear inseguridad jurídica tanto a las empresas que comercializan productos con IA en la UE\\ncomo a las autoridades encargadas de supervisar el mercado o de ejecutar las normas que puede resultarles\\nconfuso cómo intervenir, pueden no estar facultadas para tomar medidas o no contar con las\\ncapacidades técnicas adecuadas para examinar los sistemas de IA.\\nEsta inseguridad jurídica afecta también a las personas damnificadas para recibir compensaciones en\\nmateria de RC en los distintos países de la UE, al encontrar dificultad para hacer un seguimiento\\nretrospectivo de las decisiones potencialmente problemáticas adoptadas mediante IA y para acceder las\\npruebas necesarias para llevar un caso ante los tribunales. En definitiva, la probabilidad de obtener la\\nreparación efectiva será menor que si los daños son causados por tecnologías tradicionales.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 9, 'page': 5, '_split_overlap': [{'doc_id': '36c117013446c3fa0d4393b1f84d39a2', 'range': (0, 145)}, {'doc_id': '71efb70a1824fff31b2bb90f58af0c11', 'range': (1079, 1215)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b81ee320face95e8594df7d8a981271d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: En definitiva, la probabilidad de obtener la\\nreparación efectiva será menor que si los daños son causados por tecnologías tradicionales.\\nPor ello, para no reducir los niveles globales de seguridad y minar la competitividad de las empresas\\neuropeas, urge alcanzar una regulación de la IA que ofrezca seguridad jurídica a los distintos agentes\\ndel mercado, incluyendo al consumidor final.\\nLas directrices para una IA fiable del grupo de expertos de alto nivel sobre la IA (de abril de 2019) son\\nclave para un futuro marco normativo europeo de la IA. Establecen siete requisitos fundamentales que\\ndeben cumplirse y evaluarse a lo largo de todo su ciclo de vida útil:\\n1º. Intervención y supervisión humanas: Los sistemas de IA deben facilitar sociedades equitativas,\\napoyando la intervención humana y los derechos fundamentales, y no disminuir, limitar o desorientar\\nla autonomía humana.\\n2º. Solidez y seguridad técnicas: La fiabilidad de la IA requiere que los algoritmos sean seguros, fiables\\ny sólidos para resolver errores durante toda la vida útil de los sistemas de IA y hacer frente\\nadecuadamente a los resultados erróneos con un plan de contingencia. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 10, 'page': 5, '_split_overlap': [{'doc_id': 'b81ee320face95e8594df7d8a981271d', 'range': (0, 136)}, {'doc_id': 'ebdae92ffe9530e9f8bba26353c27832', 'range': (888, 1154)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '71efb70a1824fff31b2bb90f58af0c11'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Solidez y seguridad técnicas: La fiabilidad de la IA requiere que los algoritmos sean seguros, fiables\\ny sólidos para resolver errores durante toda la vida útil de los sistemas de IA y hacer frente\\nadecuadamente a los resultados erróneos con un plan de contingencia. Deben de ser resilientes frente a\\nataques abiertos o tentativas de manipular datos o los propios algoritmos.\\n3º. Privacidad y gestión de datos: Para que las personas puedan confiar en el tratamiento de datos, los\\nciudadanos deben tener pleno control sobre sus propios datos y los datos que les conciernen no deben\\nutilizarse para perjudicarles o discriminarles. Además deben garantizarse la privacidad y la protección\\nde datos en todas las fases del ciclo vital del sistema de IA.\\n4º. Transparencia: Debe garantizarse la trazabilidad de los sistemas de IA, documentando las decisiones\\ntomadas y la totalidad del proceso (descripción de la recogida, etiquetado de datos y algoritmo\\nutilizado) que dio lugar a las decisiones. Si fuera posible debe aportarse la explicabilidad del proceso de\\ntoma de decisiones algorítmico, las opciones de diseño del sistema, y la justificación de su despliegue,\\ngarantizando transparencia al modelo de negocio.\\x0c5\\n5º. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 11, 'page': 5, '_split_overlap': [{'doc_id': '71efb70a1824fff31b2bb90f58af0c11', 'range': (0, 266)}, {'doc_id': '197899ffdd974381dfe6fde901db9428', 'range': (991, 1215)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ebdae92ffe9530e9f8bba26353c27832'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Si fuera posible debe aportarse la explicabilidad del proceso de\\ntoma de decisiones algorítmico, las opciones de diseño del sistema, y la justificación de su despliegue,\\ngarantizando transparencia al modelo de negocio.\\x0c5\\n5º. Diversidad, no discriminación y equidad; Los datos utilizados para el entrenamiento y\\nfuncionamiento de la IA, deben tener en cuenta las capacidades, competencias y necesidades humanas,\\ny garantizar la accesibilidad. No pueden incluir sesgos o modelos de gobernanza deficientes que den\\nlugar a una discriminación (in)directa. El sesgo también puede afectar a la forma en que está escrito el\\ncódigo de programación. Estos problemas deben abordarse desde el inicio del desarrollo del sistema.\\n6º. Bienestar social y medioambiental: Los sistemas de IA deben utilizarse para mejorar el cambio social\\npositivo y aumentar la sostenibilidad y la responsabilidad ecológicas. Debe tomarse en cuenta su\\nimpacto sobre el medio ambiente y sobre otros seres sensibles.\\n7º: Rendición de cuentas: Deben implantarse mecanismos que garanticen la responsabilidad y la\\nrendición de cuentas de los sistemas de IA y de sus resultados antes y después de su implementación.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 12, 'page': 5, '_split_overlap': [{'doc_id': 'ebdae92ffe9530e9f8bba26353c27832', 'range': (0, 224)}, {'doc_id': 'd4dd354177662cee2c2f11817bc4145', 'range': (981, 1175)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '197899ffdd974381dfe6fde901db9428'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: 7º: Rendición de cuentas: Deben implantarse mecanismos que garanticen la responsabilidad y la\\nrendición de cuentas de los sistemas de IA y de sus resultados antes y después de su implementación.\\nLa posibilidad de evaluación de los sistemas de IA por parte de auditores internos y externos y la\\ndisponibilidad de los informes de evaluación, contribuye a su fiabilidad especialmente en aplicaciones\\nque afecten a los derechos fundamentales.\\nLa IA es una tecnología transformadora y disruptiva que ha evolucionado en los últimos años gracias a\\nla disponibilidad de un gran volumen de datos digitales, los avances computacionales, la capacidad de\\nalmacenamiento, la innovación científica y de ingeniería en métodos y herramientas de IA. Advierten\\nde su impacto en la sociedad y en los ciudadanos en formas que aún no podemos imaginar.\\nLos riesgos más notables incluyen el reconocimiento facial, el uso de datos biométricos involuntarios, la\\nidentificación automática, los sistemas clasificatorios de ciudadanos y, por último, los sistemas de armas\\nautónomas letales con habilidades cognitivas para decidir quién, cuándo y dónde luchar sin intervención\\nhumana. Todos ellos plantean muchos problemas éticos además de los legales ya que son susceptibles\\nde vulnerar los derechos fundamentales.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 13, 'page': 6, '_split_overlap': [{'doc_id': '197899ffdd974381dfe6fde901db9428', 'range': (0, 194)}, {'doc_id': 'a4388f7a12720200b68f3a57a5089745', 'range': (831, 1286)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd4dd354177662cee2c2f11817bc4145'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Los riesgos más notables incluyen el reconocimiento facial, el uso de datos biométricos involuntarios, la\\nidentificación automática, los sistemas clasificatorios de ciudadanos y, por último, los sistemas de armas\\nautónomas letales con habilidades cognitivas para decidir quién, cuándo y dónde luchar sin intervención\\nhumana. Todos ellos plantean muchos problemas éticos además de los legales ya que son susceptibles\\nde vulnerar los derechos fundamentales.\\nEn sus conclusiones resaltan la importancia de construir sistemas de IA en los que la tecnología,\\nincluyendo los procesos y las personas que están detrás de la tecnología, sea fiable, trazando unas\\nnormas de juego y marcando los límites y consecuencias de un mal uso (culposo o reprochable) de la\\nIA, cobrando importancia la RC y su relación con la IA.\\nLa Directiva sobre responsabilidad por los daños causados por productos defectuosos atribuye al fabricante la\\nresponsabilidad de los daños que cause por un producto defectuoso. En los casos en los que aplique IA\\nserá difícil demostrar el nexo causal entre defecto y daño por las características de estos sistemas. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 14, 'page': 6, '_split_overlap': [{'doc_id': 'd4dd354177662cee2c2f11817bc4145', 'range': (0, 455)}, {'doc_id': 'ad724a8c4fa67e49ef00b069e052cd85', 'range': (986, 1122)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a4388f7a12720200b68f3a57a5089745'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: En los casos en los que aplique IA\\nserá difícil demostrar el nexo causal entre defecto y daño por las características de estos sistemas. Para\\nlos consumidores será igualmente difícil acceder a las pruebas que demuestren que efectivamente los\\ndaños que han padecido son responsabilidad de la empresa detrás del producto defectuoso. La\\x0c6\\nComisión considera conveniente mejorar el marco normativo actual para abordar los riesgos y\\nsituaciones siguientes:\\n● Aplicación y cumplimiento efectivos de la legislación nacional y de la UE en vigor: La\\nopacidad de la IA hace difícil detectar y probar incumplimientos de la legislación sobre\\nderechos fundamentales, imputación de responsabilidades y reclamación de indemnizaciones.\\nHay que clarificar la normativa actual y adaptarla a nuevos escenarios, para que en casos de RC\\nse ofrezca una solución real a las personas que sufran un perjuicio causado por un producto o\\nservicio marcado por la IA.\\n● Limitaciones del ámbito de aplicación de la legislación vigente de la UE: si bien la legislación\\nsobre seguridad de los productos de la UE se aplica al software cuando forma parte de un\\nproducto final, no está claro si el software independiente, como una IA, está cubierto por esta\\nregulación o no. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 15, 'page': 6, '_split_overlap': [{'doc_id': 'a4388f7a12720200b68f3a57a5089745', 'range': (0, 136)}, {'doc_id': 'b34c9f151feb64a1307042ce4ba7cd7c', 'range': (938, 1238)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ad724a8c4fa67e49ef00b069e052cd85'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: ● Limitaciones del ámbito de aplicación de la legislación vigente de la UE: si bien la legislación\\nsobre seguridad de los productos de la UE se aplica al software cuando forma parte de un\\nproducto final, no está claro si el software independiente, como una IA, está cubierto por esta\\nregulación o no. La legislación general de la UE en materia de seguridad en vigor es de\\naplicación a los productos pero no a los servicios, y, por consiguiente, a priori no se aplica\\ntampoco a los servicios basados en las tecnologías de IA (como servicios sanitarios, financieros\\no de transporte).\\n● Funcionalidad cambiante de los sistemas de IA: Dado que la IA se actualiza o incluso por su\\naprendizaje automático, se pueden añadir nuevas funciones durante la vida útil de la IA que\\nden lugar a nuevos riesgos no contemplados en el momento de su comercialización. La\\nvelocidad de la tecnología no permite una reforma normativa rígida sino que deberá poder\\namoldarse a los constantes cambios y actualizaciones que sufren los sistemas de IA.\\nActualmente la legislación en vigor se centra únicamente en los riesgos de seguridad en el\\nmomento de la comercialización.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 16, 'page': 7, '_split_overlap': [{'doc_id': 'ad724a8c4fa67e49ef00b069e052cd85', 'range': (0, 300)}, {'doc_id': '8e7c7fe5e99b0ee05b2be0c710461d77', 'range': (849, 1147)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b34c9f151feb64a1307042ce4ba7cd7c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: La\\nvelocidad de la tecnología no permite una reforma normativa rígida sino que deberá poder\\namoldarse a los constantes cambios y actualizaciones que sufren los sistemas de IA.\\nActualmente la legislación en vigor se centra únicamente en los riesgos de seguridad en el\\nmomento de la comercialización.\\n● Incertidumbre para imputar la responsabilidad entre los distintos agentes económicos: La\\nlegislación de la UE imputa la responsabilidad al productor del producto comercializado, lo\\nque plantea dudas con la IA porque algunos riesgos nacen a posteriori. Además, la legislación\\nde la UE sobre la RC por los productos, deja que las normas nacionales en materia de RC se\\nencarguen de los demás participantes en la cadena de suministro. La legislación de la UE en\\nmateria de seguridad solo aplica a productos y no a servicios, lo cual, si lo extrapolamos a\\nservicios de IA, podremos concluir que tampoco aplica a estos.\\n● Cambios en el concepto de seguridad: el uso de la IA puede dar lugar a riesgos no previstos\\nactualmente de forma específica por la legislación (ciberamenazas, seguridad personal, pérdida\\nde conectividad…). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 17, 'page': 7, '_split_overlap': [{'doc_id': 'b34c9f151feb64a1307042ce4ba7cd7c', 'range': (0, 298)}, {'doc_id': 'f152d3c536d5127d62fe474fa83b0ed0', 'range': (915, 1122)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8e7c7fe5e99b0ee05b2be0c710461d77'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: ● Cambios en el concepto de seguridad: el uso de la IA puede dar lugar a riesgos no previstos\\nactualmente de forma específica por la legislación (ciberamenazas, seguridad personal, pérdida\\nde conectividad…). Estos riesgos pueden estar presentes en el momento de su comercialización\\no llegar después, tras una actualización o por aprendizaje automático del producto. Minimizar\\nlos riesgos para los derechos fundamentales, especialmente la protección de datos personales,\\nla privacidad y la no discriminación, así como, los riesgos para la seguridad y el\\nfuncionamiento eficaz del régimen de RC, es la dificultad a la que se enfrentan los sistemas\\nbasado en la IA.\\nEs necesario prestar especial atención a las aplicaciones de IA de alto riesgo, es decir, aquellas que se\\nemplean en sectores en los que es previsible que existan o puedan surgir riesgos significativos, desde la\\nperspectiva de la protección de la seguridad, derechos de los consumidores y derechos fundamentales\\n(la sanidad, el transporte, la energía y en determinados ámbitos del sector público), así como en\\ndeterminados usos que pueden considerarse críticos como los ligados a conducción automáticas o los\\nprocesos de contratación laboral.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 18, 'page': 7, '_split_overlap': [{'doc_id': '8e7c7fe5e99b0ee05b2be0c710461d77', 'range': (0, 207)}, {'doc_id': '458005ebd85a6a15f9fc1bc4901ff1be', 'range': (663, 1205)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f152d3c536d5127d62fe474fa83b0ed0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Es necesario prestar especial atención a las aplicaciones de IA de alto riesgo, es decir, aquellas que se\\nemplean en sectores en los que es previsible que existan o puedan surgir riesgos significativos, desde la\\nperspectiva de la protección de la seguridad, derechos de los consumidores y derechos fundamentales\\n(la sanidad, el transporte, la energía y en determinados ámbitos del sector público), así como en\\ndeterminados usos que pueden considerarse críticos como los ligados a conducción automáticas o los\\nprocesos de contratación laboral.\\x0c7\\nPor otro lado, la Comisión también se refiere a los requisitos legales que se les debe de imponer a los\\n\"actores relevantes\" que desarrollen IAs de alto riesgo. Los campos que se contemplan, acompañados\\npor sus posibles criterios, son los siguientes:\\n● Datos de entrenamiento: los datos utilizados para entrenar los sistemas de IA han de ser\\nsuficientemente amplios para evitar situaciones peligrosas, que no generen discriminación y que\\nprotejan la privacidad de los datos personales.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 19, 'page': 7, '_split_overlap': [{'doc_id': 'f152d3c536d5127d62fe474fa83b0ed0', 'range': (0, 542)}, {'doc_id': '34e70ec2a3303c2cffd44d04c8dfbc9f', 'range': (706, 1030)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '458005ebd85a6a15f9fc1bc4901ff1be'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Los campos que se contemplan, acompañados\\npor sus posibles criterios, son los siguientes:\\n● Datos de entrenamiento: los datos utilizados para entrenar los sistemas de IA han de ser\\nsuficientemente amplios para evitar situaciones peligrosas, que no generen discriminación y que\\nprotejan la privacidad de los datos personales.\\n● Conservación de registros y datos: la complejidad y la opacidad de muchos sistemas de IA, hacen\\nnecesario mantener un registro de los datos usados y por qué se han seleccionado, documentar la\\nprogramación, entrenamiento, procesos y técnicas usadas para construir la IA, incluso conservar los\\npropios conjuntos de datos.\\n● Suministro de Información: se requiere transparencia más allá de la conservación de datos. Se debe\\nfacilitar información clara sobre las capacidades y limitaciones de la IA, o informar \"claramente\" a\\nlos usuarios de que están interactuando con una IA y no con un humano.\\n● Robustez y precisión: Los sistemas de IA sobre todo en sus aplicaciones de riesgo elevado, para\\nque sean fiables deben de ser sólidos y exactos todas las fases de su vida útil. Los resultados han de\\nser replicables y que son resilientes ante ataques abiertos o intentos de manipulación de los propios\\ndatos o algoritmo.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 20, 'page': 8, '_split_overlap': [{'doc_id': '458005ebd85a6a15f9fc1bc4901ff1be', 'range': (0, 324)}, {'doc_id': '25b2f0d65b074e6aea593e0b4dc03069', 'range': (1099, 1241)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '34e70ec2a3303c2cffd44d04c8dfbc9f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Los resultados han de\\nser replicables y que son resilientes ante ataques abiertos o intentos de manipulación de los propios\\ndatos o algoritmo.\\n● Supervisión humana: Ayuda a garantizar que un sistema de IA no socave la autonomía humana o\\nprovoque otros efectos adversos. Los resultados de la IA no deben de ser efectivos hasta que un\\nhumano los valide o si lo son, deben poder supervisarse después.\\n● Requisitos específicos en el caso de identificación biométrica remota: en la normativa europea el\\nreconocimiento facial a distancia dependiendo de los usos y de su tratamiento está muy limitado\\npor el GDPR. En principio, está prohibido salvo en condiciones específicas principalmente por\\nmotivos de interés público significativo.\\ne. Destinatarios\\nLa cuestión es establecer cómo repartir las obligaciones entre los distintos agentes económicos que\\nparticipen en todo el proceso de creación del producto o servicio: Desarrollador, implementador, otras\\npartes potenciales (productor, distribuidor, proveedor de servicios y usuario). La Comisión considera a\\ntal efecto que cada obligación deberá dirigirse a la parte que esté en mejor posición para abordar todo\\nposible riesgo. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 21, 'page': 8, '_split_overlap': [{'doc_id': '34e70ec2a3303c2cffd44d04c8dfbc9f', 'range': (0, 142)}, {'doc_id': 'b39b800af58a662d35e26043f3ee772', 'range': (1030, 1173)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '25b2f0d65b074e6aea593e0b4dc03069'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: La Comisión considera a\\ntal efecto que cada obligación deberá dirigirse a la parte que esté en mejor posición para abordar todo\\nposible riesgo. Recordemos que, en la actualidad, la normativa de la UE sobre RC establece que será el\\nproductor sobre quien recaiga la RC por productos defectuosos, independientemente de que la\\nnormativa nacional de los EEMM contemple en su normativa una indemnización a cargo de otras partes\\ninvolucradas.\\x0c8\\nf. Cumplimiento y ejecución\\nTal y como ya ha destacado la Comisión, uno de los mayores retos será el de generar confianza alrededor\\nde la IA, garantizando un cumplimiento y ejecución efectivo de las normas existentes que se adapten a\\nla realidad que vivimos y a las de nueva redacción. Se considera necesario un control objetivo previo que\\ncompruebe y asegure que se cumplen los requisitos que la normativa marque como obligatorios en\\nmateria de IA cuando su aplicación sea considerada de alto riesgo.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 22, 'page': 8, '_split_overlap': [{'doc_id': '25b2f0d65b074e6aea593e0b4dc03069', 'range': (0, 143)}, {'doc_id': '9011d664cdaae154ba7a4cf7b513d43c', 'range': (724, 939)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b39b800af58a662d35e26043f3ee772'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Se considera necesario un control objetivo previo que\\ncompruebe y asegure que se cumplen los requisitos que la normativa marque como obligatorios en\\nmateria de IA cuando su aplicación sea considerada de alto riesgo.\\nEste control podrá realizarse ex ante o ex post y deberá servir para facilitar un resarcimiento efectivo para\\nlos casos en los que a través de un sistema de IA se ocasione un daño o un perjuicio, garantizando una\\nacción judicial efectiva, especialmente en los casos de aplicaciones de IA en sectores o actividades que\\nse consideren de riesgo elevado.\\ng. Conclusión\\nUn uso diligente de la IA, traerá a los ciudadanos, empresas y a la sociedad en general, múltiples\\nbeneficios. Sin embargo, es fundamental que la aplicación de la IA no contravenga los Derechos\\nFundamentales, los principios éticos y valores de la UE y de sus EEMM.\\nDebemos tener en cuenta que la regulación actual no cubre estos supuestos de manera precisa y clara.\\nPor ello, deberá introducirse normativa específica capaz de regular la IA de forma satisfactoria para\\nofrecer una mayor seguridad jurídica a todos los agentes del mercado. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 23, 'page': 9, '_split_overlap': [{'doc_id': 'b39b800af58a662d35e26043f3ee772', 'range': (0, 215)}, {'doc_id': 'b5efd2c40e348e580df207846721d8c8', 'range': (947, 1118)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9011d664cdaae154ba7a4cf7b513d43c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Por ello, deberá introducirse normativa específica capaz de regular la IA de forma satisfactoria para\\nofrecer una mayor seguridad jurídica a todos los agentes del mercado. Los pain points que hay que\\nsolucionar a través de legislación específica son los siguientes:\\n● Algunas aplicaciones de IA requerirán supervisión humana que garantice un uso seguro.\\n● Adopción de medidas específicas si el daño deriva de datos incorrectos en la fase de diseño y\\nmecanismos que garanticen la calidad de los datos durante la vida del producto.\\n● Establecer requisitos de transparencia para combatir la opacidad de los sistemas de IA para\\nfacilitar la viabilidad de cualquier pretensión jurídica que reclame RC.\\n● Adaptar normativa para los casos concretos en los que la IA se implemente tras la\\ncomercialización del producto, especialmente si pueda afectar a su seguridad.\\n● La complejidad de la cadena de suministros ha aumentado lo que dificulta depurar\\nresponsabilidades adecuadamente entre los distintos agentes implicados en el desarrollo.\\nComo ya se ha señalado, puede complicar la trazabilidad de los daños padecidos por la víctima\\ndebiendo de esta manera recurrir a un sistema de responsabilidad civil subjetiva. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 24, 'page': 9, '_split_overlap': [{'doc_id': '9011d664cdaae154ba7a4cf7b513d43c', 'range': (0, 171)}, {'doc_id': '48c2e521212ef7ad35703ad681b6b050', 'range': (1031, 1206)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b5efd2c40e348e580df207846721d8c8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Como ya se ha señalado, puede complicar la trazabilidad de los daños padecidos por la víctima\\ndebiendo de esta manera recurrir a un sistema de responsabilidad civil subjetiva. Esto podría aumentar\\nlos costes de litigación de las víctimas complicando demostrar la RC de otros partícipes del producto o\\nservicio distintos del productor.\\nEl camino aún será largo, pero la UE no puede descuidarse si no quiere que los EEMM emprendan su\\ncamino de manera individual, fragmentando el mercado único, lo que se traduciría en la pérdida de\\noportunidad de afrontar de manera conjunta el reto y la imposibilidad de que la UE se erija como una\\npotencia mundial en este campo.\\x0c9\\n3. Comentarios y propuestas sobre IA y RC\\na. Introducción al problema\\nLa IA indudablemente va a traer ventajas a la sociedad, a las administraciones públicas, a las empresas\\nprivadas y, especialmente, a quienes exploten estas tecnologías, por los elevados beneficios económicos\\nque va a reportar su uso a los distintos agentes del mercado.\\nSin embargo, esto va a traer nuevas situaciones y problemas que tanto el derecho de la UE como el de\\nlos distintos EEMM tiene que poder solventar. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 25, 'page': 9, '_split_overlap': [{'doc_id': 'b5efd2c40e348e580df207846721d8c8', 'range': (0, 175)}, {'doc_id': '666718bd3b9d259b8cf1c6d4b6272b08', 'range': (1005, 1151)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '48c2e521212ef7ad35703ad681b6b050'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Sin embargo, esto va a traer nuevas situaciones y problemas que tanto el derecho de la UE como el de\\nlos distintos EEMM tiene que poder solventar. La dificultad reside en cómo enfocar la RC de la IA de\\nmanera solvente, con seguridad jurídica y que, además no asfixie a fabricantes, desarrolladores y\\ncomercializadores de IA, fomentando su desarrollo e investigación sin una regulación muy severa que\\npara proteger al consumidor haga que las empresas se lo replanteen.\\nVamos a tratar de abordar estas cuestiones por medio de soluciones ya existentes como el tipo de\\nresponsabilidad que debe operar bajo estos presupuestos, si es o no pertinente un seguro de RC obligatorio\\ny otros nuevos como por ejemplo la posible creación de un nuevo tipo de personalidad jurídica\\natribuible a las máquinas de IA con un patrimonio y una solvencia que los permita responder por el\\neventual daño causado.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 26, 'page': 10, '_split_overlap': [{'doc_id': '48c2e521212ef7ad35703ad681b6b050', 'range': (0, 146)}, {'doc_id': 'cd38af4de40bb1732e54cc80940e6c52', 'range': (468, 887)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '666718bd3b9d259b8cf1c6d4b6272b08'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Vamos a tratar de abordar estas cuestiones por medio de soluciones ya existentes como el tipo de\\nresponsabilidad que debe operar bajo estos presupuestos, si es o no pertinente un seguro de RC obligatorio\\ny otros nuevos como por ejemplo la posible creación de un nuevo tipo de personalidad jurídica\\natribuible a las máquinas de IA con un patrimonio y una solvencia que los permita responder por el\\neventual daño causado.\\nb. Fragmentación del mercado único y consecuencias sobre la RC\\nEl riesgo que conlleva la falta de una visión desde la UE, en relación a la RC y la IA, y una normativa\\neuropea para desarrollar una normativa Estatal, fomentaría consecuencias distintas para los agentes\\nparticipantes en el desarrollo de productos con IA en función del EEMM. Por ello, es preponderante\\nque se plantee un cuerpo legislativo fuerte desde la UE que prevea todos estos riesgos y marque un\\ncamino de acción por parte de los EEMM. A continuación intentaremos retratar estos riesgos y ofrecer\\nposibles soluciones de acuerdo a los valores y derechos defendidos por la UE.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 27, 'page': 10, '_split_overlap': [{'doc_id': '666718bd3b9d259b8cf1c6d4b6272b08', 'range': (0, 419)}, {'doc_id': 'e39ee07e07f59a780955e544b2d951f0', 'range': (925, 1063)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'cd38af4de40bb1732e54cc80940e6c52'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: A continuación intentaremos retratar estos riesgos y ofrecer\\nposibles soluciones de acuerdo a los valores y derechos defendidos por la UE.\\nc. Problemas RC\\nLa complejidad y opacidad de los sistemas de IA complica la tarea de discernir qué agente puede ser\\nresponsable de un daño ocasionado en el uso de productos IA o de la prestación de servicios de IA.\\nHacen muy difícil que un consumidor pueda hacer valer de manera eficaz sus derechos y reclamar una\\ncompensación por un daño sufrido, a través de un sistema subjetivo de responsabilidad en el que este\\ndeba demostrar la culpa del fabricante.\\nPor ello, esta responsabilidad extracontractual deberá descansar en un criterio de imputación objetivo o, al\\nmenos, de presunción de culpa, en el que el usuario que ha sufrido un daño deba demostrar este y el nexo\\ncausal entre el comportamiento del producto o servicio de IA y el daño, debiendo ser los agentes detrás\\nde la solución de IA los que deban encontrar alguna causa que pueda eximirles de responsabilidad.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 28, 'page': 10, '_split_overlap': [{'doc_id': 'cd38af4de40bb1732e54cc80940e6c52', 'range': (0, 138)}, {'doc_id': 'e9a9abdf7b73af8a4839062267e735a5', 'range': (594, 1009)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e39ee07e07f59a780955e544b2d951f0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Por ello, esta responsabilidad extracontractual deberá descansar en un criterio de imputación objetivo o, al\\nmenos, de presunción de culpa, en el que el usuario que ha sufrido un daño deba demostrar este y el nexo\\ncausal entre el comportamiento del producto o servicio de IA y el daño, debiendo ser los agentes detrás\\nde la solución de IA los que deban encontrar alguna causa que pueda eximirles de responsabilidad.\\nLas primeras soluciones que planteamos son:\\x0c10\\n1) la inversión de la carga de la prueba sobre las personas (físicas o jurídicas) que hayan\\nparticipado en el desarrollo, producción y comercialización.\\n2) la presunción de culpabilidad como un criterio de imputación objetiva por el cual estos\\nmismos agentes deberán demostrar que han actuado de manera diligente y que no se les puede\\nresponsabilizar por las consecuencias del evento dañoso.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 29, 'page': 10, '_split_overlap': [{'doc_id': 'e39ee07e07f59a780955e544b2d951f0', 'range': (0, 415)}, {'doc_id': '84d61f51743d9bab84b2ac99dd9c27bb', 'range': (616, 854)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e9a9abdf7b73af8a4839062267e735a5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: 2) la presunción de culpabilidad como un criterio de imputación objetiva por el cual estos\\nmismos agentes deberán demostrar que han actuado de manera diligente y que no se les puede\\nresponsabilizar por las consecuencias del evento dañoso.\\nBajo este criterio de imputación objetiva o presunción de culpa de los agentes involucrados, estos\\nserían los que tendrían que demostrar su hacer diligente y adecuado, facilitando al consumidor la\\nreclamación de estos daños, puesto que solo tendrá que probar el daño que se le ha causado y la relación\\ncausal entre este y la solución de IA que presuntamente se lo ha ocasionado.\\nDe otra forma estos procedimientos serían muy costosos y muchas acciones con fundamento no\\nprosperarían porque muchos afectados no tendrían capacidad económica para afrontar el coste del\\nprocedimiento, perdiendo irremediablemente la acción. Sería necesaria la contratación de peritos\\nespecializados que pudieran discernir dónde ha estado el fallo que ha causado el daño.\\nA través de la inversión de la carga de la prueba son las empresas las que tienen que aportar la prueba\\ny abogar por su diligencia. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 30, 'page': 11, '_split_overlap': [{'doc_id': 'e9a9abdf7b73af8a4839062267e735a5', 'range': (0, 238)}, {'doc_id': '68ea0330f201c8cded744d6c8a2e409a', 'range': (989, 1120)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '84d61f51743d9bab84b2ac99dd9c27bb'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: A través de la inversión de la carga de la prueba son las empresas las que tienen que aportar la prueba\\ny abogar por su diligencia. Tienen acceso a toda la prueba y pueden demostrar si han actuado de manera\\ndiligente, culposa o si han atendido de manera adecuada un posible riesgo. Conocen los códigos y\\nalgoritmos que hacen funcionar estos productos y servicios, los datos en los que se basan y sobre los\\ncuales toman sus decisiones estas soluciones de IA. Es mucho más sencillo que sean ellas las que tengan\\nque aportar la prueba a que sean los usuarios los que tengan que demostrar el daño, el nexo causal y la\\nculpa de las empresas.\\nEn consecuencia, creemos que cuando estemos antes soluciones de IA que puedan tener un riesgo\\nrelevante que pueda causar un daño, deberá de estarse a estas dos cuestiones: la inversión de la carga de\\nla prueba y la presunción de culpabilidad. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 31, 'page': 11, '_split_overlap': [{'doc_id': '84d61f51743d9bab84b2ac99dd9c27bb', 'range': (0, 131)}, {'doc_id': '9277b435524dba1ab4e4988ad21bda34', 'range': (637, 879)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '68ea0330f201c8cded744d6c8a2e409a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: En consecuencia, creemos que cuando estemos antes soluciones de IA que puedan tener un riesgo\\nrelevante que pueda causar un daño, deberá de estarse a estas dos cuestiones: la inversión de la carga de\\nla prueba y la presunción de culpabilidad. De esta manera las empresas que hayan causado un daño deberán\\nde probar que han actuado de acuerdo la diligencia exigida o que, por el contrario, el daño ha surgido\\ncomo consecuencia de fuerza mayor, que se trate de un caso fortuito, el hacer de un tercero o que la\\nculpa recaiga exclusivamente sobre la víctima.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 32, 'page': 11, '_split_overlap': [{'doc_id': '68ea0330f201c8cded744d6c8a2e409a', 'range': (0, 242)}, {'doc_id': '55914acb135a6c85ad4d5117c831a54f', 'range': (243, 555)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9277b435524dba1ab4e4988ad21bda34'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: De esta manera las empresas que hayan causado un daño deberán\\nde probar que han actuado de acuerdo la diligencia exigida o que, por el contrario, el daño ha surgido\\ncomo consecuencia de fuerza mayor, que se trate de un caso fortuito, el hacer de un tercero o que la\\nculpa recaiga exclusivamente sobre la víctima.\\nd. Responsabilidad por hechos propios (responsabilidad objetiva, doctrina del riesgo) y\\nresponsabilidad por hechos ajenos\\nPara poder determinar la concurrencia responsabilidad civil extracontractual deben de cumplirse los\\nsiguientes requisitos:\\n- Una acción u omisión\\n- Causación de un daño\\n- Nexo causal entre la acción u omisión y el daño\\n- Existencia de un criterio que permita imputar la responsabilidad extracontractual\\nDadas las características de la IA (que en ocasiones el hacer de esta diverge de la intención inicial de su\\ncreador y se desarrolla y razona de acuerdo a su algoritmo) y de manera más concreta a aquellas IAs\\nque conlleven un riesgo elevado para los usuarios y por la opacidad para poder demostrar la\\nconcurrencia de culpa y a quién corresponde debemos de considerar qué solución se aproxima más a\\nser justa.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 33, 'page': 11, '_split_overlap': [{'doc_id': '9277b435524dba1ab4e4988ad21bda34', 'range': (0, 312)}, {'doc_id': 'dc20b0033212c7114e5e4893874fcc34', 'range': (313, 1145)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '55914acb135a6c85ad4d5117c831a54f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: d. Responsabilidad por hechos propios (responsabilidad objetiva, doctrina del riesgo) y\\nresponsabilidad por hechos ajenos\\nPara poder determinar la concurrencia responsabilidad civil extracontractual deben de cumplirse los\\nsiguientes requisitos:\\n- Una acción u omisión\\n- Causación de un daño\\n- Nexo causal entre la acción u omisión y el daño\\n- Existencia de un criterio que permita imputar la responsabilidad extracontractual\\nDadas las características de la IA (que en ocasiones el hacer de esta diverge de la intención inicial de su\\ncreador y se desarrolla y razona de acuerdo a su algoritmo) y de manera más concreta a aquellas IAs\\nque conlleven un riesgo elevado para los usuarios y por la opacidad para poder demostrar la\\nconcurrencia de culpa y a quién corresponde debemos de considerar qué solución se aproxima más a\\nser justa.\\x0c11\\nPresentamos tres soluciones las cuales presentan ventajas enfocadas a facilitar el resarcimiento de daños\\ncausados por soluciones de IA pero, a su vez, también tienen sus desventajas como podría ser un\\nrégimen demasiado gravoso y exigente a la hora de marcar un nivel de diligencia adecuado. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 34, 'page': 11, '_split_overlap': [{'doc_id': '55914acb135a6c85ad4d5117c831a54f', 'range': (0, 832)}, {'doc_id': 'c4e4fb23b7816c33d5ac0637bd9c02b', 'range': (833, 1127)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'dc20b0033212c7114e5e4893874fcc34'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: 11\\nPresentamos tres soluciones las cuales presentan ventajas enfocadas a facilitar el resarcimiento de daños\\ncausados por soluciones de IA pero, a su vez, también tienen sus desventajas como podría ser un\\nrégimen demasiado gravoso y exigente a la hora de marcar un nivel de diligencia adecuado. Estas tres\\nposibilidades serían aplicar: 1) una responsabilidad objetiva, 2) la doctrina del riesgo o 3) un régimen\\nsimilar o comparable al de los padres, madres o tutores en relación con sus hijos.\\na) Responsabilidad por hechos propios\\n1. Responsabilidad objetiva\\nComo fundamento de la responsabilidad objetiva suele admitirse que no existe un único argumento\\nsino un conjunto de criterios determinados por un riesgo anormal o extraordinario. Lo que motiva este\\ncriterio de determinación objetivo de la responsabilidad es el riesgo extraordinario o anormal inherente a\\nuna acción u omisión. Los criterios de la responsabilidad objetiva son una probabilidad especialmente\\nalta de que el riesgo se materialice, la probabilidad de que el daño sea catastrófico o que pueda existir\\nun riesgo potencial que a priori no se pueda descartar y que pudiera acaecer. Todos los anteriores son\\nposibles resultados de la aplicación de la IA en determinados sectores y para determinadas tareas.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 35, 'page': 12, '_split_overlap': [{'doc_id': 'dc20b0033212c7114e5e4893874fcc34', 'range': (0, 294)}, {'doc_id': '707e11e46cdf477b4a8765aaedc060a4', 'range': (887, 1274)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c4e4fb23b7816c33d5ac0637bd9c02b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Los criterios de la responsabilidad objetiva son una probabilidad especialmente\\nalta de que el riesgo se materialice, la probabilidad de que el daño sea catastrófico o que pueda existir\\nun riesgo potencial que a priori no se pueda descartar y que pudiera acaecer. Todos los anteriores son\\nposibles resultados de la aplicación de la IA en determinados sectores y para determinadas tareas.\\nPensamos que son aplicables a este sector, al menos cuando el riesgo sea elevado.\\nQue la responsabilidad no dependa de la culpa no debe entenderse como una forma de repartir\\nsocialmente ciertos riesgos. Quienes deciden llevar estas actividades anormalmente peligrosas para\\nponer en marcha una actividad o servicio para lucrarse y causan un daño, pese a haber actuado de\\nmanera diligente, han aceptado la existencia de estos riesgos de antemano, por lo que cobra sentido que\\nsean estos sujetos privados los que soporten la responsabilidad.\\nEl potencial económico de todos los negocios que apliquen IA va a ser exponencial e ingente. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 36, 'page': 12, '_split_overlap': [{'doc_id': 'c4e4fb23b7816c33d5ac0637bd9c02b', 'range': (0, 387)}, {'doc_id': 'da796972bf81933c5248dd8de2ebc55a', 'range': (591, 1019)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '707e11e46cdf477b4a8765aaedc060a4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Quienes deciden llevar estas actividades anormalmente peligrosas para\\nponer en marcha una actividad o servicio para lucrarse y causan un daño, pese a haber actuado de\\nmanera diligente, han aceptado la existencia de estos riesgos de antemano, por lo que cobra sentido que\\nsean estos sujetos privados los que soporten la responsabilidad.\\nEl potencial económico de todos los negocios que apliquen IA va a ser exponencial e ingente. De modo\\nque tiene sentido que sean los agentes detrás de un producto o servicio IA quienes deban responder por\\nlos posibles daños que puedan acaecer como consecuencia de la explotación de la IA a pesar de que\\nhayan actuado de forma diligente.\\nEl punto negativo de la objetivación de la responsabilidad es que no premia la diligencia del empresario\\no no castiga la falta de cuidado y puede provocar que el empresario no cuide tanto “no cometer errores”\\ny “no proteja al consumidor de una manera tan exhaustiva” dado que en cualquier caso va a recaer\\nsobre él la RC.\\nEsta solución no está libre de problemas. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 37, 'page': 12, '_split_overlap': [{'doc_id': '707e11e46cdf477b4a8765aaedc060a4', 'range': (0, 428)}, {'doc_id': '38eb5f540216b514aaf7dc4e9c3f1201', 'range': (672, 1035)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'da796972bf81933c5248dd8de2ebc55a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: El punto negativo de la objetivación de la responsabilidad es que no premia la diligencia del empresario\\no no castiga la falta de cuidado y puede provocar que el empresario no cuide tanto “no cometer errores”\\ny “no proteja al consumidor de una manera tan exhaustiva” dado que en cualquier caso va a recaer\\nsobre él la RC.\\nEsta solución no está libre de problemas. Sin embargo, dado el beneficio económico que van a reportar\\nlos negocios que implementen soluciones IA a sus productos y servicios, parece apropiado que sean\\nobjetivamente responsable en los casos en los que la aplicación de la IA implique que se den los criterios\\npara la aplicación de este tipo de responsabilidad civil extracontractual.\\n2. Doctrina del Riesgo\\nCobra sentido para los casos de aplicación de la IA en los que exista un riesgo considerable, un principio\\nde precaución. La doctrina del riesgo acepta que el riesgo sea el fundamento de una eventual responsabilidad\\ncivil extracontractual. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 38, 'page': 12, '_split_overlap': [{'doc_id': 'da796972bf81933c5248dd8de2ebc55a', 'range': (0, 363)}, {'doc_id': '75bfe729249ceee20601d62ff6013f2a', 'range': (707, 966)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '38eb5f540216b514aaf7dc4e9c3f1201'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Doctrina del Riesgo\\nCobra sentido para los casos de aplicación de la IA en los que exista un riesgo considerable, un principio\\nde precaución. La doctrina del riesgo acepta que el riesgo sea el fundamento de una eventual responsabilidad\\ncivil extracontractual. No se objetiva la responsabilidad sino que, debido al elevado riesgo de la actividad,\\nse exigen cánones de diligencia más elevados y se invierte la carga de la prueba para que sea el posible\\nresponsable quien deba de demostrar que su actuar era diligente y concurría con todas las previsiones\\x0c12\\ny precauciones debidas en relación el riesgo en cuestión, medidas de precaución y de cuidados mayores\\nen pro de evitar el daño.\\nSin embargo, se concede al potencial responsable del daño la posibilidad de liberarse de la\\nresponsabilidad demostrando que, efectivamente, ha actuado con la diligencia exigible y con el\\nsuficiente cuidado de acuerdo al riesgo que estaba en juego. Para el supuesto de que no se cumpliera\\ncon esta diligencia exigible de acuerdo al riesgo, se entendería probado el nexo causal tanto desde el\\npunto de vista físico como desde el jurídico.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 39, 'page': 12, '_split_overlap': [{'doc_id': '38eb5f540216b514aaf7dc4e9c3f1201', 'range': (0, 259)}, {'doc_id': 'ea03c670a920d97c091778ae6e3c2852', 'range': (932, 1120)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '75bfe729249ceee20601d62ff6013f2a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Para el supuesto de que no se cumpliera\\ncon esta diligencia exigible de acuerdo al riesgo, se entendería probado el nexo causal tanto desde el\\npunto de vista físico como desde el jurídico.\\nPor lo tanto, la responsabilidad por riesgo es una de las posibles soluciones al problema que arroja la IA\\na la RC. Para aquellas actividades de riesgo que puedan ser peligrosas para los usuarios tanto por el\\nsector en el que operen como por la actividad que desempeñen, habremos de estar a una elevación del\\nestándar de diligencia en proporción al potencial riesgo. En caso de que estos agentes no sean capaces\\nde probar su diligencia y falta de cuidado en función del riesgo se les tendrá como responsables de\\ndaño.\\nb) Responsabilidad por hechos ajenos\\nEl artículo 1.903 del Código Civil prevé la responsabilidad por hecho ajeno, una responsabilidad por\\nculpa en cuanto a una falta de diligencia. De esta manera, una persona distinta de la que ha ocasionado\\nel daño es directamente responsable del mismo. Está previsto para aplicarse a padres, tutores o\\nempresario. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 40, 'page': 13, '_split_overlap': [{'doc_id': '75bfe729249ceee20601d62ff6013f2a', 'range': (0, 188)}, {'doc_id': '272d646546723cb64abab43115baa0b1', 'range': (888, 1056)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ea03c670a920d97c091778ae6e3c2852'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: De esta manera, una persona distinta de la que ha ocasionado\\nel daño es directamente responsable del mismo. Está previsto para aplicarse a padres, tutores o\\nempresario. Esta negligencia puede concretarse en una falta de vigilancia dada la relación de\\nsubordinación o dependencia existente entre el autor material del daño y la persona que será\\ndirectamente responsable del daño. Esta responsabilidad será directa, por lo que podrá reclamarse\\ndirectamente contra las personas que refiere este art. 1.903.\\nDestaca el marcado carácter de culpa subjetivo ya que se responsabiliza directamente a otra persona de\\nla que depende el agente que ha cometido la acción que ha dado lugar a la responsabilidad por una\\nactitud pasiva, de omisión o de falta de vigilancia que ha permitido que se cause el daño en cuestión.\\nAterrizando esto a la IA son escenarios similares. En ambos casos se trata de entes subordinados y\\ndependientes cuya voluntad se escinde de la de su creador o persona de la que dependen. Por medio\\nde este sistema se pretende cuidar la falta de diligencia de vigilancia y de cuidado por la persona directamente\\nresponsable a la que se le puede cargar con este deber de vigilancia.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 41, 'page': 13, '_split_overlap': [{'doc_id': 'ea03c670a920d97c091778ae6e3c2852', 'range': (0, 168)}, {'doc_id': '67e7d6d77fab117cb20eed2a0a2ee184', 'range': (995, 1187)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '272d646546723cb64abab43115baa0b1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Por medio\\nde este sistema se pretende cuidar la falta de diligencia de vigilancia y de cuidado por la persona directamente\\nresponsable a la que se le puede cargar con este deber de vigilancia.\\nEn el caso de los sistemas de IA (siempre y cuando no se le atribuya una personalidad jurídica con un\\npatrimonio que pudiera responder de los daños causados) no van a estar en condiciones de responder\\npor un daño que hayan podido causar. Por eso, tiene sentido que se responsabilice de manera directa a\\nla persona de la cual dependen, la que tiene este deber de vigilancia y que no puede permitir todo, sino\\nque tiene que limitar el hacer de estas. El hacer de la IA, al igual que el de un menor, está marcado por\\nunos patrones (basados en código y algoritmo) pero su voluntad se escinde de la de su creador ya que\\nrazona de manera independiente para alcanzar un fin lo cual lo dota de una cierta imprevisibilidad. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 42, 'page': 13, '_split_overlap': [{'doc_id': '272d646546723cb64abab43115baa0b1', 'range': (0, 192)}, {'doc_id': '17bb4d537d223ff42b7a1951c4fa5124', 'range': (642, 907)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '67e7d6d77fab117cb20eed2a0a2ee184'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: El hacer de la IA, al igual que el de un menor, está marcado por\\nunos patrones (basados en código y algoritmo) pero su voluntad se escinde de la de su creador ya que\\nrazona de manera independiente para alcanzar un fin lo cual lo dota de una cierta imprevisibilidad. Así,\\nel fabricante, comercializador o agente que use esta solución IA deberá ejercer este control, llegando a\\nretirarlo si fuera necesario del mercado para solucionar cualquier riesgo que pudiera haber o, por el\\ncontrario, afrontar la responsabilidad directa de la materialización del riesgo en daños.\\x0c13\\ne. ¿Sobre quién recaería la RC? ¿Cobra sentido una Personalidad Jurídica para la IA?\\nLa conducta de los sistemas de IA con capacidad de aprendizaje no supervisado, en ocasiones puede\\nser imprevisible, no pudiendo incluso prever algunos riesgos o situaciones que pueden darse. Esto va a\\nconcretarse en muchas ocasiones en daños y en situaciones que pueden poner en jaque los sistemas de\\nresponsabilidad civil y en los que, además, deberemos determinar los parámetros por los que se va a\\ndeterminar quién es responsable de estos daños.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 43, 'page': 13, '_split_overlap': [{'doc_id': '67e7d6d77fab117cb20eed2a0a2ee184', 'range': (0, 265)}, {'doc_id': 'fe5b4bda065c91e2b46604afc9ab1faf', 'range': (847, 1104)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '17bb4d537d223ff42b7a1951c4fa5124'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Esto va a\\nconcretarse en muchas ocasiones en daños y en situaciones que pueden poner en jaque los sistemas de\\nresponsabilidad civil y en los que, además, deberemos determinar los parámetros por los que se va a\\ndeterminar quién es responsable de estos daños.\\na) Fabricante\\nConsiderando la incertidumbre y los riesgos inherentes a la IA debe prevalecer un principio de\\nprecaución que obligue al fabricante o al propietario que lo controla a actuar de manera especialmente\\ndiligente y tomando las medidas posibles para minimizar el riesgo.\\nHacer responsable al fabricante de los daños o riesgos que puedan materializarse por el uso de sistemas\\nde IA fomentará que el fabricante operé con un especial cuidado. Sin embargo, un régimen demasiado\\nférreo puede ser un obstáculo para que el sector privado invierta en la UE en investigación y desarrollo.\\nLa dificultad oscila en encontrar el equilibrio.\\nLa UE aboga por marcar un límite cuantitativo a esta responsabilidad el cual debemos recordar que\\naplicará para daños materiales, pero no a los personales. De nuevo, la determinación de la\\nresponsabilidad deberá de atender a criterios objetivos. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 44, 'page': 14, '_split_overlap': [{'doc_id': '17bb4d537d223ff42b7a1951c4fa5124', 'range': (0, 257)}, {'doc_id': 'f382ce8e8d33e2bdcd67d04624026b0a', 'range': (895, 1140)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fe5b4bda065c91e2b46604afc9ab1faf'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: La UE aboga por marcar un límite cuantitativo a esta responsabilidad el cual debemos recordar que\\naplicará para daños materiales, pero no a los personales. De nuevo, la determinación de la\\nresponsabilidad deberá de atender a criterios objetivos. Se invierte la carga de la prueba para que el\\nfabricante pueda argumentar cualquier cuestión que le exima de responsabilidad (actuación correcta\\ndel robot, fuerza mayor, culpa del perjudicado, etc.).\\nUna limitación o exoneración de la responsabilidad puede encontrarse en que el fabricante haya\\ncompartido unas limitaciones de expectativas de seguridad o instrucciones, si de acuerdo a la evolución\\ndel sistema de IA y de los conocimientos del fabricante este puede vaticinar un riesgo o la consecución\\nde un potencial daño.\\nSerá interesante la imposición de un seguro de responsabilidad obligatorio, al menos en los supuestos\\ncatalogados de riesgo, a pesar de que esto en un último término se traduzca en un aumento en el precio\\ndel producto o servicio.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 45, 'page': 14, '_split_overlap': [{'doc_id': 'fe5b4bda065c91e2b46604afc9ab1faf', 'range': (0, 245)}, {'doc_id': 'a17f7c05c4cf9e4975a72606d562079f', 'range': (771, 1000)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f382ce8e8d33e2bdcd67d04624026b0a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Será interesante la imposición de un seguro de responsabilidad obligatorio, al menos en los supuestos\\ncatalogados de riesgo, a pesar de que esto en un último término se traduzca en un aumento en el precio\\ndel producto o servicio.\\nb) Empresario que se sirve del robot inteligente\\nEl empresario que se sirva de los servicios del robot inteligente en la esfera profesional con la finalidad\\nde obtener una ganancia económica deberá responder por los daños cometidos por el robot de acuerdo\\na criterios objetivos.\\nPodrán darse dos situaciones, una responsabilidad contractual o una responsabilidad por hecho ajeno\\ncuando no exista contrato entre las partes. La responsabilidad estará basada en la teoría del riesgo\\natendiendo a dos criterios: la probabilidad de que el riesgo se materialice y la gravedad del mismo.\\nEl empresario deberá tener la obligación controlar y vigilar el robot y su desempeño y, de acuerdo al\\nrango de peligrosidad concreto deberá atenderse a criterios de responsabilidad objetiva. El perjudicado\\ndeberá, únicamente probar el daño y el nexo con el sistema de IA.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 46, 'page': 14, '_split_overlap': [{'doc_id': 'f382ce8e8d33e2bdcd67d04624026b0a', 'range': (0, 229)}, {'doc_id': '40abd5839a369afaef8dcea70dea2753', 'range': (811, 1082)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a17f7c05c4cf9e4975a72606d562079f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: El empresario deberá tener la obligación controlar y vigilar el robot y su desempeño y, de acuerdo al\\nrango de peligrosidad concreto deberá atenderse a criterios de responsabilidad objetiva. El perjudicado\\ndeberá, únicamente probar el daño y el nexo con el sistema de IA.\\x0c14\\nc) Responsabilidad del usuario del robot:\\nSi entendemos por el usuario a la persona que adquiere el sistema de IA para su uso personal, este\\npuede ser o no el propietario del mismo. En el supuesto en el que poseedor y propietario coincidan en\\nuna misma persona estaremos a los criterios de responsabilidad objetiva o por riesgo que hemos\\nreferido.\\nPara el caso de que propietario y poseedor del robot no coincidan deberemos distinguir entre los\\nsiguientes supuestos:\\n- Cesión de uso a un tercero o pérdida de la máquina: la responsabilidad deberá ser solidaria\\npor partes iguales entre el propietario (obligación de vigilancia) y el usuario-poseedor que\\ndeberá de actuar con diligencia y precaución para reducir los riesgos.\\n- En caso de robo o apropiación indebida el único responsable será el ladrón que se está valiendo\\ndel sistema de IA.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 47, 'page': 14, '_split_overlap': [{'doc_id': 'a17f7c05c4cf9e4975a72606d562079f', 'range': (0, 271)}, {'doc_id': '7d4e85c1996dc2a19646ae3e3cf164ef', 'range': (1000, 1116)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '40abd5839a369afaef8dcea70dea2753'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: - En caso de robo o apropiación indebida el único responsable será el ladrón que se está valiendo\\ndel sistema de IA.\\nd) Responsabilidad del Robot Autónomo Inteligente con Personalidad Jurídica\\nOtro mecanismo a valorar en relación con las IA de Alto riesgo es la creación de una personalidad\\njurídica propia para los robots (e-personality). Hay un sector favorable a la creación de un nuevo\\nvehículo apropiado y a medida, acorde a las necesidades que permita a los sistemas de IA tener\\npersonalidad jurídica propia de una manera Ad hoc. Otro sector, en cambio, no lo ven necesario porque\\nel ordenamiento jurídico ya ofrece soluciones de este tipo. Por muy completa y autónoma que sea la IA\\nnunca podrán ser consideradas auténticas personas.\\nSi se acepta la e-personality a las soluciones de IA, se les podría atribuir un estatus jurídico específico\\npara proteger determinados intereses de la sociedad, similar a la ya existente personalidad jurídica\\nsocietaria. Serían sujetos susceptibles de adquirir derechos y contraer obligaciones, podrían ser\\nacreedoras o contraer deudas, poseer patrimonio propio y representar un interés social o económico.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 48, 'page': 15, '_split_overlap': [{'doc_id': '40abd5839a369afaef8dcea70dea2753', 'range': (0, 116)}, {'doc_id': '197deddd4aa87b7f860bc55d0f78a66d', 'range': (961, 1146)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7d4e85c1996dc2a19646ae3e3cf164ef'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Serían sujetos susceptibles de adquirir derechos y contraer obligaciones, podrían ser\\nacreedoras o contraer deudas, poseer patrimonio propio y representar un interés social o económico.\\nSupondría un mecanismo de control para evitar los riesgos de la nueva realidad, con unas finalidades\\nque determinan sus condiciones de uso y sus límites, específica a determinados robots (a los sistemas\\nde IA más autónomos o avanzados), como invención puramente técnica, formal y abstracta, con el objeto\\nde proteger determinados intereses de la humanidad, teniendo muy presente su condición de sistema\\nsometido y subordinado en todo momento al beneficio e interés de los humanos.\\nUn robot autónomo no es un ente libre e independiente, no se le puede imputar por el momento ningún\\ntipo de culpabilidad, ni de responsabilidad que derive de la conciencia de sus actos. Siempre va a\\npertenecer a personas físicas o jurídicas, que son las que en última instancia van a permitir o decidir que\\nsiga funcionando o que cese en su empleo. Su voluntad no se ha formado de manera completamente\\nlibre, sino más bien es dependiente y sometido a la voluntad de otro.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 49, 'page': 15, '_split_overlap': [{'doc_id': '7d4e85c1996dc2a19646ae3e3cf164ef', 'range': (0, 185)}, {'doc_id': '8a70e4707d61177391a6f8fb4af4b2ee', 'range': (1016, 1138)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '197deddd4aa87b7f860bc55d0f78a66d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Su voluntad no se ha formado de manera completamente\\nlibre, sino más bien es dependiente y sometido a la voluntad de otro.\\nNo obstante, The Expert Group on Liability and New Technologies, en su informe de 2019, establecen que\\nno es necesario el atribuir esta personalidad legal a los sistemas autónomos de IA a efectos de atribuirles\\nRC.\\nLa creación de un fondo de compensación de los daños y perjuicios sería útil en los casos en los que no\\nexista la cobertura de seguro, a cargo del fabricante, del comercializador o, en general, de cualquier\\nagente interviniente en el proceso productivo del robot o sistema de inteligencia artificial; como acto\\núnico, o mediante dotaciones periódicas; disponibilidad del fondo y requisitos para la gestión y, en su\\ncaso, rentabilización del mismo.\\x0c15\\nEn ocasiones la personalidad jurídica puede llegar a emplearse para defraudar a los acreedores (“abuso\\nde la personalidad jurídica”). Para combatir existe la doctrina del levantamiento del velo la cual\\npodríamos trasladar y aplicar en estos casos. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 50, 'page': 15, '_split_overlap': [{'doc_id': '197deddd4aa87b7f860bc55d0f78a66d', 'range': (0, 122)}, {'doc_id': '5b1a47b1fa2c093dc07bf177f5233dce', 'range': (786, 1036)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8a70e4707d61177391a6f8fb4af4b2ee'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: 15\\nEn ocasiones la personalidad jurídica puede llegar a emplearse para defraudar a los acreedores (“abuso\\nde la personalidad jurídica”). Para combatir existe la doctrina del levantamiento del velo la cual\\npodríamos trasladar y aplicar en estos casos. Cuestión muy relevante puesto que esta suerte de persona\\nelectrónica no deberá de incurrir en infracapitalización, teniendo en cuenta el riesgo de la actividad, la\\ngravedad de los daños que pueda ocasionar y la probabilidad de los mismos o un seguro de\\nresponsabilidad civil obligatorio que pueda afrontar con solvencia eventual los daños que haya podido\\ncausar.\\nLa cuestión no es pacífica y parece una solución viable pero lo cierto es que la responsabilidad objetiva\\npor parte de los distintos agentes que participen en el desarrollo de la solución de IA puede también ser\\nuna solución adecuada a este problema.\\nf. Alcance temporal de la responsabilidad\\n¿Hasta qué momento deben de responder los agentes detrás de una solución de IA por los daños que\\ncause el mismo? No hay un referente actual en el mercado que pueda proveernos con una solución\\nadecuada y que además haya sido contrastada y demostrada o no su viabilidad.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 51, 'page': 16, '_split_overlap': [{'doc_id': '8a70e4707d61177391a6f8fb4af4b2ee', 'range': (0, 250)}, {'doc_id': 'f7a7cdcff096803f1b32fabf7a031114', 'range': (1020, 1175)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5b1a47b1fa2c093dc07bf177f5233dce'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: No hay un referente actual en el mercado que pueda proveernos con una solución\\nadecuada y que además haya sido contrastada y demostrada o no su viabilidad.\\nAl tratarse de sistemas que funcionan con código y algoritmo que hace que la voluntad del sistema de\\nIA se escinda de la de su creador, el deber de vigilancia y cuidado de este no puede tener un límite\\ntemporal. El fabricante deberá llevar a cabo un seguimiento de la solución IA observando el\\nfuncionamiento del mismo y estando pendiente de posibles riesgos que puedan surgir a lo largo de la\\nvida del mismo.\\nPor ello recae sobre el fabricante una obligación de vigilancia o seguimiento. Esta obligación incluye un\\ndeber de información y de adopción de medidas para reducir los posibles riesgos, incluso retirando el\\nproducto o servicio con el fin de modificar lo que sea necesario para asegurar la seguridad de la solución\\nIA.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 52, 'page': 16, '_split_overlap': [{'doc_id': '5b1a47b1fa2c093dc07bf177f5233dce', 'range': (0, 155)}, {'doc_id': 'f005e9124f3b3b3fc090f54e62b411b0', 'range': (645, 884)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f7a7cdcff096803f1b32fabf7a031114'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Esta obligación incluye un\\ndeber de información y de adopción de medidas para reducir los posibles riesgos, incluso retirando el\\nproducto o servicio con el fin de modificar lo que sea necesario para asegurar la seguridad de la solución\\nIA.\\ng. Seguro de RC obligatorio\\nTeniendo en consideración todo lo expuesto y a su vez el Informe sobre responsabilidad derivada de la\\nIA y otras tecnologías digitales emergentes del Grupo de Expertos sobre responsabilidad y nuevas tecnologías\\nde la Comisión Europea, que dentro identificaba, entre las características esenciales que deberán tener los\\nregímenes responsabilidad derivada de la IA y el uso de otras tecnologías digitales emergentes para\\nproteger a las víctimas de los daños sufridos, ya señala que “En situaciones que exponen a terceros a un\\nriesgo incrementado de daños, un seguro de responsabilidad civil obligatorio podría darles a las víctimas un\\nmejor acceso a la compensación y proteger a los potenciales causantes contra el riesgo de responsabilidad”.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 53, 'page': 16, '_split_overlap': [{'doc_id': 'f7a7cdcff096803f1b32fabf7a031114', 'range': (0, 239)}, {'doc_id': '20b8f840dc28472639cad404bb83137', 'range': (240, 1008)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f005e9124f3b3b3fc090f54e62b411b0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: g. Seguro de RC obligatorio\\nTeniendo en consideración todo lo expuesto y a su vez el Informe sobre responsabilidad derivada de la\\nIA y otras tecnologías digitales emergentes del Grupo de Expertos sobre responsabilidad y nuevas tecnologías\\nde la Comisión Europea, que dentro identificaba, entre las características esenciales que deberán tener los\\nregímenes responsabilidad derivada de la IA y el uso de otras tecnologías digitales emergentes para\\nproteger a las víctimas de los daños sufridos, ya señala que “En situaciones que exponen a terceros a un\\nriesgo incrementado de daños, un seguro de responsabilidad civil obligatorio podría darles a las víctimas un\\nmejor acceso a la compensación y proteger a los potenciales causantes contra el riesgo de responsabilidad”.\\nConcluyendo “33) Cuanto más frecuente o grave sea el daño potencial resultante de la tecnología digital emergente\\ny cuanto menos probable sea que el operador pueda indemnizar a las víctimas; más adecuado será obligar a contar\\ncon un seguro de responsabilidad civil para la cobertura de tales riesgos.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 54, 'page': 16, '_split_overlap': [{'doc_id': 'f005e9124f3b3b3fc090f54e62b411b0', 'range': (0, 768)}, {'doc_id': 'beb59deb3efcd4f4d89fc4d4ae68dd59', 'range': (769, 1069)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '20b8f840dc28472639cad404bb83137'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Concluyendo “33) Cuanto más frecuente o grave sea el daño potencial resultante de la tecnología digital emergente\\ny cuanto menos probable sea que el operador pueda indemnizar a las víctimas; más adecuado será obligar a contar\\ncon un seguro de responsabilidad civil para la cobertura de tales riesgos.\\nConsideramos que sí sería prudente implantar el seguro obligatorio pero haciendo especial atención al\\nriesgo inherente a la aplicación de la solución de IA en cuestión y no como un criterio general aplicable\\na cualquier solución de IA, dado que algunas de sus posibles aplicaciones o funcionalidades podrían no\\nllevar riesgos aparejados a su desempeño.\\nHabrá muchas situaciones en las que exigir la contratación de un seguro de responsabilidad civil pueda\\nser contraproducente. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 55, 'page': 16, '_split_overlap': [{'doc_id': '20b8f840dc28472639cad404bb83137', 'range': (0, 300)}, {'doc_id': '2618d872c9cb0b8c20faee56d2793663', 'range': (301, 778)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'beb59deb3efcd4f4d89fc4d4ae68dd59'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Consideramos que sí sería prudente implantar el seguro obligatorio pero haciendo especial atención al\\nriesgo inherente a la aplicación de la solución de IA en cuestión y no como un criterio general aplicable\\na cualquier solución de IA, dado que algunas de sus posibles aplicaciones o funcionalidades podrían no\\nllevar riesgos aparejados a su desempeño.\\nHabrá muchas situaciones en las que exigir la contratación de un seguro de responsabilidad civil pueda\\nser contraproducente. Si en el mercado de seguros, además, las compañías no estuvieran dispuestas\\x0c16\\nsuscribir pólizas de este tipo porque supone cubrir riesgos aún desconocidos o que se ofrezcan\\ncoberturas de seguro para tecnologías digitales emergentes que limiten la cobertura de ciertos riesgos\\natendiendo a la dificultad de prever estos o de acuerdo a estadísticas de siniestralidad podríamos\\nencontrarnos con el mismo problema un riesgo que queda sin protección y además se frenaría el avance\\ndel desarrollo de soluciones IA por una imposibilidad sobrevenida para cumplir con los requisitos\\nmarcados.\\nEn cualquier otro escenario, el seguro obligatorio de responsabilidad civil puede ser una solución\\npositiva. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 56, 'page': 16, '_split_overlap': [{'doc_id': 'beb59deb3efcd4f4d89fc4d4ae68dd59', 'range': (0, 477)}, {'doc_id': '89d0c9115ef2ee9de8e49dcbd5cb2e1b', 'range': (478, 1171)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2618d872c9cb0b8c20faee56d2793663'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Si en el mercado de seguros, además, las compañías no estuvieran dispuestas\\x0c16\\nsuscribir pólizas de este tipo porque supone cubrir riesgos aún desconocidos o que se ofrezcan\\ncoberturas de seguro para tecnologías digitales emergentes que limiten la cobertura de ciertos riesgos\\natendiendo a la dificultad de prever estos o de acuerdo a estadísticas de siniestralidad podríamos\\nencontrarnos con el mismo problema un riesgo que queda sin protección y además se frenaría el avance\\ndel desarrollo de soluciones IA por una imposibilidad sobrevenida para cumplir con los requisitos\\nmarcados.\\nEn cualquier otro escenario, el seguro obligatorio de responsabilidad civil puede ser una solución\\npositiva. En concreto, y de acuerdo a la experiencia en otros sectores con riesgos inherentes a la actividad\\ncomo puede ser el transporte, con un alto potencial de siniestralidad, la experiencia nos ha demostrado\\nque el mecanismo del seguro obligatorio en el tráfico motorizado ofrece una solución solvente a un\\nproblema similar.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 57, 'page': 16, '_split_overlap': [{'doc_id': '2618d872c9cb0b8c20faee56d2793663', 'range': (0, 693)}, {'doc_id': 'caf801cfbe9a3c65c638dc4d10df473', 'range': (694, 1013)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '89d0c9115ef2ee9de8e49dcbd5cb2e1b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: En concreto, y de acuerdo a la experiencia en otros sectores con riesgos inherentes a la actividad\\ncomo puede ser el transporte, con un alto potencial de siniestralidad, la experiencia nos ha demostrado\\nque el mecanismo del seguro obligatorio en el tráfico motorizado ofrece una solución solvente a un\\nproblema similar.\\nPor lo tanto, atendiendo a lo anteriormente mencionado, las soluciones de IA de alto riesgo, tanto por\\nel sector en el que se emplean como por el uso critico que se les pueda atribuir, se deberán crear nuevas\\ncoberturas de seguro basadas en nuevos estándares y requisitos de entrenamiento de datos, registros\\nde los mismos, que la información en la que se basan sea clara y esté libre de errores y que se desempeñe\\ncon supervisión humana, entre otros. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 58, 'page': 17, '_split_overlap': [{'doc_id': '89d0c9115ef2ee9de8e49dcbd5cb2e1b', 'range': (0, 319)}, {'doc_id': 'b677afb9a8a20c8a59ccf47cf4874668', 'range': (320, 771)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'caf801cfbe9a3c65c638dc4d10df473'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Por lo tanto, atendiendo a lo anteriormente mencionado, las soluciones de IA de alto riesgo, tanto por\\nel sector en el que se emplean como por el uso critico que se les pueda atribuir, se deberán crear nuevas\\ncoberturas de seguro basadas en nuevos estándares y requisitos de entrenamiento de datos, registros\\nde los mismos, que la información en la que se basan sea clara y esté libre de errores y que se desempeñe\\ncon supervisión humana, entre otros. Esto sería especialmente relevante para vehículos autónomos,\\ndrones no tripulados, prótesis robóticas, robots para el cuidado de las personas, o sistemas quirúrgicos\\no de cirugía computerizada, todos a título de ejemplo y sin ser una lista numerus clausus, dado que en el\\npunto en el que nos hallamos parece que lo único que limita la aplicación de IA es nuestra imaginación\\ny su aplicación irá aumentándose e incorporándose en nuevos sectores y actividades económicas.\\nh. Conclusiones\\nDe acuerdo con todo lo anterior, el riesgo en principio es una cuestión inherente a la aplicación de IA.\\nPuede variar en función del sector y de la actividad para la que se utiliza pudiendo ser inexistente hasta\\nsuponer un riesgo extraordinario. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 59, 'page': 17, '_split_overlap': [{'doc_id': 'caf801cfbe9a3c65c638dc4d10df473', 'range': (0, 451)}, {'doc_id': 'b87aa84d10ad65ac85d881021889e34e', 'range': (1043, 1183)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b677afb9a8a20c8a59ccf47cf4874668'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Puede variar en función del sector y de la actividad para la que se utiliza pudiendo ser inexistente hasta\\nsuponer un riesgo extraordinario. Cobra sentido marcar una escala o una división de las aplicaciones\\nde IA en función del riesgo de mayor a menor, debiendo adecuarse en función de este riesgo a unas\\nreglas u otras.\\nHemos alcanzado el quorum de que la RC aparejada a la IA debe de estar a criterios objetivos, dejando\\natrás los criterios subjetivos de determinación de culpa. Habremos de estar a cuestiones como la\\nposibilidad de que se materialice el riesgo y la gravedad del mismo. La carga de la prueba deberá\\ninvertirse, lo cual tiene sentido de acuerdo al principio de disponibilidad probatoria, dependiendo del\\nresponsable civil demostrar que ha actuado con la suficiente diligencia.\\nDentro de los regímenes propuestos por esta parte para atender la RC en casos de daños por IA debemos\\nrecordar que hemos propuesto: a) responsabilidad objetiva, b) teoría del riesgo y c) responsabilidad\\najena aparejada a la determinada por el 1.903 del Código Civil español.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 60, 'page': 17, '_split_overlap': [{'doc_id': 'b677afb9a8a20c8a59ccf47cf4874668', 'range': (0, 140)}, {'doc_id': 'b0a27f88faa4d2eaa9cd191a09ad5c18', 'range': (796, 1070)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b87aa84d10ad65ac85d881021889e34e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Dentro de los regímenes propuestos por esta parte para atender la RC en casos de daños por IA debemos\\nrecordar que hemos propuesto: a) responsabilidad objetiva, b) teoría del riesgo y c) responsabilidad\\najena aparejada a la determinada por el 1.903 del Código Civil español.\\nDe los daños ocasionados por IA, el responsable civil podrá variar y podrá ser: 1) el fabricante\\n(entendiendo por fabricante todos los agentes que participen en la creación o desarrollo de la solución\\nen cuestión), 2) el empresario que comercializa el producto o servicio, 3) consumidor privativo\\n(incluidos los poseedores que no coincidan con el propietario) y 4) la propia máquina de IA en tanto en\\ncuanto disponga de una suerte de personalidad jurídica acompañada de un patrimonio o seguro de\\nresponsabilidad civil obligatorio que soporte estos daños.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 61, 'page': 17, '_split_overlap': [{'doc_id': 'b87aa84d10ad65ac85d881021889e34e', 'range': (0, 274)}, {'doc_id': '6d5fff413e10797d24f96df1a2c27f8f', 'range': (275, 829)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b0a27f88faa4d2eaa9cd191a09ad5c18'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: De los daños ocasionados por IA, el responsable civil podrá variar y podrá ser: 1) el fabricante\\n(entendiendo por fabricante todos los agentes que participen en la creación o desarrollo de la solución\\nen cuestión), 2) el empresario que comercializa el producto o servicio, 3) consumidor privativo\\n(incluidos los poseedores que no coincidan con el propietario) y 4) la propia máquina de IA en tanto en\\ncuanto disponga de una suerte de personalidad jurídica acompañada de un patrimonio o seguro de\\nresponsabilidad civil obligatorio que soporte estos daños.\\x0c17\\nEn este mismo sentido, cabe atender a que la responsabilidad de los agentes que ponen el producto o\\nservicio de IA en el mercado no termina con la venta del producto sino que deben de actuar con cuidado,\\ndiligencia y vigilando el desarrollo de la IA para poder advertir de cualquiera problemas que pudieran\\nsurgir durante la vida del producto o servicio a razón de su actuar autónoma. Recordemos que este\\ndeber de información únicamente involucra riesgos previsibles.\\nEl seguro obligatorio es una buena solución a la responsabilidad objetiva propuesta para los daños\\ncausados por IA. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 62, 'page': 17, '_split_overlap': [{'doc_id': 'b0a27f88faa4d2eaa9cd191a09ad5c18', 'range': (0, 554)}, {'doc_id': '1a1c617a04681cca4394bd4b588cbbc1', 'range': (943, 1141)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6d5fff413e10797d24f96df1a2c27f8f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Recordemos que este\\ndeber de información únicamente involucra riesgos previsibles.\\nEl seguro obligatorio es una buena solución a la responsabilidad objetiva propuesta para los daños\\ncausados por IA. Esto se verá reflejado en los precios de mercado finales pero a su vez es garante de que\\nlas reclamaciones por responsabilidad civil sean atendidas.\\nEn último lugar, como resulta obvio, una especialización en relación con estas cuestiones en los\\njuzgadores que van a discernir a quién corresponde la responsabilidad en estos supuestos va a ofrecer\\nmayor seguridad jurídica ya que las sentencias serán congruentes y acordes a la realidad presentada\\ndado que en temas complicados como son los tecnológicos una correcta comprensión del supuesto de\\nhecho y de las circunstancias es preponderante para que la sentencia sea ajustada a los hechos y a\\nderecho.\\nPor último, y como cierre a esta reflexión, podemos ver como la IA presenta incontables problemas ya\\nque aquí sólo hemos tratado un ínfimo porcentaje de ellos y todos relacionados con la RC. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 63, 'page': 18, '_split_overlap': [{'doc_id': '6d5fff413e10797d24f96df1a2c27f8f', 'range': (0, 198)}, {'doc_id': '50cb524fc401972fa0ff0082da379df5', 'range': (852, 1042)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1a1c617a04681cca4394bd4b588cbbc1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Por último, y como cierre a esta reflexión, podemos ver como la IA presenta incontables problemas ya\\nque aquí sólo hemos tratado un ínfimo porcentaje de ellos y todos relacionados con la RC. Sin embargo,\\nesto no debe frenar a las empresas a trabajar en la implementación de esta en sus productos y servicios\\ny a los consumidores en procurar confiar en la misma por los incontables beneficios que puede aportar.\\nEs esencial como venimos diciendo una regulación que fomente una atmósfera adecuada para el cultivo,\\ncrecimiento y desarrollo de la IA teniendo en cuenta que a su vez deberá ser suficientemente flexible\\ncomo para poder adaptarse a los cambios que sufran los sistemas de IA que, al ser autónomos, son\\nimprevisibles.\\nEn este contexto es necesario adaptar los Ordenamientos Jurídicos tanto europeo como los Estatales\\npara una correcta adaptación de la IA al mercado único europeo y sólo desde una regulación común se\\npodrá garantizar una adopción común y en condiciones de equidad en los distintos EEMM que pueda\\nsituar a la UE como referencia mundial en el campo de la IA.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 64, 'page': 18, '_split_overlap': [{'doc_id': '1a1c617a04681cca4394bd4b588cbbc1', 'range': (0, 190)}, {'doc_id': '2f38d946a9db7023c9aaa1180fc84799', 'range': (726, 1081)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '50cb524fc401972fa0ff0082da379df5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: En este contexto es necesario adaptar los Ordenamientos Jurídicos tanto europeo como los Estatales\\npara una correcta adaptación de la IA al mercado único europeo y sólo desde una regulación común se\\npodrá garantizar una adopción común y en condiciones de equidad en los distintos EEMM que pueda\\nsituar a la UE como referencia mundial en el campo de la IA.\\nEntre los desafíos jurídicos que plantea el uso de sistemas de IA destaca el marco de responsabilidades\\nque derivan de su uso. Las instituciones de la UE están creando un marco normativo sobre la tecnología.\\nEl comité de Asuntos jurídicos del Parlamento Europeo ha propuesto recientemente unas\\nRecomendaciones para la Comisión (2020/2014(INL)), sobre el Régimen de responsabilidad civil\\nderivada del uso de sistemas inteligentes entre los que está la elaboración de un Reglamento sobre esta\\nmateria, que armonice los diferentes aspectos, basándose en una necesaria combinación de sólidas\\nnormas éticas con un sistema sólido y justo de compensación de daños.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 65, 'page': 18, '_split_overlap': [{'doc_id': '50cb524fc401972fa0ff0082da379df5', 'range': (0, 355)}, {'doc_id': '910ef884f6714760218148d5ac9f72bc', 'range': (564, 1013)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2f38d946a9db7023c9aaa1180fc84799'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: El comité de Asuntos jurídicos del Parlamento Europeo ha propuesto recientemente unas\\nRecomendaciones para la Comisión (2020/2014(INL)), sobre el Régimen de responsabilidad civil\\nderivada del uso de sistemas inteligentes entre los que está la elaboración de un Reglamento sobre esta\\nmateria, que armonice los diferentes aspectos, basándose en una necesaria combinación de sólidas\\nnormas éticas con un sistema sólido y justo de compensación de daños.\\nEn su exposición de motivos habla del doble papel del concepto de \"responsabilidad\": por un lado, una\\npersona que ha sufrido un daño tiene derecho a reclamar una indemnización de la persona responsable\\nde causar ese daño y, por otro lado, proporciona incentivos para que las personas eviten causar daños\\nen primer lugar o cualquier responsabilidad orientada al futuro.\\nEl marco normativo debe buscar el equilibrio entre proteger eficientemente posibles víctimas de daños\\ny, al mismo tiempo, proporcionar suficiente margen de maniobra para desarrollo de nuevas tecnologías,\\nproductos o servicios posibles. Especialmente al comienzo del ciclo de vida de nuevos productos y\\nservicios, hay un cierto grado de riesgo para el usuario y para terceros de que algo no funciona\\ncorrectamente.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 66, 'page': 18, '_split_overlap': [{'doc_id': '2f38d946a9db7023c9aaa1180fc84799', 'range': (0, 449)}, {'doc_id': '39a34c9d00a5ebb3fa59ee634c67fc39', 'range': (1055, 1232)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '910ef884f6714760218148d5ac9f72bc'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Especialmente al comienzo del ciclo de vida de nuevos productos y\\nservicios, hay un cierto grado de riesgo para el usuario y para terceros de que algo no funciona\\ncorrectamente.\\x0c18\\nLa idea que debe de perseguirse es el principio de que “toda persona que sufra un daño causado por un\\nsistema de IA debe de disfrutar del mismo nivel de protección que aquella que los sufra por un sistema o dispositivo\\nconvencional, no inteligente”. Es decir, las características inherentes de la IA como son cierta opacidad de\\nsu funcionamiento o de su algoritmo y la dificultades que pueden agravarse por la posible conectividad\\nentre diferentes sistemas de IA y otros que no lo son, dependencia de datos externos, vulnerabilidades\\nde ciberseguridad y en algunos casos su creciente autonomía provocada por un aprendizaje automático\\n(machine learning) o un Deep learnig, no pueden menoscabar los derechos de la persona que haya\\nsufrido un daño a ser resarcido por ello.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 67, 'page': 18, '_split_overlap': [{'doc_id': '910ef884f6714760218148d5ac9f72bc', 'range': (0, 177)}, {'doc_id': 'a6ce44a604df3ed460a6f10d5e5c09dd', 'range': (431, 951)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '39a34c9d00a5ebb3fa59ee634c67fc39'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Es decir, las características inherentes de la IA como son cierta opacidad de\\nsu funcionamiento o de su algoritmo y la dificultades que pueden agravarse por la posible conectividad\\nentre diferentes sistemas de IA y otros que no lo son, dependencia de datos externos, vulnerabilidades\\nde ciberseguridad y en algunos casos su creciente autonomía provocada por un aprendizaje automático\\n(machine learning) o un Deep learnig, no pueden menoscabar los derechos de la persona que haya\\nsufrido un daño a ser resarcido por ello.\\nA día de hoy hay ya cierto consenso entre las diferentes instituciones europeas y no consideran necesario\\nsustituir algunos de los regímenes de responsabilidad ya existentes y que funcionan bien, son útiles,\\npero resultan insuficientes:\\n1) Directiva 85/374/CEE sobre responsabilidad derivada de productos defectuosos, sino que tan\\nsolo hacerse algunos ajustes en la misma para adaptarla al nuevo contexto de los sistemas de\\nIA.\\na. Si una persona sufre un daño causado por un sistema de IA defectuoso y se quiere\\nsolicitar una indemnización al productor, sin duda el cauce legal para lograrlo es esta\\nDirectiva. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 68, 'page': 19, '_split_overlap': [{'doc_id': '39a34c9d00a5ebb3fa59ee634c67fc39', 'range': (0, 520)}, {'doc_id': '35351e47f67e22e33e635965d1d6252c', 'range': (949, 1131)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a6ce44a604df3ed460a6f10d5e5c09dd'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: a. Si una persona sufre un daño causado por un sistema de IA defectuoso y se quiere\\nsolicitar una indemnización al productor, sin duda el cauce legal para lograrlo es esta\\nDirectiva. Pero solo cubre los daños ocasionados por defectos de fabricación a\\ncondición de que el perjudicado pueda demostrar el daño real, el defecto del producto\\ny la relación causa efecto entre defecto y daño.\\nEn la medida en que a los sistemas de IA se les puede dotar de capacidades de\\nadaptación y aprendizaje y el número de interrelaciones se complica, porque aprende\\nde manera autónoma o interactúe con su entorno de forma imprevisible, esta legislación\\nes insuficiente.\\nb. Si, por el contrario, el daño es causado por un tercero que interfiere, sería de aplicación\\nel sistema de responsabilidad basado en la culpa de los diferentes EEMM. Es aquí\\ndonde habría que buscar la armonización de los diferentes marcos jurídicos teniendo\\ncomo objeto que al fin y al cabo se trata de establecer el marco regulatorio de un\\nmercado único o común.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 69, 'page': 19, '_split_overlap': [{'doc_id': 'a6ce44a604df3ed460a6f10d5e5c09dd', 'range': (0, 182)}, {'doc_id': '490424827455e118457b54b01f15c902', 'range': (820, 1017)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '35351e47f67e22e33e635965d1d6252c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Es aquí\\ndonde habría que buscar la armonización de los diferentes marcos jurídicos teniendo\\ncomo objeto que al fin y al cabo se trata de establecer el marco regulatorio de un\\nmercado único o común.\\nc. En cualquier caso, no se debe limitar el tipo de alcance de los daños y perjuicios que\\npuedan ser objeto de compensación, ni limitar la naturaleza de dicha compensación,\\npor el único motivo de que los daños y perjuicios hayan sido causados por un agente\\nno humano.\\nd. Una vez que las partes en las que incumba la responsabilidad última hayan sido\\nidentificadas, dicha responsabilidad debería de ser proporcional al nivel real de las\\ninstrucciones impartidas a la IA y a su grado de autonomía.\\nEn España, además la responsabilidad por daños causados por productos defectuosos está\\nregulada por el TRLCU (Texto refundido de la Ley de consumidores y usuarios) en sus art. 128\\na 149 establece la responsabilidad civil tanto por bienes como por servicios defectuosos.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 70, 'page': 19, '_split_overlap': [{'doc_id': '35351e47f67e22e33e635965d1d6252c', 'range': (0, 197)}, {'doc_id': '9c8f3f994ff67b846f0de45f66f954d1', 'range': (694, 963)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '490424827455e118457b54b01f15c902'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: En España, además la responsabilidad por daños causados por productos defectuosos está\\nregulada por el TRLCU (Texto refundido de la Ley de consumidores y usuarios) en sus art. 128\\na 149 establece la responsabilidad civil tanto por bienes como por servicios defectuosos.\\n2) RGPD (Reglamento general de Protección de datos) o la normativa de protección del\\nconsumidor vigente, es la adecuada en el caso de que los daños que causen los sistemas de IA\\nafecten a derechos personales y/o a otros intereses importantes protegidos por ley incluidos\\naquellos relativos al uso de datos biométricos o por técnicas de reconocimiento facial.\\x0c19\\n3) La atribución de personalidad jurídica a la IA, es un debate superado y una opción que parece\\nya considerada obsoleta por la mayoría de las instituciones europeas, aunque no se descarta\\nquizás más a largo plazo, cuando los sistemas devengan más autónomos. No obstante, un\\nseguro de responsabilidad civil adecuado según el riesgo que sea exigible a los desplegadores\\nde sistemas de IA, es una opción que cobra más sentido, en tanto en cuanto el riesgo de provocar\\ndaños vaya en aumento. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 71, 'page': 19, '_split_overlap': [{'doc_id': '490424827455e118457b54b01f15c902', 'range': (0, 269)}, {'doc_id': 'd5e3266d9f9a34c3aafd6bfd2ccb8579', 'range': (891, 1120)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9c8f3f994ff67b846f0de45f66f954d1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: No obstante, un\\nseguro de responsabilidad civil adecuado según el riesgo que sea exigible a los desplegadores\\nde sistemas de IA, es una opción que cobra más sentido, en tanto en cuanto el riesgo de provocar\\ndaños vaya en aumento. Queda descartado en aquellas situaciones en las que el uso o\\naplicaciones de IA no lleven aparejado ningún riesgo.\\n4) Este informe pone de manifiesto un vacío legal en cuanto a la responsabilidad de los\\nimplementadores o utilizadores de los sistemas de IA. Aunque estas personas están\\ndecidiendo sobre su uso de sistemas, son quienes ejercen control sobre los riesgos asociados y\\nse benefician de sus operaciones, muchas de las reclamaciones de responsabilidad contra ellos\\nfracasarían debido a la incapacidad de las personas afectadas para probar la culpa del\\nimplementador.\\nEs muy difícil establecer un nexo de unión que pruebe su culpa por el daño sufrido en la\\nmayoría de los casos, sobre todo si el daño fue causado en un ámbito público, donde no existe\\nuna relación contractual con enorme grupo de personas afectadas.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 72, 'page': 20, '_split_overlap': [{'doc_id': '9c8f3f994ff67b846f0de45f66f954d1', 'range': (0, 229)}, {'doc_id': '151f3c11709af8ee8f26030a67479649', 'range': (806, 1053)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd5e3266d9f9a34c3aafd6bfd2ccb8579'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Es muy difícil establecer un nexo de unión que pruebe su culpa por el daño sufrido en la\\nmayoría de los casos, sobre todo si el daño fue causado en un ámbito público, donde no existe\\nuna relación contractual con enorme grupo de personas afectadas.\\nEl Parlamento Europeo propone dos formas de resolver este vacío según el nivel de riesgo que\\nconlleve el sistema de IA:\\na. Si se trata de un sistema de IA de alto riesgo, el implantador debe de estar sujeto a\\nun régimen de responsabilidad objetiva estricta e indemnizar a la víctima por\\ncualquier daño sufrido en sus derechos legalmente protegidos (vida, salud,\\nintegridad física y propiedad) provocados por una actividad física o virtual de esos\\nsistemas.\\nb. Para el resto de los sistemas (todos los que no sean de alto riesgo) se prevé un\\nsistema de responsabilidad basada en la culpa que admitirá prueba en contrario si\\nel sistema fue activado sin su consentimiento o si hubiera desplegado la diligencia\\nexigible en la elección, utilización y mantenimiento del sistema.\\n5) Los tres elementos que componen los sistemas de IA son al menos un software, el algoritmo\\ny los datos tratados. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 73, 'page': 20, '_split_overlap': [{'doc_id': 'd5e3266d9f9a34c3aafd6bfd2ccb8579', 'range': (0, 247)}, {'doc_id': 'ea130e3f968856451952e8fa25eee819', 'range': (1021, 1135)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '151f3c11709af8ee8f26030a67479649'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: 5) Los tres elementos que componen los sistemas de IA son al menos un software, el algoritmo\\ny los datos tratados. Hay que añadir aquí la casi total ausencia de responsabilidad de los\\nproductores de software por programas inseguros o defectuosos. La gran mayoría del software\\nque utilizamos hoy en día se rige por contratos de licencia que excluyen la responsabilidad por\\ndaños en el que no los desarrolladores ni los vendedores asumen su responsabilidad por sus\\nproductos. Todas estas licencias incluyen la cláusula “as is” o “tal cual” que excluye no solo\\ncualquier garantía sobre el software licenciado sino que traslada el riesgo al usuario.\\nEl TRLC de protección de los consumidores establece que ninguna cláusula contractual ha de\\ndisminuir la responsabilidad del productor frente al perjudicado, lo que, es práctica habitual en\\nla redacción de contratos de licencia de software, incluido el embebido en producto, lo que hace\\nentrar en colisión la normativa de producto defectuoso con la práctica avalada\\njurisprudencialmente en el mundo del desarrollo de software.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 74, 'page': 20, '_split_overlap': [{'doc_id': '151f3c11709af8ee8f26030a67479649', 'range': (0, 114)}, {'doc_id': 'ccd7949f004ac1aad13da3664592e519', 'range': (646, 1071)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ea130e3f968856451952e8fa25eee819'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: El TRLC de protección de los consumidores establece que ninguna cláusula contractual ha de\\ndisminuir la responsabilidad del productor frente al perjudicado, lo que, es práctica habitual en\\nla redacción de contratos de licencia de software, incluido el embebido en producto, lo que hace\\nentrar en colisión la normativa de producto defectuoso con la práctica avalada\\njurisprudencialmente en el mundo del desarrollo de software.\\nPor ello, parece que tanto la Directiva de productos defectuosos como el propio acervo\\ncomunitario dista de ser apto para los fines de determinar la responsabilidad del productor o\\nprestador de los dispositivos o servicios IoT (también aplicable a sistemas de IA), y necesita\\nrevisión.\\x0c20\\n6) Se deberán de crear mecanismos para la evaluación y mitigación de los riesgos asociados a la\\nIA que afectan directamente a la protección de los derechos fundamentales (protección de datos\\npersonales, privacidad o no discriminación). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 75, 'page': 20, '_split_overlap': [{'doc_id': 'ea130e3f968856451952e8fa25eee819', 'range': (0, 425)}, {'doc_id': 'dfce69e558e38f90ffd16af7ea0af418', 'range': (712, 950)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ccd7949f004ac1aad13da3664592e519'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: 20\\n6) Se deberán de crear mecanismos para la evaluación y mitigación de los riesgos asociados a la\\nIA que afectan directamente a la protección de los derechos fundamentales (protección de datos\\npersonales, privacidad o no discriminación). Que pueden estar originados por defectos en el\\ndiseño general de los sistemas de IA, por uso de datos sesgados, fallos de ciberseguridad o\\nconectividad en infraestructuras clave, usos malintencionados, problemas de interacción entre\\npersonas y máquinas…\\nLa implantación de planes de evaluación de los riesgos en el que se identifiquen los más\\ncríticos, instaurando controles generales estrictos para guiar el desarrollo y el uso de los\\nsistemas de IA, asegurar una supervisión adecuada y crear procedimientos y planes de\\ncontingencia sólidos. Siendo necesario el ajuste de las normas de seguridad comunitarias sobre\\nseguridad de los productos y a la vez garantizar la información de los usuarios sobre cómo\\nutilizar esos productos y protegerles contra posibles daños.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 76, 'page': 21, '_split_overlap': [{'doc_id': 'ccd7949f004ac1aad13da3664592e519', 'range': (0, 238)}, {'doc_id': '67c45b1e9771730f4dc4d2a97e6bc7c2', 'range': (782, 1006)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'dfce69e558e38f90ffd16af7ea0af418'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Siendo necesario el ajuste de las normas de seguridad comunitarias sobre\\nseguridad de los productos y a la vez garantizar la información de los usuarios sobre cómo\\nutilizar esos productos y protegerles contra posibles daños.\\nEstos controles deberán abordar temas como los datos y su análisis o la ciberseguridad, para\\nevitar posibles quiebras de la seguridad, un elevado nivel de seguridad y protección de los\\ndatos personales, en el que se asegure aplicar los principios de “accountability”, “privacy by\\ndesign” y “by default” y obligatoriedad de la Evaluación de Impacto en la Protección de Datos\\nPersonales (EIPD) que consiste en un análisis de los riesgos que un producto o servicio puede\\nentrañar para la protección de datos de los afectados y en función del resultado obtenido se\\nadoptaran las medidas necesarios para la gestión de dichos riesgos y así eliminarlos o\\nmitigarlos.\\nPor otra parte, y como último apunte a este ensayo, dada la funcionabilidad cambiante de los\\nsistemas de IA que se actualiza o por su aprendizaje automático puede añadir nuevas funciones\\na la vida útil de la IA generando nuevos riesgos no contemplados en el momento de la\\ncomercialización. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 77, 'page': 21, '_split_overlap': [{'doc_id': 'dfce69e558e38f90ffd16af7ea0af418', 'range': (0, 224)}, {'doc_id': 'ffbb7375a65f1ea67e71c80ad2877a59', 'range': (885, 1174)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '67c45b1e9771730f4dc4d2a97e6bc7c2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: EU Citizen, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: Spain, document_date: 14-06-2020 01:52, language: Spanish, \\n\\nPassage: Por otra parte, y como último apunte a este ensayo, dada la funcionabilidad cambiante de los\\nsistemas de IA que se actualiza o por su aprendizaje automático puede añadir nuevas funciones\\na la vida útil de la IA generando nuevos riesgos no contemplados en el momento de la\\ncomercialización. Es conveniente el establecimiento controles ex ante y ex post, que se amolden\\na los constantes cambios y actualizaciones de estas que actualmente no están contemplados en\\nlas legislaciones europeas.', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', 'stakeholder_name': nan, 'stakeholder_type': 'EU Citizen', 'stakeholder_size': nan, 'stakeholder_country': 'Spain', 'stakeholder_scope': nan, 'document_date': '14-06-2020 01:52', 'language': 'Spanish', 'document_reference': 'F530276', 'document_name': 'F530276-A_vueltas_con_la_Inteligencia_Artificial_y_la_Responsabilidad_Civil.pdf', '_split_id': 78, 'page': 21, '_split_overlap': [{'doc_id': '67c45b1e9771730f4dc4d2a97e6bc7c2', 'range': (0, 289)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ffbb7375a65f1ea67e71c80ad2877a59'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: AI4Belgium, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 16:58, language: English, \\n\\nPassage: Feedback Report on the “White Paper on Artificial Intelligence”\\nin the context of the European Commission’s public consultation\\nby AI4Belgium\\nA. Introduction\\nWe welcome the publication of the White Paper on Artificial Intelligence (AI) by the European\\nCommission (EC), and the opportunity to provide our feedback on it. Overall, we believe that the risk-\\nbased approach to AI governance is something that could be very beneficial in terms of safeguarding\\nthe protection of EU citizens, without overburdening European companies and organizations with\\nheavy requirements. A balance must be found between securing innovation and protecting our\\nEuropean values, which seems to be acknowledged by the European Commission. While this White\\nPaper provides a good start in setting out how this balance should be reached, its publication also\\nraises a lot of questions around the concrete implementation of this approach, around the terminology\\nand scope of the measures, and about some of the propositions made.\\nThis Feedback Report is the product of a workshop held by AI4Belgium. AI4Belgium is a community-\\nled initiative, enabling Belgian individuals and organisations to capture the opportunities of AI while\\nfacilitating the ongoing transition towards the technology’s increased adoption in a responsible\\nmanner. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', 'stakeholder_name': 'AI4Belgium', 'stakeholder_type': 'Other', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 16:58', 'language': 'English', 'document_reference': 'F529972', 'document_name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': '886ba2797313afe1f772a7b62f2f10e6', 'range': (1074, 1309)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '87fc4389ff57ddd5d6e563bfe325293a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: AI4Belgium, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 16:58, language: English, \\n\\nPassage: AI4Belgium is a community-\\nled initiative, enabling Belgian individuals and organisations to capture the opportunities of AI while\\nfacilitating the ongoing transition towards the technology’s increased adoption in a responsible\\nmanner. AI4Belgium has the ambition to position Belgium firmly within the European AI landscape,\\ndrawing on the many assets vested in the Belgian AI ecosystem, from high quality researchers,\\nexcellent entrepreneurs and companies, to innovative public entities.\\nDuring the workshop, a delegate from the European Commission explained the context and purpose\\nof the White Paper, and engaged into fruitful discussions with members of the AI4Belgian initiative. A\\nlot of questions were directly answered during the workshop, yet further questions and remarks were\\nalso raised which we believe could help in contributing to the improvement of the Commission’s\\napproach to AI regulation. These questions and remarks were collected during the workshop, and\\nsubsequently circulated within the AI4Belgium community, allowing all members an opportunity to\\nconsult the feedback document and provide their further input. The end result comprises the\\nconsolidated feedback of the AI4Belgium members.\\nThis report first provides general points of feedback raised by the community (B). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', 'stakeholder_name': 'AI4Belgium', 'stakeholder_type': 'Other', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 16:58', 'language': 'English', 'document_reference': 'F529972', 'document_name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', '_split_id': 1, 'page': 1, '_split_overlap': [{'doc_id': '87fc4389ff57ddd5d6e563bfe325293a', 'range': (0, 235)}, {'doc_id': '20d00c401522e353b1bf4a2be05bf23', 'range': (1136, 1296)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '886ba2797313afe1f772a7b62f2f10e6'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: AI4Belgium, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 16:58, language: English, \\n\\nPassage: The end result comprises the\\nconsolidated feedback of the AI4Belgium members.\\nThis report first provides general points of feedback raised by the community (B). Thereafter,\\ncomments are provided more specifically concerning the eco-system of excellence (C) and the eco-\\nsystem of trust (D) that the Commission intends to establish. Finally, some concluding remarks are\\noffered (E).\\nB. General comments\\n• Several concerns were raised regarding the scope of the White Paper. On the one hand, it is\\nappropriate to delineate which technology is being assessed, and to propose a working definition\\nof Artificial Intelligence. On the other hand, such definition would need to reflect the state of the\\ntechnology in adequate manner, providing legal certainty and not being overly broad. We would\\nsuggest the EC to carefully reconsider the scope of its AI-definition, and in particular to clarify to\\nwhich extent it is meant to cover also traditional software, or whether it is rather only limited to\\ne.g. machine learning applications. The currently proposed working definition seems to be\\nRef. Ares(2020)3359996 - 26/06/2020\\x0cdeficient in this regard and is in need of further clarification. Actively involving more (technical) AI-\\nexperts would be beneficial. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', 'stakeholder_name': 'AI4Belgium', 'stakeholder_type': 'Other', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 16:58', 'language': 'English', 'document_reference': 'F529972', 'document_name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', '_split_id': 2, 'page': 1, '_split_overlap': [{'doc_id': '886ba2797313afe1f772a7b62f2f10e6', 'range': (0, 160)}, {'doc_id': '5731a814f93ba815fa6355eed253d270', 'range': (1088, 1253)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '20d00c401522e353b1bf4a2be05bf23'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: AI4Belgium, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 16:58, language: English, \\n\\nPassage: Ares(2020)3359996 - 26/06/2020\\x0cdeficient in this regard and is in need of further clarification. Actively involving more (technical) AI-\\nexperts would be beneficial. It might also be useful to clarify the link between AI and robotics.\\n• The main focus of the White Paper lies on AI, and more specifically on AI applications using deep\\nlearning methods. However, a number of issues directly stem from the data that is being used\\nrather than from the AI-application. We would hence suggest to put more emphasis on the need\\nfor adequate data governance processes, as for many AI challenges (such as bias, quality or\\ntransparency) this will be key to solving the issues, regardless of whether the underlying\\napplication could be strictly categorized as an “AI-system”.\\n• The document is structured around enhancing consumer trust in AI. However, it fails to focus on\\nthe importance of also enhancing companies’ trust in implementing AI. Due to the great ambiguity\\nand uncertainty around the regulations that are currently applicable to the use of AI applications,\\nmany companies are reluctant to start using them, precisely because they do not trust that by\\ndoing so they do not expose themselves to legal infringements. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', 'stakeholder_name': 'AI4Belgium', 'stakeholder_type': 'Other', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 16:58', 'language': 'English', 'document_reference': 'F529972', 'document_name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', '_split_id': 3, 'page': 1, '_split_overlap': [{'doc_id': '20d00c401522e353b1bf4a2be05bf23', 'range': (0, 165)}, {'doc_id': '6df99566b071302b54d74eb4efe442a9', 'range': (933, 1216)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5731a814f93ba815fa6355eed253d270'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: AI4Belgium, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 16:58, language: English, \\n\\nPassage: Due to the great ambiguity\\nand uncertainty around the regulations that are currently applicable to the use of AI applications,\\nmany companies are reluctant to start using them, precisely because they do not trust that by\\ndoing so they do not expose themselves to legal infringements. A specific example here is that,\\ncurrently, some companies may not be willing to use AI in their HR processes because they fear\\nthat they might not be legally compliant, and that thereby the positive effects of using AI (when\\ndoing so in an ethical manner), such as the removal of previous human biases, are missed out on.\\nWe would therefore suggest the EC to issue specific guidance (potentially also on a sectoral basis)\\nwhat regulations already apply to AI and in which manner their compliance can be secured by\\ncompanies.\\n• While the White Paper recognizes that there are already a lot of regulations in place, there have\\nonly been limited studies on the interplay between AI and these existing regulations. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', 'stakeholder_name': 'AI4Belgium', 'stakeholder_type': 'Other', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 16:58', 'language': 'English', 'document_reference': 'F529972', 'document_name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', '_split_id': 4, 'page': 2, '_split_overlap': [{'doc_id': '5731a814f93ba815fa6355eed253d270', 'range': (0, 283)}, {'doc_id': 'f90d0da0498a162f21e11c39d431a2e3', 'range': (810, 995)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6df99566b071302b54d74eb4efe442a9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: AI4Belgium, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 16:58, language: English, \\n\\nPassage: • While the White Paper recognizes that there are already a lot of regulations in place, there have\\nonly been limited studies on the interplay between AI and these existing regulations. We would\\nsuggest considering and clarifying to which extent it would be a more suitable approach to try and\\nintegrate potential concerns arising from AI as much as possible into these separate existing\\nregulations rather than proposing a new all-encompassing regulation which may raise important\\noverlaps.\\n• The current crisis around COVID-19 sheds a new light on AI as a supporting instrument in fighting\\nthe fallout of the disease. At the same time, the ethical concerns associated with the impact on\\nprivacy, autonomy and civil liberties are likewise more prominent. It would be beneficial for these\\nconsiderations to be taken into account in the Commission’s reviewed approach to AI.\\n• Better integration between the AI strategy and the Commission’s data strategy could be helpful.\\nMore clarity is also needed on the link between AI policy on the one hand, and open data and FAIR\\naccess to data on the other.\\n• It is important that the Commission collaborate with practitioners, businesses, developers etc. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', 'stakeholder_name': 'AI4Belgium', 'stakeholder_type': 'Other', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 16:58', 'language': 'English', 'document_reference': 'F529972', 'document_name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', '_split_id': 5, 'page': 2, '_split_overlap': [{'doc_id': '6df99566b071302b54d74eb4efe442a9', 'range': (0, 185)}, {'doc_id': '2503041ab47ec060d87834f278bf0253', 'range': (972, 1196)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f90d0da0498a162f21e11c39d431a2e3'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: AI4Belgium, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 16:58, language: English, \\n\\nPassage: More clarity is also needed on the link between AI policy on the one hand, and open data and FAIR\\naccess to data on the other.\\n• It is important that the Commission collaborate with practitioners, businesses, developers etc. in\\ndefining the requirements to ensure that it is workable and realistic in practice. A multidisciplinary\\napproach involving experts from other disciplines (ethicists, lawyers, sociologists...) is crucial.\\nC. An ecosystem of excellence\\n• We welcome the acknowledgment of the need to build an ecosystem of excellence around AI,\\nwhich is a crucial element of the EU approach to AI.\\n• However, it appears that the actions proposed in this section might be more political than\\nconcrete: most of them are rather ‘high level’, and for people who are working with AI on a daily\\nbasis it is unclear what direct benefits they will generate. This renders it more complicated for\\nEuropean companies and organizations, especially for SME’s, to see where and how they can\\nactively participate in these actions and how this will create value for them specifically. Moreover,\\nit appears that many of the actions proposed are in fact reiterations from previously made\\x0ccommitments. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', 'stakeholder_name': 'AI4Belgium', 'stakeholder_type': 'Other', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 16:58', 'language': 'English', 'document_reference': 'F529972', 'document_name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', '_split_id': 6, 'page': 2, '_split_overlap': [{'doc_id': 'f90d0da0498a162f21e11c39d431a2e3', 'range': (0, 224)}, {'doc_id': '1d6778a883904a655f9fb3a5537fc6cf', 'range': (857, 1189)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2503041ab47ec060d87834f278bf0253'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: AI4Belgium, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 16:58, language: English, \\n\\nPassage: This renders it more complicated for\\nEuropean companies and organizations, especially for SME’s, to see where and how they can\\nactively participate in these actions and how this will create value for them specifically. Moreover,\\nit appears that many of the actions proposed are in fact reiterations from previously made\\x0ccommitments. We would therefore recommend further stimulus towards the development of an\\nAI ecosystem of excellence in Europe, with actionable plans for achieving this.\\n• “Excellence” should, furthermore, not be seen as separately from “trust”. We can further enhance\\nEuropean AI excellence by ensuring that the technology is of high quality and trustworthy, and\\nensuring trust will also contribute to European excellence in AI. It would hence be good to see both\\necosystems as one common endeavor rather than as separate issues.\\nD. An ecosystem of trust\\n• While a focus on AI regulation that is centered around risk seems appropriate, the concept of ‘high\\nrisk sectors’ raises a number of questions.\\no Some concerns are raised about the cumulative requirement of high-risk sector and high-\\nrisk application, which could leave out some important high-risk applications in sectors\\nthat were not marked as such.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', 'stakeholder_name': 'AI4Belgium', 'stakeholder_type': 'Other', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 16:58', 'language': 'English', 'document_reference': 'F529972', 'document_name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', '_split_id': 7, 'page': 2, '_split_overlap': [{'doc_id': '2503041ab47ec060d87834f278bf0253', 'range': (0, 332)}, {'doc_id': 'e39a75106619430674031b8b8fe9898a', 'range': (1021, 1229)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1d6778a883904a655f9fb3a5537fc6cf'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: AI4Belgium, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 16:58, language: English, \\n\\nPassage: o Some concerns are raised about the cumulative requirement of high-risk sector and high-\\nrisk application, which could leave out some important high-risk applications in sectors\\nthat were not marked as such.\\no It is unclear what happens to applications that can be used across different sectors, which\\ncan often be the case when it comes to AI. How would a delineation and evaluation take\\nplace of whether an application that is working in a certain sector cannot also be used in\\nanother sector? Are multiple certifications/ex ante assessments needed for this? On paper\\nthis distinction may sound straightforward, but in practice many applications are designed\\nfor horizontal rather than vertical usage.\\no Moreover, this may incentivize companies to try to classify their applications in a vertical\\nsetting which has not been categorized as “high-risk” to avoid strict requirements,\\npotentially leading to situations where applications that can nevertheless cause a\\nsignificant risk are classified as non-high risk.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', 'stakeholder_name': 'AI4Belgium', 'stakeholder_type': 'Other', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 16:58', 'language': 'English', 'document_reference': 'F529972', 'document_name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', '_split_id': 8, 'page': 3, '_split_overlap': [{'doc_id': '1d6778a883904a655f9fb3a5537fc6cf', 'range': (0, 208)}, {'doc_id': 'd9088df9c8ebbbadd51ee500b152faad', 'range': (705, 1016)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e39a75106619430674031b8b8fe9898a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: AI4Belgium, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 16:58, language: English, \\n\\nPassage: o Moreover, this may incentivize companies to try to classify their applications in a vertical\\nsetting which has not been categorized as “high-risk” to avoid strict requirements,\\npotentially leading to situations where applications that can nevertheless cause a\\nsignificant risk are classified as non-high risk.\\n• How and where to draw the line between high and non-high risk will be key, and we advise that\\nthis classification be made as clear as possible so as to not create unclarity about which AI systems\\nhave to comply and which do not. Risk can be defined in many different ways, and the White Paper\\nhas not yet defined those different ways and the consequences thereof. For instance, even if “risk”\\nis defined as “a breach of fundamental rights”, it is far from straightforward for a company to\\nassess whether or not their AI application may breach a fundamental right, without first knowing\\nwhat those rights entail, how they apply in a certain setting, and engaging into a fundamental\\nrights impact assessment. This would, however, not only be time-consuming but also prohibitive\\nfor many smaller productions, especially if the legal expertise is lacking.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', 'stakeholder_name': 'AI4Belgium', 'stakeholder_type': 'Other', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 16:58', 'language': 'English', 'document_reference': 'F529972', 'document_name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', '_split_id': 9, 'page': 3, '_split_overlap': [{'doc_id': 'e39a75106619430674031b8b8fe9898a', 'range': (0, 311)}, {'doc_id': 'dcce5863e4e004dc868ec3de25eb4d6e', 'range': (1021, 1165)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd9088df9c8ebbbadd51ee500b152faad'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: AI4Belgium, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 16:58, language: English, \\n\\nPassage: This would, however, not only be time-consuming but also prohibitive\\nfor many smaller productions, especially if the legal expertise is lacking.\\n• Consideration must be given to risks that may arise from the development and use of AI\\napplications, but which are not specific thereto and could also arise from other technologies.\\nAlthough currently a regulation is envisaged that only deals with AI, this would leave out the exact\\nsame risks created by non-AI technologies which would nevertheless also negatively impact\\ncitizens.\\n• Risks involving the dual use of AI is also something that should be taken into account and reflected\\ninto the Commission’s approach.\\n• We suggest further consideration on the extent to which the importance of these requirements –\\nand their concrete implementation – may differ across sectors, even across sectors that are “high-\\nrisk”.\\n• We understand that the future regulatory framework would need to be applied to operators that\\nare not established in the EU. However, considering the importance of correctly allocating\\nresponsibilities between operators, we wonder how this will be enforced and controlled in\\x0cpractice. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', 'stakeholder_name': 'AI4Belgium', 'stakeholder_type': 'Other', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 16:58', 'language': 'English', 'document_reference': 'F529972', 'document_name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', '_split_id': 10, 'page': 3, '_split_overlap': [{'doc_id': 'd9088df9c8ebbbadd51ee500b152faad', 'range': (0, 144)}, {'doc_id': '793ba8e8d29f29b74242f7b80c5f4402', 'range': (995, 1154)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'dcce5863e4e004dc868ec3de25eb4d6e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: AI4Belgium, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 16:58, language: English, \\n\\nPassage: However, considering the importance of correctly allocating\\nresponsibilities between operators, we wonder how this will be enforced and controlled in\\x0cpractice. More clarity is needed on the governance of this controlling and enforcing structure, both\\nfor actors within the EU and those outside the EU. Clarity is also needed on whether there will be\\na specific / new authority enforcing this.\\n• Regarding the question of “subsequent use”, the extension to which AI can be used is less definable\\nand trickier than it is for a classic product. Behind a lawful use can lie an unlawful or discriminant\\none in a way that is more subtle than it is for a classic product. The same goes for other terms such\\nas “safe”. It might therefore be interesting to define those kinds of terms.\\n• A clear distribution is needed of the requirements in terms of who is ultimately accountable for\\ncompliance (and potential damages) in case of breach. For example, the collection of data for a\\nfinal application can be done by one operator, the development by another. There should be a\\nclear procedure of how the requirements – and consequences of breaching those requirements -\\nwould be applied. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', 'stakeholder_name': 'AI4Belgium', 'stakeholder_type': 'Other', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 16:58', 'language': 'English', 'document_reference': 'F529972', 'document_name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', '_split_id': 11, 'page': 3, '_split_overlap': [{'doc_id': 'dcce5863e4e004dc868ec3de25eb4d6e', 'range': (0, 159)}, {'doc_id': 'f594611505d2f0de6e662ea474637d86', 'range': (1047, 1175)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '793ba8e8d29f29b74242f7b80c5f4402'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: AI4Belgium, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 16:58, language: English, \\n\\nPassage: There should be a\\nclear procedure of how the requirements – and consequences of breaching those requirements -\\nwould be applied. For instance, if responsibility for these requirements ultimately rests with only\\nto the final operator, then legislation should mention this it in clearest terms possible.\\n• More clarity is needed regarding the temporal application and implementation of the regulatory\\nframework. Will it work retroactively? Will the regulation regularly be updated in light of new\\ntechnological developments? Will all products and services which are already in the market also\\nbe subjected to these requirements, or will this only apply to applications and services that are put\\non the market after the regulation comes into force? For AI-users, developers and providers it is\\nimportant to have such information as soon as possible, in order to have a reasonable time frame\\nto modify their products, services and processes.\\n• A number of suggestions in the White Paper indicate a close link to certification, both as concerns\\nthe ex-ante scheme for high-risk applications, and as concerns the voluntary labelling scheme for\\nthe lower-risk applications. We would suggest the EC to carefully consider the cost of such\\ncertification mechanisms versus the potential return. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', 'stakeholder_name': 'AI4Belgium', 'stakeholder_type': 'Other', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 16:58', 'language': 'English', 'document_reference': 'F529972', 'document_name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', '_split_id': 12, 'page': 4, '_split_overlap': [{'doc_id': '793ba8e8d29f29b74242f7b80c5f4402', 'range': (0, 128)}, {'doc_id': '179aa917078a3f8a36bc04bc90573b89', 'range': (938, 1283)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f594611505d2f0de6e662ea474637d86'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: AI4Belgium, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 16:58, language: English, \\n\\nPassage: • A number of suggestions in the White Paper indicate a close link to certification, both as concerns\\nthe ex-ante scheme for high-risk applications, and as concerns the voluntary labelling scheme for\\nthe lower-risk applications. We would suggest the EC to carefully consider the cost of such\\ncertification mechanisms versus the potential return. Overly burdensome certification schemes\\nwill limit market access for new players and stifle not only innovation but also competition. Time\\nto market will also increase which may put Europe at a disadvantage against international players,\\nand deprive European consumers of the same benefits. While we acknowledge that an\\nenforcement mechanism needs to be put in place to verify that the requirements are met, it would\\nbe important that all the modalities of such mechanism are carefully considered. Moreover, it\\nwould be essential to consider to which extent a new certification/verification would be needed\\nwhen the system acquires new features or knowledge, and what the impact of such need would\\nbe on the market and on consumers.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', 'stakeholder_name': 'AI4Belgium', 'stakeholder_type': 'Other', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 16:58', 'language': 'English', 'document_reference': 'F529972', 'document_name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', '_split_id': 13, 'page': 4, '_split_overlap': [{'doc_id': 'f594611505d2f0de6e662ea474637d86', 'range': (0, 345)}, {'doc_id': 'a4f2b71aae1ba1f461e547e3136e234b', 'range': (844, 1078)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '179aa917078a3f8a36bc04bc90573b89'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: AI4Belgium, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 16:58, language: English, \\n\\nPassage: Moreover, it\\nwould be essential to consider to which extent a new certification/verification would be needed\\nwhen the system acquires new features or knowledge, and what the impact of such need would\\nbe on the market and on consumers.\\n• Certain requirements that are suggested, such as the provision of information about the AI-\\napplication, could be applicable more broadly for AI-systems in general rather than only for high-\\nrisk applications, as there is a substantial benefit to ensure more transparency around this. Any\\nadditional information obligation should however be implemented in a consumer-friendly way.\\n• The voluntary labelling as it is currently suggested in the whitepaper raises a lot of questions. If\\nthere are no standards or procedures to solidify this suggestion, we fear this may become a\\nmeaningless label, or even a false flag of convenience that non-EU companies could fly under to\\npromote their non-compliant products in the EU. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', 'stakeholder_name': 'AI4Belgium', 'stakeholder_type': 'Other', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 16:58', 'language': 'English', 'document_reference': 'F529972', 'document_name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', '_split_id': 14, 'page': 4, '_split_overlap': [{'doc_id': '179aa917078a3f8a36bc04bc90573b89', 'range': (0, 234)}, {'doc_id': '70e2c00b7a5e4b34d875370efa8bb5da', 'range': (718, 956)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a4f2b71aae1ba1f461e547e3136e234b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: AI4Belgium, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 16:58, language: English, \\n\\nPassage: If\\nthere are no standards or procedures to solidify this suggestion, we fear this may become a\\nmeaningless label, or even a false flag of convenience that non-EU companies could fly under to\\npromote their non-compliant products in the EU. While we appreciate that also producers of\\napplications with lower risk would also like to be able to promote their products as “trustworthy”,\\na clear mechanism would need to be foreseen if this were to be put in place, to ensure that such\\nlabels could be verified and thus be meaningful for consumers.\\n• More careful analysis of ex-post requirements and/or self-assessment mechanisms should be\\ncarried out as a potential additional approach.\\x0cE. Conclusion\\nThe comments formulated above are meant as a helpful addition to the approach set out by the EC, of\\nwhich our impression and vision is overall very positive. We believe that it is important for the\\nCommission to take ownership of the debate around the usage of Artificial Intelligence, and that a\\ncoordinated EU approach is the best way forward.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', 'stakeholder_name': 'AI4Belgium', 'stakeholder_type': 'Other', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 16:58', 'language': 'English', 'document_reference': 'F529972', 'document_name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', '_split_id': 15, 'page': 4, '_split_overlap': [{'doc_id': 'a4f2b71aae1ba1f461e547e3136e234b', 'range': (0, 238)}, {'doc_id': '9a5464d22d7dfd6a09d3298330063e03', 'range': (854, 1041)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '70e2c00b7a5e4b34d875370efa8bb5da'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: AI4Belgium, stakeholder_type: Other, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 16:58, language: English, \\n\\nPassage: We believe that it is important for the\\nCommission to take ownership of the debate around the usage of Artificial Intelligence, and that a\\ncoordinated EU approach is the best way forward.\\nThe organization of the public consultation shows an openness towards the input of the all those who\\nultimately would be affected by the outcomes of the policies and regulations adopted by the EU, and\\nthe opportunity to contribute our views is something we greatly appreciate.\\nWe look forward to the Commission’s revised approach, and to working together on creating Artificial\\nIntelligence for the benefit of Europe and its citizens.', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', 'stakeholder_name': 'AI4Belgium', 'stakeholder_type': 'Other', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 16:58', 'language': 'English', 'document_reference': 'F529972', 'document_name': 'F529972-AI4Belgium_WhitePaper_Feedback_final.pdf', '_split_id': 16, 'page': 5, '_split_overlap': [{'doc_id': '70e2c00b7a5e4b34d875370efa8bb5da', 'range': (0, 187)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9a5464d22d7dfd6a09d3298330063e03'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Association of Commercial Television in Europe (ACT), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 14-06-2020 19:25, language: English, \\n\\nPassage: 1\\nConsultation on the White Paper on Artificial\\nIntelligence - A European Approach\\nIntroduction\\nArtificial intelligence (AI) is a strategic technology that offers many benefits for citizens and the economy.\\nIt will change our lives by improving healthcare (e.g. making diagnosis more precise, enabling better\\nprevention of diseases), increasing the efficiency of farming, contributing to climate change mitigation and\\nadaptation, improving the efficiency of production systems through predictive maintenance, increasing the\\nsecurity of Europeans and the protection of workers, and in many other ways that we can only begin to\\nimagine.\\nAt the same time, AI entails a number of potential risks, such as risks to safety, gender-based or other\\nkinds of discrimination, opaque decision-making, or intrusion in our private lives.\\nThe European approach for AI aims to promote Europe’s innovation capacity in the area of AI while\\nsupporting the development and uptake of ethical and trustworthy AI across the EU. According to this\\napproach, AI should work for people and be a force for good in society.\\nFor Europe to seize fully the opportunities that AI offers, it must develop and reinforce the necessary\\nindustrial and technological capacities. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', 'stakeholder_name': 'Association of Commercial Television in Europe (ACT)', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:25', 'language': 'English', 'document_reference': 'F530363', 'document_name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': 'cd43a20759c23688596a3f7b2c77ce99', 'range': (1095, 1239)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3740c489680302a7edaff808529649ac'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Association of Commercial Television in Europe (ACT), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 14-06-2020 19:25, language: English, \\n\\nPassage: For Europe to seize fully the opportunities that AI offers, it must develop and reinforce the necessary\\nindustrial and technological capacities. As set out in the accompanying European strategy for data, this\\nalso requires measures that will enable the EU to become a global hub for data.\\nThe current public consultation comes along with the White Paper on Artificial Intelligence - A European\\nApproach aimed to foster a European ecosystem of excellence and trust in AI and a Report on the safety\\nand liability aspects of AI. The White Paper proposes:\\nMeasures that will streamline research, foster collaboration between Member States and increase\\ninvestment into AI development and deployment;\\nPolicy options for a future EU regulatory framework that would determine the types of legal\\nrequirements that would apply to relevant actors, with a particular focus on high-risk applications.\\nThis consultation enables all European citizens, Member States and relevant stakeholders (including civil\\nsociety, industry and academics) to provide their opinion on the White Paper and contribute to a European\\napproach for AI. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', 'stakeholder_name': 'Association of Commercial Television in Europe (ACT)', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:25', 'language': 'English', 'document_reference': 'F530363', 'document_name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', '_split_id': 1, 'page': 1, '_split_overlap': [{'doc_id': '3740c489680302a7edaff808529649ac', 'range': (0, 144)}, {'doc_id': 'e6bd208dbf0a47e085de70ca6084059b', 'range': (888, 1116)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'cd43a20759c23688596a3f7b2c77ce99'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Association of Commercial Television in Europe (ACT), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 14-06-2020 19:25, language: English, \\n\\nPassage: This consultation enables all European citizens, Member States and relevant stakeholders (including civil\\nsociety, industry and academics) to provide their opinion on the White Paper and contribute to a European\\napproach for AI. To this end, the following questionnaire is divided in three sections:\\nSection 1 refers to the specific actions, proposed in the White Paper’s Chapter 4 for the building of\\nan ecosystem of excellence that can support the development and uptake of AI across the EU\\neconomy and public administration;\\nSection 2 refers to a series of options for a regulatory framework for AI, set up in the White Paper’s\\nChapter 5;\\nSection 3 refers to the Report on the safety and liability aspects of AI.\\nFields marked with * are mandatory.\\nRef. Ares(2020)3359880 - 26/06/2020\\x0c2\\nRespondents can provide their opinion by choosing the most appropriate answer among the ones\\nsuggested for each question or suggesting their own ideas in dedicated text boxes. Feedback can also\\nbe provided in a document format (e.g. position paper) that can be uploaded through the button made\\navailable at the end of the questionnaire.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', 'stakeholder_name': 'Association of Commercial Television in Europe (ACT)', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:25', 'language': 'English', 'document_reference': 'F530363', 'document_name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', '_split_id': 2, 'page': 1, '_split_overlap': [{'doc_id': 'cd43a20759c23688596a3f7b2c77ce99', 'range': (0, 228)}, {'doc_id': 'a5b9e5648b7195de248d8d110a2d9546', 'range': (966, 1126)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e6bd208dbf0a47e085de70ca6084059b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Association of Commercial Television in Europe (ACT), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 14-06-2020 19:25, language: English, \\n\\nPassage: Feedback can also\\nbe provided in a document format (e.g. position paper) that can be uploaded through the button made\\navailable at the end of the questionnaire.\\n*The survey will remain open until 31 May 2020 while the questions will become available in all\\nEU languages on 4 March 2020.\\nAbout you\\n* Language of my\\ncontribution\\nEnglish\\n* I am giving my contribution as\\nBusiness association\\n* First name\\nMonika\\n* Surname\\nMagyar\\n* Email\\nmm@acte.be\\n* Scope\\nInternation\\nal\\n* Organisation name\\nAssociation of Commercial Television in Europe\\n* Organisation size\\nMicro (1 to 9 employees)\\nTransparency register number\\nTransparency Register N° 18574111503-28 | EU\\n* Country of origin\\nBelgium\\n* Publication privacy settings\\nPublic\\x0c3\\nSection 1 - An ecosystem of excellence\\nTo build an ecosystem of excellence that can support the development and uptake of AI across the EU\\neconomy, the White Paper proposes a series of actions.\\nIn your opinion, how important are the six actions proposed in section 4\\nof the White Paper on AI (1-5: 1 is not important at all, 5 is very\\nimportant)?\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', 'stakeholder_name': 'Association of Commercial Television in Europe (ACT)', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:25', 'language': 'English', 'document_reference': 'F530363', 'document_name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', '_split_id': 3, 'page': 2, '_split_overlap': [{'doc_id': 'e6bd208dbf0a47e085de70ca6084059b', 'range': (0, 160)}, {'doc_id': '4724557f3f1529d9d7691ea7dcf739cc', 'range': (916, 1068)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a5b9e5648b7195de248d8d110a2d9546'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Association of Commercial Television in Europe (ACT), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 14-06-2020 19:25, language: English, \\n\\nPassage: In your opinion, how important are the six actions proposed in section 4\\nof the White Paper on AI (1-5: 1 is not important at all, 5 is very\\nimportant)?\\n1 - Not\\nimportant\\nat all\\n2 - Not\\nimportant\\n3 -\\nNeutral\\n4 -\\nImportant\\n5 - Very\\nimportant\\nNo\\nopinion\\nWorking with Member\\nstates\\nx\\nFocusing the efforts of\\nthe research and\\ninnovation community\\nx\\nSkills\\nFocus on SMEs\\nPartnership with the\\nprivate sector\\nx\\nPromoting the adoption of\\nAI by the public sector\\nAre there other actions that should be considered?\\nPromoting AI Compliance by design (transparency, explainability, internal\\nand external auditability) to ensure AI applications respect and uphold\\nexisting IP and Media rules and freedoms. Ensure AI applications do not\\nreinforce the market dominance of certain players, notably in the online\\nenvironment.\\nRevising the Coordinated Plan on AI (Action 1)\\nThe Commission, taking into account the results of the public consultation on the White Paper, will\\npropose to Member States a revision of the Coordinated Plan to be adopted by end 2020.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', 'stakeholder_name': 'Association of Commercial Television in Europe (ACT)', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:25', 'language': 'English', 'document_reference': 'F530363', 'document_name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', '_split_id': 4, 'page': 3, '_split_overlap': [{'doc_id': 'a5b9e5648b7195de248d8d110a2d9546', 'range': (0, 152)}, {'doc_id': '3637ea2194a18e45d9afbe391350b7f', 'range': (809, 1042)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4724557f3f1529d9d7691ea7dcf739cc'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Association of Commercial Television in Europe (ACT), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 14-06-2020 19:25, language: English, \\n\\nPassage: Revising the Coordinated Plan on AI (Action 1)\\nThe Commission, taking into account the results of the public consultation on the White Paper, will\\npropose to Member States a revision of the Coordinated Plan to be adopted by end 2020.\\nIn your opinion, how important is it in each of these areas to align policies and\\nstrengthen coordination as described in section 4.A of the White Paper (1-5: 1\\nis not important at all, 5 is very important)?\\x0c4\\n1 - Not\\nimportant\\nat all\\n2 - Not\\nimportant\\n3 -\\nNeutral\\n4 -\\nImportant\\n5 - Very\\nimportant\\nNo\\nopinion\\nStrengthen excellence in\\nresearch\\nx\\nEstablish world-reference\\ntesting facilities for AI\\nPromote the uptake of AI\\nby business and the\\npublic sector\\nx\\nIncrease the financing for\\nstart-ups innovating in AI\\nDevelop skills for AI and\\nadapt existing training\\nprogrammes\\nBuild up the European\\ndata space\\nx\\nAre there other areas that that should be considered?\\n500 character(s) maximum\\nA united and strengthened research and innovation community striving for excellence\\nJoining forces at all levels, from basic research to deployment, will be key to overcome fragmentation and\\ncreate synergies between the existing networks of excellence.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', 'stakeholder_name': 'Association of Commercial Television in Europe (ACT)', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:25', 'language': 'English', 'document_reference': 'F530363', 'document_name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', '_split_id': 5, 'page': 3, '_split_overlap': [{'doc_id': '4724557f3f1529d9d7691ea7dcf739cc', 'range': (0, 233)}, {'doc_id': '3cb7a3c9269f4efc6495fe23dcb50008', 'range': (896, 1173)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3637ea2194a18e45d9afbe391350b7f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Association of Commercial Television in Europe (ACT), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 14-06-2020 19:25, language: English, \\n\\nPassage: 500 character(s) maximum\\nA united and strengthened research and innovation community striving for excellence\\nJoining forces at all levels, from basic research to deployment, will be key to overcome fragmentation and\\ncreate synergies between the existing networks of excellence.\\nIn your opinion how important are the three actions proposed in sections 4.B,\\n4.C and 4.E of the White Paper on AI (1-5: 1 is not important at all, 5 is very\\nimportant)?\\nACT HAS NO OPINION ON BELOW\\n1 - Not\\nimportant\\nat all\\n2 - Not\\nimportant\\n3 -\\nNeutral\\n4 -\\nImportant\\n5 - Very\\nimportant\\nNo\\nopinion\\x0c5\\nSupport the establishment\\nof a lighthouse research\\ncentre that is world class\\nand able to attract the best\\nminds\\nNetwork of existing AI\\nresearch excellence centres\\nSet up a public-private\\npartnership for industrial\\nresearch\\nAre there any other actions to strengthen the research and innovation\\ncommunity that should be given a priority?\\n500 character(s) maximum\\nFocusing on Small and Medium Enterprises (SMEs)\\nThe Commission will work with Member States to ensure that at least one digital innovation hub per\\nMember State has a high degree of specialisation on AI.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', 'stakeholder_name': 'Association of Commercial Television in Europe (ACT)', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:25', 'language': 'English', 'document_reference': 'F530363', 'document_name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', '_split_id': 6, 'page': 4, '_split_overlap': [{'doc_id': '3637ea2194a18e45d9afbe391350b7f', 'range': (0, 277)}, {'doc_id': 'a74049d46177a2b0365d9558b6a17927', 'range': (914, 1141)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3cb7a3c9269f4efc6495fe23dcb50008'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Association of Commercial Television in Europe (ACT), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 14-06-2020 19:25, language: English, \\n\\nPassage: 500 character(s) maximum\\nFocusing on Small and Medium Enterprises (SMEs)\\nThe Commission will work with Member States to ensure that at least one digital innovation hub per\\nMember State has a high degree of specialisation on AI.\\nIn your opinion, how important are each of these tasks of the specialised\\nDigital Innovation Hubs mentioned in section 4.D of the White Paper in\\nrelation to SMEs (1-5: 1 is not important at all, 5 is very important)?\\n1 - Not\\nimportant\\nat all\\n2 - Not\\nimportant\\n3 -\\nNeutral\\n4 -\\nImportant\\n5 - Very\\nimportant\\nNo\\nopinion\\nHelp to raise SME’s\\nawareness about potential\\nbenefits of AI\\nProvide access to testing\\nand reference facilities\\nPromote knowledge\\ntransfer and support the\\ndevelopment of AI\\nexpertise for SMEs\\nSupport partnerships\\nbetween SMEs, larger\\nenterprises and academia\\naround AI projects\\nx\\nProvide information about\\nequity financing for AI\\nstartups\\x0c6\\nAre there any other tasks that you consider important for specialised Digital\\nInnovations Hubs?\\nNO OPINION\\x0c7\\nSection 2 - An ecosystem of trust\\nChapter 5 of the White Paper sets out options for a regulatory framework for AI.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', 'stakeholder_name': 'Association of Commercial Television in Europe (ACT)', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:25', 'language': 'English', 'document_reference': 'F530363', 'document_name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', '_split_id': 7, 'page': 5, '_split_overlap': [{'doc_id': '3cb7a3c9269f4efc6495fe23dcb50008', 'range': (0, 227)}, {'doc_id': 'e59b47caca0d3668ec5da12a1c0d9f6c', 'range': (981, 1108)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a74049d46177a2b0365d9558b6a17927'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Association of Commercial Television in Europe (ACT), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 14-06-2020 19:25, language: English, \\n\\nPassage: NO OPINION\\x0c7\\nSection 2 - An ecosystem of trust\\nChapter 5 of the White Paper sets out options for a regulatory framework for AI.\\nIn your opinion, how important are the following concerns about AI (1-5: 1 is\\nnot important at all, 5 is very important)?\\n1 - Not\\nimportant\\nat all\\n2 - Not\\nimportant\\n3 -\\nNeutral\\n4 -\\nImportant\\n5 - Very\\nimportant\\nNo\\nopinion\\nAI may endanger safety X\\nAI may breach fundamental\\nrights (such as human\\ndignity, privacy, data\\nprotection, freedom of\\nexpression, workers' rights\\netc.)\\nX\\nThe use of AI may lead to\\ndiscriminatory outcomes\\nX\\nAI may take actions for\\nwhich the rationale cannot\\nbe explained\\nX\\nAI may make it more\\ndifficult for persons having\\nsuffered harm to obtain\\ncompensation\\nX\\nAI is not always accurate X\\nDo you have any other concerns about AI that are not mentioned above?\\nPlease specify:\\n500 character(s) maximum\\nThe AV sector increasingly uses AI tools at several points of the creative,\\nproduction and distribution chain. See examples attached in annex to this\\nresponse. The core concern for commercial televisions on AI focuses on\\nintellectual property rights (IPRs) and editorial integrity. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', 'stakeholder_name': 'Association of Commercial Television in Europe (ACT)', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:25', 'language': 'English', 'document_reference': 'F530363', 'document_name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', '_split_id': 8, 'page': 6, '_split_overlap': [{'doc_id': 'a74049d46177a2b0365d9558b6a17927', 'range': (0, 127)}, {'doc_id': 'e24c1fb9a39e1be81c530519c2d58a2', 'range': (960, 1130)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e59b47caca0d3668ec5da12a1c0d9f6c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Association of Commercial Television in Europe (ACT), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 14-06-2020 19:25, language: English, \\n\\nPassage: See examples attached in annex to this\\nresponse. The core concern for commercial televisions on AI focuses on\\nintellectual property rights (IPRs) and editorial integrity. Any legislation on AI\\nshould ensure existing IPRs are maintained and enforced whilst maintaining\\nstrong editorial integrity to ensure high trust in news media.\\nDo you think that the concerns expressed above can be addressed by\\napplicable EU legislation? If not, do you think that there should be specific\\nnew rules for AI systems?\\nOther\\nOther, please specify\\x0c8\\n500 character(s) maximum\\nAny new legislation regarding AI should be aligned with existing IP and media\\nlaw in order to ensure that IPRs are maintained, contractual freedom is not\\nundermined and existing media laws and freedoms are upheld.\\nIf you think that new rules are necessary for AI system, do you agree that the\\nintroduction of new compulsory requirements should be limited to high-risk\\napplications (where the possible harm caused by the AI system is particularly\\nhigh)?\\nOther\\nOther, please specify:\\n500 character(s) maximum\\nA low or high risk assessments should also account for whether the AI\\napplication may be at risk of undermining existing legal provisions and\\nprotections. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', 'stakeholder_name': 'Association of Commercial Television in Europe (ACT)', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:25', 'language': 'English', 'document_reference': 'F530363', 'document_name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', '_split_id': 9, 'page': 7, '_split_overlap': [{'doc_id': 'e59b47caca0d3668ec5da12a1c0d9f6c', 'range': (0, 170)}, {'doc_id': '610bf04bff1becca8b6b2481baabd646', 'range': (1010, 1218)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e24c1fb9a39e1be81c530519c2d58a2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Association of Commercial Television in Europe (ACT), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 14-06-2020 19:25, language: English, \\n\\nPassage: Other\\nOther, please specify:\\n500 character(s) maximum\\nA low or high risk assessments should also account for whether the AI\\napplication may be at risk of undermining existing legal provisions and\\nprotections. AI applications are a means and not an end. As such the ACT would\\nrecommend an approach that is compliant by design (transparency,\\nexplainability, internal and external auditability).\\nDo you agree with the approach to determine “high-risk” AI applications\\nproposed in Section 5.B of the White Paper? Section 5.B of the White\\nPaper (p.13-16) is mostly related to Product Liability and safety issues\\nOther, please specify:\\n500 character(s) maximum\\nA risk assessment\\nIf you wish, please indicate the AI application or use that is most concerning\\n(“high-risk”) from your perspective:\\n500 character(s) maximum\\nWhere AI applications use proprietary data to create works without due\\ncompensation/prior authorisation of the right holder. AI applications that\\nautomatically generate “news” content without due human supervision. AI\\napplications used to create deep fakes with the intention to disinform or mislead\\nthe general public. It is important to make sure monitoring and crime prevention\\ndoes not endanger journalistic sources, source material and journalistic\\nresearch. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', 'stakeholder_name': 'Association of Commercial Television in Europe (ACT)', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:25', 'language': 'English', 'document_reference': 'F530363', 'document_name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', '_split_id': 10, 'page': 8, '_split_overlap': [{'doc_id': 'e24c1fb9a39e1be81c530519c2d58a2', 'range': (0, 208)}, {'doc_id': '65f8f4cf3f1e762ef1a3c210bb366db8', 'range': (1134, 1277)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '610bf04bff1becca8b6b2481baabd646'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Association of Commercial Television in Europe (ACT), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 14-06-2020 19:25, language: English, \\n\\nPassage: It is important to make sure monitoring and crime prevention\\ndoes not endanger journalistic sources, source material and journalistic\\nresearch. Another risk for the audiovisual sector is the use of non-efficient AI-\\nbased content recognition systems by dominant platforms, profiting therefore\\nfrom the illegal uploading of copyright-protected works\\x0c9\\nIn your opinion, how important are the following mandatory requirements of\\na possible future regulatory framework for AI (as section 5.D of the White\\nPaper) (1-6: 1 is not important at all, 6 is very important)?\\n1 - Not\\nimportant\\nat all\\n2 - Not\\nimportant\\n3 -\\nNeutral\\n4 -\\nImportant\\n5 - Very\\nimportant\\nNo\\nopinion\\nThe quality of training\\ndata sets\\nX\\nThe keeping of records\\nand data\\nX\\nInformation on the\\npurpose and the nature of\\nAI systems\\nX\\nRobustness and accuracy\\nof AI systems\\nX\\nHuman oversight X\\nClear liability and safety\\nrules\\nX\\nIn addition to the existing EU legislation, in particular the data protection\\nframework, including the General Data Protection Regulation and the Law\\nEnforcement Directive, or, where relevant, the new possibly mandatory\\nrequirements foreseen above (see question above), do you think that the use\\nof remote biometric identification systems (e.g. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', 'stakeholder_name': 'Association of Commercial Television in Europe (ACT)', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:25', 'language': 'English', 'document_reference': 'F530363', 'document_name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', '_split_id': 11, 'page': 8, '_split_overlap': [{'doc_id': '610bf04bff1becca8b6b2481baabd646', 'range': (0, 143)}, {'doc_id': '757b0f243cd8f7d67a200f404e097ebb', 'range': (563, 1227)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '65f8f4cf3f1e762ef1a3c210bb366db8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Association of Commercial Television in Europe (ACT), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 14-06-2020 19:25, language: English, \\n\\nPassage: 1 - Not\\nimportant\\nat all\\n2 - Not\\nimportant\\n3 -\\nNeutral\\n4 -\\nImportant\\n5 - Very\\nimportant\\nNo\\nopinion\\nThe quality of training\\ndata sets\\nX\\nThe keeping of records\\nand data\\nX\\nInformation on the\\npurpose and the nature of\\nAI systems\\nX\\nRobustness and accuracy\\nof AI systems\\nX\\nHuman oversight X\\nClear liability and safety\\nrules\\nX\\nIn addition to the existing EU legislation, in particular the data protection\\nframework, including the General Data Protection Regulation and the Law\\nEnforcement Directive, or, where relevant, the new possibly mandatory\\nrequirements foreseen above (see question above), do you think that the use\\nof remote biometric identification systems (e.g. face recognition) and other\\ntechnologies which may be used in public spaces need to be subject to\\nfurther EU-level guidelines or regulation:\\nPlease specify your answer:\\nWhere AI applications are compliant with existing legal protections, including\\nGDPR, they can be a useful tool to enhance the creation and distribution of\\ncontent as well as viewer experience. For example, emotion-tracking can be\\nused in the media sector as a means of enhancing viewer experience. Biometric\\nidentification in public spaces pose major risks to journalistic sources.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', 'stakeholder_name': 'Association of Commercial Television in Europe (ACT)', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:25', 'language': 'English', 'document_reference': 'F530363', 'document_name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', '_split_id': 12, 'page': 9, '_split_overlap': [{'doc_id': '65f8f4cf3f1e762ef1a3c210bb366db8', 'range': (0, 664)}, {'doc_id': 'e69b54a6381f1021ef18b3e0116af471', 'range': (1027, 1215)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '757b0f243cd8f7d67a200f404e097ebb'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Association of Commercial Television in Europe (ACT), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 14-06-2020 19:25, language: English, \\n\\nPassage: For example, emotion-tracking can be\\nused in the media sector as a means of enhancing viewer experience. Biometric\\nidentification in public spaces pose major risks to journalistic sources.\\nDo you believe that a voluntary labelling system (Section 5.G of the White\\nPaper) would be useful for AI systems that are not considered high-risk in\\naddition to existing legislation?\\nVery much\\nDo you have any further suggestion on a voluntary labelling system?\\n500 character(s) maximum\\nWhat is the best way to ensure that AI is trustworthy, secure and in respect\\nof European values and rules?\\nA combination of ex-ante compliance and ex-post enforcement mechanisms\\x0c10\\nPlease specify any other enforcement system:\\n500 character(s) maximum\\nDo you have any further suggestion on the assessment of compliance?\\n500 character(s) maximum\\nACT would suggest a by design approach in the development of AI\\napplications that includes the relevant provisions of existing eu laws\\ngoverning IP and media (eg; Copyright directive, , IPRED) to ensure ex-ante\\ncompliance. (transparency, explainability, internal and external auditability).\\nFor any monitoring of publishing (e.g. AVMS) ex-post mode must remain the\\nrule. Further ex-post verification measures should be in place to ensure the\\ncompliance requirements are present and effective.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', 'stakeholder_name': 'Association of Commercial Television in Europe (ACT)', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:25', 'language': 'English', 'document_reference': 'F530363', 'document_name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', '_split_id': 13, 'page': 9, '_split_overlap': [{'doc_id': '757b0f243cd8f7d67a200f404e097ebb', 'range': (0, 188)}, {'doc_id': '57f03582046dcbc4db92979f477133c', 'range': (1150, 1312)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e69b54a6381f1021ef18b3e0116af471'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Association of Commercial Television in Europe (ACT), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 14-06-2020 19:25, language: English, \\n\\nPassage: AVMS) ex-post mode must remain the\\nrule. Further ex-post verification measures should be in place to ensure the\\ncompliance requirements are present and effective.\\nSection 3 – Safety and liability implications of AI, IoT and robotics\\nThe overall objective of the safety and liability legal frameworks is to ensure that all products and services,\\nincluding those integrating emerging digital technologies, operate safely, reliably and consistently and that\\ndamage having occurred is remedied efficiently.\\nThe current product safety legislation already supports an extended concept\\nof safety protecting against all kind of risks arising from the product\\naccording to its use. However, which particular risks stemming from the use\\nof artificial intelligence do you think should be further spelled out to provide\\nmore legal certainty?\\nCyber risks\\nPersonal security risks\\nRisks related to the loss of connectivity\\nMental health risks\\nIn your opinion, are there any further risks to be expanded on to provide\\nmore legal certainty?\\nBreach of intellectual property\\nBreach of editorial integrity\\nBreach of the safety of journalistic sources\\nDo you think that the safety legislative framework should consider new risk\\nassessment procedures for products subject to important changes during\\ntheir lifetime?\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', 'stakeholder_name': 'Association of Commercial Television in Europe (ACT)', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:25', 'language': 'English', 'document_reference': 'F530363', 'document_name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', '_split_id': 14, 'page': 10, '_split_overlap': [{'doc_id': 'e69b54a6381f1021ef18b3e0116af471', 'range': (0, 162)}, {'doc_id': 'caea735f4e3df2561f8cd2cf0bfd12f1', 'range': (1024, 1293)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '57f03582046dcbc4db92979f477133c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Association of Commercial Television in Europe (ACT), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 14-06-2020 19:25, language: English, \\n\\nPassage: Breach of intellectual property\\nBreach of editorial integrity\\nBreach of the safety of journalistic sources\\nDo you think that the safety legislative framework should consider new risk\\nassessment procedures for products subject to important changes during\\ntheir lifetime?\\nyes\\nDo you have any further considerations regarding risk assessment\\nprocedures?\\nRisk assessments should be updated with new legal provisions in place\\x0c11\\nDo you think that the current EU legislative framework for liability (Product\\nLiability Directive) should be amended to better cover the risks engendered\\nby certain AI applications?\\nyes\\nDo you have any further considerations regarding the question above?\\n500 character(s) maximum\\nConcerning high risk getting ex ante control and no risk getting ex post\\ncontrol, the specifics of media publishing needs to be addressed. Any kind of\\nmedia publishing must be regulated via ex post control when it comes to\\nutterances. However, when it comes to protection of data, especially in\\nrelation to journalistic sources, publishers deal with high risk information and\\nsystem safety used for this purpose needs ex-ante control.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', 'stakeholder_name': 'Association of Commercial Television in Europe (ACT)', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:25', 'language': 'English', 'document_reference': 'F530363', 'document_name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', '_split_id': 15, 'page': 10, '_split_overlap': [{'doc_id': '57f03582046dcbc4db92979f477133c', 'range': (0, 269)}, {'doc_id': '6e4299af471e8048308b9f62f172fe51', 'range': (939, 1138)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'caea735f4e3df2561f8cd2cf0bfd12f1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Association of Commercial Television in Europe (ACT), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 14-06-2020 19:25, language: English, \\n\\nPassage: However, when it comes to protection of data, especially in\\nrelation to journalistic sources, publishers deal with high risk information and\\nsystem safety used for this purpose needs ex-ante control.\\nDo you think that the current national liability rules should be adapted for the\\noperation of AI to better ensure proper compensation for damage and a fair\\nallocation of liability?\\nYes, for all AI applications\\nPlease specify the AI applications:\\nNew AI applications are continuously being developed. It is important that any\\nnew national or European rules governing AI and liability ensure that existing\\nliability rules are upheld so as to ensure proper compensation of right holders\\nand reflect existing rules.\\nDo you have any further considerations regarding the question above?\\n500 character(s) maximum\\nThe ACT is concerned that certain reports have outlined the need to reevaluate\\nexisting IPR protections in the light of AI applications. AI applications are a\\nmeans and not an end in themselves. As such we see no need or justification for\\nnew exemptions to existing IP rules. As such AI applications should by design\\nrespect existing rules, notably in the field of IP and media law, whilst upholding\\nthe principle of contractual freedom.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', 'stakeholder_name': 'Association of Commercial Television in Europe (ACT)', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:25', 'language': 'English', 'document_reference': 'F530363', 'document_name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', '_split_id': 16, 'page': 11, '_split_overlap': [{'doc_id': 'caea735f4e3df2561f8cd2cf0bfd12f1', 'range': (0, 199)}, {'doc_id': 'd6b2a81a8e970add310b31a174fc6dcb', 'range': (1082, 1243)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6e4299af471e8048308b9f62f172fe51'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Association of Commercial Television in Europe (ACT), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 14-06-2020 19:25, language: English, \\n\\nPassage: As such AI applications should by design\\nrespect existing rules, notably in the field of IP and media law, whilst upholding\\nthe principle of contractual freedom.\\nThank you for your contribution to this questionnaire. In case you want to share further ideas on\\nthese topics, you can upload a document below.\\nYou can upload a document here:\\nThe maximum file size is 1 MB\\nOnly files of the type pdf,txt,doc,docx,odt,rtf are allowed', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', 'stakeholder_name': 'Association of Commercial Television in Europe (ACT)', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '14-06-2020 19:25', 'language': 'English', 'document_reference': 'F530363', 'document_name': 'F530363-200614_ACT_-_AI_consultation_-_final.pdf', '_split_id': 17, 'page': 11, '_split_overlap': [{'doc_id': '6e4299af471e8048308b9f62f172fe51', 'range': (0, 161)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd6b2a81a8e970add310b31a174fc6dcb'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 1\\nEuropean Digital Rights 12 Rue Belliard, 1040 Brussels www https://edri.org twitter @edri_org tel +32 (0) 2 274 25 70\\nBan Biometric Mass Surveillance\\nA set of fundamental rights demands for the\\nEuropean Commission and EU Member States\\nOn the use of technology for the untargeted mass\\nprocessing of special categories of personal data in\\npublic spaces\\nRef. Ares(2020)3358439 - 26/06/2020\\x0c2\\nPublished on 13 May 2020 in Brussels\\nLead author:\\nElla Jakubowska, EDRi\\nCo-Lead author:\\nDiego Naranjo, EDRi Head of Policy\\nLayout by:\\nRafael Hernández, EDRi Communications Intern\\nThe EDRi Brussels office would like to express our enormous thanks the whole ne-\\ntwork for their time, advice, participation and support in producing this paper and to\\nthe 28 organisations that particpated in the consultation. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': 'fb67f93b136f2735865d001ce0692c89', 'range': (358, 796)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '39165544ff90940bc171455e90c57b84'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Ares(2020)3358439 - 26/06/2020\\x0c2\\nPublished on 13 May 2020 in Brussels\\nLead author:\\nElla Jakubowska, EDRi\\nCo-Lead author:\\nDiego Naranjo, EDRi Head of Policy\\nLayout by:\\nRafael Hernández, EDRi Communications Intern\\nThe EDRi Brussels office would like to express our enormous thanks the whole ne-\\ntwork for their time, advice, participation and support in producing this paper and to\\nthe 28 organisations that particpated in the consultation. In particular, the following\\norganisations and individuals have been instrumental across multiple stages of re-\\nsearching, drafting, discussing and reviewing:\\nAccess Now\\nARTICLE 19\\nLotte Houwing, Bits of Freedom\\nDigitale Gesellschaft Schweiz\\nDouwe Korff, Emeritus Professor of International Law\\nDrzavljan D\\nEFF\\nHomo Digitalis\\nLa Quadrature du Net\\nOpen Rights Group (ORG) and ORG Scotland\\nPrivacy International (PI)\\nBan Biometric Mass Surveillance\\nA set of fundamental rights demands for the European\\nCommission and EU Member States\\x0c3\\nTable of Contents\\n1. Executive Summary ..............................................................................................4\\n2. Introduction: Ban Biometric Mass Surveillance..................................................7\\n3. Core Problem Definition......................................................................................10\\n3.1 Mass Surveillance ....................................................................................10\\n3.1.1 Biometric Mass Surveillance in EU Law.............................................12\\n3.2 Power Imbalances, Biases, and lack of Accountability...................................13\\n3.3 Function Creep and Normalisation............................................................14\\n3.4 (Re-) Identification and Tracking Over Time..............................................15\\n3.5 Social Control and Illegitimate Science....................................................16\\n4. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 1, 'page': 1, '_split_overlap': [{'doc_id': '39165544ff90940bc171455e90c57b84', 'range': (0, 438)}, {'doc_id': '81abcf465cd17b4469462bd4e91bc11c', 'range': (1211, 1912)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fb67f93b136f2735865d001ce0692c89'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Core Problem Definition......................................................................................10\\n3.1 Mass Surveillance ....................................................................................10\\n3.1.1 Biometric Mass Surveillance in EU Law.............................................12\\n3.2 Power Imbalances, Biases, and lack of Accountability...................................13\\n3.3 Function Creep and Normalisation............................................................14\\n3.4 (Re-) Identification and Tracking Over Time..............................................15\\n3.5 Social Control and Illegitimate Science....................................................16\\n4. Rationale for EU Action........................................................................................17\\n5. Policy Analysis & Discussion..............................................................................19\\n5.1 Fundamental Rights Law................................................................................19\\n5.1.1 Biometrics and the Right to Dignity.........................................................22\\n5.2 Data Protection Law.........................................................................................23\\n5.3 Defining “Recognition”: Considering Identification, Detection and Processing....26\\n5.4 Comprehensive Analysis of Existing Biometric Systems..............................27\\n5.5 Biometric Processing Outside the Scope of a Ban..........................................28\\n6. Case Study Assessments..........................................................................................30\\n6.1 Facial Recognition in Ampère High School, Marseille...............................30\\n6.2. Other Case Studies with Assessment and Analysis........................................32\\n6.3 Mass Surveillance for Public Health Purposes (COVID-19).........................33\\n7. EDRi’s Recommendations.........................................................................................35\\n7.1 Recommendations: Ban Biometric Mass Surveillance..................................36\\n7.2 European Commission White Paper on AI....................................................38\\n7.3 Preventing a Digital Dystopia.........................................................................38\\x0c4\\n1. EXECUTIVE SUMMARY\\nAcross the EU, highly intrusive and rights-violating facial recognition and other biometric\\nprocessing technologies are quietly becoming ubiquitous in our public spaces. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 2, 'page': 3, '_split_overlap': [{'doc_id': 'fb67f93b136f2735865d001ce0692c89', 'range': (0, 701)}, {'doc_id': '7a73e055808d5c2e88b999a8a25bfe3a', 'range': (2330, 2517)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '81abcf465cd17b4469462bd4e91bc11c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: EXECUTIVE SUMMARY\\nAcross the EU, highly intrusive and rights-violating facial recognition and other biometric\\nprocessing technologies are quietly becoming ubiquitous in our public spaces. As the\\nEuropean Commission consults the public as part of its consultation on the White Paper\\non Artificial Intelligence (AI), EDRi - a network of 44 civil society organisations - calls on\\nEU bodies including the European Commission, the European Parliament, plus all EU\\nMember States, to ensure that such technologies are comprehensively and indefinite-\\nly banned in both law and practice. Given that the current regulatory and enforcement\\nframework has not been successful in preventing Member States from deploying unlaw-\\nful biometric mass surveillance systems, we urge the Commission to act now.\\nThe use of biometric technologies for the untargeted mass processing of special cate-\\ngories of personal data, in particular biometric data in public places, creates serious\\nrisks of mass surveillance. This unjustifiably infringes on fundamental rights including\\nprivacy, data protection, equality, freedom of expression and information, freedom of\\nassembly and association, due process and more. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 3, 'page': 4, '_split_overlap': [{'doc_id': '81abcf465cd17b4469462bd4e91bc11c', 'range': (0, 187)}, {'doc_id': 'ccbb95abb94be009ff58efb54243bf63', 'range': (991, 1185)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7a73e055808d5c2e88b999a8a25bfe3a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: This unjustifiably infringes on fundamental rights including\\nprivacy, data protection, equality, freedom of expression and information, freedom of\\nassembly and association, due process and more. Such uses of biometric processing\\nconstitutes an objectification of people’s intimate and personal qualities in a way that is\\nso intrusive as to infringe on their human right to dignity. As this paper will demonstrate,\\nthese deployments of untargeted mass biometric processing systems - whether by\\nlaw enforcement, public authorities (such as schools or local councils), or private ac-\\ntors - do not meet the required justifications or thresholds of necessity or proportion-\\nality to be considered lawful for the level of violation and intrusion they create. This\\nthreshold is demanded by the the Charter of Fundamental Rights, the General Data Pro-\\ntection Regulation (GDPR) and the Law Enforcement Directive (LED). The legal frame-\\nworks within which such activities take place often do not meet the requirements of\\n“prescribed for by law” established under the European Convention on Human Rights\\n(ECHR) and the EU Charter of Fundamental Rights, and fail to provide adequate, effective\\nremedies against untargeted, unnecessary, disproportionate surveillance.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 4, 'page': 4, '_split_overlap': [{'doc_id': '7a73e055808d5c2e88b999a8a25bfe3a', 'range': (0, 194)}, {'doc_id': '504557dcb979930c7fd377ffc0dadfa7', 'range': (912, 1256)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ccbb95abb94be009ff58efb54243bf63'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The legal frame-\\nworks within which such activities take place often do not meet the requirements of\\n“prescribed for by law” established under the European Convention on Human Rights\\n(ECHR) and the EU Charter of Fundamental Rights, and fail to provide adequate, effective\\nremedies against untargeted, unnecessary, disproportionate surveillance.\\nOn the grounds elucidated in chapter 5 (Policy Analysis and Discussion) and for the rea-\\nsons explained in chapter 3 (Core Problem Definition), EDRi calls on EU Member States,\\nSUMMARY\\x0c5\\nas well as the European Commission as the guardian of the EU’s fundamental rights\\ntreaties and in its competency with regard to European borders, to permanently stop all\\nbiometric processing in public and publicly-accessible spaces, wherever it has the ef-\\nfect or potential effect to establish mass surveillance. This call to action requires that:\\n1. EU Member States immediately halt all biometric processing that could amount\\nto mass surveillance in public spaces, ensuring that both current and future\\ndeployments are included. This should be supported by a political debate by the\\nEuropean Council on the fundamental rights impacts of biometric mass pro-\\ncessing in Member States;\\n2. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 5, 'page': 4, '_split_overlap': [{'doc_id': 'ccbb95abb94be009ff58efb54243bf63', 'range': (0, 344)}, {'doc_id': 'b37c8278f1008f6676fbb3b384b7e90c', 'range': (1063, 1219)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '504557dcb979930c7fd377ffc0dadfa7'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: This should be supported by a political debate by the\\nEuropean Council on the fundamental rights impacts of biometric mass pro-\\ncessing in Member States;\\n2. EU Member States, under the auspices of the European Data Protection Board\\n(EDPB) and national Data Protection Authorities (DPAs), publicly disclose all\\nexisting and planned activities and deployments that fall within this remit;\\n3. EU Member States cease all planned legislation which establishes biometric\\nprocessing that could lead to mass surveillance in public spaces. Instead, clear\\nand foreseeable laws should only allow for targeted identification checks that\\nare proportionate to the issues and context, and provide for effective remedies\\nagainst abuse. DPAs can play a role by advising national regulators and re-\\nquesting action from their national governments;\\n4. The European Commission, in particular Directorate-General (DG) HOME and\\nwith reference to DG RTD for the Horizon2020 Programme, ensure that funding\\ngiven to Member States for biometric research or deployment is for activities\\nwhich are fully compliant with the Charter, including immediately ceasing all\\nfunding for biometric processing programmes which could contribute to mass\\nsurveillance in public spaces. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 6, 'page': 5, '_split_overlap': [{'doc_id': '504557dcb979930c7fd377ffc0dadfa7', 'range': (0, 156)}, {'doc_id': '1a9b5a7c2e4a6c664a34d10fe544f123', 'range': (833, 1243)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b37c8278f1008f6676fbb3b384b7e90c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The European Commission, in particular Directorate-General (DG) HOME and\\nwith reference to DG RTD for the Horizon2020 Programme, ensure that funding\\ngiven to Member States for biometric research or deployment is for activities\\nwhich are fully compliant with the Charter, including immediately ceasing all\\nfunding for biometric processing programmes which could contribute to mass\\nsurveillance in public spaces. All EU bodies who give operational support or ad-\\nvice to EU institutions, including but not limited to Europol, Frontex and the Fun-\\ndamental Rights Agency (FRA), ensure that Member States cannot use these\\ntechnologies in a way which gives way to fundamental rights abuses;\\n5. The European Commission, under the auspices of the EDPS’s advisory role, re-\\nview and ex post facto evaluate on fundamental rights and data protection\\ngrounds all laws covering EU biometrics that contribute to or amount to mass\\nsurveillance and, as appropriate, recast, repeal or provide appropriate guidance\\nto Member States about safeguards;1 and\\n1 Many ofthe relevant laws are analysed in the reportFundamental rights review of EU data collection instruments and pro-\\ngrammes <http://www.fondazionebrodolini.it/sites/default/files/final_report_0.pdf>\\nSUMMARY\\x0c6\\n6. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 7, 'page': 5, '_split_overlap': [{'doc_id': 'b37c8278f1008f6676fbb3b384b7e90c', 'range': (0, 410)}, {'doc_id': '6f2a80c5496536edc0169f1fa0914ace', 'range': (689, 1255)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1a9b5a7c2e4a6c664a34d10fe544f123'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The European Commission, under the auspices of the EDPS’s advisory role, re-\\nview and ex post facto evaluate on fundamental rights and data protection\\ngrounds all laws covering EU biometrics that contribute to or amount to mass\\nsurveillance and, as appropriate, recast, repeal or provide appropriate guidance\\nto Member States about safeguards;1 and\\n1 Many ofthe relevant laws are analysed in the reportFundamental rights review of EU data collection instruments and pro-\\ngrammes <http://www.fondazionebrodolini.it/sites/default/files/final_report_0.pdf>\\nSUMMARY\\x0c6\\n6. The European Commission (in particular DGs GROW, CNECT and JUST as the\\nDirectorate-Generals leading the Commission’s work on the White Paper on\\nArtificial Intelligence (AI) and DG HOME in its capacity on borders) implement,\\nthrough legislative and non-legislative means and if necessary, infringement\\nproceedings and Court action, an immediate and indefinite ban on biometric\\nprocessing that leads to mass surveillance in public spaces. This process must\\nbe done under the supervision and/or support of the European Data Protection\\nSupervisor (EDPS), the European Data Protection Board (EDPB), the FRA and\\nDPAs.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 8, 'page': 5, '_split_overlap': [{'doc_id': '1a9b5a7c2e4a6c664a34d10fe544f123', 'range': (0, 566)}, {'doc_id': 'c9d934e668a8a790d580ff8416767ce8', 'range': (1004, 1178)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6f2a80c5496536edc0169f1fa0914ace'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: This process must\\nbe done under the supervision and/or support of the European Data Protection\\nSupervisor (EDPS), the European Data Protection Board (EDPB), the FRA and\\nDPAs.\\nIt is the role and responsibility of the European Union, in particular the Euro-\\npean Commission, the Council of the EU and the European Parliament, with the\\nsupport of the European Data Protection Board which also includes the Euro-\\npean Data Protection Supervisor, the EU Fundamental Rights Agency (FRA),\\nnational Member States, the national Data Protection Authorities (DPAs) of ev-\\nery EU Member State and any other oversight bodies, to determine the appro-\\npriate methods to ensure that biometric mass surveillance is comprehensively\\nstopped and banned in law, and in practice, across the EU.\\nIn addition, this paper proposes further fundamental rights measures and safeguards,\\nincluding the proper resourcing of national DPAs, the clearer interpretation of data\\nprotection law, and strict controls even for uses of biometric processing that do not\\ncontribute to establishing mass surveillance. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 9, 'page': 6, '_split_overlap': [{'doc_id': '6f2a80c5496536edc0169f1fa0914ace', 'range': (0, 174)}, {'doc_id': '66724749a11afa4f215238efa853d428', 'range': (773, 1074)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c9d934e668a8a790d580ff8416767ce8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: In addition, this paper proposes further fundamental rights measures and safeguards,\\nincluding the proper resourcing of national DPAs, the clearer interpretation of data\\nprotection law, and strict controls even for uses of biometric processing that do not\\ncontribute to establishing mass surveillance. We ask the EDPS and the EDPB to issue\\nstatements and guidelines calling for Member State action to halt and disclose mass\\nbiometric processing in public spaces, and encourage the European Council and Euro-\\npean Parliament, in their legislative capacities, to provide political support and instigate\\ndebates. This could be well-complemented by Parliamentary resolutions and research\\nreports.\\nWe further encourage Members of the European Parliament (MEPs) – in particular the\\nintergroup on Artificial Intelligence & Digital; the Committee of the Regions (CoR); the\\nEuropean Economic & Social Committee (EESC) and all stakeholders who care about\\nprotecting the EU’s fundamental rights, freedoms and values to join this call to ban bio-\\nmetric mass surveillance.\\nSUMMARY\\x0c7\\n2. INTRODUCTION: Ban Biometric\\nMass Surveillance\\nNota Bene: Work on this paper started before the COVID-19 pandemic. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 10, 'page': 6, '_split_overlap': [{'doc_id': 'c9d934e668a8a790d580ff8416767ce8', 'range': (0, 301)}, {'doc_id': 'c37931192c6008e16e60980720dd4478', 'range': (693, 1187)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '66724749a11afa4f215238efa853d428'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: We further encourage Members of the European Parliament (MEPs) – in particular the\\nintergroup on Artificial Intelligence & Digital; the Committee of the Regions (CoR); the\\nEuropean Economic & Social Committee (EESC) and all stakeholders who care about\\nprotecting the EU’s fundamental rights, freedoms and values to join this call to ban bio-\\nmetric mass surveillance.\\nSUMMARY\\x0c7\\n2. INTRODUCTION: Ban Biometric\\nMass Surveillance\\nNota Bene: Work on this paper started before the COVID-19 pandemic. We believe that\\nits findings and recommendations are as relevant, if not more so, in light of the situa-\\ntion, and demonstrate the need for action against all forms of bodily surveillance. See\\nSection 6.3 on Mass Surveillance for public health.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 11, 'page': 6, '_split_overlap': [{'doc_id': '66724749a11afa4f215238efa853d428', 'range': (0, 494)}, {'doc_id': '69f6117f625b39d4fdf2046d4245d835', 'range': (495, 739)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c37931192c6008e16e60980720dd4478'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: We believe that\\nits findings and recommendations are as relevant, if not more so, in light of the situa-\\ntion, and demonstrate the need for action against all forms of bodily surveillance. See\\nSection 6.3 on Mass Surveillance for public health.\\nAs of May 2020, at least 15 European countries have experimented with biometric tech-\\nnologies such as facial recognition in public spaces, for purposes which lead to mass\\nsurveillance.2 They have deployed these systems in ways that often lack transparency\\nand accountability, and in a concerning absence of proper necessity and proportionality\\nassessments, adequate public warning, or societal debate.3 These systems violate peo-\\nple’s right to conduct their daily life in privacy and with due respect for their fundamental\\nfreedoms and dignity; have a chilling effect on their freedoms of expression and assem-\\nbly; and put limits on their ability to participate in public, social or democratic activities.\\nGiven the centrality of appearance to personal identity and the general uniqueness and\\nimmutability of bodily characteristics, the use of biometric surveillance systems in pub-\\nlic spaces can enable unlawful permanent intrusion into our autonomy, freedom and\\nprivacy on a mass scale across time and place.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 12, 'page': 7, '_split_overlap': [{'doc_id': 'c37931192c6008e16e60980720dd4478', 'range': (0, 244)}, {'doc_id': '2891f1194f6c8955ab6c90a3d9b56237', 'range': (954, 1259)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '69f6117f625b39d4fdf2046d4245d835'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Given the centrality of appearance to personal identity and the general uniqueness and\\nimmutability of bodily characteristics, the use of biometric surveillance systems in pub-\\nlic spaces can enable unlawful permanent intrusion into our autonomy, freedom and\\nprivacy on a mass scale across time and place.\\nBiometric processing is being used more and more, largely due to increased availability\\nof public funding and advances in machine learning algorithms, which have made the\\nmass-scale analysis of photographic, video and other material cheaper and more ac-\\ncessible. Despite these advances, the capture, processing and storage of biometric data\\n2 At a minimum, activities are happening in Czech Republic, Denmark, France, Germany, Greece, Hungary, Italy, the Nether-\\nlands, Poland, Romania, Serbia, Slovenia, Sweden, Switzerland and the UK.\\n3 The RSA, Artificial Intelligence in the Police Force: A Force for Good? ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 13, 'page': 7, '_split_overlap': [{'doc_id': '69f6117f625b39d4fdf2046d4245d835', 'range': (0, 305)}, {'doc_id': 'c63186c8f5d128a788ca38dc36c30175', 'range': (570, 917)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2891f1194f6c8955ab6c90a3d9b56237'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Despite these advances, the capture, processing and storage of biometric data\\n2 At a minimum, activities are happening in Czech Republic, Denmark, France, Germany, Greece, Hungary, Italy, the Nether-\\nlands, Poland, Romania, Serbia, Slovenia, Sweden, Switzerland and the UK.\\n3 The RSA, Artificial Intelligence in the Police Force: A Force for Good? (2020) <https://www.thersa.org/discover/publica-\\ntions-and-articles/reports/ai-police-force>\\nINTRODUCTION\\x0c8\\nare problematic not just technically, but by their very nature, as over 80% of Europeans\\nare against sharing their facial image with authorities.4 Whilst procedural safeguards\\nand rights to justice are at the core of the European Union’s legal framework, the use of\\nbiometric technologies which can lead to mass surveillance inherently negates the basic\\nprocedures of police and criminal law by treating every person as a suspect in a perpet-\\nual, omnipotent line-up.\\nThe heart of the problem lies in what facial recognition and other biometric pro-\\ncessing mean for our societies, including how they can amplify existing inequal-\\nities and discrimination, and whether they fit with our conceptions of democra-\\ncy, freedom, equality and social justice.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 14, 'page': 7, '_split_overlap': [{'doc_id': '2891f1194f6c8955ab6c90a3d9b56237', 'range': (0, 347)}, {'doc_id': '23e80b6cf0d98692bfb43dc5f3f9a3bd', 'range': (924, 1208)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c63186c8f5d128a788ca38dc36c30175'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The heart of the problem lies in what facial recognition and other biometric pro-\\ncessing mean for our societies, including how they can amplify existing inequal-\\nities and discrimination, and whether they fit with our conceptions of democra-\\ncy, freedom, equality and social justice.\\nData supervisory authorities including the French CNIL, the UK’s ICO and Sweden’s\\nDatainspektionen have raised serious concerns that many current deployments are il-\\nlegal.5 Whilst EU data protection and fundamental rights legislation already regulates\\nmany aspects of biometric processing, this paper urges the EU to review whether ex-\\nisting laws and enforcement are sufficient in light of the size of the threat posed to our\\nsocieties by biometric processing which may have the effect of mass surveillance. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 15, 'page': 8, '_split_overlap': [{'doc_id': 'c63186c8f5d128a788ca38dc36c30175', 'range': (0, 284)}, {'doc_id': '78d57f19a9120bd1270528a5076fce0e', 'range': (285, 794)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '23e80b6cf0d98692bfb43dc5f3f9a3bd'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Data supervisory authorities including the French CNIL, the UK’s ICO and Sweden’s\\nDatainspektionen have raised serious concerns that many current deployments are il-\\nlegal.5 Whilst EU data protection and fundamental rights legislation already regulates\\nmany aspects of biometric processing, this paper urges the EU to review whether ex-\\nisting laws and enforcement are sufficient in light of the size of the threat posed to our\\nsocieties by biometric processing which may have the effect of mass surveillance. This\\npaper demonstrates that at its core, biometric processing which has the potential to\\namount to mass surveillance is incompatible with the fundamental rights and freedoms,\\ndata protection law, democracy, and essential principles of the rule of law at the heart\\nof the EU.6 EDRi calls, therefore, on the European Commission and Member States to\\ntake a series of bold steps to permanently end the use of opaque, intrusive systems for\\nthe untargeted processing of biometric or associated special categories of personal data\\nin public spaces.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 16, 'page': 8, '_split_overlap': [{'doc_id': '23e80b6cf0d98692bfb43dc5f3f9a3bd', 'range': (0, 509)}, {'doc_id': '5b2e0328b48d97d0f097abf0c7d1bbd9', 'range': (510, 1052)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '78d57f19a9120bd1270528a5076fce0e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: This\\npaper demonstrates that at its core, biometric processing which has the potential to\\namount to mass surveillance is incompatible with the fundamental rights and freedoms,\\ndata protection law, democracy, and essential principles of the rule of law at the heart\\nof the EU.6 EDRi calls, therefore, on the European Commission and Member States to\\ntake a series of bold steps to permanently end the use of opaque, intrusive systems for\\nthe untargeted processing of biometric or associated special categories of personal data\\nin public spaces.\\n4 Fundamental Rights Agency (2020) <https://twitter.com/EURightsAgency/status/1234804039449239553>\\n5 The CNIL (2019) <https://www.cnil.fr/fr/experimentation-de-la-reconnaissance-faciale-dans-deux-lycees-la-cnil-pre-\\ncise-sa-position>; EDPB (2019) <https://edpb.europa.eu/news/national-news/2019/facial-recognition-school-renders-swe-\\ndens-first-gdpr-fine_en>; ICO (2019) <https://ico.org.uk/about-the-ico/news-and-events/news-and-blogs/2019/10/live-fa-\\ncial-recognition-technology-police-forces-need-to-slow-down-and-justify-its-use/>\\n6 As the Fundamental rights review has stated, “[e]mphasis should now lie on the establishment of robust horizontal pro-\\ntections and safeguards for fundamental rights and corresponding data protection inspection and enforcement capabilities\\nthat can meet the requirements stemming from EU law and fundamental rights standards.” <http://www.fondazionebrodoli-\\nni.it/sites/default/files/final_report_0.pdf>\\nINTRODUCTION\\x0c9\\nKey Definitions\\nBiometric data – Article 4(14) of the General Data Protection Regulation (GDPR) defines biometric\\ndata as “personal data resulting from specific technical processing relating to the physical, physio-\\nlogical or behavioural characteristics of a natural person, which allow or confirm the unique identifi-\\ncation of that natural person, such as facial images or dactyloscopic [fingerprint] data.”\\nBiometric processing – there are many types of biometric processing, which may be referred to\\ninvariably as recognition, identification, authentication, detection or other related terms, as well as\\n(often opaque) ways of collecting and storing biometric data even if the data is not immediately pro-\\ncessed, all of which are in scope of this paper. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 17, 'page': 8, '_split_overlap': [{'doc_id': '78d57f19a9120bd1270528a5076fce0e', 'range': (0, 542)}, {'doc_id': '80206a77ca758b17d6e6e5ef23307676', 'range': (543, 2258)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5b2e0328b48d97d0f097abf0c7d1bbd9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 4 Fundamental Rights Agency (2020) <https://twitter.com/EURightsAgency/status/1234804039449239553>\\n5 The CNIL (2019) <https://www.cnil.fr/fr/experimentation-de-la-reconnaissance-faciale-dans-deux-lycees-la-cnil-pre-\\ncise-sa-position>; EDPB (2019) <https://edpb.europa.eu/news/national-news/2019/facial-recognition-school-renders-swe-\\ndens-first-gdpr-fine_en>; ICO (2019) <https://ico.org.uk/about-the-ico/news-and-events/news-and-blogs/2019/10/live-fa-\\ncial-recognition-technology-police-forces-need-to-slow-down-and-justify-its-use/>\\n6 As the Fundamental rights review has stated, “[e]mphasis should now lie on the establishment of robust horizontal pro-\\ntections and safeguards for fundamental rights and corresponding data protection inspection and enforcement capabilities\\nthat can meet the requirements stemming from EU law and fundamental rights standards.” <http://www.fondazionebrodoli-\\nni.it/sites/default/files/final_report_0.pdf>\\nINTRODUCTION\\x0c9\\nKey Definitions\\nBiometric data – Article 4(14) of the General Data Protection Regulation (GDPR) defines biometric\\ndata as “personal data resulting from specific technical processing relating to the physical, physio-\\nlogical or behavioural characteristics of a natural person, which allow or confirm the unique identifi-\\ncation of that natural person, such as facial images or dactyloscopic [fingerprint] data.”\\nBiometric processing – there are many types of biometric processing, which may be referred to\\ninvariably as recognition, identification, authentication, detection or other related terms, as well as\\n(often opaque) ways of collecting and storing biometric data even if the data is not immediately pro-\\ncessed, all of which are in scope of this paper. See section 5.3\\nFacial recognition – facial recognition is one type of biometric processing. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 18, 'page': 8, '_split_overlap': [{'doc_id': '5b2e0328b48d97d0f097abf0c7d1bbd9', 'range': (0, 1715)}, {'doc_id': '8588d220883ce33909019c83638bd889', 'range': (1716, 1808)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '80206a77ca758b17d6e6e5ef23307676'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: See section 5.3\\nFacial recognition – facial recognition is one type of biometric processing. The Article 29 Working\\nParty defines facial recognition as the “automatic processing of digital images which contain the fac-\\nes of individuals for identification, authentication/verification or categorisation of those individuals,”\\nwhether or not individuals have consented or have knowledge of its use.7\\nIdentification – distinguishing a person from a larger set of individuals. See sections 5.3 and 3.4.\\nMass surveillance – any monitoring, tracking, and otherwise processing of personal data of indi-\\nviduals in an incriminate or general manner, or of groups, that is not performed in a “targeted” way\\nagainst a specific individual. See section 3.1.\\nProfiling – Article 4(4) of the GDPR defines profiling as “any form of automated processing of person-\\nal data consisting of the use of personal data to evaluate certain personal aspects relating to a natu-\\nral person, in particular to analyse or predict aspects concerning that natural person’s performance\\nat work, economic situation, health, personal preferences, interests, reliability, behaviour, location\\nor movements”.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 19, 'page': 9, '_split_overlap': [{'doc_id': '80206a77ca758b17d6e6e5ef23307676', 'range': (0, 92)}, {'doc_id': 'e4c13c11d53aab0d533b8c4211e7bb53', 'range': (746, 1171)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8588d220883ce33909019c83638bd889'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Profiling – Article 4(4) of the GDPR defines profiling as “any form of automated processing of person-\\nal data consisting of the use of personal data to evaluate certain personal aspects relating to a natu-\\nral person, in particular to analyse or predict aspects concerning that natural person’s performance\\nat work, economic situation, health, personal preferences, interests, reliability, behaviour, location\\nor movements”.\\nPublic (including publicly-accessible) spaces – UNESCO defines a public space as “an area or place\\nthat is open and accessible to all peoples, regardless of gender, race, ethnicity, age or socio-eco-\\nnomic level. […] In the 21st century, some even consider the virtual spaces available through the\\ninternet as a new type of public space that develops interaction”.8 Our analysis includes public spaces\\nlike streets, parks, or hospitals, as well as privately-owned but publicly-accessible spaces such as\\nshopping centers, stadiums, public transport and other public interest services. Our analysis also\\nincludes online spaces, as they have become an important part of civic debate, democracy and public\\nparticipation.\\nPurpose(s) – this paper is concerned with uses of biometric processing where the purpose of a de-\\nployment will or could lead to establishing mass surveillance. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 20, 'page': 9, '_split_overlap': [{'doc_id': '8588d220883ce33909019c83638bd889', 'range': (0, 425)}, {'doc_id': '5f10da2dd41a40f0a9a8e72e1ada1678', 'range': (1143, 1303)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e4c13c11d53aab0d533b8c4211e7bb53'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Purpose(s) – this paper is concerned with uses of biometric processing where the purpose of a de-\\nployment will or could lead to establishing mass surveillance. See section 3.1 for more information.\\n7 Article 29 Data Protection Working Party, Opinion 02/2012 on facial recognition in online and mobile services, 00727/12/EN\\n(2012) 2; quoted in FRA Facial recognition technology: fundamental rights considerations in the context of law enforcement\\n(2019), 7 <https://fra.europa.eu/sites/default/files/fra_uploads/fra-2019-facial-recognition-technology-focus-paper-1_\\nen.pdf>\\n8 UNESCO, Inclusion Through Access to Public Space (2017) <http://www.unesco.org/new/en/social-and-human-sciences/\\nthemes/urban-development/migrants-inclusion-in-cities/good-practices/inclusion-through-access-to-public-space/>\\nINTRODUCTION\\x0c10\\nCORE PROBLEMS\\nCORE PROBLEM DEFINITIONS\\nThis chapter outlines the harmful societal, ethical and fundamental rights effects and out-\\ncomes generated by the deployment and use of untargeted biometric processing technolo-\\ngies in public spaces by any actor, whether public or private. These problems demonstrate\\nthe urgency of the EU Commission and Member States taking immediate action.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 21, 'page': 9, '_split_overlap': [{'doc_id': 'e4c13c11d53aab0d533b8c4211e7bb53', 'range': (0, 160)}, {'doc_id': '4f26818ac7275f0e3a1682e56f8bb3f8', 'range': (199, 1200)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5f10da2dd41a40f0a9a8e72e1ada1678'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 7 Article 29 Data Protection Working Party, Opinion 02/2012 on facial recognition in online and mobile services, 00727/12/EN\\n(2012) 2; quoted in FRA Facial recognition technology: fundamental rights considerations in the context of law enforcement\\n(2019), 7 <https://fra.europa.eu/sites/default/files/fra_uploads/fra-2019-facial-recognition-technology-focus-paper-1_\\nen.pdf>\\n8 UNESCO, Inclusion Through Access to Public Space (2017) <http://www.unesco.org/new/en/social-and-human-sciences/\\nthemes/urban-development/migrants-inclusion-in-cities/good-practices/inclusion-through-access-to-public-space/>\\nINTRODUCTION\\x0c10\\nCORE PROBLEMS\\nCORE PROBLEM DEFINITIONS\\nThis chapter outlines the harmful societal, ethical and fundamental rights effects and out-\\ncomes generated by the deployment and use of untargeted biometric processing technolo-\\ngies in public spaces by any actor, whether public or private. These problems demonstrate\\nthe urgency of the EU Commission and Member States taking immediate action.\\n3.1 Mass Surveillance\\nThe use of technology to process mass-scale biometric data, whether for law enforce-\\nment, public authority or commercial purposes, presents unique and grave threats to\\nprivacy and security.9 The Council of Europe defines mass surveillance as any monitoring\\nthat is not performed in a “targeted” way against a specific individual, and the EU Fun-\\ndamental Rights Agency (FRA) notes that an untargeted use “starts without prior suspi-\\ncion”.10 In practice, mass surveillance measures will disproportionately impact already\\nover-surveilled groups, for example migrants, poor communities and people of colour,\\nwhich can increase systemic discrimination against them. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 22, 'page': 9, '_split_overlap': [{'doc_id': '5f10da2dd41a40f0a9a8e72e1ada1678', 'range': (0, 1001)}, {'doc_id': '2452655449bbf66a9eea0f88cef2f45a', 'range': (1002, 1687)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4f26818ac7275f0e3a1682e56f8bb3f8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 3.1 Mass Surveillance\\nThe use of technology to process mass-scale biometric data, whether for law enforce-\\nment, public authority or commercial purposes, presents unique and grave threats to\\nprivacy and security.9 The Council of Europe defines mass surveillance as any monitoring\\nthat is not performed in a “targeted” way against a specific individual, and the EU Fun-\\ndamental Rights Agency (FRA) notes that an untargeted use “starts without prior suspi-\\ncion”.10 In practice, mass surveillance measures will disproportionately impact already\\nover-surveilled groups, for example migrants, poor communities and people of colour,\\nwhich can increase systemic discrimination against them. Even when conducted in a tar-\\ngeted way, principles of privacy and due process require that authorities have particular\\nlawful interest in, and reasonable suspicion of, an individual to justify surveilling them.\\nMass surveillance in public spaces, by contrast, relates to actions which impact on the\\npublic in general and which rely on watching them indiscriminately, without reasonable\\nsuspicion, sufficient possibilities for them to have knowledge of what is happening, abil-\\nity to consent, nor the genuine and free choice to opt in or out.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 23, 'page': 10, '_split_overlap': [{'doc_id': '4f26818ac7275f0e3a1682e56f8bb3f8', 'range': (0, 685)}, {'doc_id': '82fbdcc51e5ebd0e77ac5c2324a0907b', 'range': (898, 1229)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2452655449bbf66a9eea0f88cef2f45a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Mass surveillance in public spaces, by contrast, relates to actions which impact on the\\npublic in general and which rely on watching them indiscriminately, without reasonable\\nsuspicion, sufficient possibilities for them to have knowledge of what is happening, abil-\\nity to consent, nor the genuine and free choice to opt in or out.\\nDecades ago, and despite wide criticism,11 CCTV cameras were implemented fervently\\nyet untransparently all over the world, with the alleged goal of deterring crime. Even\\n9 Privacy International, The police are increasingly using facial recognition cameras in public to spy on us, (2019) <https://privacy-\\ninternational.org/long-read/2726/police-are-increasingly-using-facial-recognition-cameras-public-spy-us>\\n10 Council of Europe, Factsheet on Mass Surveillance (2018) 3 <https://rm.coe.int/factsheet-on-mass-surveillance-ju-\\nly2018-docx/16808c168e; https://fra.europa.eu/sites/default/files/fra_uploads/fra-2017-surveillance-intelligence-ser-\\nvices-vol-2-summary_en.pdf>\\n11 Surveillance Studies Network, A Report on the Surveillance Society (2006) <https://ico.org.uk/media/about-the-ico/docu-\\nments/1042390/surveillance-society-full-report-2006.pdf>\\n3.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 24, 'page': 10, '_split_overlap': [{'doc_id': '2452655449bbf66a9eea0f88cef2f45a', 'range': (0, 331)}, {'doc_id': 'ce5686a1c7ef0ad8789065afc8d1646e', 'range': (497, 1187)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '82fbdcc51e5ebd0e77ac5c2324a0907b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Even\\n9 Privacy International, The police are increasingly using facial recognition cameras in public to spy on us, (2019) <https://privacy-\\ninternational.org/long-read/2726/police-are-increasingly-using-facial-recognition-cameras-public-spy-us>\\n10 Council of Europe, Factsheet on Mass Surveillance (2018) 3 <https://rm.coe.int/factsheet-on-mass-surveillance-ju-\\nly2018-docx/16808c168e; https://fra.europa.eu/sites/default/files/fra_uploads/fra-2017-surveillance-intelligence-ser-\\nvices-vol-2-summary_en.pdf>\\n11 Surveillance Studies Network, A Report on the Surveillance Society (2006) <https://ico.org.uk/media/about-the-ico/docu-\\nments/1042390/surveillance-society-full-report-2006.pdf>\\n3.\\x0c11\\nCORE PROBLEMS\\nproponents of CCTV have found it difficult to prove that these cameras are effective in\\npreventing crime, demonstrating only that they can be efficient in very limited, specific\\ncircumstances as part of investigation or prosecution.12 Now these same systems can be\\nupdated with biometric analysis capacities for even greater levels of remote surveillance\\nin order to watch not just what happens on a certain spot, but to follow who may be doing\\nit.13 The impacts upon freedom of expression and assembly are stark; mass surveillance\\nmeans that people lose the right to be anonymous in public spaces.14 As the German\\nConstitutional Court put it in its famous 1983 Census judgment:\\nA person who wonders whether unusual behaviour is noted each time and there-\\nafter always kept on record, used or disseminated, will try not to come to attention\\nin this way. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 25, 'page': 10, '_split_overlap': [{'doc_id': '82fbdcc51e5ebd0e77ac5c2324a0907b', 'range': (0, 690)}, {'doc_id': 'd0c71ab5fb720cb75b58d626f24d6425', 'range': (691, 1561)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ce5686a1c7ef0ad8789065afc8d1646e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 11\\nCORE PROBLEMS\\nproponents of CCTV have found it difficult to prove that these cameras are effective in\\npreventing crime, demonstrating only that they can be efficient in very limited, specific\\ncircumstances as part of investigation or prosecution.12 Now these same systems can be\\nupdated with biometric analysis capacities for even greater levels of remote surveillance\\nin order to watch not just what happens on a certain spot, but to follow who may be doing\\nit.13 The impacts upon freedom of expression and assembly are stark; mass surveillance\\nmeans that people lose the right to be anonymous in public spaces.14 As the German\\nConstitutional Court put it in its famous 1983 Census judgment:\\nA person who wonders whether unusual behaviour is noted each time and there-\\nafter always kept on record, used or disseminated, will try not to come to attention\\nin this way. A person who assumes, for instance, that participation in a meeting\\nor citizen initiative is officially recorded, and may create risks for him, may well\\ndecide not to exercise the relevant fundamental rights ([guaranteed in] Articles 8\\nand 9 of the Constitution). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 26, 'page': 11, '_split_overlap': [{'doc_id': 'ce5686a1c7ef0ad8789065afc8d1646e', 'range': (0, 870)}, {'doc_id': '190058705aa8067ae83b8bd405f44363', 'range': (871, 1134)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd0c71ab5fb720cb75b58d626f24d6425'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: A person who assumes, for instance, that participation in a meeting\\nor citizen initiative is officially recorded, and may create risks for him, may well\\ndecide not to exercise the relevant fundamental rights ([guaranteed in] Articles 8\\nand 9 of the Constitution). This would not only limit the possibilities for personal\\ndevelopment of the individual, but also the common good, because self-determi-\\nnation is an essential prerequisite for a free and democratic society that is based\\non the capacity and solidarity of its citizens.15\\nBecause of the impact of mass surveillance on individuals, inferences based on such\\nsurveillance practices are fundamentally unreliable. For example, the CNIL notes that\\nconstant surveillance in public spaces can make seemingly normal attitudes and be-\\nhaviours appear suspect, citing examples such as wearing sunglasses, having one’s\\nhood up and staring at the ground or at a phone.16\\nThe ubiquity and intrusiveness of mass surveillance puts limits on everyone’s participation in\\nsocial, public and political life and, as noted in Census, impacts on their ability to live an au-\\ntonomous life without having to adapt behaviours due to a fear of being constantly watched. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 27, 'page': 11, '_split_overlap': [{'doc_id': 'd0c71ab5fb720cb75b58d626f24d6425', 'range': (0, 263)}, {'doc_id': '6b20ef1055d23b81e604215a9285d15e', 'range': (671, 1205)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '190058705aa8067ae83b8bd405f44363'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: For example, the CNIL notes that\\nconstant surveillance in public spaces can make seemingly normal attitudes and be-\\nhaviours appear suspect, citing examples such as wearing sunglasses, having one’s\\nhood up and staring at the ground or at a phone.16\\nThe ubiquity and intrusiveness of mass surveillance puts limits on everyone’s participation in\\nsocial, public and political life and, as noted in Census, impacts on their ability to live an au-\\ntonomous life without having to adapt behaviours due to a fear of being constantly watched. It\\nprevents people from exercising their political and civil rights.17\\nThis places a heavy onus of proof on those seeking to justify its use.18\\n12 Michelle Cayford, The effectiveness of surveillance technology: What intelligence officials are saying (2017) <https://www.tand-\\nfonline.com/doi/full/10.1080/01972243.2017.1414721>\\n13 European Network Against Racism, Data-Driven Policing: The Hardwiring of Discriminatory Policing Practices across Europe\\n(2019) 6 <https://www.enar-eu.org/IMG/pdf/data-driven-profiling-web-final.pdf>\\n14 ARTICLE 19, The Right to Protest Principles: Background Paper (2016) <https://www.article19.org/resources/the-right-to-pro-\\ntest-principles-on-the-protection-of-human-rights-in-protests/>\\n15 BVerfG, 15.12.1983, BVerfGE Bd. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 28, 'page': 11, '_split_overlap': [{'doc_id': '190058705aa8067ae83b8bd405f44363', 'range': (0, 534)}, {'doc_id': '2ed0bf55af96f832953821967fe9ff87', 'range': (535, 1291)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6b20ef1055d23b81e604215a9285d15e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: It\\nprevents people from exercising their political and civil rights.17\\nThis places a heavy onus of proof on those seeking to justify its use.18\\n12 Michelle Cayford, The effectiveness of surveillance technology: What intelligence officials are saying (2017) <https://www.tand-\\nfonline.com/doi/full/10.1080/01972243.2017.1414721>\\n13 European Network Against Racism, Data-Driven Policing: The Hardwiring of Discriminatory Policing Practices across Europe\\n(2019) 6 <https://www.enar-eu.org/IMG/pdf/data-driven-profiling-web-final.pdf>\\n14 ARTICLE 19, The Right to Protest Principles: Background Paper (2016) <https://www.article19.org/resources/the-right-to-pro-\\ntest-principles-on-the-protection-of-human-rights-in-protests/>\\n15 BVerfG, 15.12.1983, BVerfGE Bd. 65, S. 1 ff (“Volkszählungsurteil”), <https://www.bverfg.de/e/rs19831215_1bvr020983.html>\\n16 The CNIL, Reconaissance Faciale: Pour un Debat La Hauteur des Enjeux (2019) <https://www.cnil.fr/fr/reconnaissance-faciale-\\npour-un-debat-la-hauteur-des-enjeux>\\n17 Amnesty International, Russia: Intrusive facial recognition technology must not be used to crackdown on protests (2020)\\n<https://www.amnesty.org/en/latest/news/2020/01/russia-intrusive-facial-recognition-technology-must-not-be-used-to-crack-\\ndown-on-protests/>; OHCHR, Human Rights Committee holds general discussion in preparation for a general comment on the\\nright of peaceful assembly (2019) <https://ohchr.org/en/newsevents/pages/displaynews.aspx?newsid=24378&landid=e>\\n18 Privacy International, Protecting Civic Spaces (2019) <https://privacyinternational.org/long-read/2852/protecting-civic-spac-\\nes>\\x0c12\\nCORE PROBLEMS\\n3.1.1 Biometric mass surveillance in EU law\\nMass surveillance is prohibited in EU law. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 29, 'page': 11, '_split_overlap': [{'doc_id': '6b20ef1055d23b81e604215a9285d15e', 'range': (0, 756)}, {'doc_id': 'b64ae75afef12736b1dab9fafc1d00fd', 'range': (757, 1724)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2ed0bf55af96f832953821967fe9ff87'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 65, S. 1 ff (“Volkszählungsurteil”), <https://www.bverfg.de/e/rs19831215_1bvr020983.html>\\n16 The CNIL, Reconaissance Faciale: Pour un Debat La Hauteur des Enjeux (2019) <https://www.cnil.fr/fr/reconnaissance-faciale-\\npour-un-debat-la-hauteur-des-enjeux>\\n17 Amnesty International, Russia: Intrusive facial recognition technology must not be used to crackdown on protests (2020)\\n<https://www.amnesty.org/en/latest/news/2020/01/russia-intrusive-facial-recognition-technology-must-not-be-used-to-crack-\\ndown-on-protests/>; OHCHR, Human Rights Committee holds general discussion in preparation for a general comment on the\\nright of peaceful assembly (2019) <https://ohchr.org/en/newsevents/pages/displaynews.aspx?newsid=24378&landid=e>\\n18 Privacy International, Protecting Civic Spaces (2019) <https://privacyinternational.org/long-read/2852/protecting-civic-spac-\\nes>\\x0c12\\nCORE PROBLEMS\\n3.1.1 Biometric mass surveillance in EU law\\nMass surveillance is prohibited in EU law. The fundamental right to respect for private\\nand family life and the protection of personal data are central to the Charter of Funda-\\nmental Rights of the European Union (herewith “the Charter”), the European Convention\\non Human Rights (ECHR) and other legally-binding instruments.19 The Charter and ECHR\\nalso guarantee rights to dignity, freedom of expression, and freedom of assembly and\\nassociation – all of which are seriously threatened by mass surveillance.20 The General\\nData Protection Regulation (GDPR) sets out important principles for the protection of\\npersonal data, which results in a high legal barrier to mass data collection and process-\\ning. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 30, 'page': 11, '_split_overlap': [{'doc_id': '2ed0bf55af96f832953821967fe9ff87', 'range': (0, 967)}, {'doc_id': 'fb7d46191560a24280dfead077603254', 'range': (968, 1626)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b64ae75afef12736b1dab9fafc1d00fd'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The fundamental right to respect for private\\nand family life and the protection of personal data are central to the Charter of Funda-\\nmental Rights of the European Union (herewith “the Charter”), the European Convention\\non Human Rights (ECHR) and other legally-binding instruments.19 The Charter and ECHR\\nalso guarantee rights to dignity, freedom of expression, and freedom of assembly and\\nassociation – all of which are seriously threatened by mass surveillance.20 The General\\nData Protection Regulation (GDPR) sets out important principles for the protection of\\npersonal data, which results in a high legal barrier to mass data collection and process-\\ning. The Data Protection Law Enforcement Directive (LED) adds that special category\\ndata processing must be ‘strictly necessary’, which as Working Party 29 explains means\\nthat law enforcement agencies must “foresee precise and particularly solid justifications\\nfor the processing of such data”,21 and that it must be explicitly authorised under EU or\\nMember State law.\\nUnder the GDPR and the LED, some forms of personal data are especially sensitive and\\ntherefore enjoy enhanced protections. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 31, 'page': 12, '_split_overlap': [{'doc_id': 'b64ae75afef12736b1dab9fafc1d00fd', 'range': (0, 658)}, {'doc_id': 'f216ae7baea8232b0943f70a21591fbc', 'range': (659, 1145)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fb7d46191560a24280dfead077603254'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The Data Protection Law Enforcement Directive (LED) adds that special category\\ndata processing must be ‘strictly necessary’, which as Working Party 29 explains means\\nthat law enforcement agencies must “foresee precise and particularly solid justifications\\nfor the processing of such data”,21 and that it must be explicitly authorised under EU or\\nMember State law.\\nUnder the GDPR and the LED, some forms of personal data are especially sensitive and\\ntherefore enjoy enhanced protections. This includes the processing of biometric data\\nsuch as faces or fingerprints when used for the purpose of uniquely identifying a natural\\nperson, and observations which could enable someone to identify or predict character-\\nistics such as race, ethnicity, gender, sexual orientation, religion or health status. This\\nmeans that proxies, such as may be used in public surveillance – like wearing religious\\naccessories, or how we walk – are similarly protected, as are analyses of how we look,\\nmove or act which could expose sensitive information. European data protection law ap-\\nplies equally to information that we have made public, for example by posting photos or\\ndetails of our activities on the internet.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 32, 'page': 12, '_split_overlap': [{'doc_id': 'fb7d46191560a24280dfead077603254', 'range': (0, 486)}, {'doc_id': '96cee02a8483854acdcbe17f4ef2636d', 'range': (1031, 1194)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f216ae7baea8232b0943f70a21591fbc'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: European data protection law ap-\\nplies equally to information that we have made public, for example by posting photos or\\ndetails of our activities on the internet.\\nPerforming untargeted biometric recognition in public spaces, whether online or offline,\\nrelies on the indiscriminate collection, processing or storage of the above described sen-\\nsitive personal data on a mass scale, without control and knowledge from the individuals\\nbeing surveilled. It obscures the possibility of targeted use, as random passersby are\\nan inherent feature of public spaces. This is different to targeted or personal uses such\\nas unlocking one’s personal phone, which are outside the scope of this paper, as such\\nuses do not infringe on people’s ability to enjoy public spaces. We re-iterate, however,\\nthat whilst the scope of this paper is focused on biometric processing which could or will\\nlead to a sense of mass surveillance, we have serious concerns about the fundamental\\n19 Rights to privacy and data protection are enshrined in Arts. 7 and 8 of the Charter and 7 and 8 of the ECHR.\\n20 The Charter also establishes rights to dignity (Art. 1), freedom of expression (Art.11) and freedom of assembly and associ-\\nation (Art. 12). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 33, 'page': 12, '_split_overlap': [{'doc_id': 'f216ae7baea8232b0943f70a21591fbc', 'range': (0, 163)}, {'doc_id': '496c264d2a166683fafaec123e02bd7d', 'range': (1073, 1216)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '96cee02a8483854acdcbe17f4ef2636d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 20 The Charter also establishes rights to dignity (Art. 1), freedom of expression (Art.11) and freedom of assembly and associ-\\nation (Art. 12). The corresponding sections in ECHR are the Preamble (by reference to the Universal Declaration of Human\\nRights) and Arts. 10 and 11 respectively.\\n21 European Commission, Opinion on some key issues of the Law Enforcement Directive (2017) 8 <https://ec.europa.eu/news-\\nroom/article29/item-detail.cfm?item_id=610178>\\x0c13\\nCORE PROBLEMS\\nrights violations and potential abuses of power by authorities, private or even commer-\\ncial entities when conducting any targeted or untargeted biometric processing in public\\nspaces. Such surveillance must always be subject to strict controls and fundamental\\nrights as outlined in Section 5.5.\\nUntargeted mass processing of biometric data in public spaces obscures\\nthe possibility of targeted use, as random passersby are an inherent\\nfeature of public spaces.\\n3.2 Power Imbalances, Biases and a Lack of Accountability\\nThe use of biometric surveillance systems creates a dynamic where the powerful\\nwatch and the powerless are watched. It enables disproportionately powerful groups to\\nfurther fortify their power over socially-marginalised groups such as people living in pov-\\nerty or social exclusion, people of colour, or human rights activists. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 34, 'page': 12, '_split_overlap': [{'doc_id': '96cee02a8483854acdcbe17f4ef2636d', 'range': (0, 143)}, {'doc_id': 'b92ddf174006dc4e39f976998f4285a8', 'range': (1110, 1321)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '496c264d2a166683fafaec123e02bd7d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: It enables disproportionately powerful groups to\\nfurther fortify their power over socially-marginalised groups such as people living in pov-\\nerty or social exclusion, people of colour, or human rights activists. This raises important\\nquestions about ethics and social justice, in addition to fundamental rights concerns\\nsuch as the structural inability to gain genuinely informed, free, and explicit consent for\\npublic biometric processing, making the watched even more subordinate.\\nBiometric processing is already being used to systematise the targeting of citizens ex-\\npressing legitimate dissent (such as environmental activists) or marginalised groups\\nsuch as migrants or people with insecure housing situations. Surveillance and profiling\\ntechnologies are in essence sorting technologies: their purpose is to assess and codify\\nrisk, and to treat people differently as a result. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 35, 'page': 13, '_split_overlap': [{'doc_id': '496c264d2a166683fafaec123e02bd7d', 'range': (0, 211)}, {'doc_id': 'e6684d32db45de102ff4b1c2eeeeba59', 'range': (717, 882)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b92ddf174006dc4e39f976998f4285a8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Surveillance and profiling\\ntechnologies are in essence sorting technologies: their purpose is to assess and codify\\nrisk, and to treat people differently as a result. In the context of highly-discriminatory\\ncategorisations of who is considered ‘suspicious’ or ‘risky’, and numerous examples of\\nviolence in cases of profiling, there is a great risk that over-policed communities will be\\nmore likely to suffer from mass surveillance by biometric technologies.22 This is further\\nexacerbated by the fact that input data, such as are used to train biometric recognition\\nsystems, are not neutral, but reflect and encode the biases and structural discrimination\\nof the societies from which they are drawn. Within discriminatory structures, this bias\\nand lack of accuracy can lead to traumatic repeated false identifications of people of co-\\nlour and can exacerbate over-policing.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 36, 'page': 13, '_split_overlap': [{'doc_id': 'b92ddf174006dc4e39f976998f4285a8', 'range': (0, 165)}, {'doc_id': '67cd418c44d92d3cfd64e2f5004f7bba', 'range': (698, 871)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e6684d32db45de102ff4b1c2eeeeba59'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Within discriminatory structures, this bias\\nand lack of accuracy can lead to traumatic repeated false identifications of people of co-\\nlour and can exacerbate over-policing.\\nFacial data processing technologies have been shown to be biased against people of\\ncolour, in particular women of colour, having dramatically higher error (false positive or\\nnegative) rates for identifying them.23 However, even if the technology is trained to accu-\\n22 European Network Against Racism, Data-Driven Policing: The Hardwiring of Discriminatory Policing Practices across Europe\\n(2019) <https://www.enar-eu.org/IMG/pdf/data-driven-profiling-web-final.pdf>; Fundamental Rights Agency, Facial recog-\\nnition technology: fundamental rights considerations in the context of law enforcement (2019) 20 <https://fra.europa.eu/sites/\\ndefault/files/fra_uploads/fra-2019-facial-recognition-technology-focus-paper-1_en.pdf>\\n23 Joy Buolamwini, Gender Shades (2018) <http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf>\\x0c14\\nCORE PROBLEMS\\nrately identify all faces equally, this will not increase its respect for fundamental rights.\\nInstead, it will become even more effective at profiling and targeting specific groups,\\nwhen they have not even been suspected of committing a crime.24 Moreover, profiling\\nbased on self-learning (“artificial intelligence”) algorithms is effectively unchallenge-\\nable because even those operating the systems cannot explain the underlying reasoning.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 37, 'page': 13, '_split_overlap': [{'doc_id': 'e6684d32db45de102ff4b1c2eeeeba59', 'range': (0, 173)}, {'doc_id': '40da99bffb3f20bc7cec872c6dc4b677', 'range': (1115, 1463)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '67cd418c44d92d3cfd64e2f5004f7bba'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Instead, it will become even more effective at profiling and targeting specific groups,\\nwhen they have not even been suspected of committing a crime.24 Moreover, profiling\\nbased on self-learning (“artificial intelligence”) algorithms is effectively unchallenge-\\nable because even those operating the systems cannot explain the underlying reasoning.\\nThis is made worse by the well-known phenomenon of “computer bias”: the tendency of\\nindividuals to uncritically accept a computer-generated prediction.25 In a nutshell, if it is\\ninaccurate, biometric mass surveillance is problematic; but if it is 100% accurate, it can\\nbe even worse.\\nThe current deployment of biometric identification and surveillance systems in public-\\nly-accessible spaces is occurring in a vacuum of state accountability or public oversight\\nand in violation of constitutional privacy protections which are designed to defend people\\nfrom abuses of state power.26 Furthermore, private actors are gaining disproportionate\\npower over the technology used by public authorities and law enforcement, with little\\nor no accountability for their actions. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 38, 'page': 14, '_split_overlap': [{'doc_id': '67cd418c44d92d3cfd64e2f5004f7bba', 'range': (0, 348)}, {'doc_id': 'bea262bbf891ff0af85189a271d1ecde', 'range': (633, 1113)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '40da99bffb3f20bc7cec872c6dc4b677'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The current deployment of biometric identification and surveillance systems in public-\\nly-accessible spaces is occurring in a vacuum of state accountability or public oversight\\nand in violation of constitutional privacy protections which are designed to defend people\\nfrom abuses of state power.26 Furthermore, private actors are gaining disproportionate\\npower over the technology used by public authorities and law enforcement, with little\\nor no accountability for their actions. From deliberately obfuscating the inner-workings\\nof their technologies,27 to profiting from exploitative policing practices (in the case of\\nClearviewAI)28, the blurred involvement of private actors in developing biometric mass\\nsurveillance systems can give them power not only over people – but great influence over\\nstates, too.\\n3.3 Function Creep and Normalisation\\nFacial recognition and other biometric processing represents a massive increase in the\\ncapabilities for omnipresent surveillance, power imbalances between people and state\\n(and private companies), and the potential for authoritarian abuse. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 39, 'page': 14, '_split_overlap': [{'doc_id': '40da99bffb3f20bc7cec872c6dc4b677', 'range': (0, 480)}, {'doc_id': '45d1bb5e524fedaf9640a1f0bf606d3d', 'range': (810, 1086)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bea262bbf891ff0af85189a271d1ecde'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 3.3 Function Creep and Normalisation\\nFacial recognition and other biometric processing represents a massive increase in the\\ncapabilities for omnipresent surveillance, power imbalances between people and state\\n(and private companies), and the potential for authoritarian abuse. There is already evi-\\ndence that biometric systems which have been deployed for one use are re-deployed or\\nabused in other, more sinister ways so that even if people have initially provided consent\\nover the use of their biometric or genetic data for a specific purpose, they have little to\\nno knowledge of, or power to correct or object to, the further processing of those data.\\nOnce infrastructure is in place, the existence of these systems creates new possibilities\\nfor expanded intrusion. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 40, 'page': 14, '_split_overlap': [{'doc_id': 'bea262bbf891ff0af85189a271d1ecde', 'range': (0, 276)}, {'doc_id': 'c73349b340d29043cd330c0c586b8e36', 'range': (277, 769)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '45d1bb5e524fedaf9640a1f0bf606d3d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: There is already evi-\\ndence that biometric systems which have been deployed for one use are re-deployed or\\nabused in other, more sinister ways so that even if people have initially provided consent\\nover the use of their biometric or genetic data for a specific purpose, they have little to\\nno knowledge of, or power to correct or object to, the further processing of those data.\\nOnce infrastructure is in place, the existence of these systems creates new possibilities\\nfor expanded intrusion. Some of the initial reactions to the global coronavirus pandemic\\nshow that once this possibility exists, states may take advantage of technological in-\\n24 The Guardian, Facial recognition technology threatens to end all individual privacy (2019) <https://www.theguardian.com/com-\\nmentisfree/2019/sep/20/facial-recognition-technology-privacy>\\n25 Douwe Korff and Marie Georges, Passenger Name Records, data mining & data protection: the need for strong safeguards,\\nsection I.iii, The dangers inherent in data mining and profiling (2015) <https://rm.coe.int/16806a601b>\\n26 For example, SHARE Foundation, Serbia: Unlawful facial recognition video surveillance in Belgrade (2019) <https://edri.org/\\nserbia-unlawful-facial-recognition-video-surveillance-in-belgrade/>; Administrative Tribunal of Marseille found in 2020\\nthat facial recognition in two schools violated fundamental rights <https://www.laquadrature.net/wp-content/uploads/sit\\nes/8/2020/02/1090394890_1901249.pdf>\\n27 Panoptykon Foundation, Black-Boxed Politics: Opacity is a Choice in AI Systems (2020) <https://en.panoptykon.org/articles/\\nblack-boxed-politics-opacity-choice-ai-systems>\\n28 EURACTIV, After Clearview AI scandal, Commission ‘in close contact’ with EU data authorities (2020) <https://www.euractiv.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 41, 'page': 14, '_split_overlap': [{'doc_id': '45d1bb5e524fedaf9640a1f0bf606d3d', 'range': (0, 492)}, {'doc_id': 'c102c7c3e9ab5feb1a83a79e5090fe8b', 'range': (493, 1763)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c73349b340d29043cd330c0c586b8e36'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Some of the initial reactions to the global coronavirus pandemic\\nshow that once this possibility exists, states may take advantage of technological in-\\n24 The Guardian, Facial recognition technology threatens to end all individual privacy (2019) <https://www.theguardian.com/com-\\nmentisfree/2019/sep/20/facial-recognition-technology-privacy>\\n25 Douwe Korff and Marie Georges, Passenger Name Records, data mining & data protection: the need for strong safeguards,\\nsection I.iii, The dangers inherent in data mining and profiling (2015) <https://rm.coe.int/16806a601b>\\n26 For example, SHARE Foundation, Serbia: Unlawful facial recognition video surveillance in Belgrade (2019) <https://edri.org/\\nserbia-unlawful-facial-recognition-video-surveillance-in-belgrade/>; Administrative Tribunal of Marseille found in 2020\\nthat facial recognition in two schools violated fundamental rights <https://www.laquadrature.net/wp-content/uploads/sit\\nes/8/2020/02/1090394890_1901249.pdf>\\n27 Panoptykon Foundation, Black-Boxed Politics: Opacity is a Choice in AI Systems (2020) <https://en.panoptykon.org/articles/\\nblack-boxed-politics-opacity-choice-ai-systems>\\n28 EURACTIV, After Clearview AI scandal, Commission ‘in close contact’ with EU data authorities (2020) <https://www.euractiv.\\ncom/section/digital/news/after-clearview-ai-scandal-commission-in-close-contact-with-eu-data-authorities/>\\x0c15\\nCORE PROBLEMS\\nfrastructures to watch people in ways that are well beyond the scope of managing the\\ncurrent situation.29 Furthermore, the existence of surveillance infrastructure and its use\\nin day-to-day life can lead to the false belief that being constantly watched, tracked and\\nanalysed is normal. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 42, 'page': 14, '_split_overlap': [{'doc_id': 'c73349b340d29043cd330c0c586b8e36', 'range': (0, 1270)}, {'doc_id': 'c44dec8cdbdf30b20884dc43c3c51e4', 'range': (1271, 1681)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c102c7c3e9ab5feb1a83a79e5090fe8b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: com/section/digital/news/after-clearview-ai-scandal-commission-in-close-contact-with-eu-data-authorities/>\\x0c15\\nCORE PROBLEMS\\nfrastructures to watch people in ways that are well beyond the scope of managing the\\ncurrent situation.29 Furthermore, the existence of surveillance infrastructure and its use\\nin day-to-day life can lead to the false belief that being constantly watched, tracked and\\nanalysed is normal. To the contrary, democratic societies cannot and must not allow\\nthe normalisation of activities that bear the hallmark of authoritarian regimes. As UN\\nSpecial Rapporteur David Kaye emphasises, surveillance technologies are dangerously\\nuncontrolled, and both states and companies must step up to tackle this delta.30\\n3.4 (Re-)identification and Tracking Over Time\\nThe risks to fundamental freedoms are further enhanced if data gathered through mass\\nsurveillance are analysed and used to create profiles that, in turn, are applied to indi-\\nviduals in a crowd or group in order to “identify” persons worthy of even more intrusive\\nattention.31 Regardless of the technology used or the method of personal data collection,\\nbiometric processing systems are designed to enable individual retrospective identifica-\\ntion – a function which can increase over time as more and more data are linked through\\nexisting surveillance infrastructures, searchable databases, data from other public au-\\nthorities, and biometric processing in public spaces. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 43, 'page': 14, '_split_overlap': [{'doc_id': 'c102c7c3e9ab5feb1a83a79e5090fe8b', 'range': (0, 410)}, {'doc_id': '9ba8b834117aa05ecbc953e87c91b7a5', 'range': (556, 1446)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c44dec8cdbdf30b20884dc43c3c51e4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: As UN\\nSpecial Rapporteur David Kaye emphasises, surveillance technologies are dangerously\\nuncontrolled, and both states and companies must step up to tackle this delta.30\\n3.4 (Re-)identification and Tracking Over Time\\nThe risks to fundamental freedoms are further enhanced if data gathered through mass\\nsurveillance are analysed and used to create profiles that, in turn, are applied to indi-\\nviduals in a crowd or group in order to “identify” persons worthy of even more intrusive\\nattention.31 Regardless of the technology used or the method of personal data collection,\\nbiometric processing systems are designed to enable individual retrospective identifica-\\ntion – a function which can increase over time as more and more data are linked through\\nexisting surveillance infrastructures, searchable databases, data from other public au-\\nthorities, and biometric processing in public spaces. Even metadata and anonymised,\\npseudonymised or non-personal data can be used to infer sensitive, personal, identifi-\\nable information when combined with the vast sources at the disposal of public and pri-\\nvate actors.32 These ever-increasing surveillance networks create “permanent records”\\nof our lives, interactions and behaviours without proper consent or genuine possibilities\\nto opt out, and without the opportunity to return to lawful anonymity once we realise that\\nthis was the wrong way to go.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 44, 'page': 15, '_split_overlap': [{'doc_id': 'c44dec8cdbdf30b20884dc43c3c51e4', 'range': (0, 890)}, {'doc_id': '27b12348bd92dc666b0fad094963cd7c', 'range': (891, 1392)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9ba8b834117aa05ecbc953e87c91b7a5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Even metadata and anonymised,\\npseudonymised or non-personal data can be used to infer sensitive, personal, identifi-\\nable information when combined with the vast sources at the disposal of public and pri-\\nvate actors.32 These ever-increasing surveillance networks create “permanent records”\\nof our lives, interactions and behaviours without proper consent or genuine possibilities\\nto opt out, and without the opportunity to return to lawful anonymity once we realise that\\nthis was the wrong way to go.\\nThe increased capacity of states to track and identify individuals through facial recog-\\nnition and other biometric processing is likely to disproportionately impact populations\\nwhich are already highly policed, surveilled and targeted by abuse, including people of\\ncolour, Roma and Muslim communities, social activists, LGBTQ+ people and people with\\nirregular migration status.33 The combined impact of facial recognition technology and\\nthe pursued mass merging of European-wide biometric databases will pose even great-\\ner risks to safety, privacy and other fundamental rights for these communities.\\n29 The EU-wide example of bulk metadata collection shows how states collect information for a particular use (eg finding\\nterrorists) but over time increase the scope to include non-violent crimes such as burglaries.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 45, 'page': 15, '_split_overlap': [{'doc_id': '9ba8b834117aa05ecbc953e87c91b7a5', 'range': (0, 501)}, {'doc_id': '251b25cbc4ff2e629cb97be5678c09', 'range': (1104, 1319)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '27b12348bd92dc666b0fad094963cd7c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 29 The EU-wide example of bulk metadata collection shows how states collect information for a particular use (eg finding\\nterrorists) but over time increase the scope to include non-violent crimes such as burglaries.\\n30 UN OHCHR, UN expert calls for immediate moratorium on the sale, transfer and use of surveillance tools (2019) <https://ohchr.\\norg/en/newsevents/pages/displaynews.aspx?newsid=24736>\\n31 See Douwe Korff and Marie Georges, footnote 25, pages 32 – 34 <https://rm.coe.int/16806a601b>\\n32 European Data Protection Board (EDPB), Guidelines 3/2019 on processing of personal data through video devices (2019) 16\\n<https://edpb.europa.eu/sites/edpb/files/consultation/edpb_guidelines_201903_videosurveillance.pdf>; see also Douwe\\nKorff and Marie Georges, o.c. (footnote 25), 34 – 36.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 46, 'page': 15, '_split_overlap': [{'doc_id': '27b12348bd92dc666b0fad094963cd7c', 'range': (0, 215)}, {'doc_id': '63fdeace3ab516239314d9ada2faf52b', 'range': (345, 789)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '251b25cbc4ff2e629cb97be5678c09'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: org/en/newsevents/pages/displaynews.aspx?newsid=24736>\\n31 See Douwe Korff and Marie Georges, footnote 25, pages 32 – 34 <https://rm.coe.int/16806a601b>\\n32 European Data Protection Board (EDPB), Guidelines 3/2019 on processing of personal data through video devices (2019) 16\\n<https://edpb.europa.eu/sites/edpb/files/consultation/edpb_guidelines_201903_videosurveillance.pdf>; see also Douwe\\nKorff and Marie Georges, o.c. (footnote 25), 34 – 36.\\n33 PICUM, Data Protection, Immigration Enforcement and Fundamental Rights (2019) <https://picum.org/wp-content/up-\\nloads/2019/11/Data-Protection-Immigration-Enforcement-and-Fundamental-Rights-Full-Report-EN.pdf>\\x0c16\\n3.5 Social Control and Illegitimate Science\\nOnce untargeted biometric processing in public spaces is normalised, and people can\\nbe identified and tracked across systems and locations, they can then be scored, cate-\\ngorised and assessed without ever knowing how or why this is happening or how it may\\naffect their life.34 With governments rushing to innovate with big data and become lead-\\ners in AI-enabled public services, the massive amount of data held by authorities and\\nincreasingly by commercial actors about our health, criminal records and many other\\npersonal details can be combined.35 With the rise of mass surveillance, this can be linked\\nto physical individuals on the streets and can log their interactions and movements in\\na way that creates a detailed, intimate pictures of people’s lives.36 This can be exploited\\nfor extreme uses such as social scoring and behavioural manipulation which become\\nultimately a question of control.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 47, 'page': 15, '_split_overlap': [{'doc_id': '251b25cbc4ff2e629cb97be5678c09', 'range': (0, 444)}, {'doc_id': '8eaddbdb9d4d2e7c2c3fb55665b7b334', 'range': (445, 1604)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '63fdeace3ab516239314d9ada2faf52b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 33 PICUM, Data Protection, Immigration Enforcement and Fundamental Rights (2019) <https://picum.org/wp-content/up-\\nloads/2019/11/Data-Protection-Immigration-Enforcement-and-Fundamental-Rights-Full-Report-EN.pdf>\\x0c16\\n3.5 Social Control and Illegitimate Science\\nOnce untargeted biometric processing in public spaces is normalised, and people can\\nbe identified and tracked across systems and locations, they can then be scored, cate-\\ngorised and assessed without ever knowing how or why this is happening or how it may\\naffect their life.34 With governments rushing to innovate with big data and become lead-\\ners in AI-enabled public services, the massive amount of data held by authorities and\\nincreasingly by commercial actors about our health, criminal records and many other\\npersonal details can be combined.35 With the rise of mass surveillance, this can be linked\\nto physical individuals on the streets and can log their interactions and movements in\\na way that creates a detailed, intimate pictures of people’s lives.36 This can be exploited\\nfor extreme uses such as social scoring and behavioural manipulation which become\\nultimately a question of control.\\nThe use of biometric technology for evaluation of behaviour, motivations or character\\noften lacks a scientific basis, for example so-called “affect recognition” or “behavioural\\nprediction” which claim to be able to identify a person’s emotions or intentions, but fun-\\ndamentally threaten human dignity and autonomy. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 48, 'page': 15, '_split_overlap': [{'doc_id': '63fdeace3ab516239314d9ada2faf52b', 'range': (0, 1159)}, {'doc_id': '1b2b6c03fc253b960dec06f9865c077a', 'range': (1160, 1475)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8eaddbdb9d4d2e7c2c3fb55665b7b334'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The use of biometric technology for evaluation of behaviour, motivations or character\\noften lacks a scientific basis, for example so-called “affect recognition” or “behavioural\\nprediction” which claim to be able to identify a person’s emotions or intentions, but fun-\\ndamentally threaten human dignity and autonomy. A recent meta-analysis of research\\non ‘emotion science’ by leading researchers in the field concluded that there is no sci-\\nentific support for claims made by technology companies that they can ‘detect’ emotion\\nthrough video analysis. The researchers stated that such initiatives rest on misunder-\\nstandings and that “the science of emotion is ill-equipped to support any of these initia-\\ntives.”37 Similar concerns apply to unproven attempts to use advanced statistical analysis\\nto detect whether someone is lying in a video interview.38 Such forms of dubious behav-\\nioral prediction remove the ability of individuals to consent to the processing of their\\nbiometric data, deprive them of their right to due process and to be properly informed,\\nand removes the ability for them to seek explanation or redress when they suffer harm.\\nSuch violations of rights will fundamentally and irreversibly undermine people’s trust in\\nthose that deploy biometric technologies.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 49, 'page': 16, '_split_overlap': [{'doc_id': '8eaddbdb9d4d2e7c2c3fb55665b7b334', 'range': (0, 315)}, {'doc_id': 'e138c7e5fe590f2d110fbdfda5b52104', 'range': (551, 1279)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1b2b6c03fc253b960dec06f9865c077a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The researchers stated that such initiatives rest on misunder-\\nstandings and that “the science of emotion is ill-equipped to support any of these initia-\\ntives.”37 Similar concerns apply to unproven attempts to use advanced statistical analysis\\nto detect whether someone is lying in a video interview.38 Such forms of dubious behav-\\nioral prediction remove the ability of individuals to consent to the processing of their\\nbiometric data, deprive them of their right to due process and to be properly informed,\\nand removes the ability for them to seek explanation or redress when they suffer harm.\\nSuch violations of rights will fundamentally and irreversibly undermine people’s trust in\\nthose that deploy biometric technologies.\\n34 World Privacy Forum, The Scoring of America: How Secret Consumer Scores Threaten Your Privacy and Your Future (2014)\\n<www.worldprivacyforum.org/wp-content/uploads/2014/04/WPF_Scoring_of_America_April2014_fs.pdf>\\n35 For an early survey of UK state databases, see Joseph Rowntree Reform Trust, The Database State (2009) <https://www.\\ncl.cam.ac.uk/~rja14/Papers/database-state.pdf>. This showed that in sharing data “between health and social services,\\nthe police, schools, local government and the taxman”, “fewer than 15% of the public databases assessed [were] effective,\\nproportionate and necessary, with a proper legal basis”.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 50, 'page': 16, '_split_overlap': [{'doc_id': '1b2b6c03fc253b960dec06f9865c077a', 'range': (0, 728)}, {'doc_id': 'f664640267c96c87215bf1a731933c26', 'range': (1112, 1360)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e138c7e5fe590f2d110fbdfda5b52104'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: This showed that in sharing data “between health and social services,\\nthe police, schools, local government and the taxman”, “fewer than 15% of the public databases assessed [were] effective,\\nproportionate and necessary, with a proper legal basis”.\\n36 The Guardian, The New Normal (2020) <https://www.theguardian.com/world/2020/mar/09/the-new-normal-chinas-exces-\\nsive-coronavirus-public-monitoring-could-be-here-to-stay>\\n37 Barrett, Adolphs, Marsella, Martinez & Pollak, Emotional Expressions Reconsidered: Challenges to Inferring Emotion from\\nHuman Facial Movements (2019) 48 <https://doi.org/10.1177%2F1529100619832930>\\n38 The Intercept, We Tested Europe’s New Lie Detector for Travelers — and Immediately Triggered a False Positive (2019) <https://\\ntheintercept.com/2019/07/26/europe-border-control-ai-lie-detector/>. See also Anders Eriksson and Francisco Lacerda,\\nCharlatanry in forensic speech science: A problem to be taken seriously (2007) <http://www.cs.columbia.edu/~julia/papers/\\neriksson&lacerda07.pdf>. More generally, see Douwe Korff, The use of the Internet & related services, private life & data pro-\\ntection: trends & technologies, threats & implications, Council of Europe (2007) 25 – 27.\\nCORE PROBLEMS\\x0c17\\n4.\\nACT NOW\\nRATIONALE FOR EU ACTION\\nThe legal basis for deploying any biometric systems in public, whether in trial or full im-\\nplementation, is unclear – and in some cases non-existent - in European and Member\\nState national law. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 51, 'page': 16, '_split_overlap': [{'doc_id': 'e138c7e5fe590f2d110fbdfda5b52104', 'range': (0, 248)}, {'doc_id': '976e9e79f1ec332d0a829bd4e09d157d', 'range': (1229, 1455)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f664640267c96c87215bf1a731933c26'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: ACT NOW\\nRATIONALE FOR EU ACTION\\nThe legal basis for deploying any biometric systems in public, whether in trial or full im-\\nplementation, is unclear – and in some cases non-existent - in European and Member\\nState national law. Many deployments have been carried out entirely without evidence\\nof prior data protection impact assessments (DPIAs) and other safeguarding measures,\\ndespite the potential for many of these uses to contribute to unlawful mass surveillance\\nand other fundamental rights abuses.39 Three UN Special Rapporteurs have warned\\nabout biometrics systems. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 52, 'page': 17, '_split_overlap': [{'doc_id': 'f664640267c96c87215bf1a731933c26', 'range': (0, 226)}, {'doc_id': '150c1682b2f59264019154f86fe8e1ee', 'range': (227, 571)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '976e9e79f1ec332d0a829bd4e09d157d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Many deployments have been carried out entirely without evidence\\nof prior data protection impact assessments (DPIAs) and other safeguarding measures,\\ndespite the potential for many of these uses to contribute to unlawful mass surveillance\\nand other fundamental rights abuses.39 Three UN Special Rapporteurs have warned\\nabout biometrics systems. UN Special Rapporteur on Freedom of Association and As-\\nsembly, Clément Voule, expressed in his 2019 Report that “[t]he use of surveillance tech-\\nniques for the indiscriminate and untargeted surveillance of those exercising their right\\nto peaceful assembly and association, in both physical and digital spaces, should be\\nprohibited.”40 The necessity and proportionality of such systems have been called into\\nquestion by UN Special Rapporteur on the Right to Privacy, Joseph Cannataci.41 Similar\\nconcerns have been raised about the impact on human rights defenders, journalists,\\npoliticians and UN investigators by UN Special Rapporteur on Freedom of Expression,\\nDavid Kaye.42\\nPublic or civic spaces are the physical and digital settings where people express them-\\nselves freely, formulate ideas, discuss them with like-minded people and groups, raise\\ndissenting views, consider possible reforms, expose bias and corruption, and organise\\nfor political, economic, social, environmental, and cultural change.43\\n39 Under the GDPR Arts. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 53, 'page': 17, '_split_overlap': [{'doc_id': '976e9e79f1ec332d0a829bd4e09d157d', 'range': (0, 344)}, {'doc_id': '4f48acbe4628ad5677a5f08720b17c8', 'range': (345, 1376)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '150c1682b2f59264019154f86fe8e1ee'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: UN Special Rapporteur on Freedom of Association and As-\\nsembly, Clément Voule, expressed in his 2019 Report that “[t]he use of surveillance tech-\\nniques for the indiscriminate and untargeted surveillance of those exercising their right\\nto peaceful assembly and association, in both physical and digital spaces, should be\\nprohibited.”40 The necessity and proportionality of such systems have been called into\\nquestion by UN Special Rapporteur on the Right to Privacy, Joseph Cannataci.41 Similar\\nconcerns have been raised about the impact on human rights defenders, journalists,\\npoliticians and UN investigators by UN Special Rapporteur on Freedom of Expression,\\nDavid Kaye.42\\nPublic or civic spaces are the physical and digital settings where people express them-\\nselves freely, formulate ideas, discuss them with like-minded people and groups, raise\\ndissenting views, consider possible reforms, expose bias and corruption, and organise\\nfor political, economic, social, environmental, and cultural change.43\\n39 Under the GDPR Arts. 15, 35 and 36 and LED Arts. 27, 28 and 47, mass biometric processing clearly triggers the require-\\nment under law to perform Data Protection Impact Assessments (DPIAs).\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 54, 'page': 17, '_split_overlap': [{'doc_id': '150c1682b2f59264019154f86fe8e1ee', 'range': (0, 1031)}, {'doc_id': 'dbe2c16bf622293611d11827dc3067b8', 'range': (1060, 1200)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4f48acbe4628ad5677a5f08720b17c8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 27, 28 and 47, mass biometric processing clearly triggers the require-\\nment under law to perform Data Protection Impact Assessments (DPIAs).\\n40 UN, Report of the Special Rapporteur on the rights to freedom of peaceful assembly and of association (2019) 15 <https://docu-\\nments-dds-ny.un.org/doc/UNDOC/GEN/G19/141/02/PDF/G1914102.pdf?OpenElement>\\n41 Biometric Update, UN privacy rapporteur criticizes accuracy and proportionality of Wales police use of facial recognition (2018)\\n<https://www.biometricupdate.com/201807/un-privacy-rapporteur-criticizes-accuracy-and-proportionality-of-wales-po-\\nlice-use-of-facial-recognition>\\n42 OHCHR, UN expert calls for immediate moratorium on the sale, transfer and use of surveillance tools (2019) <https://www.\\nohchr.org/EN/NewsEvents/Pages/DisplayNews.aspx?NewsID=24736>\\n43 Privacy International, Defending Democracy and Dissent <https://privacyinternational.org/strategic-areas/defending-democ-\\nracy-and-dissent>\\x0c18\\nThe effect of mass surveillance technology may be that in the long-term,\\npeople self-censor their thoughts, words, and actions.\\nIn February 2020, the European Commission released its “White Paper on Artificial Intel-\\nligence”, laying out policy options for a wide range of Artificial Intelligence (AI) applica-\\ntions.44 On facial recognition and other biometric processing, the paper proposed that –\\ndue to the fundamental risks posed by the use of the technology – it should automatically\\nbe considered “high risk”, invoking mandatory conformity assessments. However, the\\npaper did not go further to adequately consider the impact of these “high risk” applica-\\ntions on fundamental rights. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 55, 'page': 17, '_split_overlap': [{'doc_id': '4f48acbe4628ad5677a5f08720b17c8', 'range': (0, 140)}, {'doc_id': '4b11ff19b3bb3ae33ca22647b26448f5', 'range': (1516, 1646)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'dbe2c16bf622293611d11827dc3067b8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: However, the\\npaper did not go further to adequately consider the impact of these “high risk” applica-\\ntions on fundamental rights. Had it done so, we believe the logical conclusion would have\\nbeen to ban biometric processing technologies for mass surveillance purposes.\\nThese concerns are shared even by industry players: the President of Microsoft has\\nwarned that facial recognition risks creating Orwellian surveillance societies45 and Am-\\nazon’s shareholders rebelled against its biometric surveillance plans, citing threats to\\ncivil liberties46.\\nAlthough biometric processing technologies typically involve the use of ‘Artificial Intel-\\nligence’ techniques (more specifically, machine learning), we believe that the precise\\ntechnical implementation of these systems is far less important than their consequenc-\\nes: mass surveillance has the same impact on fundamental rights whether it is accom-\\nplished by a machine learning algorithm or a team of humans reviewing video footage,\\nalthough AI may allow for mass surveillance on an unprecedented scale. The current\\nlegal accountability and vacuum in which biometric deployments are occurring, in con-\\njunction with widespread concerns across businesses, civil society and the general pub-\\nlic, means that there is a strong basis to demand that the EU takes action.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 56, 'page': 18, '_split_overlap': [{'doc_id': 'dbe2c16bf622293611d11827dc3067b8', 'range': (0, 130)}, {'doc_id': '85d0bdced78df843e68f3391832d5a0', 'range': (1056, 1317)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4b11ff19b3bb3ae33ca22647b26448f5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The current\\nlegal accountability and vacuum in which biometric deployments are occurring, in con-\\njunction with widespread concerns across businesses, civil society and the general pub-\\nlic, means that there is a strong basis to demand that the EU takes action.\\n44 European Commission COM(2020) 65, White Paper: On Artificial Intelligence – A European approach to excellence and trust\\n(2020), <https://ec.europa.eu/info/sites/info/files/commission-white-paper-artificial-intelligence-feb2020_en.pdf>\\n45 Microsoft, Facial Recognition: It’s Time for Action (2018) <https://blogs.microsoft.com/on-the-issues/2018/12/06/facial-recog-\\nnition-its-time-for-action/>\\n46 The New York Times, Amazon’s Facial Recognition (2019) <https://www.nytimes.com/2019/05/20/technology/amazon-fa-\\ncial-recognition.html>\\x0c19\\n5.\\nANALYSIS\\nPOLICY ANALYSIS & DISCUSSION\\nThis chapter explores and analyses the legal and policy arguments for permanently\\nstopping untargeted biometric processing in public spaces, using fundamental rights and\\ndata protection law to scrutinise the legitimacy, lawfulness, necessity and proportionality of\\nuntargeted biometric processing in public spaces. This analysis provides the justification for\\nthe set of actions, amounting to a ban on biometric mass surveillance, which are proposed\\nin chapter 7.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 57, 'page': 18, '_split_overlap': [{'doc_id': '4b11ff19b3bb3ae33ca22647b26448f5', 'range': (0, 261)}, {'doc_id': 'd7c6af39b9fdac0af3528f8b5b25a43c', 'range': (1157, 1305)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '85d0bdced78df843e68f3391832d5a0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: This analysis provides the justification for\\nthe set of actions, amounting to a ban on biometric mass surveillance, which are proposed\\nin chapter 7.\\nUnder the Charter, the ECHR, the GDPR and the LED, untargeted biometric processing in\\npublic spaces – even as a means to achieve legitimate public policy outcomes - cannot be\\nconsidered necessary or proportionate because the size of the threat posed to sensitive\\npersonal data and the limitations that it places on our rights and freedoms means that it is\\nnever the least intrusive option. Its use creates conditions for unlawful mass surveillance\\nand by its very purpose, constitutes a fundamental violation of human dignity. The CJEU\\nAdvocate General adds that “mass, indiscriminate surveillance is inherently disproportionate\\nand constitutes an unwarranted interference” with rights to privacy and data protection.47\\nDespite this, deployments of biometric technology which establish mass surveillance continue\\nunchecked across the EU. Legislative fragmentation, enforcement challenges and a lack of\\nresources (political, financial and human) for national Data Protection Authorities (DPAs)\\nfurther compound the problem of the untransparent deployment of biometric technologies in\\nviolation of the GDPR, the LED and the Charter.\\n5.1 Fundamental Rights Law\\nThe Charter (Art. 52(1)) and the ECHR (Arts. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 58, 'page': 19, '_split_overlap': [{'doc_id': '85d0bdced78df843e68f3391832d5a0', 'range': (0, 148)}, {'doc_id': 'd72faea58efde367da80fefde423cc0b', 'range': (987, 1351)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd7c6af39b9fdac0af3528f8b5b25a43c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Legislative fragmentation, enforcement challenges and a lack of\\nresources (political, financial and human) for national Data Protection Authorities (DPAs)\\nfurther compound the problem of the untransparent deployment of biometric technologies in\\nviolation of the GDPR, the LED and the Charter.\\n5.1 Fundamental Rights Law\\nThe Charter (Art. 52(1)) and the ECHR (Arts. 8-11) establish that any interference with\\nfundamental rights – as must be anticipated by any deployment of biometric technolo-\\ngies - must be “provided for by law”, “[s]ubject to the principle of proportionality” and\\napplied only “if they are necessary and genuinely meet objectives of general interest\\nrecognised by the Union or the need to protect the rights and freedoms of others.” The\\n47 CJEU, C-362/14, Maximillian Schrems v Data Protection Commissioner, Advocate General’s Opinion (2015) <https://fra.\\neuropa.eu/sites/default/files/fra_uploads/fra-2015-surveillance-intelligence-services-summary-0_en.pdf>\\nACT NOW\\x0c20\\nANALYSIS\\nEuropean Data Protection Supervisor (EDPS) provides stringent guidance about demon-\\nstrating necessity and proportionality.48 By contrast, current deployments have largely\\nfailed to demonstrate these legal criteria.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 59, 'page': 19, '_split_overlap': [{'doc_id': 'd7c6af39b9fdac0af3528f8b5b25a43c', 'range': (0, 364)}, {'doc_id': '8d50489dd1ceee7dc57e71196505a531', 'range': (875, 1214)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd72faea58efde367da80fefde423cc0b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: europa.eu/sites/default/files/fra_uploads/fra-2015-surveillance-intelligence-services-summary-0_en.pdf>\\nACT NOW\\x0c20\\nANALYSIS\\nEuropean Data Protection Supervisor (EDPS) provides stringent guidance about demon-\\nstrating necessity and proportionality.48 By contrast, current deployments have largely\\nfailed to demonstrate these legal criteria.\\nThe prohibition of mass surveillance can be found across European case law, and is\\noften characterised by a lack of reasonable suspicion against the surveilled.49 Notably,\\nthe case of S. and Marper v UK at the European Court of Human Rights (ECtHR) found\\nthe “blanket and indiscriminate” retention of biometric data to be a “disproportionate\\ninterference” with the right to privacy, as it failed to satisfy the requirements of the ECHR\\nand could not be regarded to be “necessary in a democratic society”.50 Article 15 of the\\ne-Commerce Directive (2000/31/EC) recognises that the general monitoring of internet\\nusers is intrusive and unlawful.\\nThe ECtHR has held that measures such as covert surveillance for the purposes of de-\\ntecting or preventing crime, or the sharing of CCTV footage as in the case of Peck v UK,\\nfall within the ambit of Art. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 60, 'page': 19, '_split_overlap': [{'doc_id': 'd72faea58efde367da80fefde423cc0b', 'range': (0, 339)}, {'doc_id': '18bbd66b39513f96a2c3ae44b2428ef8', 'range': (983, 1186)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8d50489dd1ceee7dc57e71196505a531'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The ECtHR has held that measures such as covert surveillance for the purposes of de-\\ntecting or preventing crime, or the sharing of CCTV footage as in the case of Peck v UK,\\nfall within the ambit of Art. 8 of the Convention, which protects the right to private and\\nfamily life, and has underlined that restrictions imposed upon this right should not un-\\nacceptably weaken the protection afforded by this right.51 In the case of Digital Rights\\nIreland, for example, the Court of Justice of the European Union (CJEU) examined the\\ncompatibility of the Data Retention Directive 2006/24/EC with Arts. 7 and 8 of the Char-\\nter.52 It took particular note of the fact that the Directive:\\ncover[ed], in a generalised manner, all persons and all means of electronic\\ncommunication [...] without any differentiation, limitation or exception being\\nmade in the light of the objective of fighting against serious crime” (para 57).\\nThe Court noted that the measures were “likely to generate in the minds of the persons\\nconcerned the feeling that their private lives are the subject of constant surveillance”\\n(para 37). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 61, 'page': 20, '_split_overlap': [{'doc_id': '8d50489dd1ceee7dc57e71196505a531', 'range': (0, 203)}, {'doc_id': 'f5d7c58f4cd9eb2b4bcec3b19d98581e', 'range': (916, 1102)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '18bbd66b39513f96a2c3ae44b2428ef8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The Court noted that the measures were “likely to generate in the minds of the persons\\nconcerned the feeling that their private lives are the subject of constant surveillance”\\n(para 37). This applies a fortiori to mass surveillance over all manners of behaviour by\\nindividuals who are not linked to suspected crime or threats to public order in public\\nplaces. In Schrems I, the Court held that:53\\n48 EDPS, Guidelines on assessing the proportionality of measures that limit the fundamental rights to privacy and to the protection\\nof personal data (2019) <edps.europa.eu/sites/edp/files/publication/19-12-19_edps_proportionality_guidelines2_en.pdf. This\\ndraws on extensive case-law of the ECtHR and CJEU in which these principles were first developed. See Sunday Times (I)\\nand Handyside judgments, ECtHR.\\n49 For case law, see Digital Rights Ireland (2014) CJEU and Big Brother Watch and Others v the United Kingdom (2018) ECtHR. For\\nlack of reasonable suspicion, see Zakharov v Russia (2006) ECtHR.\\n50 ECtHR, S. and Marper v the United Kingdom (2008) para 125.\\n51 ECtHR, S. and Marper v the United Kingdom (2008) para 112; ECtHR; Christine Goodwin v the United Kingdom (2002); Peck v\\nUK (2003) ECtHR. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 62, 'page': 20, '_split_overlap': [{'doc_id': '18bbd66b39513f96a2c3ae44b2428ef8', 'range': (0, 186)}, {'doc_id': '8724eafd9822912924f75ffca1d09cc7', 'range': (1059, 1198)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f5d7c58f4cd9eb2b4bcec3b19d98581e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 51 ECtHR, S. and Marper v the United Kingdom (2008) para 112; ECtHR; Christine Goodwin v the United Kingdom (2002); Peck v\\nUK (2003) ECtHR. See also ECtHR Factsheet on mass surveillance <https://www.echr.coe.int/Documents/FS_Mass_surveil-\\nlance_ENG.pdf>\\n52 Joined Cases C-293/12 and C-594-12 Digital Rights Ireland Ltd v Minister for Communications, Marine and Natural Resources\\n& Others and Seitlinger and Others (2014) ECR I-238.\\n53 Case C-362/14, Schrems v Data Protection Commissioner (2015) E.C.R. 627.\\x0c21\\nANALYSIS\\nlegislation permitting public authorities to have access to the content of elec-\\ntronic communications on a generalized basis must be regarded as compro-\\nmising the essence of the fundamental right to respect for private life, as\\nguaranteed in Art. 7 of the Charter … (para 94)\\nSimilarly, mass surveillance of the (offline or online) activities – including political, artis-\\ntic or social activities – of large groups of people or even entire populations by means of\\nindiscriminate collection and further use of biometric data undoubtedly also “adversely\\naffects the essence” – the “untouchable core”54 – of rights to privacy, freedom of expres-\\nsion and association. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 63, 'page': 20, '_split_overlap': [{'doc_id': 'f5d7c58f4cd9eb2b4bcec3b19d98581e', 'range': (0, 139)}, {'doc_id': '9c115d4172d1134747547b7cf470eaf4', 'range': (769, 1187)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8724eafd9822912924f75ffca1d09cc7'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 7 of the Charter … (para 94)\\nSimilarly, mass surveillance of the (offline or online) activities – including political, artis-\\ntic or social activities – of large groups of people or even entire populations by means of\\nindiscriminate collection and further use of biometric data undoubtedly also “adversely\\naffects the essence” – the “untouchable core”54 – of rights to privacy, freedom of expres-\\nsion and association. This occurs irrespective of any link between the great majority of\\nthose surveilled and any crime or threat to public order, and must therefore always be\\nregarded as incompatible with the Charter. In other words, a measure allowing for con-\\nstant, real-time surveillance, especially involving the processing of sensitive, spe-\\ncial-category data such as facial biometric data, in a blanket or indiscriminate man-\\nner, would per se violate the essence of fundamental rights such as privacy, dignity,\\nfreedom of expression and freedom of association and would thus be incompatible\\nwith EU law.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 64, 'page': 21, '_split_overlap': [{'doc_id': '8724eafd9822912924f75ffca1d09cc7', 'range': (0, 418)}, {'doc_id': '20a16b02762fb152538eff7809d850c7', 'range': (616, 1010)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9c115d4172d1134747547b7cf470eaf4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: In other words, a measure allowing for con-\\nstant, real-time surveillance, especially involving the processing of sensitive, spe-\\ncial-category data such as facial biometric data, in a blanket or indiscriminate man-\\nner, would per se violate the essence of fundamental rights such as privacy, dignity,\\nfreedom of expression and freedom of association and would thus be incompatible\\nwith EU law.\\nUnder the Charter, Titles V (Citizens’ Rights) and VI (Justice) in particular establish a\\nrigorous framework for due process, proper procedure, and the rule of law which en-\\nsure that citizens have access to information about how their affairs are being handled\\n(Articles 41 and 42), access to an effective remedy and fair trials (Article 47) and the\\npresumption of innocence (Article 48). This is complemented by Article 20 on the right\\nto equality before the law.55 These criteria bring important safeguards to ensure people\\nare treated within a framework of democracy and justice; that states cannot arbitrarily\\nabuse their power; and that people have knowledge over how they are being treated. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 65, 'page': 21, '_split_overlap': [{'doc_id': '9c115d4172d1134747547b7cf470eaf4', 'range': (0, 394)}, {'doc_id': 'a1b5064bf615a835e5bcedfb206bea1f', 'range': (785, 1092)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '20a16b02762fb152538eff7809d850c7'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: This is complemented by Article 20 on the right\\nto equality before the law.55 These criteria bring important safeguards to ensure people\\nare treated within a framework of democracy and justice; that states cannot arbitrarily\\nabuse their power; and that people have knowledge over how they are being treated. The\\ncovert, remote and indiscriminate use of facial recognition and other biometric process-\\ning in public spaces, however, is a fundamental violation of these criteria as applied by\\nthe CJEU and the ECtHR.\\nIt treats everyone as a potential suspect in a perpetual line up, which is at\\nodds with freedoms and rights to live one’s life with dignity, privacy, liberty,\\nsecurity, and the presumption of innocence.\\n54 The concept of an “untouchable core” to all fundamental rights that may never be impinged upon, for any reason no matter\\nhow pressing or serious, was first developed in German constitutional law but is now recognised in international human\\nrights law, and expressly stipulated in Art. 52 of the Charter. See: Pierre Thielbörger, The “Essence” of International Human\\nRights, German Law Journal (2019), 20, 924–939, <https://www.researchgate.net/publication/335615595_The_Essence_of_\\nInternational_Human_Rights>\\n55 Schrems v Data Protection Commissioner, 2015 E.C.R. 627. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 66, 'page': 21, '_split_overlap': [{'doc_id': '20a16b02762fb152538eff7809d850c7', 'range': (0, 307)}, {'doc_id': '17705b2910ed9322dd7eda4cd64beb34', 'range': (1025, 1290)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a1b5064bf615a835e5bcedfb206bea1f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: See: Pierre Thielbörger, The “Essence” of International Human\\nRights, German Law Journal (2019), 20, 924–939, <https://www.researchgate.net/publication/335615595_The_Essence_of_\\nInternational_Human_Rights>\\n55 Schrems v Data Protection Commissioner, 2015 E.C.R. 627. In Digital Rights Ireland, the Court held that the “essence” of the\\nright to privacy was not affected because, while the Data Retention Directive required the retention of communication meta-\\ndata, it did not extend to the contents of the communications (para 39).\\x0c22\\nANALYSIS\\nThe fundamental rights-led approach in this paper demonstrates that mass surveillance\\nis never permissible in the EU under the Charter, and so by definition the use of bio-\\nmetric processing in public spaces that leads to mass surveillance is already unlawful.\\nBiometric processing is so intrinsically intrusive, and its functioning so conducive to of\\nmass surveillance, that it must be specifically and indefinitely banned. In order to per-\\nmanently stop this practice, responses by the EU must cover any actions or programmes\\nthat have the intention or effect of constituting or leading to mass surveillance, rather\\nthan specific technologies, which are liable to adaptation but will remain harmful as long\\nas they can be used for mass surveillance and, therefore, control. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 67, 'page': 21, '_split_overlap': [{'doc_id': 'a1b5064bf615a835e5bcedfb206bea1f', 'range': (0, 265)}, {'doc_id': 'b3955b2d9b66f5914947b4b5c04efa8f', 'range': (968, 1318)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '17705b2910ed9322dd7eda4cd64beb34'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: In order to per-\\nmanently stop this practice, responses by the EU must cover any actions or programmes\\nthat have the intention or effect of constituting or leading to mass surveillance, rather\\nthan specific technologies, which are liable to adaptation but will remain harmful as long\\nas they can be used for mass surveillance and, therefore, control. Mass surveillance by\\nits very nature is a fundamental breach of fundamental rights: it impinges on the very\\nessence of privacy, data protection and other rights. Any use of biometric processing\\nwhich interferes with the right to privacy without proper justification and thereby contrib-\\nutes to mass surveillance – even unintended – is within scope, regardless of whether the\\nuse is by law enforcement, public authorities, or commercial actors. The UK ICO notes\\nthat even for public policy purposes, most biometric technologies are developed and de-\\nployed through a combination of public and private actors.56\\n5.1.1 Biometrics and the right to dignity\\nBuilding on the fundamental rights implications described in Section 5.1, all EU funda-\\nmental rights are founded on the fundamental dignity of the person under Article 1 of the\\nCharter, which states that “Human dignity is inviolable. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 68, 'page': 22, '_split_overlap': [{'doc_id': '17705b2910ed9322dd7eda4cd64beb34', 'range': (0, 350)}, {'doc_id': 'ac0c4759b2d35b90b5b8dfca5480b40', 'range': (796, 1238)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b3955b2d9b66f5914947b4b5c04efa8f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The UK ICO notes\\nthat even for public policy purposes, most biometric technologies are developed and de-\\nployed through a combination of public and private actors.56\\n5.1.1 Biometrics and the right to dignity\\nBuilding on the fundamental rights implications described in Section 5.1, all EU funda-\\nmental rights are founded on the fundamental dignity of the person under Article 1 of the\\nCharter, which states that “Human dignity is inviolable. It must be respected and pro-\\ntected.” Other national and international human rights instruments are similarly cen-\\ntrally founded on universal and inalienable human dignity.57 ThiThis has led to dignity being\\nconsidered a “motherright.”58 The use of mass surveillance in public for recognising,\\nidentifying or detecting special categories of personal data, however, is fundamentally\\nin violation of the right to dignity, as it uses people’s own qualities, behaviours, emotions\\nor characteristics against them in ways that are not justified or proportionate in EU or\\nnational law. This leads to the unlawful and dignity-violating effects explored extensively\\nin chapter 2. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 69, 'page': 22, '_split_overlap': [{'doc_id': 'b3955b2d9b66f5914947b4b5c04efa8f', 'range': (0, 442)}, {'doc_id': 'fe56d40b68deb2eef1fe6e4df35bc28c', 'range': (443, 1115)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ac0c4759b2d35b90b5b8dfca5480b40'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: It must be respected and pro-\\ntected.” Other national and international human rights instruments are similarly cen-\\ntrally founded on universal and inalienable human dignity.57 ThiThis has led to dignity being\\nconsidered a “motherright.”58 The use of mass surveillance in public for recognising,\\nidentifying or detecting special categories of personal data, however, is fundamentally\\nin violation of the right to dignity, as it uses people’s own qualities, behaviours, emotions\\nor characteristics against them in ways that are not justified or proportionate in EU or\\nnational law. This leads to the unlawful and dignity-violating effects explored extensively\\nin chapter 2. As FRA describes, the use of facial recognition can violate dignity by making\\npeople avoid important places or events; through excessively forceful/coercive ways that\\ndata might be collected; and through “inappropriate police behaviour”, confirming that:59\\n“[T]he impact on what people may perceive as surveillance technologies on their lives\\nmay be so significant as to affect their capacity to live a dignified life.”\\n56 Information Commissioner’s Office, Statement on Live Facial Recognition Technology in King’s Cross (2019) <https://ico.org.\\nuk/about-the-ico/news-and-events/news-and-blogs/2019/08/statement-live-facial-recognition-technology-in-kings-cross/>\\n57 Cf. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 70, 'page': 22, '_split_overlap': [{'doc_id': 'ac0c4759b2d35b90b5b8dfca5480b40', 'range': (0, 672)}, {'doc_id': '69265a78c08a7e5e2d912d7f118c3d45', 'range': (673, 1344)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fe56d40b68deb2eef1fe6e4df35bc28c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: As FRA describes, the use of facial recognition can violate dignity by making\\npeople avoid important places or events; through excessively forceful/coercive ways that\\ndata might be collected; and through “inappropriate police behaviour”, confirming that:59\\n“[T]he impact on what people may perceive as surveillance technologies on their lives\\nmay be so significant as to affect their capacity to live a dignified life.”\\n56 Information Commissioner’s Office, Statement on Live Facial Recognition Technology in King’s Cross (2019) <https://ico.org.\\nuk/about-the-ico/news-and-events/news-and-blogs/2019/08/statement-live-facial-recognition-technology-in-kings-cross/>\\n57 Cf. the German constitutional (proto-)right of “[respect for the] human personality” (das allgemeine Persönlichkeitsrecht),\\nand the principle at the basis of the French data protection law of 1978 (retained in all subsequent laws and now granted\\nconstitutional status) that “Informatics must serve mankind.”\\n58 Barak, A.Human Dignity: The Constitutional Value and the Constitutional Right (2015) 156-169.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 71, 'page': 22, '_split_overlap': [{'doc_id': 'fe56d40b68deb2eef1fe6e4df35bc28c', 'range': (0, 671)}, {'doc_id': 'dcea8c1257725fecd11b2c8f3dedb2f2', 'range': (672, 1072)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '69265a78c08a7e5e2d912d7f118c3d45'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: the German constitutional (proto-)right of “[respect for the] human personality” (das allgemeine Persönlichkeitsrecht),\\nand the principle at the basis of the French data protection law of 1978 (retained in all subsequent laws and now granted\\nconstitutional status) that “Informatics must serve mankind.”\\n58 Barak, A.Human Dignity: The Constitutional Value and the Constitutional Right (2015) 156-169.\\n59 FRA, Facial recognition technology: fundamental rights considerations in the context of law enforcement (2019) 20 <https://\\nfra.europa.eu/sites/default/files/fra_uploads/fra-2019-facial-recognition-technology-focus-paper-1_en.pdf>\\x0c23\\nANALYSIS\\nThe European Data Protection Supervisor (EDPS) expands on this, explaining that the\\ncommodification and objectification of people’s faces, in particular by algorithms and for\\nthe benefit of private companies or state surveillance to be used against us at a mass\\nscale - all of which are inherent elements of facial recognition - are in and of themselves\\nan infringement of dignity.60 Coupled with the intimacy and intrusiveness of tracking peo-\\nple’s bodily characteristics, untargeted biometric processing in public spaces becomes\\nan inherently dignity-violating practice. Its potential to be used for mass surveillance\\nonly serves to add to its incompatibility with fundamental rights. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 72, 'page': 22, '_split_overlap': [{'doc_id': '69265a78c08a7e5e2d912d7f118c3d45', 'range': (0, 400)}, {'doc_id': '7f7e4b8add1a2c18af319434acc23c38', 'range': (401, 1334)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'dcea8c1257725fecd11b2c8f3dedb2f2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 59 FRA, Facial recognition technology: fundamental rights considerations in the context of law enforcement (2019) 20 <https://\\nfra.europa.eu/sites/default/files/fra_uploads/fra-2019-facial-recognition-technology-focus-paper-1_en.pdf>\\x0c23\\nANALYSIS\\nThe European Data Protection Supervisor (EDPS) expands on this, explaining that the\\ncommodification and objectification of people’s faces, in particular by algorithms and for\\nthe benefit of private companies or state surveillance to be used against us at a mass\\nscale - all of which are inherent elements of facial recognition - are in and of themselves\\nan infringement of dignity.60 Coupled with the intimacy and intrusiveness of tracking peo-\\nple’s bodily characteristics, untargeted biometric processing in public spaces becomes\\nan inherently dignity-violating practice. Its potential to be used for mass surveillance\\nonly serves to add to its incompatibility with fundamental rights. Lastly, as the right to\\ndignity is inviolable, even when EU Member States take measures based on national\\nsecurity or to counter a public emergency, they must still always refrain from violations\\nof dignity. Dignity thus forms a fundamental underpinning for the call for a ban on bio-\\nmetric mass surveillance.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 73, 'page': 22, '_split_overlap': [{'doc_id': 'dcea8c1257725fecd11b2c8f3dedb2f2', 'range': (0, 933)}, {'doc_id': '414645426d53e22f2263f27ec736bce2', 'range': (934, 1244)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7f7e4b8add1a2c18af319434acc23c38'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Lastly, as the right to\\ndignity is inviolable, even when EU Member States take measures based on national\\nsecurity or to counter a public emergency, they must still always refrain from violations\\nof dignity. Dignity thus forms a fundamental underpinning for the call for a ban on bio-\\nmetric mass surveillance.\\n5.2 Data Protection Law\\nThe GDPR sets out rules for the processing of personal data, and applies to the pro-\\ncessing of all personal data other than for law enforcement purposes (which is covered\\nby the LED). Under Article 9(1), the processing of biometric data, as well as data that\\nreveals other protected characteristics, is in principle prohibited due to the sensitivity of\\nsuch data. Legitimate exceptions are made possible – for example on the basis of con-\\nsent (Article 7) – although the deployment of mass monitoring in public spaces, which\\nare an essential part of public life, fundamentally precludes the ability for people to give\\ngenuine, informed, freely-given consent, thereby violating their rights to data protection.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 74, 'page': 23, '_split_overlap': [{'doc_id': '7f7e4b8add1a2c18af319434acc23c38', 'range': (0, 310)}, {'doc_id': '5e8f65a9604acf8d0b8f309c9478d5c2', 'range': (700, 1045)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '414645426d53e22f2263f27ec736bce2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Legitimate exceptions are made possible – for example on the basis of con-\\nsent (Article 7) – although the deployment of mass monitoring in public spaces, which\\nare an essential part of public life, fundamentally precludes the ability for people to give\\ngenuine, informed, freely-given consent, thereby violating their rights to data protection.\\nAs the example of Ampère School, Marseille, will demonstrate (Section 6.1), current\\ndeployments of biometric processing in public spaces have not adhered to the lawful\\nbasis requirement in Article 5 of the GDPR, and other examples have fundamentally con-\\ntravenedthe GDPR’s Art. 5 requirements including for data minimisation, meaning that\\ndata collected should be limited to what is necessary for clearly-defined and expressly\\nspecified legitimate purposes; purpose limitation; data quality requirements prohibiting\\nthe use of personal information that is insufficiently accurate; transparency, and the bur-\\nden on the data controller to prove that they meet these requirements. Article 22 of the\\nGDPR furthermore prohibits fully-automated decisions based upon, among other types,\\nbiometric data.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 75, 'page': 23, '_split_overlap': [{'doc_id': '414645426d53e22f2263f27ec736bce2', 'range': (0, 345)}, {'doc_id': '76a4ea2ca8864c86d2ae77741bae5792', 'range': (625, 1143)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5e8f65a9604acf8d0b8f309c9478d5c2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 5 requirements including for data minimisation, meaning that\\ndata collected should be limited to what is necessary for clearly-defined and expressly\\nspecified legitimate purposes; purpose limitation; data quality requirements prohibiting\\nthe use of personal information that is insufficiently accurate; transparency, and the bur-\\nden on the data controller to prove that they meet these requirements. Article 22 of the\\nGDPR furthermore prohibits fully-automated decisions based upon, among other types,\\nbiometric data.\\nThe LED sets out the rules for the processing of personal data by “competent authori-\\nties”, most frequently (but not exclusively) law enforcement authorities in criminal pro-\\ncedures, when undertaken strictly for law enforcement purposes (such as the preven-\\n60 Wojciech Wiewiórowski, Facial recognition: A solution in search of a problem? (2019) <https://edps.europa.eu/press-publi-\\ncations/press-news/blog/facial-recognition-solution-search-problem_en>\\x0c24\\nANALYSIS\\ntion, detection or prosecution of criminal offences). It was adopted at the same time as\\nthe GDPR as part of a combined package and is its sister instrument, based on the same\\nprinciples. It too emphasises that ‘[t]he protection of natural persons in relation to the\\nprocessing of personal data is a fundamental right”.61\\nThe LED reiterates that even for law enforcement purposes, data must be processed\\n“lawfully and fairly” (Art 4(1)(a)). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 76, 'page': 23, '_split_overlap': [{'doc_id': '5e8f65a9604acf8d0b8f309c9478d5c2', 'range': (0, 518)}, {'doc_id': '3223cdf5f9d038971630983794fad80f', 'range': (1175, 1427)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '76a4ea2ca8864c86d2ae77741bae5792'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: It too emphasises that ‘[t]he protection of natural persons in relation to the\\nprocessing of personal data is a fundamental right”.61\\nThe LED reiterates that even for law enforcement purposes, data must be processed\\n“lawfully and fairly” (Art 4(1)(a)). The LED additionally sets out distinctions between the\\ntreatment of criminal convicts or suspects (in which case law enforcement must have\\n“serious grounds for believing that they have committed or are about to commit a criminal\\noffence”) (Article 6(a)) compared to those who are not convicted or suspected of criminal\\nactivity. This distinction is important, because it demonstrates a difference between\\nthe legitimate and lawful targeting of a genuine suspect (subject to the suspicions\\nmeeting the LED’s threshold for “serious grounds”) and the illegitimate, indiscrimi-\\nnate targeting of the general public inherent to untargeted biometric processing.\\nAs in the GDPR, the processing of data for law enforcement purposes must meet strict\\ncriteria. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 77, 'page': 24, '_split_overlap': [{'doc_id': '76a4ea2ca8864c86d2ae77741bae5792', 'range': (0, 252)}, {'doc_id': 'dfbdc3b0c86e4a366e5878e0665a8d4c', 'range': (582, 1003)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3223cdf5f9d038971630983794fad80f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: This distinction is important, because it demonstrates a difference between\\nthe legitimate and lawful targeting of a genuine suspect (subject to the suspicions\\nmeeting the LED’s threshold for “serious grounds”) and the illegitimate, indiscrimi-\\nnate targeting of the general public inherent to untargeted biometric processing.\\nAs in the GDPR, the processing of data for law enforcement purposes must meet strict\\ncriteria. Under the LED, such processing must be necessary (Article 8(1)), will have spe-\\ncial requirements for sensitive – including biometric - data (Article 10), and must adhere\\nto a long list of requirements for safeguards, due process/good administration, the right\\nto information and “data protection by design and default” (Article 20(1)). Unlike in the\\nGDPR, consent is not a legal basis. Working Party 29 adds that data processing for law\\nenforcement must meet the high criteria of “strict necessity.”62\\nWhilst some uses of biometric processing are clearly within the remit of the GDPR (for\\nexample queue management in shops, local authority activities such as in schooling)\\nand others within the LED (judiciary, police law and order activities), the overlapping\\nsubject matter of the laws makes some scenarios ambiguous. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 78, 'page': 24, '_split_overlap': [{'doc_id': '3223cdf5f9d038971630983794fad80f', 'range': (0, 421)}, {'doc_id': 'aff0529e730310950e9cec9e87599434', 'range': (809, 1242)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'dfbdc3b0c86e4a366e5878e0665a8d4c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Working Party 29 adds that data processing for law\\nenforcement must meet the high criteria of “strict necessity.”62\\nWhilst some uses of biometric processing are clearly within the remit of the GDPR (for\\nexample queue management in shops, local authority activities such as in schooling)\\nand others within the LED (judiciary, police law and order activities), the overlapping\\nsubject matter of the laws makes some scenarios ambiguous. For example, the follow-\\ning scenarios are unclear: a police database containing details of criminals, victims and\\nwitnesses; or police using a watchlist at a football game to identify known criminals – but\\nin doing so, capture members of the crowd, which under the GDPR requires consent. For\\nthese reasons, some Member States have introduced combined national laws. For the\\npurpose of this paper, the essential issues of biometric processing leading to unlawful\\nmass surveillance, unjustified infringement of data protection rules, and a violation of\\ndignity remain unchanged whether the GDPR or LED applies to the case of a specific\\ndeployment of the technology. Regardless, such legal grey areas demonstrate the ur-\\ngent need for more interpretation of the laws by courts and data protection bodies and\\nauthorities.\\n61 Cf. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 79, 'page': 24, '_split_overlap': [{'doc_id': 'dfbdc3b0c86e4a366e5878e0665a8d4c', 'range': (0, 433)}, {'doc_id': '4d668bc10e8f4c31c1eacf41840c0b1f', 'range': (1099, 1259)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'aff0529e730310950e9cec9e87599434'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Regardless, such legal grey areas demonstrate the ur-\\ngent need for more interpretation of the laws by courts and data protection bodies and\\nauthorities.\\n61 Cf. the German constitutional (proto-)right of “[respect for the] human personality” (dass allgemeine Persönlichkeitsrecht),\\nand the principle at the basis of the French data protection law of 1978 (retained in all subsequent laws and now granted\\nconstitutional status) that “Informatics must serve mankind.”\\n62 European Commission, Opinion on some key issues of the Law Enforcement Directive (2017) 7-8 <https://ec.europa.eu/\\nnewsroom/article29/item-detail.cfm?item_id=610178>\\x0c25\\nANALYSIS\\nSuch issues are further complicated by the growing role of private actors in law en-\\nforcement data processing, for example as a result of outsourcing or the provision of\\ncomplicated technologies over which law enforcement officers may not have sufficient\\ntechnical expertise. It is questionable whether such actors are in a position to comply\\nwith the LED or even the strict “explicit consent requirements” contained also in the\\nGDPR, as well as strict confidentiality, security, safeguarding and prevention of abuse\\nrequirements.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 80, 'page': 24, '_split_overlap': [{'doc_id': 'aff0529e730310950e9cec9e87599434', 'range': (0, 160)}, {'doc_id': 'bccf20f2a653e755b9ce8592ebc48126', 'range': (924, 1178)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4d668bc10e8f4c31c1eacf41840c0b1f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: It is questionable whether such actors are in a position to comply\\nwith the LED or even the strict “explicit consent requirements” contained also in the\\nGDPR, as well as strict confidentiality, security, safeguarding and prevention of abuse\\nrequirements.\\nActivities undertaken on national security grounds – which are the competence of nation-\\nal intelligence bodies, not law enforcement agencies – are not covered within the data\\nprotection rules under the LED.63 Yet FRA highlights that even when it comes to national\\nsecurity issues “the mere fact that a decision concerns state security does not render\\nEU law inapplicable […] The ‘national security’ exception thus cannot be seen as entirely\\nexcluding the applicability of EU law.”64 Any processing undertaken on the basis of law\\nenforcement (i.e. criminal matters) remains distinct from national security exemptions\\n– which, FRA emphasises, are still subject to fundamental rights. By contrast, “public\\nsecurity” measures for law enforcement are considered within scope under Article (1(1))\\nof the LED. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 81, 'page': 25, '_split_overlap': [{'doc_id': '4d668bc10e8f4c31c1eacf41840c0b1f', 'range': (0, 254)}, {'doc_id': 'b40b8efb659573ae7bd46e28397eb833', 'range': (803, 1058)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bccf20f2a653e755b9ce8592ebc48126'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: criminal matters) remains distinct from national security exemptions\\n– which, FRA emphasises, are still subject to fundamental rights. By contrast, “public\\nsecurity” measures for law enforcement are considered within scope under Article (1(1))\\nof the LED. FRA clarifies this point, emphasising that “[a]n objective of general interest\\n- such as crime prevention or public security – is not, in itself, sufficient to justify an in-\\nterference” with fundamental rights, meaning the LED’s data protections must apply.65\\nThere is both an urgent requirement, and a great opportunity, for better enforcement\\nand clearer interpretation (including through litigation) of the GDPR and the LED, and of\\nthe interrelations between them, such as in relation to the transfer of data from private\\nentities to law enforcement agencies (and the further transfer or making accessible of\\nsuch data to national security agencies),66 in regards to protecting biometric and related\\nsensitive data or closing loopholes that have been exploited. The adoption of the GDPR\\nwas welcomed by European civil society, but its implementation has not been consistent\\nacross the EU, giving Member States discretion over how to deal with certain violations.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 82, 'page': 25, '_split_overlap': [{'doc_id': 'bccf20f2a653e755b9ce8592ebc48126', 'range': (0, 255)}, {'doc_id': '2dea63dde010462e9dba270980d65457', 'range': (1022, 1222)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b40b8efb659573ae7bd46e28397eb833'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The adoption of the GDPR\\nwas welcomed by European civil society, but its implementation has not been consistent\\nacross the EU, giving Member States discretion over how to deal with certain violations.\\n63 Actions relating to “public security” and “law enforcement” (subject to EU law) versus “national security” (outside EU law)\\nare increasingly interlinked. See Douwe Korff and Marie Georges, The DPO handbook (2019) section 1.4.3 <http://www.\\nfondazionebasso.it/2015/wp-content/uploads/2019/07/T4DATA-MANUAL-2019.pdf > in particular “Scope of the LEDPD” (pp.\\n59 – 63) and section 1.4.6, 89ff, Transmission of personal data between different EU data protection regimes (which clarifies\\nthat transfers of personal data from entities subject to the GDPR to national security agencies of the Member States are\\nsubject to the GDPR, even if the actions of the receiving agencies are not subject to EU law, including the Charter). On rule\\nof law requirements relating to national security activities generally, see the CoE Commissioner for Human Rights, Issue\\nPaper on The Rule of Law on the Internet and in the wider digital environment (2014) section 4.6, 107 – 110 <https://rm.coe.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 83, 'page': 25, '_split_overlap': [{'doc_id': 'b40b8efb659573ae7bd46e28397eb833', 'range': (0, 200)}, {'doc_id': 'fde1fa08fe76f0ef3a9b9bc574c201b4', 'range': (925, 1178)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2dea63dde010462e9dba270980d65457'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: On rule\\nof law requirements relating to national security activities generally, see the CoE Commissioner for Human Rights, Issue\\nPaper on The Rule of Law on the Internet and in the wider digital environment (2014) section 4.6, 107 – 110 <https://rm.coe.\\nint/ref/CommDH/IssuePaper(2014)1>\\n64 Fundamental Rights Agency, Surveillance by intelligence services: fundamental rights safeguards and remedies in the\\nEU, Volume I: Member States’ legal frameworks (2015) <https://fra.europa.eu/en/publication/2015/surveillance-intelli-\\ngence-services-volume-i-member-states-legal-frameworks?_cldee=ZG5AZGllZ29uYXJhbmpvLmV1&urlid=1>\\n65 Fundamental Rights Agency, Facial recognition technology: fundamental rights considerations in the context of law enforce-\\nment (2019) <https://fra.europa.eu/sites/default/files/fra_uploads/fra-2019-facial-recognition-technology-focus-paper-1_\\nen.pdf>\\n66 See Douwe Korff and Marie Georges, o.c. (footnote 62), section 1.4.6.\\x0c26\\nANALYSIS\\nNational data protection authorities (DPAs) have been inadequately resourced and po-\\nlitically disempowered by their Member States, meaning that their efforts to enforce the\\nGDPR and LED have suffered, and actors in violation of the law have faced few incentives\\nto comply. Ensuring that DPAs and other oversight bodies have specific privacy and bio-\\nmetric data expertise will further strengthen their ability to protect fundamental rights\\nfrom biometric mass surveillance.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 84, 'page': 25, '_split_overlap': [{'doc_id': '2dea63dde010462e9dba270980d65457', 'range': (0, 253)}, {'doc_id': '9de715546801f2ab1d76f8af9d18687c', 'range': (1235, 1435)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fde1fa08fe76f0ef3a9b9bc574c201b4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Ensuring that DPAs and other oversight bodies have specific privacy and bio-\\nmetric data expertise will further strengthen their ability to protect fundamental rights\\nfrom biometric mass surveillance.\\nIn sum, any biometric processing is seriously problematic because of the challenges that\\nit poses to requirements for necessity, proportionality and the difficulty of demonstrating\\ncompliance with data protection law; as well as the inherent violation of dignity through\\nthe objectification of existential characteristics. However, once the possibility of untar-\\ngeted (mass) processing in public spaces is added, such processing becomes near im-\\npossible to justify according to its stated purpose, and therefore becomes impermissible\\non data protection grounds.\\n5.3 Defining “Recognition”: Identification, Detection and Processing\\nUnder the GDPR, the processing of special categories of personal data including “for\\nthe purpose of uniquely identifying a natural person” is prohibited (except when explicitly\\nallowed for under certain circumstances) (Art. 9(1)). Under Art. 10 of the LED, this is ad-\\nditionally only allowed when “strictly necessary”. The terms “facial recognition” and “bio-\\nmetric recognition” are popular - but often imprecise - ways to describe a wide range of\\nspecial category data processing activities.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 85, 'page': 26, '_split_overlap': [{'doc_id': 'fde1fa08fe76f0ef3a9b9bc574c201b4', 'range': (0, 200)}, {'doc_id': '95b65c4424f168188be8f6a193d5dc91', 'range': (1154, 1328)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9de715546801f2ab1d76f8af9d18687c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The terms “facial recognition” and “bio-\\nmetric recognition” are popular - but often imprecise - ways to describe a wide range of\\nspecial category data processing activities.\\nThe European Data Protection Board (EDPB) have confirmed that “identification” does\\nnot need to reveal someone’s official name or identity, but includes any processing that\\nmakes it possible to distinguish one person from others,67 which can be equally intru-\\nsive. This means that not only identification but also detection of appearance, inferred\\nbehaviour, predicted emotions or other personal characteristics are all within the scope\\nof biometric processing as defined in the GDPR and if used in purposes that lead to mass\\nsurveillance, are within the scope of this paper.\\nThe transient local analysis of user data (as opposed to transferring data to a central\\nserver) will not exempt uses of biometric recognition from being considered “process-\\ning”. Nor will refraining from tracking users as they move from one camera to anoth-\\ner exempt applications from being considered “identification”. Both of these examples\\nwould remain within the relevant data processing obligations under the GDPR or LED.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 86, 'page': 26, '_split_overlap': [{'doc_id': '9de715546801f2ab1d76f8af9d18687c', 'range': (0, 174)}, {'doc_id': '51ce84a158582dcedda7dbea49de4b68', 'range': (932, 1180)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '95b65c4424f168188be8f6a193d5dc91'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Nor will refraining from tracking users as they move from one camera to anoth-\\ner exempt applications from being considered “identification”. Both of these examples\\nwould remain within the relevant data processing obligations under the GDPR or LED.\\nFor these reasons, this analysis has not distinguished between recognition, identification\\nor detection and has considered them all within the broader remit of processing.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 87, 'page': 26, '_split_overlap': [{'doc_id': '95b65c4424f168188be8f6a193d5dc91', 'range': (0, 248)}, {'doc_id': '41374f3ad53544106bb1de0c8a38c1c5', 'range': (249, 420)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '51ce84a158582dcedda7dbea49de4b68'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: For these reasons, this analysis has not distinguished between recognition, identification\\nor detection and has considered them all within the broader remit of processing.\\n67 EDPB, Guidelines 3/2019 on processing of personal data through video devices (2019) 16 <https://edpb.europa.eu/sites/edpb/\\nfiles/consultation/edpb_guidelines_201903_videosurveillance.pdf>\\x0c27\\nANALYSIS\\n5.4 Comprehensive analysis of existing biometric systems\\nFRA have expressed that, with the exception of a small number of the Member States re-\\nsearched, “[o]nly limited information is currently available on the possible use or tests of\\nlive facial recognition technologies in other EU Member States”.68 Considering the EU’s\\nresponsibility to uphold fundamental rights, and the lack of evidence that deployments of\\nbiometric processing for mass surveillance are necessary, proportionate, or compliant\\nwith legal safeguards (such as Data Protection Impact Assessments), there is a clear\\nneed for greater public transparency of and accountability on the actors - whether pub-\\nlic, private or a collaboration between the two - who are deploying biometric processing\\nin public, as well as data exchanges between law enforcement, border security, other\\npublic security agencies (including health) and national security agencies. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 88, 'page': 26, '_split_overlap': [{'doc_id': '51ce84a158582dcedda7dbea49de4b68', 'range': (0, 171)}, {'doc_id': 'a88d5aa9ab48192563325f5b63ed680a', 'range': (172, 1298)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '41374f3ad53544106bb1de0c8a38c1c5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 67 EDPB, Guidelines 3/2019 on processing of personal data through video devices (2019) 16 <https://edpb.europa.eu/sites/edpb/\\nfiles/consultation/edpb_guidelines_201903_videosurveillance.pdf>\\x0c27\\nANALYSIS\\n5.4 Comprehensive analysis of existing biometric systems\\nFRA have expressed that, with the exception of a small number of the Member States re-\\nsearched, “[o]nly limited information is currently available on the possible use or tests of\\nlive facial recognition technologies in other EU Member States”.68 Considering the EU’s\\nresponsibility to uphold fundamental rights, and the lack of evidence that deployments of\\nbiometric processing for mass surveillance are necessary, proportionate, or compliant\\nwith legal safeguards (such as Data Protection Impact Assessments), there is a clear\\nneed for greater public transparency of and accountability on the actors - whether pub-\\nlic, private or a collaboration between the two - who are deploying biometric processing\\nin public, as well as data exchanges between law enforcement, border security, other\\npublic security agencies (including health) and national security agencies. The example\\nof Police Scotland demonstrates that it is both possible and advisable for law enforce-\\nment bodies to proactively respond to, and take steps to avoid, the fundamental rights\\nissues raised by facial recognition.69\\nFRA, national data protection authorities (DPAs), civil society and the general public will\\nall benefit from greater knowledge of biometric surveillance measures that are being\\ntaken in public spaces, in order to challenge the uses that violate fundamental rights.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 89, 'page': 26, '_split_overlap': [{'doc_id': '41374f3ad53544106bb1de0c8a38c1c5', 'range': (0, 1126)}, {'doc_id': '60a7142a24afb48a126d0d6fcfa25536', 'range': (1127, 1617)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a88d5aa9ab48192563325f5b63ed680a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The example\\nof Police Scotland demonstrates that it is both possible and advisable for law enforce-\\nment bodies to proactively respond to, and take steps to avoid, the fundamental rights\\nissues raised by facial recognition.69\\nFRA, national data protection authorities (DPAs), civil society and the general public will\\nall benefit from greater knowledge of biometric surveillance measures that are being\\ntaken in public spaces, in order to challenge the uses that violate fundamental rights.\\nThe burden must remain on the actors developing and deploying the technology to pro-\\nvide information about what they are doing to ensure that it complies with rights to infor-\\nmation, procedural rights and all other fundamental rights and freedoms, too. The Euro-\\npean Commission must ensure that a comprehensive study on the deployments, trials,\\nand future planned deployments, motivations, legal bases, fundamental rights implica-\\ntions, involved actors and legal safeguards is undertaken for all biometric processing.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 90, 'page': 27, '_split_overlap': [{'doc_id': 'a88d5aa9ab48192563325f5b63ed680a', 'range': (0, 490)}, {'doc_id': '11fb074cdb106a25e3f9f41b42eb3b17', 'range': (746, 1012)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '60a7142a24afb48a126d0d6fcfa25536'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The Euro-\\npean Commission must ensure that a comprehensive study on the deployments, trials,\\nand future planned deployments, motivations, legal bases, fundamental rights implica-\\ntions, involved actors and legal safeguards is undertaken for all biometric processing.\\nSince the existence of what Statewatch has called the “EU security-industrial complex”70\\nmay lead (as suggested in the case of PNR systems71) to the promotion, defense and (ab)\\nuse of “securitisation” technologies, from CCTV cameras to “lie detectors” for refugees,\\nwe need to understand as a society who it is that develops these technologies and who\\nbenefits from doing so, at the expense of our rights and freedoms.\\n68 Fundamental Rights Agency, Facial recognition technology:fundamental rights considerations in the context of law enforcement\\n(2019) <https://fra.europa.eu/sites/default/files/fra_uploads/fra-2019-facial-recognition-technology-focus-paper-1_en.pdf>\\n69 Following the release of Police Scotland’s 2026 strategy, the Justice Sub-Comittee on Policing pressed the police in 2020\\nto confirm (a) they had no intention of rolling out facial recognition and (b) they agreed that they could not roll it out at this\\nstage; Police Scotland agreed. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 91, 'page': 27, '_split_overlap': [{'doc_id': '60a7142a24afb48a126d0d6fcfa25536', 'range': (0, 266)}, {'doc_id': 'f528e439fd1052556ae7402d6c8bfa4c', 'range': (686, 1223)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '11fb074cdb106a25e3f9f41b42eb3b17'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 68 Fundamental Rights Agency, Facial recognition technology:fundamental rights considerations in the context of law enforcement\\n(2019) <https://fra.europa.eu/sites/default/files/fra_uploads/fra-2019-facial-recognition-technology-focus-paper-1_en.pdf>\\n69 Following the release of Police Scotland’s 2026 strategy, the Justice Sub-Comittee on Policing pressed the police in 2020\\nto confirm (a) they had no intention of rolling out facial recognition and (b) they agreed that they could not roll it out at this\\nstage; Police Scotland agreed. See <https://sp-bpr-en-prod-cdnep.azureedge.net/published/JSP/2020/2/11/Facial-recog-\\nnition--how-policing-in-Scotland-makes-use-of-this-technology/JSPS0520R01.pdf> and <https://www.parliament.scot/\\nS5_JusticeSubCommitteeOnPolicing/Inquiries/20200410_PstoJF_Facial_Recognitio....pdf>\\n70 Statewatch, Market Forces: the development of the EU security-industrial complex (2017) <http://www.statewatch.org/market-\\nforces/index.htm>\\n71 EURACTIV, The curious tale of the French prime minister, PNR and peculiar patterns 2016, <https://www.euractiv.com/section/\\njustice-home-affairs/opinion/checked-for-tuesthe-curious-tale-of-the-french-prime-minister-pnr-and-peculiar-patterns/>\\x0c28\\nANALYSIS\\nIn addition, DPAs in each member state could review if law enforcement authorities are\\nusing technologies in accordance with existing laws – with a particular emphasis on mea-\\nsures taken for supposedly “public security” purposes, which should be reviewed in light\\nof the requirement of strict necessity (Article 10) - and clarify the role of the LED. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 92, 'page': 27, '_split_overlap': [{'doc_id': '11fb074cdb106a25e3f9f41b42eb3b17', 'range': (0, 537)}, {'doc_id': '66ec8f60a87bdf15974cddfef1aefb62', 'range': (538, 1575)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f528e439fd1052556ae7402d6c8bfa4c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: See <https://sp-bpr-en-prod-cdnep.azureedge.net/published/JSP/2020/2/11/Facial-recog-\\nnition--how-policing-in-Scotland-makes-use-of-this-technology/JSPS0520R01.pdf> and <https://www.parliament.scot/\\nS5_JusticeSubCommitteeOnPolicing/Inquiries/20200410_PstoJF_Facial_Recognitio....pdf>\\n70 Statewatch, Market Forces: the development of the EU security-industrial complex (2017) <http://www.statewatch.org/market-\\nforces/index.htm>\\n71 EURACTIV, The curious tale of the French prime minister, PNR and peculiar patterns 2016, <https://www.euractiv.com/section/\\njustice-home-affairs/opinion/checked-for-tuesthe-curious-tale-of-the-french-prime-minister-pnr-and-peculiar-patterns/>\\x0c28\\nANALYSIS\\nIn addition, DPAs in each member state could review if law enforcement authorities are\\nusing technologies in accordance with existing laws – with a particular emphasis on mea-\\nsures taken for supposedly “public security” purposes, which should be reviewed in light\\nof the requirement of strict necessity (Article 10) - and clarify the role of the LED. The\\ninclusion in the LED of a provision similar to Article 9(2)(g) of the GDPR – or simply the\\nreading of the LED in that way by Courts and/or DPAs – would ensure that “substantial\\npublic interest” exclusions are not exploited as a loophole to justify uses of biometric pro-\\ncessing which are otherwise unlawful.\\n5.5 Biometric processing outside the scope of a ban\\nEU law demands high ex ante standards for biometric processing. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 93, 'page': 27, '_split_overlap': [{'doc_id': 'f528e439fd1052556ae7402d6c8bfa4c', 'range': (0, 1037)}, {'doc_id': '6bef355526fda2c24cd22331050d536e', 'range': (1038, 1466)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '66ec8f60a87bdf15974cddfef1aefb62'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The\\ninclusion in the LED of a provision similar to Article 9(2)(g) of the GDPR – or simply the\\nreading of the LED in that way by Courts and/or DPAs – would ensure that “substantial\\npublic interest” exclusions are not exploited as a loophole to justify uses of biometric pro-\\ncessing which are otherwise unlawful.\\n5.5 Biometric processing outside the scope of a ban\\nEU law demands high ex ante standards for biometric processing. The European Data\\nProtection Supervisor (EDPS) emphasises that necessity and proportionality are “an es-\\nsential dual requirement with which any proposed measure that involves processing of\\npersonal data must comply.”72 In the case of using biometric data which contributes to\\nmass surveillance, our analysis has demonstrated that these criteria cannot be satisfied\\nbecause this impinges on the “essence” of fundamental rights protected by the Char-\\nter, in violation of Article 52(1). Such use is therefore inherently unlawful and should\\nbe banned, regardless of any arguments for any specific deployment in practice. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 94, 'page': 28, '_split_overlap': [{'doc_id': '66ec8f60a87bdf15974cddfef1aefb62', 'range': (0, 428)}, {'doc_id': 'ef9a9566e9582fb2db30bf55c4f85fbc', 'range': (915, 1047)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6bef355526fda2c24cd22331050d536e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Such use is therefore inherently unlawful and should\\nbe banned, regardless of any arguments for any specific deployment in practice. Whilst\\nincreased accuracy will not increase the safety of biometric surveillance technologies,\\ncurrent issues around a lack of accuracy are nevertheless significant problems for public\\nauthorities or law enforcement looking to justify the necessity of the applications. At this\\nstage, the necessity of a public use cannot be justified in the context of pilot deployments\\nproving to have extremely high error rates.73\\nFor uses that do not have the potential to be used for mass surveillance, every single de-\\nployment will nevertheless have to be subject to stringent ex ante rules (such as DPIAs,\\nwhich in the case of mass biometric processing are required under the GDPR and the\\nLED – see footnote 30) and requirements for ex post safeguards, and the entire develop-\\nment lifecycle must be compliant with all EU laws. This means that many non-mass sur-\\nveillance uses of biometric data, such as the use of such data for targeted surveillance,\\nindividual, consensual authentication, protection of public health, or commercial uses\\nmay still be unlawful. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 95, 'page': 28, '_split_overlap': [{'doc_id': '6bef355526fda2c24cd22331050d536e', 'range': (0, 132)}, {'doc_id': 'c6fee7b876f2fc0231f88c33e80cd847', 'range': (952, 1186)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ef9a9566e9582fb2db30bf55c4f85fbc'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: This means that many non-mass sur-\\nveillance uses of biometric data, such as the use of such data for targeted surveillance,\\nindividual, consensual authentication, protection of public health, or commercial uses\\nmay still be unlawful. The following example details the level of due diligence that must\\nbe taken on a case-by-case basis for biometric processing. Any use that cannot meet\\nevery step will be illegal.\\n72 EDPS, Guidelines on assessing the proportionality of measures that limit the fundamental rights to privacy and to the protection of\\npersonal data (2019) 3 <edps.europa.eu/sites/edp/files/publication/19-12-19_edps_proportionality_guidelines2_en.pdf>\\n73 The Guardian, UK police use of facial recognition technology a failure, says report (2018) <https://www.theguardian.com/uk-\\nnews/2018/may/15/uk-police-use-of-facial-recognition-technology-failure>\\x0c29\\nLaw enforcement processing: demonstrating a “case by case” approach\\nWhen used by public authorities, for example in law enforcement, biometric technology without the potential\\nto contribute to mass surveillance will still have to go through four cumulative steps of safeguards. First and\\nforemost, human rights law requires that measures that interfere with fundamental rights be limited to what\\nis strictly necessary and proportionate to the aim sought under Art. 52 of the Charter; this test provides a way\\nto assess if a technology may ever, under law, be used. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 96, 'page': 28, '_split_overlap': [{'doc_id': 'ef9a9566e9582fb2db30bf55c4f85fbc', 'range': (0, 234)}, {'doc_id': '5d2ce2b4e22046f558c58c15accfb06c', 'range': (1334, 1433)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c6fee7b876f2fc0231f88c33e80cd847'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 52 of the Charter; this test provides a way\\nto assess if a technology may ever, under law, be used. Secondly, legislative frameworks governing the use of\\nbiometric processing must satisfy legality or “in accordance with the law” requirements.74 This means that the\\nrules governing the deployment of the biometric data must satisfy strict accessibility, foreseeability and quality\\nof the law requirements.\\nAs a result, any authorisation and deployment of biometric processing must be explicitly prescribed by law\\nand limited to cases that are strictly and demonstrably necessary to achieve a legitimate aim. That law must\\nbe accessible to the public and sufficiently clear and precise to enable persons to foresee its application and\\nthe extent of the interference. Among others, the law needs to provide for clear rules governing the retention,\\naccess to, amounts75 and destruction of personal data obtained during the deployment of biometric processing\\nthat do not belong to the target(s) under investigation.\\nThird, the use of biometric processing for law enforcement must also be accompanied by safeguards in order to\\nprevent abuse of this intrusive power. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 97, 'page': 29, '_split_overlap': [{'doc_id': 'c6fee7b876f2fc0231f88c33e80cd847', 'range': (0, 99)}, {'doc_id': 'dc45230f26cfd4d12e8be23ccece17d4', 'range': (1011, 1159)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5d2ce2b4e22046f558c58c15accfb06c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Third, the use of biometric processing for law enforcement must also be accompanied by safeguards in order to\\nprevent abuse of this intrusive power. This at the very minimum includes transparency on criteria for inclusion\\non a watchlist;76 the existence of individualised reasonable suspicion of involvement in a serious crime or threat\\nthat would justify deploying this technology;77 prior Data Protection Impact Assessments (DPIAs) (LED recital\\n58) as well as prior consultation with relevant supervisory authorities (recital 28);78 for individuals to be ade-\\nquately notified of the processing of their biometric data and be given the opportunity to exercise their rights,\\nespecially of rectification, access, erasure, and to challenge processing operations by complaining before\\ncourts and regulators; and independent judicial or administrative authorisation and oversight to ensure rights\\nincluding to legal remedy. It is crucial that even individuals whose biometric data are captured but against\\nwhom a case is not pursued (for example because they were not held to be the target of the surveillance) are\\ninformed at least ex post facto and granted remedies in the event that the data capture was unjustified or pro-\\ncessed/shared/retained unlawfully. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 98, 'page': 29, '_split_overlap': [{'doc_id': '5d2ce2b4e22046f558c58c15accfb06c', 'range': (0, 148)}, {'doc_id': 'b0c78f0b9febce4f9589676138940f9c', 'range': (921, 1258)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'dc45230f26cfd4d12e8be23ccece17d4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: It is crucial that even individuals whose biometric data are captured but against\\nwhom a case is not pursued (for example because they were not held to be the target of the surveillance) are\\ninformed at least ex post facto and granted remedies in the event that the data capture was unjustified or pro-\\ncessed/shared/retained unlawfully. Releasing reliable and timely statistics on the capture and success rate of\\nbiometric data will ensure public confidence that these powers are not abused.\\nFourth, authorities will be under an obligation to ensure the security and integrity of the personal data pro-\\ncessed. Fundamentally speaking, the use of biometric technologies pertains to the processing of extremely\\nsensitive personal data, through equipment which may have vulnerabilities or lack proper security safeguards\\nto prevent unauthorised third-party access. For example, the hacking of just a single CCTV camera can affect\\nmany people, including those who are unrelated to a government operation. These fundamental human rights\\nand rule of law requirements demonstrate that even in the absence of untargeted biometric processing, the\\nuse of biometric technologies for recognition, identification or other processing is subject to exceptionally strict\\ncontrols under existing EU law.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 99, 'page': 29, '_split_overlap': [{'doc_id': 'dc45230f26cfd4d12e8be23ccece17d4', 'range': (0, 337)}, {'doc_id': 'b4dab08705f21848775949c580d1d864', 'range': (1002, 1287)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b0c78f0b9febce4f9589676138940f9c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: These fundamental human rights\\nand rule of law requirements demonstrate that even in the absence of untargeted biometric processing, the\\nuse of biometric technologies for recognition, identification or other processing is subject to exceptionally strict\\ncontrols under existing EU law.\\n74 Privacy International, Briefing to the UN Counter-Terrorism Executive Directorate on the responsible use and sharing of biomet-\\nric data to tackle terrorism (2019) 3-4 <https://privacyinternational.org/sites/default/files/2019-07/PI%20briefing%20on%20\\nbiometrics%20final.pdf>\\n75 Fundamental Rights Review of EU data collection instruments and programmes, 44 <http://www.fondazionebrodolini.it/\\nsites/default/files/final_report_0.pdf>\\n76 See Big Brother Watch v United Kingdom, para 387.\\n77 See Szabó v. Hungary, para 260.\\n78 This mirrors the requirements of the GDPR of a prior DPIA and possible prior consultation with the DPA for all processing\\noperations that pose a high risk to the rights and freedoms of individuals – or indeed, if stipulated by law, the DPA’s prior\\nauthorisation (Articles 35 – 36 GDPR).\\nANALYSIS\\x0c30\\nCASE STUDIES\\nCASE STUDY ASSESSMENTS\\nThis chapter applies the arguments substantiated throughout this paper to real examples\\nof biometric processing in public spaces which have led to mass surveillance. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 100, 'page': 29, '_split_overlap': [{'doc_id': 'b0c78f0b9febce4f9589676138940f9c', 'range': (0, 285)}, {'doc_id': 'f2754b67f1cf118932d2e41ee03e8dd3', 'range': (1101, 1314)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b4dab08705f21848775949c580d1d864'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: ANALYSIS\\x0c30\\nCASE STUDIES\\nCASE STUDY ASSESSMENTS\\nThis chapter applies the arguments substantiated throughout this paper to real examples\\nof biometric processing in public spaces which have led to mass surveillance. This is not an\\nexhaustive list; in general, if the processing is untargeted, and in a public or merely public-\\nly-accessible space; and has the potential to contribute to a perception of mass surveillence\\nand/or a violation of dignity, then it will be included within what this paper argues is already\\nillegal under EU law and must be banned in practice. The differences between the case\\nstudies demonstrates why it is so necessary for any deployment to be considered individual-\\nly and for those developing and deployeing such tools and systems to engage in pre-deploy-\\nment DPIA processes with national DPAs.\\n6.1 Facial recognition in Ampère high school, Marseille\\nIn July 2019, the Provence-Alpes-Côte d’Azur (PACA) regional authority asked France’s data protection\\nauthority, the CNIL, for permission to use a facial recognition system for managing entry at Ampère high\\nschool in Marseille. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 101, 'page': 29, '_split_overlap': [{'doc_id': 'b4dab08705f21848775949c580d1d864', 'range': (0, 213)}, {'doc_id': 'fe74334c60af92200a5b01f66d8397c', 'range': (825, 1108)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f2754b67f1cf118932d2e41ee03e8dd3'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 6.1 Facial recognition in Ampère high school, Marseille\\nIn July 2019, the Provence-Alpes-Côte d’Azur (PACA) regional authority asked France’s data protection\\nauthority, the CNIL, for permission to use a facial recognition system for managing entry at Ampère high\\nschool in Marseille. This “trial” was intended to be a year-long experiment and was also being carried\\nout at another school in the region (the Lycée les Eucalyptus in Nice) and was said to be held on the basis\\nof students’ and parents’ consent.79 The intention of the system was to facilitate the job of the schools’\\nsecurity agents, helping them to spot identity theft and to prevent access of unauthorised persons to the\\nschool. This was designed to increase the security of students and staff and to speed up the time it took\\nfor students to enter the school premises.\\nEDRi’s analysis:\\n• Objective: as indicated by the CNIL, we agree that the system aims to achieve a legitimate public au-\\nthority objective of managing entry into a school, to ensure that the right people could enter and the\\nwrong people could not.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 102, 'page': 30, '_split_overlap': [{'doc_id': 'f2754b67f1cf118932d2e41ee03e8dd3', 'range': (0, 283)}, {'doc_id': '664d77f0fa46313e2c551969e493abf5', 'range': (836, 1083)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fe74334c60af92200a5b01f66d8397c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: EDRi’s analysis:\\n• Objective: as indicated by the CNIL, we agree that the system aims to achieve a legitimate public au-\\nthority objective of managing entry into a school, to ensure that the right people could enter and the\\nwrong people could not.\\n• Necessity and proportionality: as the CNIL emphasised, a school facial recognition system is not\\nnecessary when there is the less intrusive alternative of using identity badges. Furthermore, this use\\nof facial recognition is disproportionate as it brings in a large-scale, intrusive data surveillance pro-\\ngram against minors simply for the objective of school entry.80\\n79 The CNIL, Experimentation de la reconnaisance faciale dans deux lycees (2019) <https://www.cnil.fr/fr/experimenta-\\ntion-de-la-reconnaissance-faciale-dans-deux-lycees-la-cnil-precise-sa-position>\\n80 EDPS, quick-guide to necessity and proportionality (2018) <edps.europa.eu/sites/edp/files/publication/20-01-28_edps_quick-\\nguide_en.pdf>\\n6.\\x0c31\\nCASE STUDIES\\n• Other legality requirements: under the GDPR, there are legal requirements for consent and for the\\nminimisation of data. As confirmed by the CNIL and the Marseille regional Court, the Ampère facial\\nrecognition trial significantly violated both of these criteria, gathering data when it was unjustified, and\\nbeing fundamentally unable to obtain legitimate consent due to the power dynamics between the public\\nauthority and students. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 103, 'page': 30, '_split_overlap': [{'doc_id': 'fe74334c60af92200a5b01f66d8397c', 'range': (0, 247)}, {'doc_id': 'e813549bc17cfe87b9dadf5f20c7b8a1', 'range': (1099, 1409)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '664d77f0fa46313e2c551969e493abf5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: As confirmed by the CNIL and the Marseille regional Court, the Ampère facial\\nrecognition trial significantly violated both of these criteria, gathering data when it was unjustified, and\\nbeing fundamentally unable to obtain legitimate consent due to the power dynamics between the public\\nauthority and students. Across EU law, young people are given enhanced protections (cf. Article 8 GDPR\\nre information society services). Under GDPR, biometric data is considered highly sensitive (Article 9(1)).\\nThe biometric data of minors therefore requires the highest level of protections, which Ampère did not\\nmeet.\\n• Severity of the risk: using facial recognition to control school entry not only processes and retains mi-\\nnors’ data unnecessarily and unlawfully, but could interfere with their fundamental right to access edu-\\ncation by creating a culture of mistrust and surveillance in their place of learning or by putting pressure\\nto conform on those that want to opt out. This was seen already in a Polish school found to be breaking\\nthe law by introducing a biometric system for assigning school lunches to pupils. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 104, 'page': 31, '_split_overlap': [{'doc_id': '664d77f0fa46313e2c551969e493abf5', 'range': (0, 310)}, {'doc_id': 'de862f650f7624a313beb5e770902773', 'range': (970, 1113)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e813549bc17cfe87b9dadf5f20c7b8a1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: This was seen already in a Polish school found to be breaking\\nthe law by introducing a biometric system for assigning school lunches to pupils. Students were allowed\\nto opt out – but were de facto punished by being made to wait until their 600 peers had received their\\nfood first.81\\n• Other factors: Other concerning factors in the case include the fact that the region seemed to deploy\\nthe experiment before obtaining the opinion of the CNIL, setting a dangerous precedent for a lack of\\nstate accountability. The decision by the PACA region to pilot such an intrusive system furthermore could\\nsuggest that the PACA region’s data protection processes (for example DPIAs) are not being undertaken\\nwith due care for fundamental rights.\\nWhat this means:\\nWhilst the objectives of the system may have been acceptable, this analysis demonstrates that facial recog-\\nnition for entry management in schools is neither a legitimate, necessary nor proportionate way to achieve\\nthis aim. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 105, 'page': 31, '_split_overlap': [{'doc_id': 'e813549bc17cfe87b9dadf5f20c7b8a1', 'range': (0, 143)}, {'doc_id': '91f5936a7fc2525eaed7a4a1904e7437', 'range': (734, 975)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'de862f650f7624a313beb5e770902773'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: What this means:\\nWhilst the objectives of the system may have been acceptable, this analysis demonstrates that facial recog-\\nnition for entry management in schools is neither a legitimate, necessary nor proportionate way to achieve\\nthis aim. The use of this mass biometric identification system in a school – which is not only a public space,\\nbut an essential one which young people are obligated to attend - is firmly within the scope of EDRi’s call\\nfor a ban. The scale of the violations of young people’s rights to privacy and data protection are so signif-\\nicant that even safeguards and DPIAs will not be able to make this sort of use compliant with Europe’s\\nfundamental rights laws.\\nThe scale at which school entry systems operate greatly increases the potential for other violations. If\\nreplicated across European schools, there is potential for millions of young people to have their data un-\\nnecessarily and unlawfully processed on a daily basis. This could contribute to the normalisation of highly\\nintrusive facial recognition, making properly-informed public debates less achievable.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 106, 'page': 31, '_split_overlap': [{'doc_id': 'de862f650f7624a313beb5e770902773', 'range': (0, 241)}, {'doc_id': '6f2698a928d63d4eed3d08ac702779d9', 'range': (791, 1095)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '91f5936a7fc2525eaed7a4a1904e7437'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: If\\nreplicated across European schools, there is potential for millions of young people to have their data un-\\nnecessarily and unlawfully processed on a daily basis. This could contribute to the normalisation of highly\\nintrusive facial recognition, making properly-informed public debates less achievable.\\nThere is widespread concern about the use of these technologies, and this means that there is a high\\nchance of successfully informing policy decisions about the use of facial and biometric recognition in pub-\\nlic mass surveillance scenarios like the case of Ampère high school. With both the CNIL and the regional\\nCourt of Marseille declaring this trial illegal, there is both a state and a public appetite to see potential\\nviolations of the rights of young people quashed at the earliest opportunity.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 107, 'page': 31, '_split_overlap': [{'doc_id': '91f5936a7fc2525eaed7a4a1904e7437', 'range': (0, 304)}, {'doc_id': '937fdea4056a9e74a6523d0ebf55b7b7', 'range': (583, 806)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6f2698a928d63d4eed3d08ac702779d9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: With both the CNIL and the regional\\nCourt of Marseille declaring this trial illegal, there is both a state and a public appetite to see potential\\nviolations of the rights of young people quashed at the earliest opportunity.\\n81 Urzad Ochrony Danych Osobowych, Fine for processing students’ fingerprints imposed on a school (2020) <https://uodo.gov.pl/\\nen/553/1102>\\x0c32\\nCASE STUDIES\\n6.2 Other Case Studies with Assessment and Analysis\\n(a) Facial recognition software used to scrape social media\\nThe ClearviewAI scandal in January 2020 raised public awareness about the risks that\\npeople’s images, uploaded for social media and networking purposes, are being covertly\\nused by private actors in ways that may help them build for-profit technology, and that\\nalso have been sold to the police.82 This raises questions about the role and influence of\\nprivate actors in law enforcement, problems with public procurement, and the potential-\\nly enormous discriminatory outcomes from inaccuracy, as well as the related issues of\\nthe (in)security of ClearviewAI’s databases. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 108, 'page': 31, '_split_overlap': [{'doc_id': '6f2698a928d63d4eed3d08ac702779d9', 'range': (0, 223)}, {'doc_id': 'b8ebeaf2ed91dc401d2195b5ef3a8adb', 'range': (224, 1061)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '937fdea4056a9e74a6523d0ebf55b7b7'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 81 Urzad Ochrony Danych Osobowych, Fine for processing students’ fingerprints imposed on a school (2020) <https://uodo.gov.pl/\\nen/553/1102>\\x0c32\\nCASE STUDIES\\n6.2 Other Case Studies with Assessment and Analysis\\n(a) Facial recognition software used to scrape social media\\nThe ClearviewAI scandal in January 2020 raised public awareness about the risks that\\npeople’s images, uploaded for social media and networking purposes, are being covertly\\nused by private actors in ways that may help them build for-profit technology, and that\\nalso have been sold to the police.82 This raises questions about the role and influence of\\nprivate actors in law enforcement, problems with public procurement, and the potential-\\nly enormous discriminatory outcomes from inaccuracy, as well as the related issues of\\nthe (in)security of ClearviewAI’s databases. But it is not just ClearviewAI: Facebook have\\nbeen analysing users’ photos for years in the name of being able to tag users, and other\\nBig Tech corporations have similarly trained algorithms on reams of people’s photos,\\nwithout those people knowing the extent of how their data is used. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 109, 'page': 31, '_split_overlap': [{'doc_id': '937fdea4056a9e74a6523d0ebf55b7b7', 'range': (0, 837)}, {'doc_id': '69be7327a98312163393fa6b2001ae82', 'range': (838, 1124)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b8ebeaf2ed91dc401d2195b5ef3a8adb'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: But it is not just ClearviewAI: Facebook have\\nbeen analysing users’ photos for years in the name of being able to tag users, and other\\nBig Tech corporations have similarly trained algorithms on reams of people’s photos,\\nwithout those people knowing the extent of how their data is used. The use of machine\\nlearning algorithms in this context provides further cause for concern: people whose\\nfaces are used for training data will face additional risks because their inclusion in train-\\ning makes the system more likely to flag them.\\nThe example of the EU Horizon 2020-funded SPIRIT project reinforces the lack of fun-\\ndamental rights compliance, transparency and accountability in a social media scraping\\nuse case. Five law enforcement-related stakeholders participate in this research proj-\\nect: the Hellenic Police (GR), West Midlands Police (UK), Police and Crime Commis-\\nsioner for Thames Valley (UK), Serbian Ministry of Interior (RS), and Police Academy in\\nSzcytno (PL). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 110, 'page': 32, '_split_overlap': [{'doc_id': 'b8ebeaf2ed91dc401d2195b5ef3a8adb', 'range': (0, 286)}, {'doc_id': 'cfa6aadf7de79651453527acf977a939', 'range': (714, 975)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '69be7327a98312163393fa6b2001ae82'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Five law enforcement-related stakeholders participate in this research proj-\\nect: the Hellenic Police (GR), West Midlands Police (UK), Police and Crime Commis-\\nsioner for Thames Valley (UK), Serbian Ministry of Interior (RS), and Police Academy in\\nSzcytno (PL). According to the sparse and untransparent website, the project aims to use\\ntools such as face extraction and matching, to correlate information from social media\\ndata, which constitutes a form of mass surveillance, and to continuously initiate complex\\nassociative searches over all sources relevant to criminal investigation.83 According to\\nfreedom of information requests, trials were planned for 2020 and 2021, with genuine\\nend users.84\\n(b) iBorderCtrl\\nThe Horizon 2020 programme also funded a set of research projects on the Hungarian,\\nGreek, and Latvian borders called iBorderCtrl.85 The included one project to use auto-\\nmated analysis of biometric data to predict evidence of deception among those looking to\\n82 The New York Times, The Secretive Company That Might End Privacy as We Know It (2020) <https://www.nytimes.\\ncom/2020/01/18/technology/clearview-privacy-facial-recognition.html>\\n83 SPIRIT (2018) <https://www.spirit-tools.com/index.php>\\n84 Ask the EU, Ref. Ares(2020)1351062 – 04/03/2020, <https://www.asktheeu.org/en/request/7495/response/25180/attach/2/\\nREA%20reply%20confirmatory%20signed.pdf?cookie_passthrough=1>\\n85 iBorderCtrl <https://www.iborderctrl.eu/>\\x0c33\\nCASE STUDIES\\nenter the EU. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 111, 'page': 32, '_split_overlap': [{'doc_id': '69be7327a98312163393fa6b2001ae82', 'range': (0, 261)}, {'doc_id': 'e4276bfaa0816b8e170044d0cbf92259', 'range': (1088, 1470)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'cfa6aadf7de79651453527acf977a939'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: com/2020/01/18/technology/clearview-privacy-facial-recognition.html>\\n83 SPIRIT (2018) <https://www.spirit-tools.com/index.php>\\n84 Ask the EU, Ref. Ares(2020)1351062 – 04/03/2020, <https://www.asktheeu.org/en/request/7495/response/25180/attach/2/\\nREA%20reply%20confirmatory%20signed.pdf?cookie_passthrough=1>\\n85 iBorderCtrl <https://www.iborderctrl.eu/>\\x0c33\\nCASE STUDIES\\nenter the EU. Freedom of information requests revealed that during the pilots in Greece,\\nno real travelers participated in the Greek pilots,86 and the project came to an end in Au-\\ngust 2019. Under this paper’s analysis of mass surveillance, such a use would not meet\\nthe criteria of indiscriminately processing the data of passersby. However, we believe\\nthat it would meet other criteria to be considered mass surveillance as the use of this\\ntechnology is not targeted against specific individuals of lawful interest. Furthermore,\\nsuch deception prediction “lie detector” tests can be considered part of the state mass\\nsurveillance apparatus because they rely on technologies of watching, with an unequal\\npower dynamic and a use that is generally targeted against marginalised individuals.\\nFollowing public scrutiny, the iBorderCtrl project team acknowledged the potentially\\nharmful ethical implications of this project and the need for both public debate and a\\nfundamental rights analysis.\\n6.3 Mass surveillance for public health purposes (COVID-19)\\nSince late 2019, the world has watched as the outbreak of Coronavirus in Wuhan quickly\\nturned into a global pandemic. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 112, 'page': 32, '_split_overlap': [{'doc_id': 'cfa6aadf7de79651453527acf977a939', 'range': (0, 382)}, {'doc_id': 'c7216cdcc95afb0f1d118e4c2e1898d0', 'range': (1361, 1538)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e4276bfaa0816b8e170044d0cbf92259'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: 6.3 Mass surveillance for public health purposes (COVID-19)\\nSince late 2019, the world has watched as the outbreak of Coronavirus in Wuhan quickly\\nturned into a global pandemic. Public health responses have put unprecedented limits\\non the daily lives of people across the world. A range of important rights, especially the\\nright to life, are of course threatened by the disease – but responses across the world\\ncan also threaten fundamental liberties and freedoms.87\\nWhilst taking proportionate public health measures is a legitimate policy action, there\\nis a significant risk that the pandemic can be abused by states and private companies to\\nsmuggle in unlawful, highly-intrusive mass surveillance measures. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 113, 'page': 33, '_split_overlap': [{'doc_id': 'e4276bfaa0816b8e170044d0cbf92259', 'range': (0, 177)}, {'doc_id': '7f2d097b76ed62db757a863a98cd7557', 'range': (279, 709)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c7216cdcc95afb0f1d118e4c2e1898d0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: A range of important rights, especially the\\nright to life, are of course threatened by the disease – but responses across the world\\ncan also threaten fundamental liberties and freedoms.87\\nWhilst taking proportionate public health measures is a legitimate policy action, there\\nis a significant risk that the pandemic can be abused by states and private companies to\\nsmuggle in unlawful, highly-intrusive mass surveillance measures. In China, for exam-\\nple, purportedly benign, voluntary tracking and tracing apps88 were quickly revealed to be\\nautomatically controlling people’s access to public spaces and even sending their per-\\nsonal data to the police.89 There are increasing calls for and attempts at the introduction\\nof similarly threatening contact tracing apps across Europe, similar to Poland’s manda-\\ntory facial recognition-based app used to enforce quarantine, which sends the police to\\nthe home of anyone that fails to share a selfie on the app within 20 minutes of an alert.90\\nWithin the limits of this paper, we cannot discuss all of the implications of the Corona-\\nvirus pandemic and associated surveillance, nor of its intersection with biometric mass\\nsurveillance. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 114, 'page': 33, '_split_overlap': [{'doc_id': 'c7216cdcc95afb0f1d118e4c2e1898d0', 'range': (0, 430)}, {'doc_id': 'ba15c2afa6baeb49df2a64ed0c6a7097', 'range': (431, 1180)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7f2d097b76ed62db757a863a98cd7557'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: In China, for exam-\\nple, purportedly benign, voluntary tracking and tracing apps88 were quickly revealed to be\\nautomatically controlling people’s access to public spaces and even sending their per-\\nsonal data to the police.89 There are increasing calls for and attempts at the introduction\\nof similarly threatening contact tracing apps across Europe, similar to Poland’s manda-\\ntory facial recognition-based app used to enforce quarantine, which sends the police to\\nthe home of anyone that fails to share a selfie on the app within 20 minutes of an alert.90\\nWithin the limits of this paper, we cannot discuss all of the implications of the Corona-\\nvirus pandemic and associated surveillance, nor of its intersection with biometric mass\\nsurveillance. Suffice to note that the mass collection and sharing of data, regardless of\\n86 Ask the EU, D6.4 Evaluation report of final prototype pilot deployment and Best Practices - Analysis of pilot feedback on final\\nprototype (2019) <https://www.asktheeu.org/en/request/7488/response/24777/attach/3/D6%204%20700626%20Eval%20re-\\nport%20final%20prototype%20pilot%20deploy%20BestPractices%20redacted.pdf?cookie_passthrough=1>\\n87 Fundamental Rights Agency, Protect human rights and public health in fighting COVID-19 (2020) <https://fra.europa.eu/en/\\nnews/2020/protect-human-rights-and-public-health-fighting-covid-19>\\n88 BBC, China launches coronavirus ‘close contact detector’ app (2020) <https://www.bbc.co.uk/news/technology-51439401>\\n89 New York Times, In Coronavirus Fight, China Gives Citizens a Color Code, With Red Flags (2020) <https://www.nytimes.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 115, 'page': 33, '_split_overlap': [{'doc_id': '7f2d097b76ed62db757a863a98cd7557', 'range': (0, 749)}, {'doc_id': '1651d9f85652490eef7a9c50da1a847c', 'range': (750, 1595)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ba15c2afa6baeb49df2a64ed0c6a7097'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Suffice to note that the mass collection and sharing of data, regardless of\\n86 Ask the EU, D6.4 Evaluation report of final prototype pilot deployment and Best Practices - Analysis of pilot feedback on final\\nprototype (2019) <https://www.asktheeu.org/en/request/7488/response/24777/attach/3/D6%204%20700626%20Eval%20re-\\nport%20final%20prototype%20pilot%20deploy%20BestPractices%20redacted.pdf?cookie_passthrough=1>\\n87 Fundamental Rights Agency, Protect human rights and public health in fighting COVID-19 (2020) <https://fra.europa.eu/en/\\nnews/2020/protect-human-rights-and-public-health-fighting-covid-19>\\n88 BBC, China launches coronavirus ‘close contact detector’ app (2020) <https://www.bbc.co.uk/news/technology-51439401>\\n89 New York Times, In Coronavirus Fight, China Gives Citizens a Color Code, With Red Flags (2020) <https://www.nytimes.\\ncom/2020/03/01/business/china-coronavirus-surveillance.html>\\n90 Gov.pl, Aplikacja „Kwarantanna domowa” – ruszya proces jej udostapniania (2020) <https://www.gov.pl/web/cyfryzacja/aplik-\\nacja-kwarantanna-domowa--ruszyl-proces-jej-udostepniania>\\x0c34\\nthe context, can pose high risks to fundamental rights. We must be equally alert to the\\nthreats to fundamental rights and the rule of law that are shared by the use of biomet-\\nrics that lead to mass surveillance in public spaces as explored in this paper, and many\\nproposed apps and other technological “solutions” for tackling Coronavirus. We firmly\\nbelieve that there is no justification for invoking derogation clauses in human rights trea-\\nties, in particular Article 15 ECHR, in order to depart from these requirements. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 116, 'page': 33, '_split_overlap': [{'doc_id': 'ba15c2afa6baeb49df2a64ed0c6a7097', 'range': (0, 845)}, {'doc_id': 'bf9931e6a8b388f29663cc1f5d3204d3', 'range': (1434, 1617)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1651d9f85652490eef7a9c50da1a847c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: We firmly\\nbelieve that there is no justification for invoking derogation clauses in human rights trea-\\nties, in particular Article 15 ECHR, in order to depart from these requirements. As noted\\nin Section 5.1, even in times of derogation, states may not impinge on the untouchable\\nessential core of those rights.\\nThe legitimation and normalisation of privacy-invading surveillance infrastructures risks\\ncreating a false sense that being watched and analysed all the time is acceptable, and con-\\ntributes to societies filled with suspicion, abuse and mistrust. As the EU’s Committee for\\ncivil liberties (LIBE) states, mass surveillance does not make us safer.91 It puts undue lim-\\nits on our liberties and rights which can continue long after a public emergency like the\\nCOVID-19 pandemic has been eased. EDRi has opened a section on its website to report and\\nanalyse on these developments.92 There, we will argue for maintenance of full respect by all\\nEuropean states for all fundamental rights and principles, in relation to mass surveillance\\nfor public health purposes as much as in relation to mass surveillance for law enforcement\\nor public order purposes. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 117, 'page': 34, '_split_overlap': [{'doc_id': '1651d9f85652490eef7a9c50da1a847c', 'range': (0, 183)}, {'doc_id': 'c30d3c10575d2a511dbd759146ebbb4d', 'range': (803, 1159)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bf9931e6a8b388f29663cc1f5d3204d3'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: EDRi has opened a section on its website to report and\\nanalyse on these developments.92 There, we will argue for maintenance of full respect by all\\nEuropean states for all fundamental rights and principles, in relation to mass surveillance\\nfor public health purposes as much as in relation to mass surveillance for law enforcement\\nor public order purposes. Different checks and balances may be required – but the funda-\\nmental principles and essential limits of state authority remain the same.\\n91 European Parliament, Use of smartphone data to manage COVID-19 must respect EU data protection rules (2020) <https://www.\\neuroparl.europa.eu/news/en/press-room/20200406IPR76604/use-of-smartphone-data-to-manage-covid-19-must-respect-\\neu-data-protection-rules>\\n92 EDRi, COVID-19 & Digital Rights Doc Pool <https://edri.org/covid-19-digital-rights-document-pool>\\nCASE STUDIES\\x0c35\\n7.\\nRECOMMENDATIONS\\nEDRi’s RECOMMENDATIONS\\nThe use of technology for the untargeted processing of biometric data (or proxy special\\ncategories of personal data) in public spaces, whether by law enforcement agencies,\\npublic authorities, or private/commercial actors, raises significant problems for funda-\\nmental rights and individual freedoms and must be taken seriously. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 118, 'page': 34, '_split_overlap': [{'doc_id': 'bf9931e6a8b388f29663cc1f5d3204d3', 'range': (0, 356)}, {'doc_id': '5cfaa56c254b84178d88e87c9df4bc2f', 'range': (877, 1243)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c30d3c10575d2a511dbd759146ebbb4d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: RECOMMENDATIONS\\nEDRi’s RECOMMENDATIONS\\nThe use of technology for the untargeted processing of biometric data (or proxy special\\ncategories of personal data) in public spaces, whether by law enforcement agencies,\\npublic authorities, or private/commercial actors, raises significant problems for funda-\\nmental rights and individual freedoms and must be taken seriously. The fundamental\\nrights analysis conducted in this paper demonstrates that biometric processing in pub-\\nlic spaces that leads to, or has the potential to lead to, mass surveillance is incompat-\\nible with the EU fundamental rights framework, especially data protection, dignity,\\nand the principles of necessity and proportionality, and is therefore illegal. This re-\\nmains true regardless of the stated purpose; and whether such mass surveillance effect\\nis intentional or unintentional. This is because mass surveillance represents an un-\\njustified restriction on privacy and is even more intrusive when using biometric data,\\nmaking its use inherently disproportionate.\\nFour European instruments already prohibit biometric mass surveillance: in the broad-\\nest sense, the European Convention on Human Rights and the EU Charter of Fundamen-\\ntal Rights, and more specifically, the (Modernised) Council of Europe Data Protection\\nConvention, the GDPR and its sister instrument, the LED. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 119, 'page': 35, '_split_overlap': [{'doc_id': 'c30d3c10575d2a511dbd759146ebbb4d', 'range': (0, 366)}, {'doc_id': '1fc3b0156e838552aa4403b883580e45', 'range': (1035, 1346)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5cfaa56c254b84178d88e87c9df4bc2f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Four European instruments already prohibit biometric mass surveillance: in the broad-\\nest sense, the European Convention on Human Rights and the EU Charter of Fundamen-\\ntal Rights, and more specifically, the (Modernised) Council of Europe Data Protection\\nConvention, the GDPR and its sister instrument, the LED. Data protection laws provide\\nfurther barriers to biometric processing.\\nIn practice, however, these instruments are not properly harmonised or uniformly\\napplied, nor are they enforced fully. This has had the result that there have been many\\ndeployments of untargeted biometric processing amounting to mass surveillance in\\nEuropean public spaces that are incompatible with fundamental European law and\\nprinciples. These deployments have violated fundamental rights including rights to dig-\\nnity; liberty; security; privacy; data protection, especially data minimisation, data pro-\\ntection by design and default, and consent; equality and non-discrimination; freedom of\\nexpression; freedom of assembly and association; freedom of information; and justice,\\nincluding the right to an effective remedy and to a fair trial. Mass surveillance impinges\\non the untouchable “essence” of these rights. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 120, 'page': 35, '_split_overlap': [{'doc_id': '5cfaa56c254b84178d88e87c9df4bc2f', 'range': (0, 311)}, {'doc_id': 'e93ba80e2de7c54b937987ced43e06c3', 'range': (724, 1201)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1fc3b0156e838552aa4403b883580e45'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: These deployments have violated fundamental rights including rights to dig-\\nnity; liberty; security; privacy; data protection, especially data minimisation, data pro-\\ntection by design and default, and consent; equality and non-discrimination; freedom of\\nexpression; freedom of assembly and association; freedom of information; and justice,\\nincluding the right to an effective remedy and to a fair trial. Mass surveillance impinges\\non the untouchable “essence” of these rights. These deployments have happened de-\\x0c36\\nRECOMMENDATIONS\\nspite objections from Member States’ dedicated Data Protection Authorities (DPAs)93, the\\nEuropean Data Protection Supervisor (EDPS),94 and in some cases, even their national\\nCourts.95 Due to the impermissible intrusive, undemocratic and violatory nature of bio-\\nmetric mass surveillance technologies in public spaces, these technologies should nev-\\ner be deployed or used. Furthermore, DPAs must be “provided with sufficient resources\\nto carry out their tasks effectively.”96\\n7.1 Recommendations: ban biometric mass surveillance\\nEDRi calls on the European Union to permanently stop all biometric processing in\\npublic and publicly-accessible spaces, wherever it has the effect or potential effect\\nto establish mass surveillance. This call comprises of six actions. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 121, 'page': 35, '_split_overlap': [{'doc_id': '1fc3b0156e838552aa4403b883580e45', 'range': (0, 477)}, {'doc_id': '8872ddb70e26a9839a41c3a566862376', 'range': (906, 1296)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e93ba80e2de7c54b937987ced43e06c3'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Furthermore, DPAs must be “provided with sufficient resources\\nto carry out their tasks effectively.”96\\n7.1 Recommendations: ban biometric mass surveillance\\nEDRi calls on the European Union to permanently stop all biometric processing in\\npublic and publicly-accessible spaces, wherever it has the effect or potential effect\\nto establish mass surveillance. This call comprises of six actions. Whilst EDRi calls for\\nthe implementation of all measures below in order to eradicate biometric mass surveil-\\nlance, these measures differ in the time-frames and efforts required for each specific\\naction:\\n1. EU Member States immediately halt all biometric processing that could amount\\nto mass surveillance in public spaces, ensuring that both current and future\\ndeployments are included. This should be supported by a political debate by the\\nEuropean Council on the fundamental rights impacts of biometric mass pro-\\ncessing in Member States;\\n2. EU Member States, under the auspices of the European Data Protection Board\\n(EDPB) and national Data Protection Authorities (DPAs), publicly disclose all\\nexisting and planned activities and deployments that fall within this remit;\\n3. EU Member States cease all planned legislation which establishes biometric\\nprocessing that could lead to mass surveillance in public spaces. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 122, 'page': 36, '_split_overlap': [{'doc_id': 'e93ba80e2de7c54b937987ced43e06c3', 'range': (0, 390)}, {'doc_id': '3ddccce7fb46ceef7aeae9698e01d466', 'range': (1168, 1308)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8872ddb70e26a9839a41c3a566862376'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: EU Member States cease all planned legislation which establishes biometric\\nprocessing that could lead to mass surveillance in public spaces. Instead, clear\\nand foreseeable laws should only allow for targeted identification checks that\\nare proportionate to the issues and context, and provide for effective remedies\\nagainst abuse. DPAs can play a role by advising national regulators and re-\\nquesting action from their national governments;\\n4. The European Commission, in particular Directorate-General (DG) HOME and\\nwith reference to DG RTD for the Horizon2020 Programme, ensure that funding\\ngiven to Member States for biometric research or deployment is for activities\\n93 EDPB, School renders Sweden’s first GDPR fine (2019) <https://edpb.europa.eu/news/national-news/2019/facial-recogni-\\ntion-school-renders-swedens-first-gdpr-fine_en>; the CNIL, Experimentation de la reconnaissance faciale dans deux lycees\\n(2019) <https://www.cnil.fr/fr/experimentation-de-la-reconnaissance-faciale-dans-deux-lycees-la-cnil-precise-sa-position>\\n94 EDPS, Facial Recognition: A Solution in Search of a Problem? (2019) <https://edps.europa.eu/press-publications/press-news/\\nblog/facial-recognition-solution-search-problem_en>\\n95 La Quadrature du Net et autres, Tribunal Administratif du Marseille, N.1901249 (2020) <https://www.laquadrature.net/\\nwp-content/uploads/sites/8/2020/02/1090394890_1901249.pdf>\\n96 Fundamental Rights Review of EU data collection instruments and programmes, 112 <http://www.fondazionebrodolini.it/\\nsites/default/files/final_report_0.pdf>\\x0c37\\nRECOMMENDATIONS\\nwhich are fully compliant with the Charter, including immediately ceasing all\\nfunding for biometric processing programmes which could contribute to mass\\nsurveillance in public spaces. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 123, 'page': 36, '_split_overlap': [{'doc_id': '8872ddb70e26a9839a41c3a566862376', 'range': (0, 140)}, {'doc_id': '95fa31dfcd57e31989b49a80a9435847', 'range': (1097, 1751)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3ddccce7fb46ceef7aeae9698e01d466'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: (2019) <https://edps.europa.eu/press-publications/press-news/\\nblog/facial-recognition-solution-search-problem_en>\\n95 La Quadrature du Net et autres, Tribunal Administratif du Marseille, N.1901249 (2020) <https://www.laquadrature.net/\\nwp-content/uploads/sites/8/2020/02/1090394890_1901249.pdf>\\n96 Fundamental Rights Review of EU data collection instruments and programmes, 112 <http://www.fondazionebrodolini.it/\\nsites/default/files/final_report_0.pdf>\\x0c37\\nRECOMMENDATIONS\\nwhich are fully compliant with the Charter, including immediately ceasing all\\nfunding for biometric processing programmes which could contribute to mass\\nsurveillance in public spaces. All EU bodies who give operational support or ad-\\nvice to EU institutions, including but not limited to Europol, Frontex and the Fun-\\ndamental Rights Agency (FRA), ensure that Member States cannot use these\\ntechnologies in a way which gives way to fundamental rights abuses;\\n5. The European Commission, under the auspices of the EDPS’s advisory role, re-\\nview and ex post facto evaluate on fundamental rights and data protection\\ngrounds all laws covering EU biometrics that contribute to or amount to mass\\nsurveillance and, as appropriate, recast, repeal or provide appropriate guidance\\nto Member States about safeguards;97 and\\n6. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 124, 'page': 36, '_split_overlap': [{'doc_id': '3ddccce7fb46ceef7aeae9698e01d466', 'range': (0, 654)}, {'doc_id': 'e0e9de2a4875bfd8b4f0665920b17103', 'range': (933, 1285)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '95fa31dfcd57e31989b49a80a9435847'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The European Commission, under the auspices of the EDPS’s advisory role, re-\\nview and ex post facto evaluate on fundamental rights and data protection\\ngrounds all laws covering EU biometrics that contribute to or amount to mass\\nsurveillance and, as appropriate, recast, repeal or provide appropriate guidance\\nto Member States about safeguards;97 and\\n6. The European Commission (in particular DGs GROW, CNECT and JUST as the\\nDirectorate-Generals leading the Commission’s work on the White Paper on\\nArtificial Intelligence (AI) and DG HOME in its capacity on borders) implement,\\nthrough legislative and non-legislative means and if necessary, infringement\\nproceedings and Court action, an immediate and indefinite ban on biometric\\nprocessing that leads to mass surveillance in public spaces. This process must\\nbe done under the supervision and/or support of the European Data Protection\\nSupervisor (EDPS), the European Data Protection Board (EDPB), the FRA and\\nDPAs.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 125, 'page': 37, '_split_overlap': [{'doc_id': '95fa31dfcd57e31989b49a80a9435847', 'range': (0, 352)}, {'doc_id': 'c11c795ed0a0a0573831f93eca6daff2', 'range': (790, 964)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e0e9de2a4875bfd8b4f0665920b17103'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: This process must\\nbe done under the supervision and/or support of the European Data Protection\\nSupervisor (EDPS), the European Data Protection Board (EDPB), the FRA and\\nDPAs.\\nIt is the role and responsibility of the European Union, in particular the European\\nCommission, theCouncil of the EU and the European Parliament, with the support of\\nthe European Data Protection Board which also includes the European Data Protec-\\ntion Supervisor, the EU Fundamental Rights Agency (FRA), the national Data Protec-\\ntion Authorities (DPAs) of every EU Member State and any other oversight bodies,\\nto determine the appropriate methods to ensure that biometric mass surveillance is\\ncomprehensively stopped and banned in law, and in practice, across the EU.\\nWe further encourage Members of the European Parliament – in particular the intergroup\\non Artificial Intelligence & Digital; the Committee of the Regions (CoR); the European\\nEconomic & Social Committee (EESC) and all stakeholders who care about protecting\\nthe EU’s fundamental rights, freedoms and values to join this call to ban biometric mass\\nsurveillance. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 126, 'page': 37, '_split_overlap': [{'doc_id': 'e0e9de2a4875bfd8b4f0665920b17103', 'range': (0, 174)}, {'doc_id': 'ce611ec37b10f07a1b19a01e84059687', 'range': (744, 1102)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c11c795ed0a0a0573831f93eca6daff2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: We further encourage Members of the European Parliament – in particular the intergroup\\non Artificial Intelligence & Digital; the Committee of the Regions (CoR); the European\\nEconomic & Social Committee (EESC) and all stakeholders who care about protecting\\nthe EU’s fundamental rights, freedoms and values to join this call to ban biometric mass\\nsurveillance. We look to these public institutions to increase awareness of these issues\\nin a variety of ways, for example proposing Parliamentary Resolutions and including\\ncalls for a ban in opinions and reports.\\n97 Many ofthe relevant laws are analysed in the report Fundamental rights review of EU data collection instruments and pro-\\ngrammes <http://www.fondazionebrodolini.it/sites/default/files/final_report_0.pdf>\\x0c38\\n7.2 European Commission White Paper on AI\\nWithin the European Commission’s upcoming AI strategy, which was outlined in the Ar-\\ntificial Intelligence White Paper of 19 February 2020, the Commission proposed to in-\\nclude facial and biometric processing within a “high risk” regulatory framework for AI.\\nThe Commission should not attempt to “risk-assess” fundamental rights violations like\\nbiometric processing that leads to mass surveillance, just like it would not propose to\\n“risk assess” genocide or torture. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 127, 'page': 37, '_split_overlap': [{'doc_id': 'c11c795ed0a0a0573831f93eca6daff2', 'range': (0, 358)}, {'doc_id': '136fc9f86dc3f57df5d42657b240e47b', 'range': (1070, 1278)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ce611ec37b10f07a1b19a01e84059687'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: The Commission should not attempt to “risk-assess” fundamental rights violations like\\nbiometric processing that leads to mass surveillance, just like it would not propose to\\n“risk assess” genocide or torture. EDRi’s position is that biometric processing in public-\\nly-accessible spaces that leads to mass surveillance poses such a significant risk to the\\nvery essence of EU fundamental rights that it must be banned, and calls on DGs GROW,\\nCONNECT and JUST to ensure that the Commission’s position is compliant.\\nIndiscriminate, untargeted facial and biometric processing amounts to mass surveil-\\nlance and is inherently associated with violations of rights to privacy, data protection,\\ndignity, fundamental freedoms and justice. Whilst some uses of facial recognition or\\nother biometric processing may use so-called artificial intelligence in the form of ma-\\nchine learning algorithms, the problem that we are specifically concerned about is the\\nsocietal impact of any kind of mass surveillance, not the type of technology that is used\\nto achieve the outcome.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 128, 'page': 38, '_split_overlap': [{'doc_id': 'ce611ec37b10f07a1b19a01e84059687', 'range': (0, 208)}, {'doc_id': '3cd819bd1d0edfbf9bf69623590f24d0', 'range': (729, 1059)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '136fc9f86dc3f57df5d42657b240e47b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Whilst some uses of facial recognition or\\nother biometric processing may use so-called artificial intelligence in the form of ma-\\nchine learning algorithms, the problem that we are specifically concerned about is the\\nsocietal impact of any kind of mass surveillance, not the type of technology that is used\\nto achieve the outcome.\\nMoreover, the Commission’s AI strategy must appropriately regulate uses of AI that are\\noutside the ban in a way that still complies with fundamental rights, including under-\\ntaking human rights impact assessments (HRIAs) and halting measures that unlawfully\\nviolate fundamental rights on any grounds. Whilst the scope of EDRi’s call for a ban\\nspecifically relates to biometric mass surveillance, EDRi additionally strongly encour-\\nages the EU to cease funding for all biometric projects which are based on behavioural\\npredictions, to assess the fundamental rights compliance of all funded projects, and to\\nmake those assessments public and subject to public debate both with civil society and\\nwith the European Parliament.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 129, 'page': 38, '_split_overlap': [{'doc_id': '136fc9f86dc3f57df5d42657b240e47b', 'range': (0, 330)}, {'doc_id': '7de1a3d125756be8bba4b7eee87df64c', 'range': (632, 1053)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3cd819bd1d0edfbf9bf69623590f24d0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: Whilst the scope of EDRi’s call for a ban\\nspecifically relates to biometric mass surveillance, EDRi additionally strongly encour-\\nages the EU to cease funding for all biometric projects which are based on behavioural\\npredictions, to assess the fundamental rights compliance of all funded projects, and to\\nmake those assessments public and subject to public debate both with civil society and\\nwith the European Parliament.\\n7.3 Preventing a digital dystopia\\nData-hungry facial and other biometric processing that enable or contribute to mass\\nsurveillance are fundamentally at odds with the essence of human dignity, democrat-\\nic society, fundamental rights and freedoms, protections for personal data, procedural\\nrights, and the rule of law. The risks for increasing power imbalances, discrimination,\\nracism, inequalities and authoritarian societal control in mass biometric processing are\\ntoo high for any alleged “benefits” that the use of these technologies could ever conceiv-\\nably bring. If the EU believes in the essence of fundamental rights, it has no choice but\\nto ban the use of biometric processing that leads to mass surveillance in public spaces.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 130, 'page': 38, '_split_overlap': [{'doc_id': '3cd819bd1d0edfbf9bf69623590f24d0', 'range': (0, 421)}, {'doc_id': '831d7665e660e4be9691417176193563', 'range': (991, 1157)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7de1a3d125756be8bba4b7eee87df64c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: European Digital Rights (EDRi), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: Belgium, document_date: 09-06-2020 16:22, language: English, \\n\\nPassage: If the EU believes in the essence of fundamental rights, it has no choice but\\nto ban the use of biometric processing that leads to mass surveillance in public spaces.\\nEDRi’s call for action is not a ceiling, but a floor for addressing biometric processing\\nwhich violates the very core of European rights, freedoms and values.\\nRECOMMENDATIONS\\x0c39\\n“The use of biometric surveillance systems creates a dynamic\\nwhere the powerful watch and the powerless\\nare watched”\\n- European Digital Rights\\x0c40', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', 'stakeholder_name': 'European Digital Rights (EDRi)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '09-06-2020 16:22', 'language': 'English', 'document_reference': 'F530499', 'document_name': 'F530499-Paper-Ban-Biometric-Mass-Surveillance.pdf', '_split_id': 131, 'page': 38, '_split_overlap': [{'doc_id': '7de1a3d125756be8bba4b7eee87df64c', 'range': (0, 166)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '831d7665e660e4be9691417176193563'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: 1\\nARTIFICIAL INTELLIGENCE AND COMPETITION\\nPrepared jointly by the National Commission on Markets and Competition (CNMC) and\\nthe Catalan Competition Authority (ACCO), this report considers the need for changes in\\nthe tools available to competition authorities in view of the challenges posed by the\\nproliferation in the use of artificial intelligence (and of an increasingly digital economy).\\nIn particular, it is suggested that the rules be adapted so that competition authorities can\\nalso make use of artificial intelligence and that these public bodies can be more\\nreceptive to existing knowledge in this field.\\n1. Preface\\nThe European Commission White Paper on Artificial Intelligence (AI),1 released on 19th\\nFebruary 2020, sets out a series of initiatives and proposals in two broad categories on\\nwhich the public consultation is focused:\\n- Building an ecosystem of excellence for the development of AI in the European\\nUnion.\\n- Regulatory options in the sphere of artificial intelligence.\\nThe level of specificity of the proposed actions is quite limited in most cases, and any\\nreference to the perspective of protecting competition in the markets is omitted. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': 'c80ab7d9d993a89ace81db6793eac851', 'range': (993, 1163)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7445b70fe8ff698403197b4a9c9d27c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: The level of specificity of the proposed actions is quite limited in most cases, and any\\nreference to the perspective of protecting competition in the markets is omitted. This is\\nthe reason for this position paper proposed jointly by the National Commission on\\nMarkets and Competition and the Catalan Competition Authority, which outlines the\\nimpact that AI may have on competition in markets and proposes specific measures to\\naddress the challenges that AI creates for competition authorities.\\nIt is also important to point out that a number of initiatives contained in the White Paper\\nmust be developed taking into account the need to avoid distorting competition. In\\nparticular, the allocation of public funding, initiatives to promote inter-firm cooperation,\\nthe creation of public–private partnerships and other similar measures that could lead to\\nan unlevelled playing field or become barriers to entry for smaller undertakings.\\n2. Main challenges to competition posed by artificial intelligence (digital\\neconomy)\\nThe digital economy and what is probably its greatest exponent, artificial intelligence,\\nbring about radical changes in the way economic markets operate. These changes pose\\na number of challenges for competition enforcement. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 1, 'page': 1, '_split_overlap': [{'doc_id': '7445b70fe8ff698403197b4a9c9d27c', 'range': (0, 170)}, {'doc_id': '69d31d739fcf3f0d67842d39b47514fe', 'range': (938, 1244)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c80ab7d9d993a89ace81db6793eac851'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: Main challenges to competition posed by artificial intelligence (digital\\neconomy)\\nThe digital economy and what is probably its greatest exponent, artificial intelligence,\\nbring about radical changes in the way economic markets operate. These changes pose\\na number of challenges for competition enforcement. Although these have already been\\nidentified2,, we feel it appropriate to include a brief summary below.\\n1 https://op.europa.eu/es/publication-detail/-/publication/aace9398-594d-11ea-8b81-01aa75ed71a1\\n2 For example, by the Catalan Competition Authority itself in ‘The Data-Driven Economy. Challenges for competition' from\\nNovember 2016 (http://acco.gencat.cat/web/.content/80_acco/documents/arxius/actuacions/Eco-Dades-i-Competencia-\\nACCO-angles.pdf) and by the National Commission on Markets and Competition in various contributions to the OECD,\\nstudies and articles.\\nRef. Ares(2020)3356824 - 26/06/2020\\x0c2\\n\\uf0b7 The proliferation of zero-pricing business models in the digital economy\\nmeans that competition shifts from price and quantity variables to\\nqualitative variables related to service quality. This poses a challenge in terms\\nof measuring qualitative aspects, as at least some aspects of this concept are\\nfar less observable than price, which makes them difficult to quantify.3\\nAlthough quality (and variety) are already aspects analysed by competition\\nauthorities,4 the price factor is more often the core element of analysis.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 2, 'page': 1, '_split_overlap': [{'doc_id': 'c80ab7d9d993a89ace81db6793eac851', 'range': (0, 306)}, {'doc_id': 'f05c8b44ea78807449394f5adc2a73f1', 'range': (1105, 1438)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '69d31d739fcf3f0d67842d39b47514fe'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: This poses a challenge in terms\\nof measuring qualitative aspects, as at least some aspects of this concept are\\nfar less observable than price, which makes them difficult to quantify.3\\nAlthough quality (and variety) are already aspects analysed by competition\\nauthorities,4 the price factor is more often the core element of analysis.\\nHowever, as pointed out, in the digital economy, it is not expected that any\\nabuses of a dominant position will entail, at least in the short or medium term, a\\nloss of well-being consisting of a reduction in supply and increase in price, so the\\nassessment developed by competition authorities cannot focus on price. For\\nexample, possible abusive behaviour by large digital platforms could consist of a\\nhidden reduction in quality in terms of user privacy or the quality of information\\nprovided (rather than an increase in price).5\\n\\uf0b7 One of the aspects that characterises the digital environment is undoubtedly\\nspeed (how fast a user can subscribe to a service, information processing,\\nmaterial provision of services, etc.). This circumstance becomes even more\\nimportant as undertakings make use of artificial intelligence to accelerate the\\nalready particularly fast network effects experienced by digital platforms. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 3, 'page': 2, '_split_overlap': [{'doc_id': '69d31d739fcf3f0d67842d39b47514fe', 'range': (0, 333)}, {'doc_id': 'b059d1c43c3843ede041b27d2dad051f', 'range': (1058, 1249)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f05c8b44ea78807449394f5adc2a73f1'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: This circumstance becomes even more\\nimportant as undertakings make use of artificial intelligence to accelerate the\\nalready particularly fast network effects experienced by digital platforms. This\\ntherefore presents competition authorities with the challenge of reacting\\nquickly.\\nThe fact is that if a digital undertaking of considerable size engages in conduct\\nthat infringes competition law, it is likely that it will harm competition in the market\\nin a way that is hard to reverse if swift action is not taken. Faced with this problem,\\nsome competition authorities are imposing interim measures more frequently, as\\nwas the case with the French competition authority in the case of Google.6\\n\\uf0b7 What are known as data mergers or mergers between undertakings with a\\nsignificant volume of data can be comparatively more complex to assess,\\nas the data supports different uses. Thus, unlike brick and mortar mergers\\nwhere the relevant market is relatively obvious, when the merger can be\\nexplained by an interest in obtaining data, it is more difficult to anticipate it or to\\n3 The challenges associated with quality measurement in zero-price markets are identified in the CNMC's contribution to\\nthe OECD debate on this issue in November 2018 (https://www.oecd.org/competition/quality-considerations-in-the-zero-\\nprice-economy.htm#:~:text=Over%20the%20course%20of%20a,of%20products%20are%20not%20new).\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 4, 'page': 2, '_split_overlap': [{'doc_id': 'f05c8b44ea78807449394f5adc2a73f1', 'range': (0, 191)}, {'doc_id': '469a7633147f9dc63baf5d20812282f8', 'range': (874, 1397)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b059d1c43c3843ede041b27d2dad051f'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: Thus, unlike brick and mortar mergers\\nwhere the relevant market is relatively obvious, when the merger can be\\nexplained by an interest in obtaining data, it is more difficult to anticipate it or to\\n3 The challenges associated with quality measurement in zero-price markets are identified in the CNMC's contribution to\\nthe OECD debate on this issue in November 2018 (https://www.oecd.org/competition/quality-considerations-in-the-zero-\\nprice-economy.htm#:~:text=Over%20the%20course%20of%20a,of%20products%20are%20not%20new).\\n4 As detailed in the article 'Novedades en la aplicación de la política de competencia en la Unión Europea en 2018',\\nprepared by Beatriz de Guindos, Jordi Fornells and Francisco de Paula Roig\\n(http://www.revistasice.com/index.php/ICE/article/view/6659).\\n5 The founders of Google themselves warned of the risks associated with a private search engine in the early days of the\\nsearch engine. In particular, they stated that if an information search engine receives remuneration from advertisers, it\\nwill be tempted to omit or hide certain negative information about such advertisers and that such behaviour would be\\nparticularly harmful because of the impossibility of even being perceived by users of the search engine (\\nhttp://infolab.stanford.edu/~backrub/google.html)\\n6https://globalcompetitionreview.com/article/1225364/french-interim-measures-force-google-to-pay-\\npublishers#:~:text=France's%20Competition%20Authority%20has%20given,content%20in%20its%20search%20results.\\x0c3\\nidentify the many markets that may be affected. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 5, 'page': 2, '_split_overlap': [{'doc_id': 'b059d1c43c3843ede041b27d2dad051f', 'range': (0, 523)}, {'doc_id': 'fe4f23845cdfee74af6f95918d604ac1', 'range': (914, 1548)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '469a7633147f9dc63baf5d20812282f8'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: In particular, they stated that if an information search engine receives remuneration from advertisers, it\\nwill be tempted to omit or hide certain negative information about such advertisers and that such behaviour would be\\nparticularly harmful because of the impossibility of even being perceived by users of the search engine (\\nhttp://infolab.stanford.edu/~backrub/google.html)\\n6https://globalcompetitionreview.com/article/1225364/french-interim-measures-force-google-to-pay-\\npublishers#:~:text=France's%20Competition%20Authority%20has%20given,content%20in%20its%20search%20results.\\x0c3\\nidentify the many markets that may be affected. For example, when Google\\nacquired thermostat manufacturer Nest Labs in 2014, it was not obvious whether\\nit did so to obtain data on electricity consumption, and therefore that would be\\nthe relevant market, or if the relevant market instead continued to be online\\nadvertising – and it will use that information to better personalise ads, as it will\\nknow whether or not we are at home – or whether it will use the information on\\nconsumption to know whether or not we have an electric vehicle/scooter and\\ntherefore enter the mobility device market.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 6, 'page': 2, '_split_overlap': [{'doc_id': '469a7633147f9dc63baf5d20812282f8', 'range': (0, 634)}, {'doc_id': 'bc286058ac4b4f46e2fa86183993e65d', 'range': (635, 1180)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fe4f23845cdfee74af6f95918d604ac1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: For example, when Google\\nacquired thermostat manufacturer Nest Labs in 2014, it was not obvious whether\\nit did so to obtain data on electricity consumption, and therefore that would be\\nthe relevant market, or if the relevant market instead continued to be online\\nadvertising – and it will use that information to better personalise ads, as it will\\nknow whether or not we are at home – or whether it will use the information on\\nconsumption to know whether or not we have an electric vehicle/scooter and\\ntherefore enter the mobility device market.\\nThis new challenge has led a growing number of experts to suggest the need to\\nshift the burden of proof so that it is the parties involved in the merger that must\\ndemonstrate that the transaction is not harmful to competition, and in particular,\\nthat they themselves specify the market affected. This way, the competition\\nanalysis can be carried out in relation to the target market. And if in the future the\\ndata obtained through that transaction is used in relation to another undeclared\\nmarket, the competition authorities may intervene7.\\nUsing artificial intelligence makes it possible to get a greater return on\\ninformation. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 7, 'page': 3, '_split_overlap': [{'doc_id': 'fe4f23845cdfee74af6f95918d604ac1', 'range': (0, 545)}, {'doc_id': '3302ab2b26d68c443eaceeb614efee29', 'range': (930, 1175)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bc286058ac4b4f46e2fa86183993e65d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: And if in the future the\\ndata obtained through that transaction is used in relation to another undeclared\\nmarket, the competition authorities may intervene7.\\nUsing artificial intelligence makes it possible to get a greater return on\\ninformation. Therefore, it may be expected that there is a positive correlation\\nbetween the use of artificial intelligence and the number of data mergers that\\noccur, allowing us to assert that artificial intelligence intensifies the challenge\\ndescribed here.\\n\\uf0b7 In an increasingly data-driven, more transparent economy, where the use\\nof pricing algorithms is increasingly widespread, the possibility of\\nalgorithmic collusion is growing8. Using algorithms to refine pricing models or\\ncustomise services can generate efficiencies that benefit both businesses and\\nconsumers in terms of new, better and individualised goods and services.\\nHowever, the increasingly widespread use of algorithms can also lead to anti-\\ncompetitive behaviour by encouraging companies to coordinate their conduct\\nwithout the need for a formal agreement or even concerted practice or without\\nthe need for human interaction.\\nAlgorithms can facilitate collusion in different ways. First, they can be used to\\nmonitor and enforce an already established coordinated strategy. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 8, 'page': 3, '_split_overlap': [{'doc_id': 'bc286058ac4b4f46e2fa86183993e65d', 'range': (0, 245)}, {'doc_id': 'ec0066d61ff3f2ac2bb6a66d69ad6719', 'range': (1129, 1275)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3302ab2b26d68c443eaceeb614efee29'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: Algorithms can facilitate collusion in different ways. First, they can be used to\\nmonitor and enforce an already established coordinated strategy. This makes\\nagreements more stable and prolonged over time, as any deviation from the\\nagreement is quickly detected. This case requires explicit communication\\nbetween companies in order to establish and implement the cartel and\\nsubsequently, the use of an algorithm to monitor the agreement reached.\\nTherefore, it could be detected using the traditional tools of competition\\nauthorities, since the algorithm is used as a facilitating and disciplinary tool of the\\nagreement.\\n7 As mentioned in the document ‘Competition Policy for the Digital Era’ (2019), prepared by Jacques Crémer, Yves-\\nAlexandre de Montjoye and Heike Schweitzer. In addition, the Commissioner for Competition herself, Mrs Vestager, may\\nbe considering this possibility, and figures such as the former Chief Economist of Directorate-General for Competition,\\nMassimo Motta, may be openly in favour of it, as shown in the paper 'Challenges for EU Merger Control'\\n(https://econpapers.repec.org/paper/bonboncrc/crctr224_5f2019_5f077.htm)\\n8 This challenge is already identified, in the area of fintechs, in the CNMC study on the impact of new technologies on\\ncompetition in the financial sector, from 2018 (https://www.cnmc.es/expedientes/ecnmc00118).\\x0c\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 9, 'page': 3, '_split_overlap': [{'doc_id': '3302ab2b26d68c443eaceeb614efee29', 'range': (0, 146)}, {'doc_id': '7a0092eca9bd54114a132ef7ba9757aa', 'range': (778, 1359)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ec0066d61ff3f2ac2bb6a66d69ad6719'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: In addition, the Commissioner for Competition herself, Mrs Vestager, may\\nbe considering this possibility, and figures such as the former Chief Economist of Directorate-General for Competition,\\nMassimo Motta, may be openly in favour of it, as shown in the paper 'Challenges for EU Merger Control'\\n(https://econpapers.repec.org/paper/bonboncrc/crctr224_5f2019_5f077.htm)\\n8 This challenge is already identified, in the area of fintechs, in the CNMC study on the impact of new technologies on\\ncompetition in the financial sector, from 2018 (https://www.cnmc.es/expedientes/ecnmc00118).\\x0c4\\nThis is not the case when the use of pricing algorithms results in tacit coordination\\nwithout the need for communication or interaction between competitors.\\nIt may so happen that multiple companies hire the same software company to\\ndesign their pricing algorithm. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 10, 'page': 3, '_split_overlap': [{'doc_id': 'ec0066d61ff3f2ac2bb6a66d69ad6719', 'range': (0, 581)}, {'doc_id': 'b13ba8e22c779d073f0cca57e51b6d53', 'range': (582, 847)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7a0092eca9bd54114a132ef7ba9757aa'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: 4\\nThis is not the case when the use of pricing algorithms results in tacit coordination\\nwithout the need for communication or interaction between competitors.\\nIt may so happen that multiple companies hire the same software company to\\ndesign their pricing algorithm. This could create a hub-and-spoke scenario in\\nwhich competitors use the same hub to develop their algorithms, resulting in the\\nuse of the same algorithm or very similar versions for pricing, facilitating\\ncoordinated behaviour by companies that are setting their pricing strategy using\\nthe same 'brain'.9 It should be noted that this effect is intensified when companies\\nalso use the same data set to feed their algorithm, because this allows the cartel\\nprice reached by the algorithm to be more profitable for the companies that use\\nit.10\\nAnother possibility is to behave like a predictable agent, that is, each company\\nestablishes its mechanism for setting prices, but reacts predictably to external\\nfactors. This behaviour can be detected and monitored by other agents, thus\\nsending out an invitation to collude.\\nFinally, companies could choose to implement deep learning algorithms to make\\npricing decisions. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 11, 'page': 4, '_split_overlap': [{'doc_id': '7a0092eca9bd54114a132ef7ba9757aa', 'range': (0, 265)}, {'doc_id': '1aa7fe02db0af327132022e8f331f288', 'range': (976, 1177)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b13ba8e22c779d073f0cca57e51b6d53'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: This behaviour can be detected and monitored by other agents, thus\\nsending out an invitation to collude.\\nFinally, companies could choose to implement deep learning algorithms to make\\npricing decisions. In this case, competitors would unilaterally design their pricing\\nalgorithms by selecting a specific goal, such as maximising profit. If the algorithm\\nis sufficiently complex, it learns, similarly to how the human brain would, and it\\ndetermines the optimal pricing strategy on its own, possibly concluding that the\\nbest strategy is to collude. The main problem for competition authorities in these\\ncases is that the algorithm makes decisions without revealing information about\\nthe process followed, so they would be faced with a black box that must be\\nanalysed in order to determine if there is a case of virtual collusion.\\n\\uf0b7 New barriers to entry related to artificial intelligence may arise, including\\naccess to data11. From this perspective, data is an essential input since it feeds\\nAI algorithms. The ability of algorithms to detect patterns of behaviour and\\nrelationships depends on the quality, quantity and variety of the data used.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 12, 'page': 4, '_split_overlap': [{'doc_id': 'b13ba8e22c779d073f0cca57e51b6d53', 'range': (0, 201)}, {'doc_id': 'b7aac4cfa4170fdf0bcc3e44d38a1043', 'range': (1005, 1143)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1aa7fe02db0af327132022e8f331f288'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: The ability of algorithms to detect patterns of behaviour and\\nrelationships depends on the quality, quantity and variety of the data used.\\nProviding little or inadequate data when training the algorithm results in poor\\nperformance of the algorithm and the possibility of drawing erroneous\\nconclusions from the results generated. Therefore, exclusionary or predatory\\npractices by some companies to limit their competitors' access to data may result\\nin barriers to entry.\\n9 'Artificial Intelligence & collusion: when computers inhibit competition' (2017), authored by Ariel Ezrachi and Maurice E.\\nStucke (https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2591874).\\n10 'Algorithms and Collusion: Competition Policy in the Digital Age', OECD (2017) (www.oecd.org/competition/algorithms-\\ncollusion-competition-policy-in-the-digital-age.htm).\\n11 As identified in the CNMC's contribution to the conference organised by the European Commission on 'Shaping\\ncompetition policy in the era of digitisation' in January 2019\\n(https://ec.europa.eu/competition/scp19/media_en.html#Contributions)\\x0c5\\nIt is true that data is not an easily monopolisable asset, in the sense that the same\\nindividual can give multiple companies access to its data. However, it may also\\nhappen that certain relevant information is only owned or acquired by one\\ncompany, through exclusive contracts with external data providers, and that this\\ncompany excludes or attempts to exclude its competitors from its data\\nwarehouse12. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 13, 'page': 4, '_split_overlap': [{'doc_id': '1aa7fe02db0af327132022e8f331f288', 'range': (0, 138)}, {'doc_id': '3dc61922486cc86eb7e136b04af69736', 'range': (1229, 1487)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b7aac4cfa4170fdf0bcc3e44d38a1043'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: However, it may also\\nhappen that certain relevant information is only owned or acquired by one\\ncompany, through exclusive contracts with external data providers, and that this\\ncompany excludes or attempts to exclude its competitors from its data\\nwarehouse12. In the case of data, we already have a structure in which\\ncompetition is highly weakened, given that the value and usefulness of the data\\nis growing exponentially with the volume of data processed, thus giving a\\nconsiderable advantage to the large established undertakings and suggesting a\\ntrend towards market concentration. It would be important, in order to ensure an\\nadequate level of competition in AI, for competition authorities to have tools to\\nensure that potential new undertakings offering AI-based services can access the\\nsame volume of data as incumbents, for example, by the user having the option\\nto transfer the historical data they have generated from the current service\\nprovider to the new service provider of their choice13.\\n\\uf0b7 Artificial intelligence makes it possible to offer particularly personalised services.\\nConsider, for example, voice assistants that, instead of offering a list of possible\\nresults, offer a single answer straightaway. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 14, 'page': 5, '_split_overlap': [{'doc_id': 'b7aac4cfa4170fdf0bcc3e44d38a1043', 'range': (0, 258)}, {'doc_id': 'ff2fc82339fc4adf2aa9902a149985d8', 'range': (1004, 1222)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3dc61922486cc86eb7e136b04af69736'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: \\uf0b7 Artificial intelligence makes it possible to offer particularly personalised services.\\nConsider, for example, voice assistants that, instead of offering a list of possible\\nresults, offer a single answer straightaway. Thus, the trend towards hyper\\npersonalisation – reinforced by AI – entails an additional risk in terms of\\ncompetition, insofar as when a user searches for a particular product, it may\\nlead them to a single supplier. The other competitors are not even mentioned.\\nThis therefore significantly increases the existing risk that whoever controls the\\ndevice (voice assistant, to continue with the example) will use their 'gatekeeper'\\nposition to benefit themself (in the event they also produce or offer the required\\nproduct or service) or help an undertaking with which they have been able to\\nreach some kind of agreement.\\nGiven the situation described above, competition authorities are likely to find\\nthemselves needing to tackle possible competitive imbalances arising from this\\nbehaviour. This would require mechanisms that would force the undertaking to\\nbehave in a neutral manner. Additionally, the requirement of neutrality in respect\\nof the service concerned should be reasonably structured in order to maintain its\\npersonalisation and efficiency functionalities.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 15, 'page': 5, '_split_overlap': [{'doc_id': '3dc61922486cc86eb7e136b04af69736', 'range': (0, 218)}, {'doc_id': '1fe9664c1e088bfd6ade0ce1900fbb8c', 'range': (1101, 1285)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ff2fc82339fc4adf2aa9902a149985d8'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: Additionally, the requirement of neutrality in respect\\nof the service concerned should be reasonably structured in order to maintain its\\npersonalisation and efficiency functionalities.\\n12 As detailed in the CNMC's contribution to the OECD round table discussion on ‘Consumer Data Rights and Competition’\\nin June 2020 (http://www.oecd.org/daf/competition/consumer-data-rights-and-competition.htm).\\n13 An initial step to be able to carry out such information transfer by users involves them knowing which service provider\\nhas their data and what data they hold. In this regard, 'personal information management systems' (PIMS), already\\nrecommended by the European Data Protection Supervisor in Opinion 9/2016, are particularly attractive. 'EDPS Opinion\\non Personal Information Management Systems. Towards more user empowerment in managing and processing personal\\ndata'. Examples of PIMS are the websites reclamadatos.es or saymine.com.\\x0c6\\n3. Adaptation of the competition authorities’ toolkit to oversee the use of\\nAI by undertakings\\nThe competition authorities’ toolkit is powerful and flexible. However, it must be adapted\\nto digital reality to address the new challenges posed by AI and the data economy.\\nAlthough the possibility of algorithmic collusion is a reality, theoretically and empirically\\ndemonstrated, competition authorities are detecting hardly any cases. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 16, 'page': 5, '_split_overlap': [{'doc_id': 'ff2fc82339fc4adf2aa9902a149985d8', 'range': (0, 184)}, {'doc_id': '5172d0c5ad8d0eeadc528661c9fcee2d', 'range': (1205, 1368)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1fe9664c1e088bfd6ade0ce1900fbb8c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: Although the possibility of algorithmic collusion is a reality, theoretically and empirically\\ndemonstrated, competition authorities are detecting hardly any cases. At the European\\nlevel, mention should be made of three cases in which sanctions have already been\\nimposed14. And the Spanish competition authority is currently investigating a possible\\ncase of algorithmic collusion in the property brokerage market.15 .\\nIn these past cases, the algorithms were used only as facilitators of an explicit agreement\\nbetween competitors, so it was possible to detect them using the traditional tools of\\ncompetition authorities. However, it is noteworthy that given how frequently pricing\\nalgorithms are used (according to a 2017 European Commission report on online\\ncommerce, two-thirds of online distributors use automatic software to adjust their own\\nprices to the monitored prices of their competitors), there are not more cases and, in\\nparticular, no situations identified so far of tacit coordination as described in the second\\nsubparagraph of the document16.\\nAmong the possible reasons for this relatively low rate of detection of algorithmic\\ncollusion is the lack of specialised profiles in the field of artificial intelligence and a lack\\nof specific training on these issues for Competition authorities’ officials. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 17, 'page': 6, '_split_overlap': [{'doc_id': '1fe9664c1e088bfd6ade0ce1900fbb8c', 'range': (0, 163)}, {'doc_id': 'd071ea0ee5610d8356f19c28323b7844', 'range': (1057, 1314)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5172d0c5ad8d0eeadc528661c9fcee2d'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: Among the possible reasons for this relatively low rate of detection of algorithmic\\ncollusion is the lack of specialised profiles in the field of artificial intelligence and a lack\\nof specific training on these issues for Competition authorities’ officials. In this respect,\\nthe challenges faced by competition authorities include understanding the specific\\n14 In 2016, the British Competition Authority, the Competition and Markets Authority (CMA), sanctioned an online poster\\ncartel in which the parties had agreed not to lower the prices of posters sold on the Amazon website in the UK. Price\\nadjustment software was used to implement the agreement.\\nIn 2018, the European Commission sanctioned four electronics manufacturers for imposing resale prices on their online\\ndistributors. The Commission emphasised that the companies had used sophisticated algorithms to monitor the price set\\nby distributors, allowing them to take quick action in the event of a price reduction.\\nIn 2019, UK energy market regulator OFGEM fined two energy companies for agreeing not to take each other's customers\\nby using software that blocked registration of the other company's customers. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 18, 'page': 6, '_split_overlap': [{'doc_id': '5172d0c5ad8d0eeadc528661c9fcee2d', 'range': (0, 257)}, {'doc_id': '34b1092bdbb023ef822fa20f0423e435', 'range': (976, 1170)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd071ea0ee5610d8356f19c28323b7844'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: In 2019, UK energy market regulator OFGEM fined two energy companies for agreeing not to take each other's customers\\nby using software that blocked registration of the other company's customers. In this case, the two companies had an\\nagreement to divide up markets and assign customers, and the algorithm was used to make the process of checking the\\ncustomer list easier and more efficient and to verify that both companies were fulfilling the established agreement.\\nIn addition, there would be hub-and-spoke cases, which without being directly affected by algorithmic collusion, could be\\nbrought into the digital world. Among others, the Eturas case should be highlighted, in which the online booking system\\nused by travel agencies limited the maximum amount of the discount\\n(http://competitionlawblog.kluwercompetitionlaw.com/2017/01/19/eturas-conclusions-platform-\\ncollusion/?doing_wp_cron=1591203312.7948870658874511718750).\\n15 In this case, in which currently investigation is still ongoing, coordination would have been implemented, among other\\nmeans, through the use of software and computer platforms and would have been facilitated by companies specialising\\nin computer solutions through the design of the property management software and its algorithms (\\nhttps://www.cnmc.es/sites/default/files/editor_contenidos/2020219%20NP%20Intermediation%20Market%20EN_.pdf)\\n16 Final report on the E-commerce Sector Inquiry. Report from the Commission to the Council and the European\\nParliament.\\x0c\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 19, 'page': 6, '_split_overlap': [{'doc_id': 'd071ea0ee5610d8356f19c28323b7844', 'range': (0, 194)}, {'doc_id': '41d7d9c8877db55c21d508ba6db12991', 'range': (929, 1493)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '34b1092bdbb023ef822fa20f0423e435'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: 15 In this case, in which currently investigation is still ongoing, coordination would have been implemented, among other\\nmeans, through the use of software and computer platforms and would have been facilitated by companies specialising\\nin computer solutions through the design of the property management software and its algorithms (\\nhttps://www.cnmc.es/sites/default/files/editor_contenidos/2020219%20NP%20Intermediation%20Market%20EN_.pdf)\\n16 Final report on the E-commerce Sector Inquiry. Report from the Commission to the Council and the European\\nParliament.\\x0c7\\nfunctioning of these algorithms, how they can facilitate collusion and how to detect\\npossible violations arising from their use.\\nAnother reason may be that the tools available to competition authorities need to be\\nadapted to the digital reality in order to be able to identify this type of anti-competitive\\npractices more widely.\\n1. In order to be able to deal effectively with the new challenges posed by the data\\neconomy and artificial intelligence, it would be advisable for competition authorities\\nto have the following options to exercise effective control over this new reality:\\n1.1. Access to the necessary information that would also make it possible to\\nuse AI tools to effectively control the behaviour of companies and to be\\nable to detect anti-competitive behaviour ex officio.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 20, 'page': 6, '_split_overlap': [{'doc_id': '34b1092bdbb023ef822fa20f0423e435', 'range': (0, 564)}, {'doc_id': '3ee7033419fe129ebf9ed2ccbdcd2674', 'range': (1157, 1355)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '41d7d9c8877db55c21d508ba6db12991'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: Access to the necessary information that would also make it possible to\\nuse AI tools to effectively control the behaviour of companies and to be\\nable to detect anti-competitive behaviour ex officio.\\nIn other words, competition authorities' control mechanisms should also be able\\nto make use of AI, and to this end, it is essential to be able to access all relevant\\ninformation. This would include information held by the public administrations,\\nincluding information from public procurement, an area particularly affected by\\ncollusive conduct, but also information related to companies, which makes it\\npossible to monitor their behaviour, particularly in terms of prices (such as data\\ncollected through cookies), and even information about users (so as to be able to\\ndetermine, for example, whether they are being discriminated)17.\\nThis need contrasts with the current situation in which, for example, some\\nwebsites detect and block their users when they engage in web scraping, so that\\nobtaining the information itself may not be feasible for control bodies. As a\\nremedy to this situation, it is suggested that mechanisms be set up that allow\\ncompetition authorities to have effective access to data relevant to their\\ninvestigations.\\n1.2. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 21, 'page': 7, '_split_overlap': [{'doc_id': '41d7d9c8877db55c21d508ba6db12991', 'range': (0, 198)}, {'doc_id': '6435b6f0d99547af862ab68268e81173', 'range': (1060, 1239)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3ee7033419fe129ebf9ed2ccbdcd2674'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: As a\\nremedy to this situation, it is suggested that mechanisms be set up that allow\\ncompetition authorities to have effective access to data relevant to their\\ninvestigations.\\n1.2. In the framework of an investigation, being able to monitor the code of the\\nalgorithm used and to access the information available on computer or\\nelectronic media, databases, applications, IT services, digital platforms and\\napplication programming interfaces. Furthermore, it should be possible to\\naccess the data entered in algorithms and used by companies, in particular it\\nshould be possible to track the data in order to detect exchanges of sensitive\\ninformation between companies. In this regard, the process of transposing the\\nECN+ Directive provides an important opportunity for Member States to\\nstrengthen the investigative powers of competition authorities in this domain.\\n2. Additionally, the availability of the software, hardware and cloud computing\\nneeded to implement AI techniques can be a barrier to entry, so it is very\\nimportant to have a sound knowledge of these markets.\\n17 Always following Organic Law 3/2018, of 5 December, on the Protection of Personal Data and guarantee of digital\\nrights.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 22, 'page': 7, '_split_overlap': [{'doc_id': '3ee7033419fe129ebf9ed2ccbdcd2674', 'range': (0, 179)}, {'doc_id': 'c2309200402237ff0ac19d8aa8ccd6ef', 'range': (1071, 1193)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6435b6f0d99547af862ab68268e81173'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: 17 Always following Organic Law 3/2018, of 5 December, on the Protection of Personal Data and guarantee of digital\\nrights.\\x0c8\\nThe development of algorithms with good explanatory and predictive capabilities\\nrequires advanced AI and data mining software. Additionally, some AI algorithms,\\nmainly those involved in deep learning, are computing intensive. To train a neural\\nnetwork, which can have a trillion neurons trained in thousands of training iterations,\\nhigh processing capacity is required. In order to achieve some efficiency, specialised\\nAI processors are used to reduce training times.\\nWhat is more, in many cases, the huge amounts of data stored to implement AI\\ntechniques create problems in terms of storage and processing, so there emerges a\\nneed to rely on IT infrastructure providers, which provide storage and computing\\ncapacity in the cloud. The emergence of cloud computing has allowed small\\nbusinesses to operate without the necessary physical infrastructure, thus reducing\\nbarriers to entry. However, the number of companies that provide access to this type\\nof computing is small, including Amazon Web Service, Microsoft Azure, Google\\nCloud Platform or IBM Cloud.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 23, 'page': 7, '_split_overlap': [{'doc_id': '6435b6f0d99547af862ab68268e81173', 'range': (0, 122)}, {'doc_id': 'b2ff30bf75c717644d2708443f393afb', 'range': (1009, 1180)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c2309200402237ff0ac19d8aa8ccd6ef'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: However, the number of companies that provide access to this type\\nof computing is small, including Amazon Web Service, Microsoft Azure, Google\\nCloud Platform or IBM Cloud.\\nIt should be noted that these companies also develop the software and hardware\\nnecessary to process large data sets and they provide it to companies that hire their\\ncloud services. Therefore, small businesses may consider this option very useful and\\nprocess their data using the software and hardware provided by them. As a result, a\\nlarge number of companies would be leaving data storage, control and\\nprocessing in the hands of a small number of suppliers, in turn facilitating access\\nto large volumes and a wide variety of data, enabling them to improve their own data\\nanalysis algorithms. According to the OECD, if this trend continues, a competition\\nproblem may arise in the future, as new companies may not be able to build IT\\ninfrastructures powerful enough to enable them to compete with those of the\\nincumbents, and the supply of software, hardware and cloud computing needed to\\nimplement AI techniques would be concentrated in the hands of few companies18.\\n2.1. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 24, 'page': 8, '_split_overlap': [{'doc_id': 'c2309200402237ff0ac19d8aa8ccd6ef', 'range': (0, 171)}, {'doc_id': '476fc98c3d8e0956fa209ed0942f5eeb', 'range': (765, 1143)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b2ff30bf75c717644d2708443f393afb'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: According to the OECD, if this trend continues, a competition\\nproblem may arise in the future, as new companies may not be able to build IT\\ninfrastructures powerful enough to enable them to compete with those of the\\nincumbents, and the supply of software, hardware and cloud computing needed to\\nimplement AI techniques would be concentrated in the hands of few companies18.\\n2.1. While processing capacity is essential to the implementation of AI, to guarantee\\nthe existence of AI competition, it is also essential to ensure that undertakings\\ncan access such processing capability (in both software and hardware, and\\ncloud computing) in a neutral manner. The need to analyse this processing\\nmarket is even greater insofar as it is highly concentrated among few suppliers\\nthat could have a clear conflict of interest as companies providing AI tools while\\nalso being users of these same tools.\\n4. Greater permeability of competition authorities\\nThe main contribution contained in this document is the need to ensure that competition\\nauthorities can make use of AI to effectively oversee the use of AI by undertakings.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 25, 'page': 8, '_split_overlap': [{'doc_id': 'b2ff30bf75c717644d2708443f393afb', 'range': (0, 378)}, {'doc_id': '155adeaee362b589c9543d120deb947c', 'range': (894, 1114)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '476fc98c3d8e0956fa209ed0942f5eeb'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: Greater permeability of competition authorities\\nThe main contribution contained in this document is the need to ensure that competition\\nauthorities can make use of AI to effectively oversee the use of AI by undertakings.\\nAs noted above, in order to make use of AI, it is materially essential to be able to access\\n(i) the information and (ii) the necessary processing capacity. However, we must not\\nforget the need for access to an intangible element: knowledge in this field. This is\\n18 'Big Data: bringing competition to the digital era', OECD (2016) (https://www.oecd.org/competition/big-data-bringing-\\ncompetition-policy-to-the-digital-era.htm)\\x0c9\\nwhy it is suggested below that competition authorities be more receptive to outside\\nknowledge, as in general terms, they are primarily made up of law and economics\\nprofessionals and to a much lesser extent, professionals who have an adequate\\nknowledge of AI and other disciplines that are part of the digital economy (such as data\\nprotection).\\nAlthough it is true that we must try to train staff internally in relation to these new digital\\nareas, it is also essential to be able to obtain knowledge outside the institution itself. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 26, 'page': 8, '_split_overlap': [{'doc_id': '476fc98c3d8e0956fa209ed0942f5eeb', 'range': (0, 220)}, {'doc_id': 'c4ed5a98694102a9efbe4ef96c9259ff', 'range': (994, 1180)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '155adeaee362b589c9543d120deb947c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: Although it is true that we must try to train staff internally in relation to these new digital\\nareas, it is also essential to be able to obtain knowledge outside the institution itself. For\\nthis purpose, below we propose greater cross-flow between competition authorities\\nthemselves and (i) other bodies or public administrations that are making use of\\nthese tools, (ii) research centres and universities, and (iii) data protection\\nauthorities to the extent that the artificial intelligence itself pivots essentially over the\\ndata.\\n\\uf0b7 Strengthening cooperation between competition authorities and public bodies by\\nseeking to share knowledge and experience in the field of AI.\\nFrom this cooperation, new ideas and applications for AI techniques can easily\\nemerge, supporting both the functioning of the bodies themselves and citizens.\\n\\uf0b7 In particular, strengthening cooperation between competition authorities and data\\nprotection authorities in order to take advantage of possible synergies.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 27, 'page': 9, '_split_overlap': [{'doc_id': '155adeaee362b589c9543d120deb947c', 'range': (0, 186)}, {'doc_id': 'f5d140ebb7f2e05cdf912b512899aa32', 'range': (834, 990)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c4ed5a98694102a9efbe4ef96c9259ff'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: \\uf0b7 In particular, strengthening cooperation between competition authorities and data\\nprotection authorities in order to take advantage of possible synergies.\\nThere may be synergies between data protection and competition authorities in\\nrelation to, for example, (i) data portability, (ii) possible qualitative abuses in terms\\nof privacy, and (iii) data merger analysis.19\\n\\uf0b7 Increased cooperation between competition authorities, research centres and\\nuniversities to achieve greater take-up of AI by the public sector.20\\nAgain, in order to take advantage of synergies, it may be very important to\\nstrengthen cooperation between competition authorities and research centres\\nand universities. Sharing experiences, knowledge and available data favours\\nboth competition authorities and research centres and increases knowledge and\\ntake-up of AI by the public sector.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 28, 'page': 9, '_split_overlap': [{'doc_id': 'c4ed5a98694102a9efbe4ef96c9259ff', 'range': (0, 156)}, {'doc_id': '37eaf4da51bcc2ec0193da3831c79801', 'range': (689, 860)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f5d140ebb7f2e05cdf912b512899aa32'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO), stakeholder_type: Public authority, stakeholder_scope: National, stakeholder_size: Large (250 or more), stakeholder_country: Spain, document_date: 19-06-2020 17:06, language: English, \\n\\nPassage: Sharing experiences, knowledge and available data favours\\nboth competition authorities and research centres and increases knowledge and\\ntake-up of AI by the public sector.\\n19 On the areas where such synergies could arise more significantly, see the October 2017 document within the framework\\nof the Digital Clearinghouse (initiative to coordinate data protection, consumer and competition authorities led by EDPS),\\n'Long Term Impact of Big Tech Sector Mergers: A proposal for specific cooperation mechanisms between competition\\nauthorities and data protection agencies', by M. REALP, X. PUIG (ACCO) and E. THOMTON (Competition and Consumer\\nProtection Commission, Ireland),\\n(http://acco.gencat.cat/web/.content/80_acco/documents/arxius/actuacions/20180130_Long-Term-Impact-of-Big-Tech-\\nSector-Mergers-2.pdf)\\n20 The CNMC is currently undergoing training, among other things, on artificial intelligence issues, thanks to the European\\nCommission program to improve the detection of competition infringements.\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', 'stakeholder_name': 'National Commission on Markets and Competition (CNMC) and Catalan Competition Authority (ACCO)', 'stakeholder_type': 'Public authority', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'Spain', 'stakeholder_scope': 'National', 'document_date': '19-06-2020 17:06', 'language': 'English', 'document_reference': 'F529887', 'document_name': 'F529887-CNMC_S_AND_ACCO_S_JOINT_CONTRIBUTION__TO_THE_PUBLIC_CONSULTATION_ON_AI.pdf', '_split_id': 29, 'page': 9, '_split_overlap': [{'doc_id': 'f5d140ebb7f2e05cdf912b512899aa32', 'range': (0, 171)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '37eaf4da51bcc2ec0193da3831c79801'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: 1\\nComments on “White Paper on Artificial Intelligence:\\na European approach to excellence and trust”\\nJune 10, 2020\\nAI Utilization Strategy Task Force\\nCommittee on Digital Economy\\nKeidanren\\n1. Overview\\nThe AI White Paper1 released recently by the European Commission deals with both AI\\ninnovation by a broad range of entities, including small and mid-sized enterprises, and\\nbuilding an “ecosystem of trust” for the utilization of AI. This is in line with Keidanren’s\\ngoal of building a “Trusted Quality AI Ecosystem.”\\nHowever, the European Commission uses a very broad definition of its envisioned AI,\\nencompassing AI systems using deep learning and other forms of machine learning, AI\\nbased on symbol manipulation, as well as a broad range of information systems beyond the\\nbounds of AI, such as technologies combining data, algorithms, and computing power\\nwhose reasoning process is not a “black box.” While the difficulty of defining AI is\\nunderstandable, careful thought still needs to be given to its definition since no entity has\\nyet succeeded in coming up with a widely accepted precise definition.\\nAI technology and business are still in the development phase. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': 'd8cf37293854f89f120a1973d270bb6b', 'range': (432, 1167)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6439d326bdbb528d3a96f27399240b2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: This is in line with Keidanren’s\\ngoal of building a “Trusted Quality AI Ecosystem.”\\nHowever, the European Commission uses a very broad definition of its envisioned AI,\\nencompassing AI systems using deep learning and other forms of machine learning, AI\\nbased on symbol manipulation, as well as a broad range of information systems beyond the\\nbounds of AI, such as technologies combining data, algorithms, and computing power\\nwhose reasoning process is not a “black box.” While the difficulty of defining AI is\\nunderstandable, careful thought still needs to be given to its definition since no entity has\\nyet succeeded in coming up with a widely accepted precise definition.\\nAI technology and business are still in the development phase. It is necessary to prioritize\\ndiscussions with the stakeholders and promotion of greater sharing of efficient processes\\nand technologies in order to come to a broad common understanding. The White Paper\\nneeds to state that hasty regulation runs the risk of obstructing the utilization of AI and\\nbusiness activities in society.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 1, 'page': 1, '_split_overlap': [{'doc_id': '6439d326bdbb528d3a96f27399240b2', 'range': (0, 735)}, {'doc_id': '617d63073a99df5054bbe33f9ad79078', 'range': (923, 1062)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd8cf37293854f89f120a1973d270bb6b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: The White Paper\\nneeds to state that hasty regulation runs the risk of obstructing the utilization of AI and\\nbusiness activities in society.\\nThe necessary tools cannot be maintained and social benefits may be undermined unless the\\nfollowing goals can all be achieved: rapid technological innovation, which characterizes the\\nAI fields; finding an optimal balance in human rights by both safeguarding people’s privacy\\n1 White Paper on Artificial Intelligence: a European approach to excellence and trust（released on Feb.\\n19, 2020）\\nRef. Ares(2020)3359061 - 26/06/2020\\x0c2\\nand ensuring people’s day-to-day livelihoods, safety, and health, an issue that has emerged\\namid the COVID-19 crisis; and ensuring the profitability of business activities. As well as\\nlooking for ways to institute balanced regulations, we hope that discussions from now on\\nwill lead to the compatibility of future standards and regulations, mutual recognition of\\nlabeling, and such other matters relating to building coherent and compatible AI\\necosystems.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 2, 'page': 1, '_split_overlap': [{'doc_id': 'd8cf37293854f89f120a1973d270bb6b', 'range': (0, 139)}, {'doc_id': '94be5629e50f96640b9d1669eb544608', 'range': (739, 1021)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '617d63073a99df5054bbe33f9ad79078'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: As well as\\nlooking for ways to institute balanced regulations, we hope that discussions from now on\\nwill lead to the compatibility of future standards and regulations, mutual recognition of\\nlabeling, and such other matters relating to building coherent and compatible AI\\necosystems.\\n２．Specific Points\\nPage 7 E. PARTNERSHIP WITH THE PRIVATE SECTOR\\nPage 7, last paragraph\\n“Action 5: In the context of Horizon Europe, the Commission will set up a new public\\nprivate partnership in AI, data and robotics to combine efforts, ensure coordination of\\nresearch and innovation in AI, collaborate with other public-private partnerships in Horizon\\nEurope and work together with the testing facilities and the Digital Innovation Hubs\\nmentioned above.”\\nOur comment\\n\\uf06c Collaboration between Japan and the EU giving full play to their strengths will\\ncontribute to the promotion of AI innovation. Consideration of cooperation with the\\nJapanese government, research organizations, and industry in Horizon Europe should be\\naccelerated.\\nPage 8 G. SECURING ACCESS TO DATA AND COMPUTING INFRASTRUCTURE\\nPage 8, paragraph 3\\n“Promoting responsible data management practices and compliance of data with the FAIR\\nprinciples will contribute to build trust and ensure re-usability of data. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 3, 'page': 2, '_split_overlap': [{'doc_id': '617d63073a99df5054bbe33f9ad79078', 'range': (0, 282)}, {'doc_id': '953d705534917f36508b1c3c7708b905', 'range': (1016, 1259)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '94be5629e50f96640b9d1669eb544608'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: Page 8 G. SECURING ACCESS TO DATA AND COMPUTING INFRASTRUCTURE\\nPage 8, paragraph 3\\n“Promoting responsible data management practices and compliance of data with the FAIR\\nprinciples will contribute to build trust and ensure re-usability of data. Equally important is\\x0c3\\ninvestment in key computing technologies and infrastructures.”\\nOur comment\\n\\uf06c In view of the importance of management and compliance systems that will facilitate\\nthe utilization of data while also protecting privacy and securing individual rights,\\nconcrete steps for “responsible data management” should be considered based on\\ndiscussions under various international frameworks.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 4, 'page': 2, '_split_overlap': [{'doc_id': '94be5629e50f96640b9d1669eb544608', 'range': (0, 243)}, {'doc_id': '2555bd869f75ba6711c6f9c79a8e4e8d', 'range': (244, 644)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '953d705534917f36508b1c3c7708b905'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: Equally important is\\x0c3\\ninvestment in key computing technologies and infrastructures.”\\nOur comment\\n\\uf06c In view of the importance of management and compliance systems that will facilitate\\nthe utilization of data while also protecting privacy and securing individual rights,\\nconcrete steps for “responsible data management” should be considered based on\\ndiscussions under various international frameworks.\\nPage 8 H. INTERNATIONAL ASPECTS\\nPage 8, last paragraph–page 9, first paragraph\\n“The EU will continue to cooperate with like-minded countries, but also with global\\nplayers, on AI, based on an approach based on EU rules and values… The Commission is\\nconvinced that international cooperation on AI matters must be based on an approach that\\npromotes the respect of fundamental rights, including human dignity, pluralism, inclusion,\\nnon-discrimination and protection of privacy and personal data26 and it will strive to export\\nits values across the world.”\\nOur comments\\n\\uf06c We hope for more in-depth discussions by the OECD and other like-minded nations\\ntoward the establishment of international rules on AI development and utilization that\\nwill ensure the promotion of innovation. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 5, 'page': 2, '_split_overlap': [{'doc_id': '953d705534917f36508b1c3c7708b905', 'range': (0, 400)}, {'doc_id': '4f069d561a109947a9b07cc321049449', 'range': (401, 1175)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2555bd869f75ba6711c6f9c79a8e4e8d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: Page 8 H. INTERNATIONAL ASPECTS\\nPage 8, last paragraph–page 9, first paragraph\\n“The EU will continue to cooperate with like-minded countries, but also with global\\nplayers, on AI, based on an approach based on EU rules and values… The Commission is\\nconvinced that international cooperation on AI matters must be based on an approach that\\npromotes the respect of fundamental rights, including human dignity, pluralism, inclusion,\\nnon-discrimination and protection of privacy and personal data26 and it will strive to export\\nits values across the world.”\\nOur comments\\n\\uf06c We hope for more in-depth discussions by the OECD and other like-minded nations\\ntoward the establishment of international rules on AI development and utilization that\\nwill ensure the promotion of innovation. We also hope that national leaders will reach a\\nconsensus on this at the G20 and other international frameworks, taking into account\\nthe realities and values in each region.\\n\\uf06c Since AI technology continues to evolve, it is not desirable to apply today’s standards to\\nfuture AI technology. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 6, 'page': 3, '_split_overlap': [{'doc_id': '2555bd869f75ba6711c6f9c79a8e4e8d', 'range': (0, 774)}, {'doc_id': 'd763c18864e890c3fbf42f83a595725d', 'range': (775, 1063)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4f069d561a109947a9b07cc321049449'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: We also hope that national leaders will reach a\\nconsensus on this at the G20 and other international frameworks, taking into account\\nthe realities and values in each region.\\n\\uf06c Since AI technology continues to evolve, it is not desirable to apply today’s standards to\\nfuture AI technology. Inasmuch as there will be ambiguities in specific regulations, we\\nask that the EU heed the opinions of non-EU businesses before these regulations go into\\x0c4\\nforce and become legally binding and provide opportunities for reviewing them based\\non such opinions.\\nPage 9 5. AN ECOSYSTEM OF TRUST: REGULATORY FRAMEWORK FOR AI\\n(Overall)\\nOur comments\\n\\uf06c AI is simply a tool, so it is inappropriate to think of AI itself as high-risk. The\\ntechnology itself does not constitute any risk; risks are brought about by how this\\ntechnology is used and its users. It is more appropriate to define “high-risk\\napplications” and “high-risk users.” Furthermore, it is necessary to promote a correct\\nunderstanding and enhance ethical awareness for the proper use of this tool in order to\\nprevent the emergence of high-risk operations and users. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 7, 'page': 3, '_split_overlap': [{'doc_id': '4f069d561a109947a9b07cc321049449', 'range': (0, 288)}, {'doc_id': 'f54bdcb3eb82be855700309556cdac01', 'range': (835, 1110)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd763c18864e890c3fbf42f83a595725d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: It is more appropriate to define “high-risk\\napplications” and “high-risk users.” Furthermore, it is necessary to promote a correct\\nunderstanding and enhance ethical awareness for the proper use of this tool in order to\\nprevent the emergence of high-risk operations and users. Since the social environment\\nwill also undergo radical changes with technological innovation, regulation is not only\\nimpractical for private businesses, but may also impede the regulators’ ability to adapt\\nto future technological advances. It is premature to define and regulate high-risk AI at\\nthis point.\\n\\uf06c The definition of high-risk AI may cause the withering of technological development in\\nthe defined areas. It is also important to take into account not only the potential\\ndamages that may arise from AI, but also the potential social losses resulting from the\\nerosion of benefits that AI would have brought due to regulation. Excessive regulation\\ncould become an obstacle to innovation that contributes to the development of\\nindustries and the resolution of social issues in Europe. Therefore, what should be\\ndefined at this point are not regulations but rather guidelines.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 8, 'page': 4, '_split_overlap': [{'doc_id': 'd763c18864e890c3fbf42f83a595725d', 'range': (0, 275)}, {'doc_id': '4e98efb4b516e0003cd7b2ad6dec4c14', 'range': (910, 1157)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f54bdcb3eb82be855700309556cdac01'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: Excessive regulation\\ncould become an obstacle to innovation that contributes to the development of\\nindustries and the resolution of social issues in Europe. Therefore, what should be\\ndefined at this point are not regulations but rather guidelines.\\n\\uf06c When introducing regulations in the future, this should be premised on a process\\x0c5\\nconsisting of closer and thorough dialogue with the industrial sector, pilot projects\\nconducted prior to actual introduction, and thorough risk assessment. Regulation should\\nonly be limited to AI that generates truly serious risks while also ensuring legal stability\\nand predictability.\\n\\uf06c Since the definition of risk and the thinking on accountability are different for each\\nsector, it is desirable for each sector to consider this issue based on their own thinking\\nafter the basic thinking applying to all sectors is presented.\\n\\uf06c With regard to the definition and standards of risk, it is desirable to engage in a\\ncomprehensive exchange of views, not only by the EU nations, but also involving a\\nbroad range of stakeholders, including governments and industrial sectors of other\\ncountries, with an eye on a global consensus and standardization in the future.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 9, 'page': 4, '_split_overlap': [{'doc_id': 'f54bdcb3eb82be855700309556cdac01', 'range': (0, 247)}, {'doc_id': '2c0751d072ed8aa6c03e72b5bc45865d', 'range': (863, 1193)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4e98efb4b516e0003cd7b2ad6dec4c14'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: \\uf06c With regard to the definition and standards of risk, it is desirable to engage in a\\ncomprehensive exchange of views, not only by the EU nations, but also involving a\\nbroad range of stakeholders, including governments and industrial sectors of other\\ncountries, with an eye on a global consensus and standardization in the future.\\n\\uf06c It is desirable not to simply focus on the introduction and review of regulations but to\\nundertake a comprehensive gap analysis first before considering the introduction and\\nreview of regulations as an option.\\nPage 16 C. SCOPE OF A FUTURE EU REGULATORY FRAMEWORK\\nPage 17, paragraph 3\\n“A risk-based approach is important to help ensure that the regulatory intervention is\\nproportionate.”\\nOur comment\\n\\uf06c A risk-based approach is indeed important. However, for the sake of technological\\nadvancement, a scheme for trial operation under a certain extent of oversight should\\nalso be considered in cases where AI utilization deemed to be high-risk is also an\\x0c6\\nextremely high-performance system.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 10, 'page': 5, '_split_overlap': [{'doc_id': '4e98efb4b516e0003cd7b2ad6dec4c14', 'range': (0, 330)}, {'doc_id': '95595fe041c13bc0766fd47b27850a6b', 'range': (777, 1020)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2c0751d072ed8aa6c03e72b5bc45865d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: However, for the sake of technological\\nadvancement, a scheme for trial operation under a certain extent of oversight should\\nalso be considered in cases where AI utilization deemed to be high-risk is also an\\x0c6\\nextremely high-performance system.\\nPage 17, paragraph 3\\n“The determination of what is a high-risk AI application should be clear and easily\\nunderstandable and applicable for all parties concerned.”\\nOur comment\\n\\uf06c When considering the definition of high-risk AI in the future, there need to be thorough\\nprior discussions on risk assessment by diverse stakeholders, and the definition of “high\\nrisk” must only be applied to AI that carries truly serious risks. As stated in the White\\nPaper, it is necessary to ensure legal stability and predictability through a clear\\ndetermination of what constitutes high risk.\\nPage 18 D. TYPES OF REQUIREMENTS\\n(Overall)\\nOur comment\\n\\uf06c The requirements in (a)–(f) need to be fair, reasonable, and realistic. The standards need\\nto be clear and their reasoning and appropriateness explicit in order to enhance legal\\nstability and predictability. Furthermore, it is also necessary to review these standards\\nas appropriate to keep in step with technological advancement.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 11, 'page': 5, '_split_overlap': [{'doc_id': '2c0751d072ed8aa6c03e72b5bc45865d', 'range': (0, 243)}, {'doc_id': '525a8d8edd907638bab80001334b71eb', 'range': (948, 1206)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '95595fe041c13bc0766fd47b27850a6b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: The standards need\\nto be clear and their reasoning and appropriateness explicit in order to enhance legal\\nstability and predictability. Furthermore, it is also necessary to review these standards\\nas appropriate to keep in step with technological advancement.\\nPage 18 a) Training data\\nPage 19, paragraph 2\\n“For instance, requirements ensuring that AI systems are trained on data sets that are\\nsufficiently broad and cover all relevant scenarios needed to avoid dangerous situations.”\\x0c7\\nPage 19, paragraph 3\\n“These requirements could entail in particular obligations to use data sets that are\\nsufficiently representative, especially to ensure that all relevant dimensions of gender,\\nethnicity and other possible grounds of prohibited discrimination are appropriately reflected\\nin those data sets.”\\nOur comment\\n\\uf06c While it is indeed important to give consideration to “data sets that are sufficiently\\nbroad and cover all relevant scenarios,” it is difficult to define its scope clearly.\\nTherefore, it is not realistic to set requirements for training data that will guarantee the\\nprevention of crisis. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 12, 'page': 6, '_split_overlap': [{'doc_id': '95595fe041c13bc0766fd47b27850a6b', 'range': (0, 258)}, {'doc_id': '3af65667a48953b34a635b0f90204369', 'range': (259, 1097)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '525a8d8edd907638bab80001334b71eb'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: Page 18 a) Training data\\nPage 19, paragraph 2\\n“For instance, requirements ensuring that AI systems are trained on data sets that are\\nsufficiently broad and cover all relevant scenarios needed to avoid dangerous situations.”\\x0c7\\nPage 19, paragraph 3\\n“These requirements could entail in particular obligations to use data sets that are\\nsufficiently representative, especially to ensure that all relevant dimensions of gender,\\nethnicity and other possible grounds of prohibited discrimination are appropriately reflected\\nin those data sets.”\\nOur comment\\n\\uf06c While it is indeed important to give consideration to “data sets that are sufficiently\\nbroad and cover all relevant scenarios,” it is difficult to define its scope clearly.\\nTherefore, it is not realistic to set requirements for training data that will guarantee the\\nprevention of crisis. At the same time, it is also unrealistic to set “obligations to use data\\nsets that are sufficiently representative” since it is difficult to define “data sets that are\\nsufficiently representative.” Careful discussion is needed in this respect.\\nPage 19, paragraph 3\\n“Requirements to take reasonable measures aimed at ensuring that such subsequent use of\\nAI systems does not lead to outcomes entailing prohibited discrimination. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 13, 'page': 6, '_split_overlap': [{'doc_id': '525a8d8edd907638bab80001334b71eb', 'range': (0, 838)}, {'doc_id': '9ade2e1fd042ed3f26eaa0f8ea3f7280', 'range': (1083, 1265)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3af65667a48953b34a635b0f90204369'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: Page 19, paragraph 3\\n“Requirements to take reasonable measures aimed at ensuring that such subsequent use of\\nAI systems does not lead to outcomes entailing prohibited discrimination. These\\nrequirements could entail in particular obligations to use data sets that are sufficiently\\nrepresentative, especially to ensure that all relevant dimensions of gender, ethnicity and\\nother possible grounds of prohibited discrimination are appropriately reflected in those data\\nsets.”\\nOur comments\\n\\uf06c Although it is very important to use unbiased data sets to avoid discrimination\\ngenerated by AI, in practice, the use of biased data sets is unavoidable. The use of\\nunbiased data sets should only be a recommendation, and in cases where the original\\ndata is biased, use of the data should be allowed if the bias is mitigated by algorithms\\x0c8\\nand other means.\\n\\uf06c Since fairness in data sets has not been defined at this point, it is necessary to examine\\nits definition and margin of tolerance.\\nPage 19 b) Keeping of records and data\\nPage 19, last paragraph–page 20 paragraph 1\\n“The records, documentation and, where relevant, data sets would need to be retained\\nduring a limited, reasonable time period to ensure effective enforcement of the relevant\\nlegislation. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 14, 'page': 7, '_split_overlap': [{'doc_id': '3af65667a48953b34a635b0f90204369', 'range': (0, 182)}, {'doc_id': '8e1b9d5194e85ff2469864d39d78e529', 'range': (977, 1246)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9ade2e1fd042ed3f26eaa0f8ea3f7280'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: Page 19 b) Keeping of records and data\\nPage 19, last paragraph–page 20 paragraph 1\\n“The records, documentation and, where relevant, data sets would need to be retained\\nduring a limited, reasonable time period to ensure effective enforcement of the relevant\\nlegislation. Measures should be taken to ensure that they are made available upon request,\\nin particular for testing or inspection by competent authorities.”\\nOur comments\\n\\uf06c Data retention is basically necessary from the standpoint of providing proof of safety\\nand traceability during audits. On the other hand, algorithms and the development of AI\\napplications are the results of long-term R&D of companies. Therefore, it is necessary\\nto pay attention to the cost of record keeping for all data sets used and the difficulty of\\ncompliance with privacy rules in EU and elsewhere (for instance, rules on deleting\\npersonal information when no longer needed).\\n\\uf06c Documents, training methods, processes, and technology for the building, testing, and\\nvalidation programs of AI systems are confidential information held by each company\\nand they should not be asked to provide such information without cause. If government\\nauthorities seek to obtain such information, a clear reason for doing so should be\\nprovided. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 15, 'page': 8, '_split_overlap': [{'doc_id': '9ade2e1fd042ed3f26eaa0f8ea3f7280', 'range': (0, 269)}, {'doc_id': '118e5ad884f3e2a4612abcae52dab68f', 'range': (912, 1262)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8e1b9d5194e85ff2469864d39d78e529'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: \\uf06c Documents, training methods, processes, and technology for the building, testing, and\\nvalidation programs of AI systems are confidential information held by each company\\nand they should not be asked to provide such information without cause. If government\\nauthorities seek to obtain such information, a clear reason for doing so should be\\nprovided. Appropriate procedures should also be followed, such as limiting the\\ninformation sought to the minimum required and careful handling of confidential\\ninformation.\\x0c9\\nPage 20 c) Information provision\\nPage 20, paragraph 4\\n“Ensuring clear information to be provided as to the AI system’s capabilities and\\nlimitations, in particular the purpose for which the systems are intended, the conditions\\nunder which they can be expected to function as intended and the expected level of accuracy\\nin achieving the specified purpose.”\\nOur comment\\n\\uf06c It is difficult to explain in terms comprehensible to humans the “capabilities and\\nlimitations” of recent AI systems using complex models to enhance sophistication based\\non deep learning. Therefore, information and methods necessary for human\\ncomprehension should be provided.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 16, 'page': 8, '_split_overlap': [{'doc_id': '8e1b9d5194e85ff2469864d39d78e529', 'range': (0, 350)}, {'doc_id': '3feab48b1bb976ed4ac43b515232bb43', 'range': (513, 1160)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '118e5ad884f3e2a4612abcae52dab68f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: 9\\nPage 20 c) Information provision\\nPage 20, paragraph 4\\n“Ensuring clear information to be provided as to the AI system’s capabilities and\\nlimitations, in particular the purpose for which the systems are intended, the conditions\\nunder which they can be expected to function as intended and the expected level of accuracy\\nin achieving the specified purpose.”\\nOur comment\\n\\uf06c It is difficult to explain in terms comprehensible to humans the “capabilities and\\nlimitations” of recent AI systems using complex models to enhance sophistication based\\non deep learning. Therefore, information and methods necessary for human\\ncomprehension should be provided.\\nPage 20 d) Robustness and accuracy\\nPage 20, paragraph 6\\n“AI systems – and certainly high-risk AI applications – must be technically robust and\\naccurate in order to be trustworthy. That means that such systems need to be developed in a\\nresponsible manner and with an ex-ante due and proper consideration of the risks that they\\nmay generate. Their development and functioning must be such to ensure that AI systems\\nbehave reliably as intended. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 17, 'page': 9, '_split_overlap': [{'doc_id': '118e5ad884f3e2a4612abcae52dab68f', 'range': (0, 647)}, {'doc_id': '75d3de2886b6493720cc6da50a42d1ee', 'range': (828, 1089)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3feab48b1bb976ed4ac43b515232bb43'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: That means that such systems need to be developed in a\\nresponsible manner and with an ex-ante due and proper consideration of the risks that they\\nmay generate. Their development and functioning must be such to ensure that AI systems\\nbehave reliably as intended. All reasonable measures should be taken to minimise the risk of\\nharm being caused.”\\nOur comment\\n\\uf06c Technical guarantee of the “robustness and accuracy of AI systems” is of vital\\nimportance for users to use AI systems with peace of mind, but at this point, this is not\\x0c10\\npossible in reality. Therefore, excessive demands such as total protection from external\\nattacks must not be made on businesses. Instead, realistic measures, including early\\ndetection of external attacks and minimization of impact on the system, should be\\nrequired.\\nPage 20, paragraph 9\\n“Requirements ensuring that outcomes are reproducible”\\nOur comment\\n\\uf06c It must be noted that depending on the type of algorithms used, the results may not be\\nfully reproducible in ex post verification in certain cases, such as when AI systems use\\nrandom numbers in the learning process.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 18, 'page': 9, '_split_overlap': [{'doc_id': '3feab48b1bb976ed4ac43b515232bb43', 'range': (0, 261)}, {'doc_id': '9c0bead820e0e57a78982e4eddda4194', 'range': (798, 1103)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '75d3de2886b6493720cc6da50a42d1ee'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: Page 20, paragraph 9\\n“Requirements ensuring that outcomes are reproducible”\\nOur comment\\n\\uf06c It must be noted that depending on the type of algorithms used, the results may not be\\nfully reproducible in ex post verification in certain cases, such as when AI systems use\\nrandom numbers in the learning process.\\nPage 20, last paragraph\\n“Requirements ensuring that AI systems can adequately deal with errors or inconsistencies\\nduring all life cycle phases”\\nOur comment\\n\\uf06c It must be noted that there are cases where AI systems carry out further learning and\\nevolve further using data obtained after the sale of the product, rendering it difficult to\\nprovide advance guarantee that errors and inconsistencies throughout the product cycle\\ncan be dealt with properly.\\nPage 21 e) Human oversight\\nPage 21, paragraph 2\\n“Human oversight helps ensuring that an AI system does not undermine human autonomy\\nor cause other adverse effects. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 19, 'page': 10, '_split_overlap': [{'doc_id': '75d3de2886b6493720cc6da50a42d1ee', 'range': (0, 305)}, {'doc_id': '2cd65c3dca1c61ed91e0af0f17e8a5b5', 'range': (757, 920)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9c0bead820e0e57a78982e4eddda4194'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: Page 21 e) Human oversight\\nPage 21, paragraph 2\\n“Human oversight helps ensuring that an AI system does not undermine human autonomy\\nor cause other adverse effects. The objective of trustworthy, ethical and human-centric AI\\x0c11\\ncan only be achieved by ensuring an appropriate involvement by human beings in relation to\\nhigh-risk AI applications.”\\nOur comments\\n\\uf06c Although human oversight and appraisal of AI is important, excessive human\\ninvolvement may delay the application of AI and impede innovation when the\\nexpansion of AI applications, including IoT and M2M, is expected. Therefore, the level\\nof human involvement and the areas where this is applicable should be considered\\ncarefully.\\n\\uf06c It is better to waive the requirement for human oversight when AI’s self-verification of\\nits actions is proven to be less biased or more accurate than human verification.\\nFurthermore, when this requirement applies, practical oversight conditions should be\\nset.\\nPage 21, paragraph 7\\n“in the design phase, by imposing operational constraints on the AI system (e.g. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 20, 'page': 10, '_split_overlap': [{'doc_id': '9c0bead820e0e57a78982e4eddda4194', 'range': (0, 163)}, {'doc_id': 'b94072dd13b13bb2262243e275a9f363', 'range': (862, 1053)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2cd65c3dca1c61ed91e0af0f17e8a5b5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: Furthermore, when this requirement applies, practical oversight conditions should be\\nset.\\nPage 21, paragraph 7\\n“in the design phase, by imposing operational constraints on the AI system (e.g. a driverless\\ncar shall stop operating in certain conditions of low visibility when sensors may become\\nless reliable or shall maintain a certain distance in any given condition from the preceding\\nvehicle).”\\nOur comments\\n\\uf06c Design should be based on the assumption that breakdowns and malfunctioning could\\noccur, and it is necessary to build in mechanisms and operational principles for safety\\ncontrol. Particularly in the design of high-precision AI realized with extremely\\ncomplicated models, full consideration also needs to be given to subsequent scenarios.\\n\\uf06c If the overall AI system has built-in designs for risk elimination, the requirement for\\x0c12\\nhuman oversight should be waived.\\nPages 18, 21 f) Specific requirements for remote biometric identification\\nPage 18\\n“Note 52 Remote biometric identification should be distinguished from biometric\\nauthentication... ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 21, 'page': 11, '_split_overlap': [{'doc_id': '2cd65c3dca1c61ed91e0af0f17e8a5b5', 'range': (0, 191)}, {'doc_id': '46313c12d31453eaa2f9a13dd009e166', 'range': (878, 1057)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b94072dd13b13bb2262243e275a9f363'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: Pages 18, 21 f) Specific requirements for remote biometric identification\\nPage 18\\n“Note 52 Remote biometric identification should be distinguished from biometric\\nauthentication... Remote biometric identification is...”\\nPage 21, last paragraph\\n“The gathering and use of biometric data for remote identification purposes, for instance\\nthrough deployment of facial recognition in public places, carries specific risks for\\nfundamental rights.”\\nOur comments\\n\\uf06c The scope of definition and use of remote biometric identification and biometric\\nauthentication, as well as the difference between the two are unclear. These should be\\nclarified by citing examples, for instance.\\n\\uf06c Face recognition in public places, in particular, has great potentials for use in\\nimmigration procedures, anticrime measures, and other public welfare purposes.\\nTherefore, the uniform regulation of face recognition for public use, even in cases\\nwhere individual consent cannot be obtained, should be avoided.\\n\\uf06c Use of face recognition in the private sector with the individual’s consent should\\nproceed based on the views of diverse stakeholders and with due consideration for\\nprivacy, in order not to restrict its utilization in the private sector unnecessarily.\\n\\uf06c The definition of remote biometric identification, biometric authentication, and so forth,\\x0c13\\nincluding their scope and use, is unclear. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 22, 'page': 12, '_split_overlap': [{'doc_id': 'b94072dd13b13bb2262243e275a9f363', 'range': (0, 179)}, {'doc_id': '74116b65e22340b5dddef4c55a4eed26', 'range': (1232, 1370)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '46313c12d31453eaa2f9a13dd009e166'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: \\uf06c The definition of remote biometric identification, biometric authentication, and so forth,\\x0c13\\nincluding their scope and use, is unclear. A legal system has yet to be established to\\ngovern the use of biometric data, such as face recognition and fingerprint data. For this\\nreason, it is necessary to come up with a clear definition and engage in careful\\ndiscussions when formulating regulations on remote biometric identification, in order\\nnot to overly restrict private sector utilization.\\n\\uf06c Furthermore, when it is necessary to respond to public health crises, regulations that\\ngive full consideration to privacy but hinder the achievement of public welfare goals to\\nprotect people’s lives are undesirable.\\nPage 22, paragraph 4\\n“… the Commission will launch a broad European debate on the specific circumstances, if\\nany, which might justify such use, and on common safeguards.”\\nOur comment\\n\\uf06c It is necessary to heed the views of multiple stakeholders and proceed with the\\ndiscussion with a firm grasp of the risks of using AI for biometric identification in\\npublic places.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 23, 'page': 12, '_split_overlap': [{'doc_id': '46313c12d31453eaa2f9a13dd009e166', 'range': (0, 138)}, {'doc_id': '4a41bebde81f7addae90084b54047919', 'range': (709, 1074)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '74116b65e22340b5dddef4c55a4eed26'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: Page 22, paragraph 4\\n“… the Commission will launch a broad European debate on the specific circumstances, if\\nany, which might justify such use, and on common safeguards.”\\nOur comment\\n\\uf06c It is necessary to heed the views of multiple stakeholders and proceed with the\\ndiscussion with a firm grasp of the risks of using AI for biometric identification in\\npublic places.\\nPage 22 E. Addressees\\nPage 22, paragraph 7\\n“For example, while the developers of AI may be best placed to address risks arising from\\nthe development phase, their ability to control risks during the use phase may be more\\nlimited. In that case, the deployer should be subject to the relevant obligation… Under EU\\nproduct liability law, liability for defective products is attributed to the producer, without\\nprejudice to national laws which may also allow recovery from other parties.”\\x0c14\\nOur comments\\n\\uf06c While it says here that “the deployer should be subject to the relevant obligation,” the\\ndevelopment of AI systems and products and services using AI involve multiple\\norganizations and responsible persons in most cases. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 24, 'page': 13, '_split_overlap': [{'doc_id': '74116b65e22340b5dddef4c55a4eed26', 'range': (0, 365)}, {'doc_id': '5726312c0089e086a6c7595e32cf42bf', 'range': (595, 1087)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4a41bebde81f7addae90084b54047919'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: In that case, the deployer should be subject to the relevant obligation… Under EU\\nproduct liability law, liability for defective products is attributed to the producer, without\\nprejudice to national laws which may also allow recovery from other parties.”\\x0c14\\nOur comments\\n\\uf06c While it says here that “the deployer should be subject to the relevant obligation,” the\\ndevelopment of AI systems and products and services using AI involve multiple\\norganizations and responsible persons in most cases. For this reason, it is necessary to\\ndefine “providers” and other entities, delineate the scope of accountability of each\\nentity specifically, and clarify the definition and scope of “defects.”\\n\\uf06c Responsibility should not lie solely on the developers and AI service providers. A\\nbalance with the obligation of the service recipients and other entities should also be\\nconsidered.\\nPage 23 F. Compliance and Enforcement\\nOur comment\\n\\uf06c It is necessary to clarify the subjects and standards of prior conformity assessment in\\norder to enhance legal stability and predictability.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 25, 'page': 13, '_split_overlap': [{'doc_id': '4a41bebde81f7addae90084b54047919', 'range': (0, 492)}, {'doc_id': 'b4bc7fc21f5c9157d3a297ce06449fb4', 'range': (871, 1063)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5726312c0089e086a6c7595e32cf42bf'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: Page 23 F. Compliance and Enforcement\\nOur comment\\n\\uf06c It is necessary to clarify the subjects and standards of prior conformity assessment in\\norder to enhance legal stability and predictability.\\nPage 23, paragraph 2\\n“In view of the high risk that certain AI applications pose for citizens and our society (see\\nsection A above), the Commission considers at this stage that an objective, prior conformity\\nassessment would be necessary to verify and ensure that certain of the above mentioned\\nmandatory requirements applicable to high-risk applications (see section D above) are\\ncomplied with.”\\nNote 59\\n“The system would be based on conformity assessment procedures in the EU… See the\\nBlue guide on the Implementation of EU product rules, 2014. ”\\x0c15\\nOur comments\\n\\uf06c Excessive prior conformity assessment may impede the marketing of AI systems and\\ninnovation due to the cumbersome procedures and additional time required. It is better\\nto set up a joint government-private sector scheme for the proper assessment of\\nbusinesses’ own initiatives.\\n\\uf06c It is necessary to clarify the subjects and standards for prior conformity assessment in\\norder to enhance legal stability and predictability. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 26, 'page': 14, '_split_overlap': [{'doc_id': '5726312c0089e086a6c7595e32cf42bf', 'range': (0, 192)}, {'doc_id': '71b27b83e7541501a43deda41ae54786', 'range': (1037, 1180)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b4bc7fc21f5c9157d3a297ce06449fb4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: \\uf06c It is necessary to clarify the subjects and standards for prior conformity assessment in\\norder to enhance legal stability and predictability. As well as clarifying the details of\\n“existing prior conformity assessment,” the contents of additional assessments to be\\nimposed on transportation, medical equipment, and other areas requiring a high level of\\nsafety should also be clarified.\\n\\uf06c In light of technological advancement in AI and the shortage of manpower, it is\\nreckoned that thorough implementation of prior conformity assessment by the\\nauthorities will be extremely difficult. Self-assessment by developers and service\\nproviders should also be considered.\\nPage 23, paragraph 2\\n“It could include checks of the algorithms and of the data sets used in the development\\nphase.”\\nOur comment\\n\\uf06c When the authorities implement prior conformity assessment, they should not unduly\\nseek the disclosure of information that could be sources of competitiveness (e.g.\\nalgorithms, details of data sets). Disclosure should not include confidential information\\nand must be limited to the minimum required, and the reason for seeking such\\ndisclosure must be clarified.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 27, 'page': 15, '_split_overlap': [{'doc_id': 'b4bc7fc21f5c9157d3a297ce06449fb4', 'range': (0, 143)}, {'doc_id': '85dae65eba65886798f0e41bde66e8d8', 'range': (996, 1157)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '71b27b83e7541501a43deda41ae54786'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: Disclosure should not include confidential information\\nand must be limited to the minimum required, and the reason for seeking such\\ndisclosure must be clarified.\\x0c16\\nPage 23, paragraph 8\\n“In case the conformity assessment shows that an AI system does not meet the requirements\\nfor example relating to the data used to train it, the identified shortcomings will need to be\\nremedied, for instance by re-training the system in the EU in such a way as to ensure that all\\napplicable requirements are met.”\\nOur comments\\n\\uf06c Requiring re-training in the EU zone may lead to performance demands on foreign\\ncompanies (e.g. use of local contents, technology transfer). Therefore, there should be\\nno regulations on the methods and location of re-training when the requirements are not\\nmet.\\n\\uf06c If prior conformity assessment shows that physical safety devices or operations can\\nfully eliminate or reduce the risks of systems using high-risk AI, it is desirable to waive\\nor ease all or part of the requirements corresponding to the risk elimination and\\nreduction steps taken.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 28, 'page': 15, '_split_overlap': [{'doc_id': '71b27b83e7541501a43deda41ae54786', 'range': (0, 161)}, {'doc_id': 'f79cfe100df525d362dea4fa2d46942', 'range': (776, 1058)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '85dae65eba65886798f0e41bde66e8d8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: \\uf06c If prior conformity assessment shows that physical safety devices or operations can\\nfully eliminate or reduce the risks of systems using high-risk AI, it is desirable to waive\\nor ease all or part of the requirements corresponding to the risk elimination and\\nreduction steps taken.\\nPage 24, paragraph 1\\n“Ex-post controls should be enabled by adequate documentation of the relevant AI\\napplication (see section E above) and, where appropriate, a possibility for third parties such\\nas competent authorities to test such applications.”\\nOur comment\\n\\uf06c With regard to ex post investigation relating to risks posed by AI to basic rights that the\\nauthorities may conduct after AI systems are deployed, clear rules should be set for\\nconducting such investigation to enhance businesses’ predictability.\\nPage 24 G. VOLUNTARY LABELLING FOR NO-HIGH RISK AI APPLICATIONS\\x0c17\\nPage 24, paragraph 5\\n“The voluntary label would allow the economic operators concerned to signal that their AI-\\nenabled products and services are trustworthy. It would allow users to easily recognise that\\nthe products and services in question are in compliance with certain objective and\\nstandardised EU-wide benchmarks, going beyond the normally applicable legal obligations.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 29, 'page': 16, '_split_overlap': [{'doc_id': '85dae65eba65886798f0e41bde66e8d8', 'range': (0, 282)}, {'doc_id': '9238a66d6c964fec88d3217eb72219c2', 'range': (1019, 1236)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f79cfe100df525d362dea4fa2d46942'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: It would allow users to easily recognise that\\nthe products and services in question are in compliance with certain objective and\\nstandardised EU-wide benchmarks, going beyond the normally applicable legal obligations.\\nThis would help enhance the trust of users in AI systems and promote the overall uptake of\\nthe technology.”\\nOur comments\\n\\uf06c In addition to labeling schemes, an approach to support industry-led moves toward\\nglobal standardization, such as providing efficient technologies and processes to ensure\\nthe reliability of AI, should also be considered.\\n\\uf06c Since it is difficult to fully enforce laws and regulations at the introduction stage of new\\ntechnology, there should probably be leeway to leave this matter to self-regulation and\\ncode of conduct by businesses.\\nPage 25 H. Governance\\nPage 24, paragraph 7\\n“A European governance structure on AI in the form of a framework for cooperation of\\nnational competent authorities is necessary to avoid fragmentation of responsibilities,\\nincrease capacity in Member States, and make sure that Europe equips itself progressively\\nwith the capacity needed for testing and certification of AI-enabled products and services. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 30, 'page': 17, '_split_overlap': [{'doc_id': 'f79cfe100df525d362dea4fa2d46942', 'range': (0, 217)}, {'doc_id': 'c61082604cf004a2e51fbb9ba44a46e3', 'range': (776, 1173)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9238a66d6c964fec88d3217eb72219c2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: Page 25 H. Governance\\nPage 24, paragraph 7\\n“A European governance structure on AI in the form of a framework for cooperation of\\nnational competent authorities is necessary to avoid fragmentation of responsibilities,\\nincrease capacity in Member States, and make sure that Europe equips itself progressively\\nwith the capacity needed for testing and certification of AI-enabled products and services. In\\nthis context, it would be beneficial to support competent national authorities to enable them\\nto fulfil their mandate where AI is used.\\x0c18\\nOur comments\\n\\uf06c The governance authorities of national governments or organizations commissioned by\\nthese authorities to investigate must have adequate specialized knowledge and must\\nimplement thorough protection of confidential information provided for the\\ninvestigation. Moreover, standards and subjects of investigation should be uniform in\\neach nation.\\n\\uf06c The EU should also consider delegating investigation powers to its members. If each\\nnation set up their own independent regulatory authorities, it is expected that this may\\nundermine the effectiveness and efficiency of investigations due to overlapping\\nadministration with existing agencies and inadequate complementation between the\\nnational authorities in terms of the industrial sectors’ knowhow and specialized\\nknowledge on AI. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 31, 'page': 17, '_split_overlap': [{'doc_id': '9238a66d6c964fec88d3217eb72219c2', 'range': (0, 397)}, {'doc_id': 'a354eba046217f0da1825d2921590e1b', 'range': (974, 1329)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c61082604cf004a2e51fbb9ba44a46e3'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: If each\\nnation set up their own independent regulatory authorities, it is expected that this may\\nundermine the effectiveness and efficiency of investigations due to overlapping\\nadministration with existing agencies and inadequate complementation between the\\nnational authorities in terms of the industrial sectors’ knowhow and specialized\\nknowledge on AI. The cost of responding to such a situation may ultimately fall on the\\nEU citizens and the end users.\\nPage 25, paragraph 4\\n“The EU enjoys excellent testing and assessment centres and should develop its capacity\\nalso in the area of AI. Economic operators established in third countries wanting to enter the\\ninternal market could either make use of designated bodies established in the EU or, subject\\nto mutual recognition agreements with third countries, have recourse to third-country bodies\\ndesignated to carry out such assessment.”\\n\\uf06c The design and renewal of testing methods and assessment regimes for the rapidly\\nevolving AI applications should be considered in terms of human resources\\ndevelopment and changing the assessment regimes in response to changes in AI\\nsystems, in order to achieve both precision and speed.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 32, 'page': 18, '_split_overlap': [{'doc_id': 'c61082604cf004a2e51fbb9ba44a46e3', 'range': (0, 355)}, {'doc_id': '1a1a543e9c5bb6ff27b7cf5be80758e9', 'range': (590, 1177)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a354eba046217f0da1825d2921590e1b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Keidanren, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Japan, document_date: 10-06-2020 04:22, language: English, \\n\\nPassage: Economic operators established in third countries wanting to enter the\\ninternal market could either make use of designated bodies established in the EU or, subject\\nto mutual recognition agreements with third countries, have recourse to third-country bodies\\ndesignated to carry out such assessment.”\\n\\uf06c The design and renewal of testing methods and assessment regimes for the rapidly\\nevolving AI applications should be considered in terms of human resources\\ndevelopment and changing the assessment regimes in response to changes in AI\\nsystems, in order to achieve both precision and speed.\\nPage 25, paragraph 4\\x0c19\\n“The EU enjoys excellent testing and assessment centres and should develop its capacity\\nalso in the area of AI. Economic operators established in third countries wanting to enter the\\ninternal market could either make use of designated bodies established in the EU or, subject\\nto mutual recognition agreements with third countries, have recourse to third-country bodies\\ndesignated to carry out such assessment.”\\nOur comment\\n\\uf06c In line with the policy of allowing the use of designated third-country assessment\\nbodies when there is a mutual recognition agreement, we hope for the expansion of\\nmutual recognition between nations with advanced AI technology.', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530509-Keidanren_Comments.pdf', 'stakeholder_name': 'Keidanren', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Japan', 'stakeholder_scope': nan, 'document_date': '10-06-2020 04:22', 'language': 'English', 'document_reference': 'F530509', 'document_name': 'F530509-Keidanren_Comments.pdf', '_split_id': 33, 'page': 18, '_split_overlap': [{'doc_id': 'a354eba046217f0da1825d2921590e1b', 'range': (0, 587)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1a1a543e9c5bb6ff27b7cf5be80758e9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: 1\\nJuin 2020\\nTECH IN France tient tout d’abord à saluer l’initiative portée par la Commission européenne\\nd’une stratégie dédiée à l’intelligence artificielle (IA) qui s’inscrit dans la lignée des travaux conduits\\navec les entreprises, et notamment des lignes directrices du groupe d’experts de haut niveau en IA,\\nqui a associé l’ensemble des parties prenantes pendant plusieurs mois dans le souci d’une approche\\nconcertée.\\nLa crise du Covid-19 a révélé l’importance du numérique et des outils technologiques comme éléments\\nau cœur de la résilience de nos sociétés et de nos économies et a montré l’importance des innovations\\nnumériques et par là-même, l’importance de donner les moyens à l’écosystème d’être innovant. De\\nnombreuses solutions visant à faciliter la gestion de la crise mais aussi à gérer au mieux l’après-crise,\\net ce, dans tous les domaines, reposent en effet sur des systèmes IA. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': '487be2826594946d17c1ac41a3ac2146', 'range': (717, 895)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3f6696a57a99e14f5205f44763162693'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: De\\nnombreuses solutions visant à faciliter la gestion de la crise mais aussi à gérer au mieux l’après-crise,\\net ce, dans tous les domaines, reposent en effet sur des systèmes IA. Ainsi, le souhait de la Commission\\neuropéenne de créer un système européen à même de garantir la confiance des citoyens et stimuler\\nl’adoption des usages IA, tout en assurant celle des entreprises dans le déploiement de leurs produits\\net applications IA et la capacité d’innovation en Europe, nous apparaît une stratégie ambitieuse et\\nadaptée aux enjeux de développement du potentiel numérique en Europe. De nombreuses entreprises\\nmembres de TECH IN France se sont d’ailleurs exprimées publiquement au cours des derniers mois en\\nfaveur du principe de l’élaboration d’une régulation.\\nDans cette optique, TECH IN France et ses adhérents sont attentifs à l’adoption d’une approche\\npragmatique et équilibrée dans la définition d’un nouveau cadre règlementaire par la Commission\\neuropéenne. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 1, 'page': 1, '_split_overlap': [{'doc_id': '3f6696a57a99e14f5205f44763162693', 'range': (0, 178)}, {'doc_id': '7e8b6cd3288729f7934f714ac35d2d5d', 'range': (762, 964)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '487be2826594946d17c1ac41a3ac2146'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Dans cette optique, TECH IN France et ses adhérents sont attentifs à l’adoption d’une approche\\npragmatique et équilibrée dans la définition d’un nouveau cadre règlementaire par la Commission\\neuropéenne. Ce principe d’équilibre dans l’élaboration d’une régulation européenne de l’IA apparait\\ncomme essentiel pour créer les conditions de l’innovation via le développement d’un écosystème de\\nl’excellence, dès le stade de la recherche et de l’innovation, incitant à une adoption rapide des\\nsolutions IA par les entreprises, notamment les TPE et les PME ; et pour être à même de stimuler\\nl’innovation, en donnant aux entreprises la sécurité juridique nécessaire. Ce nouveau cadre\\nréglementaire devra également éviter de faire peser sur les entreprises des contraintes\\ndisproportionnées par rapport à leurs compétiteurs internationaux, et devra répondre à leurs besoins\\nde compétitivité dans la bataille mondiale de l’IA et des données.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 2, 'page': 1, '_split_overlap': [{'doc_id': '487be2826594946d17c1ac41a3ac2146', 'range': (0, 202)}, {'doc_id': 'b984382161fa53f120cf48a1a7f924f1', 'range': (659, 931)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7e8b6cd3288729f7934f714ac35d2d5d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Ce nouveau cadre\\nréglementaire devra également éviter de faire peser sur les entreprises des contraintes\\ndisproportionnées par rapport à leurs compétiteurs internationaux, et devra répondre à leurs besoins\\nde compétitivité dans la bataille mondiale de l’IA et des données.\\nRemarques générales\\nL’importance du principe de cohérence (« consistency »)\\nIl semble important de rappeler ici que la cohérence est nécessaire entre une nouvelle régulation de\\nl’IA et les nombreux textes européens ou nationaux existants, qui s’appliquent pleinement comme\\nl’a d’ailleurs relevé la Commission européenne, tels que le RGPD, la directive relative à la sécurité\\ngénérale de produits, la directive sur l’égalité de traitement entre les personnes sans distinction de\\nRef. Ares(2020)3432105 - 30/06/2020\\x0c2\\nrace ou d’origine ethnique, la directive sur l’égalité de traitement en matière d’emploi et de travail ou\\nencore la directive relative aux droits des consommateurs.\\nIl s’agit donc de veiller à ce que l’élaboration de toute autre forme de nouvelle règlementation soit\\ncohérente avec les textes existants, comme les entreprises peuvent l’être dans le cadre du projet de\\nrèglement ePrivacy.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 3, 'page': 1, '_split_overlap': [{'doc_id': '7e8b6cd3288729f7934f714ac35d2d5d', 'range': (0, 272)}, {'doc_id': 'bf64a4b568008dd8ea1ffc9d0041dd3b', 'range': (954, 1176)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b984382161fa53f120cf48a1a7f924f1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Il s’agit donc de veiller à ce que l’élaboration de toute autre forme de nouvelle règlementation soit\\ncohérente avec les textes existants, comme les entreprises peuvent l’être dans le cadre du projet de\\nrèglement ePrivacy.\\nEn pratique, les entreprises ont acquis une expérience conséquente en matière de conformité\\n(process, outils, documentation, autorégulation…), notamment dans le cadre de la mise en œuvre du\\nrèglement général sur la protection des données (RGPD).\\nAinsi, en ce qui concerne les décisions automatisées, le RGPD impose des restrictions, mais aussi le\\ndroit des individus d’être informés quant à la logique sous-tendant ces décisions. De même, le\\nrèglement prévoit, notamment en son article 22, un cadre précis en matière de traitement des\\ndonnées personnelles. Il sera donc nécessaire pour toute nouvelle régulation en matière d’IA de ne\\npas se « chevaucher » avec les dispositions déjà prévues par le RGPD. Surtout, ce principe de\\ncohérence, garantie d’une harmonisation des législations, permettra également aux entreprises de\\nconserver le cadre juridique auxquelles elles se sont adaptées depuis maintenant plusieurs mois ;\\nélément nécessaire à la sécurité juridique et donc à la création d’un environnement favorable à la\\nconfiance et à l’innovation.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 4, 'page': 2, '_split_overlap': [{'doc_id': 'b984382161fa53f120cf48a1a7f924f1', 'range': (0, 222)}, {'doc_id': '8546a086006a501a573a82ee8073bdd8', 'range': (927, 1273)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bf64a4b568008dd8ea1ffc9d0041dd3b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Surtout, ce principe de\\ncohérence, garantie d’une harmonisation des législations, permettra également aux entreprises de\\nconserver le cadre juridique auxquelles elles se sont adaptées depuis maintenant plusieurs mois ;\\nélément nécessaire à la sécurité juridique et donc à la création d’un environnement favorable à la\\nconfiance et à l’innovation.\\nAu-delà des législations existantes, cette approche de cohérence doit également être conservée par la\\nCommission européenne dans le cadre de futures régulations, telles que la stratégie européenne des\\ndonnées ou encore le paquet législatif à venir DSA.\\nL’amélioration de l’accès aux données comme élément essentiel du\\ndéveloppement de l’IA\\nLe développement et le fonctionnement d’applications et de produits IA nécessitent un grand nombre\\nde données. Celles-ci sont donc au cœur de toute innovation reposant sur l’IA. Mais les données\\ndisponibles, c’est-à-dire accessibles et susceptibles d’être réutilisées, sont encore aujourd’hui\\ninsuffisantes au regard des besoins en matière d’innovation. Faciliter l’accès et la réutilisation des\\ndonnées permettra de libérer pleinement leur valeur sociétale et économique, de tirer pleinement\\npartie du potentiel offert par les jeux de données, ce qui stimulera l’innovation.\\nA ce titre, l’ouverture et le partage des données du secteur public doivent être accélérés. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 5, 'page': 2, '_split_overlap': [{'doc_id': 'bf64a4b568008dd8ea1ffc9d0041dd3b', 'range': (0, 346)}, {'doc_id': '29d1a1a3606893376c2a35fb8f2b0540', 'range': (1041, 1354)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8546a086006a501a573a82ee8073bdd8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Faciliter l’accès et la réutilisation des\\ndonnées permettra de libérer pleinement leur valeur sociétale et économique, de tirer pleinement\\npartie du potentiel offert par les jeux de données, ce qui stimulera l’innovation.\\nA ce titre, l’ouverture et le partage des données du secteur public doivent être accélérés. En effet, si\\nles données publiques présentent un potentiel sociétal important, elles présentant aussi un potentiel\\nconsidérable quant à la création de nouveaux services ou produits IA. Le souhait de la Commission\\neuropéenne de mettre à disposition davantage de données du secteur public, notamment à haute\\nvaleur, en vue de leur réutilisation apparait donc bénéfique. Il convient donc de poursuivre les\\nactions globales engagées au niveau européen d’ouverture des données publiques, ce qui passerait\\nnotamment par une transposition rapide par les Etats membres et une mise en œuvre ambitieuse de\\nla directive de juin 2019 relative aux données ouvertes et à la réutilisation des informations du secteur\\npublic. Dans ce cadre, la liste des jeux de données considérées à haute valeur devra être précisée\\nrapidement et devrait également, comme le permet la directive Données ouvertes être étendue à de\\nnouveaux secteurs, comme par exemple celui des données de justice.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 6, 'page': 2, '_split_overlap': [{'doc_id': '8546a086006a501a573a82ee8073bdd8', 'range': (0, 313)}, {'doc_id': 'c8087723116b87bcf17e8aea557e8b11', 'range': (1024, 1278)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '29d1a1a3606893376c2a35fb8f2b0540'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Dans ce cadre, la liste des jeux de données considérées à haute valeur devra être précisée\\nrapidement et devrait également, comme le permet la directive Données ouvertes être étendue à de\\nnouveaux secteurs, comme par exemple celui des données de justice.\\nUne telle dynamique en matière d’accès et de réutilisation aux données publiques permettrait ainsi\\nd’améliorer de manière conséquente l’accès des chercheurs en IA à des jeux de données qualitatifs,\\x0c3\\nélément essentiel en développement technologique et en matière d’innovation, mais aussi de\\nfavoriser le développement de champions dans des secteurs à haut potentiel.\\nConcernant les données du secteur privé, leur partage peut être encouragé afin de favoriser\\nl’innovation, mais cela doit se faire dans le respect du patrimoine informationnel des entreprises. En\\neffet, cela devrait reposer sur une démarche volontaire, mise en œuvre de manière contractuelle\\nentre les acteurs qui l’auraient décidé. Des cadres de partage de données qui permettent aux\\nentreprises qui les collectent de valoriser cette activité, sauf à dissuader la collecte de données,\\nindispensable au machine learning et deep learning, devraient être élaborés. L’ouverture des données\\ndevrait reposer avant tout sur des normes communes d’interopérabilité en phase avec les réalités du\\nmarché. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 7, 'page': 2, '_split_overlap': [{'doc_id': '29d1a1a3606893376c2a35fb8f2b0540', 'range': (0, 254)}, {'doc_id': 'e2a21021daad79a1bec9e202c581e6a1', 'range': (954, 1315)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c8087723116b87bcf17e8aea557e8b11'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Des cadres de partage de données qui permettent aux\\nentreprises qui les collectent de valoriser cette activité, sauf à dissuader la collecte de données,\\nindispensable au machine learning et deep learning, devraient être élaborés. L’ouverture des données\\ndevrait reposer avant tout sur des normes communes d’interopérabilité en phase avec les réalités du\\nmarché. La normalisation des données apparait en effet comme un préalable à tout travail sur des\\njeux de données pour que ceux-ci soient considérés comme étant de qualité et utilisables, voire\\nréutilisables, et est également un élément essentiel pour développer l’interopérabilité, permettant\\nainsi de stimuler la recherche et l’innovation.\\nEncourager les « bacs à sable » règlementaires en matière d’IA\\nLes « bacs à sable » règlementaires permettent l’expérimentation de nouvelles technologies, tout en\\nétant libéré de manière temporaire de contraintes règlementaires. Les développeurs de technologies,\\ndont l’IA, ont ainsi l’opportunité de tester, dans des conditions réelles, la sécurité et l’efficacité de\\nnouveaux produits et applications IA. Ce type de démarche devrait s’appuyer sur un engagement de\\nl’ensemble des acteurs de l’écosystème, comme les autorités compétentes en matière de protection\\ndes données et de sécurité des données. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 8, 'page': 3, '_split_overlap': [{'doc_id': 'c8087723116b87bcf17e8aea557e8b11', 'range': (0, 361)}, {'doc_id': '91d945b207d9c23d9e4548b0d30c248', 'range': (1102, 1297)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e2a21021daad79a1bec9e202c581e6a1'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Ce type de démarche devrait s’appuyer sur un engagement de\\nl’ensemble des acteurs de l’écosystème, comme les autorités compétentes en matière de protection\\ndes données et de sécurité des données. Les « bacs à sable » règlementaires en garantissant un cadre\\nd’expérimentation favorable et flexible, permettent d’inciter à l’innovation et devraient ainsi être\\nencouragés dans un cadre de régulation dédié à l’IA.\\n1- Créer un écosystème de l’excellence\\nCibler les efforts de la communauté de la recherche et de l’innovation\\nLa proposition de la Commission européenne de créer des centres d’essai et d’excellence pour la\\nrecherche, l'innovation et l'expertise en matière d'IA en Europe semble être une bonne initiative. Ces\\ncentres seraient d’une importance significative pour les projets à forts enjeux tels que le\\ndéveloppement des véhicules autonomes, ainsi que pour les projets nécessitant une grande quantité\\nde données et des infrastructures physiques.\\nIl semble essentiel que ces centres soient connectés entre eux mais aussi connectés avec les PME,\\nnotamment pour remédier à la fragmentation de la recherche en IA aujourd’hui constatée en Europe.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 9, 'page': 3, '_split_overlap': [{'doc_id': 'e2a21021daad79a1bec9e202c581e6a1', 'range': (0, 195)}, {'doc_id': '74c2ffef904841653257d5fbf77d3c03', 'range': (955, 1150)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '91d945b207d9c23d9e4548b0d30c248'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Il semble essentiel que ces centres soient connectés entre eux mais aussi connectés avec les PME,\\nnotamment pour remédier à la fragmentation de la recherche en IA aujourd’hui constatée en Europe.\\nSi un « centre phare » en matière d’IA venait à être créé en Europe, tel que le propose la Commission\\neuropéenne dans sa stratégie, il apparaît nécessaire que soit préalablement trouvé le bon équilibre en\\ntermes de centralisation. Un unique institut de recherche européen composé de centres localisés dans\\ndifférentes parties de l’UE pourrait être une bonne solution.\\x0c4\\nCompétences\\nLe livre blanc sur l’IA propose de soutenir et développer les réseaux universitaires et d’enseignement\\nsupérieur, ainsi qu’un « centre phare » pour la recherche et l’innovation en matière d’IA en Europe.\\nLes compétences manquent en Europe en matière d’IA mais aussi en matière de données. La question\\nde la compétence apparaît donc fondamentale, comme le relève la Commission européenne dans ses\\nstratégies sur l’IA et sur les données. Il convient ainsi d’encourager le plan d’investissement dans les\\ncompétences numériques proposé par la Commission européenne via le programme pour une\\nEurope numérique.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 10, 'page': 3, '_split_overlap': [{'doc_id': '91d945b207d9c23d9e4548b0d30c248', 'range': (0, 195)}, {'doc_id': 'c012dda2c38b80a82cd77b24d0f0d7d3', 'range': (1014, 1182)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '74c2ffef904841653257d5fbf77d3c03'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Il convient ainsi d’encourager le plan d’investissement dans les\\ncompétences numériques proposé par la Commission européenne via le programme pour une\\nEurope numérique.\\nEn parallèle, la question des connaissances générales des citoyens européens en matière d’IA se pose,\\nquestion intrinsèquement liée au sujet de l’éducation au numérique. Il est essentiel que la Commission\\neuropéenne s’assure que les citoyens européens disposent des compétences numériques nécessaires\\npour profiter pleinement des avantages de l’IA. Le renforcement de l’éducation au numérique par de\\nvéritables plans d’action européens et nationaux, permettant à chaque individu de disposer des bases\\net fondamentaux numériques, apparait donc comme un élément indispensable à la constitution d’une\\nsociété numérique, terreau favorable au développement du potentiel en matière d’IA.\\nAccorder une place de choix aux PME\\nL’appui de la Commission européenne en matière de sensibilisation des PME aux avantages potentiels\\nde l’IA est primordial, et passerait notamment par le renforcement des pôles d’innovation numérique.\\nAinsi, ceux-ci permettraient d’aider les entreprises à comprendre les bénéfices de l’IA et à en profiter\\npleinement. Cet appui devrait néanmoins être complété de formations sur les obstacles à surmonter\\nlorsque l’IA est mise en œuvre. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 11, 'page': 4, '_split_overlap': [{'doc_id': '74c2ffef904841653257d5fbf77d3c03', 'range': (0, 168)}, {'doc_id': '626cc512ec7954437a627f88429d2dc0', 'range': (1087, 1321)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c012dda2c38b80a82cd77b24d0f0d7d3'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Ainsi, ceux-ci permettraient d’aider les entreprises à comprendre les bénéfices de l’IA et à en profiter\\npleinement. Cet appui devrait néanmoins être complété de formations sur les obstacles à surmonter\\nlorsque l’IA est mise en œuvre. Il est en effet essentiel qu’en parallèle, les pôles d’innovation\\nnumérique puissent aider les entreprises à comprendre le processus d’implémentation de l’IA, et ce\\nqui peut survenir comme obstacles et difficultés quand elles le mettent en place (coûts, biais…). La\\nmise à disposition des centres d’essai physiques prévue par la Commission européenne est importante\\nau développement des solutions IA par les entreprises. Toutefois, des centres d’essai virtuels devraient\\négalement être développés dans une dynamique complémentaire.\\nPar ailleurs, les initiatives de partenariats dans le domaine de l’IA entre les entreprises, notamment\\nentre grands groupes et PME, sont bénéfiques à l’innovation. La multiplication de ce type de\\ncoopération contribuerait à favoriser l’innovation mais aussi la compétitivité des entreprises en\\nEurope, et devrait être encouragée par la Commission européenne.\\nEnfin, il est essentiel que les législations à venir soient proportionnées et ne soient pas trop complexes\\nà mettre en œuvre par les PME, afin de ne pas les pénaliser.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 12, 'page': 4, '_split_overlap': [{'doc_id': 'c012dda2c38b80a82cd77b24d0f0d7d3', 'range': (0, 234)}, {'doc_id': 'fb8119e58bb98f1dfb3d5ed21099163e', 'range': (1126, 1293)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '626cc512ec7954437a627f88429d2dc0'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Enfin, il est essentiel que les législations à venir soient proportionnées et ne soient pas trop complexes\\nà mettre en œuvre par les PME, afin de ne pas les pénaliser.\\nPartenariat avec le secteur privé\\nUn partenariat public-privé pour la recherche industrielle dans le domaine de l’IA pourrait être à même\\nde stimuler et concentrer la recherche dans les centres de recherche des Etats membres, tout en\\nincitant à la coopération.\\x0c5\\nPar ailleurs, l’Union européenne pourrait envisager de financer la création de chaires académiques\\npubliques-privées en IA, dont l’objectif serait de permettre à la fois la formation théorique des experts\\nen IA et de leur fournir une expérience pratique dans les organisations du secteur privé membres de\\nces chaires.\\nEncourager le secteur public à adopter l’IA\\nLa promotion de l'adoption de l'IA par le secteur public est un aspect clé de la stratégie de la\\nCommission européenne. L'IA a en effet le potentiel de permettre de répondre à des enjeux de société,\\nd’améliorer les services publics, de définir des politiques publiques plus adaptées…, permettant de\\nrépondre au mieux aux besoins des citoyens.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 13, 'page': 4, '_split_overlap': [{'doc_id': '626cc512ec7954437a627f88429d2dc0', 'range': (0, 167)}, {'doc_id': '44fa314db0726f86f72610decba92740', 'range': (913, 1135)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fb8119e58bb98f1dfb3d5ed21099163e'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: L'IA a en effet le potentiel de permettre de répondre à des enjeux de société,\\nd’améliorer les services publics, de définir des politiques publiques plus adaptées…, permettant de\\nrépondre au mieux aux besoins des citoyens.\\nIl existe aujourd’hui des disparités d’un domaine du secteur public à l’autre, dans le niveau de\\ndéploiement dans leurs activités de produits et services basés sur des systèmes d’IA. La Commission\\neuropéenne prévoit par conséquent d’accorder une « attention particulière » aux domaines les plus\\navancés, que sont la santé et les transports. Une attention particulière pourrait également être\\nportée par les programmes de soutien de la Commission européenne à d’autres domaines du secteur\\npublic dans lesquels l’IA peut jouer un rôle novateur important, tels que la justice, la gestion de la\\nrelation citoyen, l’enseignement…\\nGarantir l’accès aux données et aux infrastructures de calcul\\nLa définition et l’identification de sets de données à haute valeur dans le cadre de la stratégie\\neuropéenne sur les données, pourraient avoir un impact significatif sur la recherche en IA, en\\npermettant aux chercheurs d’accéder à des sets de données du secteur public qualitatifs.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 14, 'page': 5, '_split_overlap': [{'doc_id': 'fb8119e58bb98f1dfb3d5ed21099163e', 'range': (0, 222)}, {'doc_id': '290d576d40a7aeb7f1d69aae8d9e6a85', 'range': (564, 1191)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '44fa314db0726f86f72610decba92740'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Une attention particulière pourrait également être\\nportée par les programmes de soutien de la Commission européenne à d’autres domaines du secteur\\npublic dans lesquels l’IA peut jouer un rôle novateur important, tels que la justice, la gestion de la\\nrelation citoyen, l’enseignement…\\nGarantir l’accès aux données et aux infrastructures de calcul\\nLa définition et l’identification de sets de données à haute valeur dans le cadre de la stratégie\\neuropéenne sur les données, pourraient avoir un impact significatif sur la recherche en IA, en\\npermettant aux chercheurs d’accéder à des sets de données du secteur public qualitatifs.\\nPar ailleurs, la création de sets de données d’apprentissage fiables et partagés est essentielle à la phase\\nd’entraînement des systèmes d’IA. Toutefois, la création de ces jeux de données, sur lesquels repose\\nl’IA pour fonctionner, constitue un travail conséquent et représente des coûts élevés que les\\nentreprises ne peuvent pas supporter seules. En complément du soutien de l’Union européenne à la\\ncréation de ces sets de training data, la Commission européenne pourrait envisager d’encourager le\\ndéveloppement de joint-ventures entre entreprises, pouvant venir de différents pays, afin de\\nfaciliter l’élaboration et l’entretien de tels jeux de données.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 15, 'page': 5, '_split_overlap': [{'doc_id': '44fa314db0726f86f72610decba92740', 'range': (0, 627)}, {'doc_id': '9a13f13c9a8940c6a4d3fa334174c89c', 'range': (976, 1283)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '290d576d40a7aeb7f1d69aae8d9e6a85'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: En complément du soutien de l’Union européenne à la\\ncréation de ces sets de training data, la Commission européenne pourrait envisager d’encourager le\\ndéveloppement de joint-ventures entre entreprises, pouvant venir de différents pays, afin de\\nfaciliter l’élaboration et l’entretien de tels jeux de données.\\n2- Créer un écosystème de la confiance : le cadre de régulation de l’IA\\nLa Commission européenne propose de développer et graduer la régulation européenne en matière\\nd’IA selon une approche basée sur le niveau de « risque ». Elle précise d’ailleurs dans son livre blanc\\nque le principe de proportionnalité doit guider l’élaboration de ce nouveau cadre règlementaire pour\\nl’IA, qui devrait atteindre ses objectifs avec efficacité sans être excessivement normatif, au risque de\\ncréer une charge disproportionnée, en particulier pour les PME. Dans ce cadre, il semble essentiel que\\nle champ d’application, les notions et les critères d’application d’une régulation spécifique soient\\ndéfinis clairement et de manière pragmatique, afin de permettre aux entreprises soumises à la\\nrégulation de bénéficier de la meilleure visibilité sur les régimes juridiques applicables. Ces éléments\\x0c6\\nsont donc des conditions indispensables à toute sécurité juridique et à la dynamique d’innovation\\ndes entreprises.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 16, 'page': 5, '_split_overlap': [{'doc_id': '290d576d40a7aeb7f1d69aae8d9e6a85', 'range': (0, 307)}, {'doc_id': 'f9f1fed230597dfb2127ec358eb9e395', 'range': (848, 1303)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9a13f13c9a8940c6a4d3fa334174c89c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Dans ce cadre, il semble essentiel que\\nle champ d’application, les notions et les critères d’application d’une régulation spécifique soient\\ndéfinis clairement et de manière pragmatique, afin de permettre aux entreprises soumises à la\\nrégulation de bénéficier de la meilleure visibilité sur les régimes juridiques applicables. Ces éléments\\x0c6\\nsont donc des conditions indispensables à toute sécurité juridique et à la dynamique d’innovation\\ndes entreprises.\\nChamp d’application du cadre règlementaire IA\\nAfin de déterminer le champ d’application de la régulation à définir, la Commission européenne précise\\ndans sa stratégie qu’il s’agit de définir en amont de manière claire la notion « d’intelligence\\nartificielle ». Il est intéressant de rappeler qu’il n’existe à ce jour aucune définition arrêtée et acceptée\\npar l’ensemble de l’écosystème, que ce soit par les experts, les académiques ou les entreprises. Pour\\nce faire, la Commission évoque les éléments principaux composant l’IA : les données et les algorithmes\\net semble ainsi retenir une définition vaste de l’IA, qui appelle selon TECH IN France des points de\\nvigilance.\\nIl nous apparait tout d’abord important de préciser ici qu’une définition claire de l’IA et facilement\\ncompréhensible de tous, est une condition de l’efficacité de la régulation. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 17, 'page': 5, '_split_overlap': [{'doc_id': '9a13f13c9a8940c6a4d3fa334174c89c', 'range': (0, 455)}, {'doc_id': 'ede19928d31f36027007e1a56c06ab77', 'range': (1128, 1306)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f9f1fed230597dfb2127ec358eb9e395'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Il nous apparait tout d’abord important de préciser ici qu’une définition claire de l’IA et facilement\\ncompréhensible de tous, est une condition de l’efficacité de la régulation. Définir l’IA en essentialisant\\nles données et les algorithmes implique de facto que l’IA couvre un périmètre très large. En ce sens, il\\nconviendrait de définir plus précisément le périmètre éligible relevant de l’IA par rapport à celui de\\nl’algorithmie en général. En effet, tout traitement de données, y compris massif, ne relève pas\\nnécessairement du périmètre de l’IA.\\nPar ailleurs, certaines définitions existantes de l’IA (dont une réalisée par la Commission européenne\\nen 2018 dans sa communication « L’IA pour l’Europe »), certaines opèrent une distinction entre les\\nsystèmes d’IA « apprenants », qui font « preuve d’un comportement intelligent en analysant leur\\nenvironnement et en prenant des mesures, avec un certain degré d’autonomie, pour atteindre des\\nobjectifs spécifiques » et les systèmes d’IA classiques, « qui peuvent être purement logiciels, agissant\\ndans le monde virtuel mais aussi dans des dispositifs matériels ». ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 18, 'page': 6, '_split_overlap': [{'doc_id': 'f9f1fed230597dfb2127ec358eb9e395', 'range': (0, 178)}, {'doc_id': '913e3c35f089252651b07e797e05ccf9', 'range': (551, 1115)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ede19928d31f36027007e1a56c06ab77'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Par ailleurs, certaines définitions existantes de l’IA (dont une réalisée par la Commission européenne\\nen 2018 dans sa communication « L’IA pour l’Europe »), certaines opèrent une distinction entre les\\nsystèmes d’IA « apprenants », qui font « preuve d’un comportement intelligent en analysant leur\\nenvironnement et en prenant des mesures, avec un certain degré d’autonomie, pour atteindre des\\nobjectifs spécifiques » et les systèmes d’IA classiques, « qui peuvent être purement logiciels, agissant\\ndans le monde virtuel mais aussi dans des dispositifs matériels ». Suivre une telle logique dans une\\ndéfinition de l’IA permettrait de réaliser des distinctions de régulation selon les catégories d’IA, en\\nréalisant un focus sur les systèmes « apprenants », réduisant ainsi le champ d’application de\\nl’intervention règlementaire à définir et conduisant à ne pas créer une réglementation excessive.\\nApproche fondée sur le risque\\nL’approche européenne retenue se fonde sur la notion de « risque », qui doit permettre de graduer la\\nréponse règlementaire. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 19, 'page': 6, '_split_overlap': [{'doc_id': 'ede19928d31f36027007e1a56c06ab77', 'range': (0, 564)}, {'doc_id': '1ac3196f7146463abbb000d1613513c', 'range': (895, 1048)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '913e3c35f089252651b07e797e05ccf9'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Approche fondée sur le risque\\nL’approche européenne retenue se fonde sur la notion de « risque », qui doit permettre de graduer la\\nréponse règlementaire. Cette approche semble pertinente, notamment car elle permet a priori de\\nne pas décourager le développement et l’utilisation de l’IA, en appliquant une logique règlementaire\\ns’ajustant à la diversité des applications IA ; et semble adaptée à des technologies en évolution comme\\nl’IA et le machine learning. Elle permettrait également de ne pas réguler de manière excessive les\\napplications IA présentant peu de risques pour l’intégrité physique ou les droits fondamentaux des\\nindividus par exemple, ce qui est le cas pour la plupart des applications IA.\\nMais pour déterminer le niveau de risque de l’application IA, les critères pris en considération doivent\\nêtre clairs et intelligibles, comme le précise le livre blanc « les éléments permettant d'établir qu'une\\napplication d'IA est à haut risque devraient être clairs, faciles à comprendre et applicables à toutes les\\nparties concernées ». Ainsi, l’approche cumulative consistant à prendre en compte le secteur dans\\nlequel l’IA est utilisée, mais aussi l’utilisation qui en est faite au sein de ce même secteur, apparaît\\nraisonnable et pragmatique. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 20, 'page': 6, '_split_overlap': [{'doc_id': '913e3c35f089252651b07e797e05ccf9', 'range': (0, 153)}, {'doc_id': 'ca04b375b6dcbddc8a52917020e6ab20', 'range': (1046, 1254)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1ac3196f7146463abbb000d1613513c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Ainsi, l’approche cumulative consistant à prendre en compte le secteur dans\\nlequel l’IA est utilisée, mais aussi l’utilisation qui en est faite au sein de ce même secteur, apparaît\\nraisonnable et pragmatique. Cette combinaison de critères permettant de déterminer si une\\napplication IA est à haut risque ou à faible risque, permet de ne pas stigmatiser certains secteurs, qui\\x0c7\\npar nature seraient considérés comme à haut risque, alors que l’utilisation en question faite de\\nl’application comporterait en réalité un faible risque, voire dans certains cas contribuerait à diminuer\\nle risque.\\nIl semble néanmoins important en pratique que la distinction entre les deux types de risques\\nenvisagée par la Commission européenne soit clarifiée pour garantir la sécurité juridique des\\nentreprises, et notamment éviter de placer les petits acteurs économiques dans des situations\\njuridiques complexes.\\nEn effet, les critères peuvent être vus comme encore assez flous, ce qui pourrait laisser craindre que\\nla notion de « risque » soit interprétée de manière extensive. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 21, 'page': 6, '_split_overlap': [{'doc_id': '1ac3196f7146463abbb000d1613513c', 'range': (0, 208)}, {'doc_id': '5334fc67fbb5e37bc4d0d43c6ddd846b', 'range': (894, 1059)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ca04b375b6dcbddc8a52917020e6ab20'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: En effet, les critères peuvent être vus comme encore assez flous, ce qui pourrait laisser craindre que\\nla notion de « risque » soit interprétée de manière extensive. Des éléments complémentaires\\npourraient ainsi être pris en compte lors de l’évaluation du risque (permettant aux entreprises de la\\nréaliser plus facilement), comme le fait d’envisager les dommages potentiels, mais aussi les\\nopportunités pour la société et les citoyens, et donc de « mesurer » le coût de ne pas utiliser en\\npratique l’IA. Une telle mise en balance apparaitrait utile pour ne pas décourager l’utilisation de l’IA\\ndès lors qu’elle présenterait des risques, qui peuvent, dans de nombreux cas, être atténués en\\npratique. De même, la détermination du niveau de risque pourrait prendre en compte, au-delà de la\\ngravité potentielle d’un dommage, sa probabilité. Par ailleurs, les cas exceptionnels mentionnés par\\nla Commission européenne, qui seraient considérés par nature comme à haut-risque, et ce, quel que\\nsoit l’évaluation des risques selon les critères cumulatifs réalisée, peut être perçue comme créant un\\nvéritable flou dans la détermination du risque et l’application de la règlementation spécifique, et donc\\ncomme un facteur important d’insécurité juridique.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 22, 'page': 7, '_split_overlap': [{'doc_id': 'ca04b375b6dcbddc8a52917020e6ab20', 'range': (0, 165)}, {'doc_id': 'ceb19fd25e755311f4fe1de8da911a01', 'range': (837, 1244)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5334fc67fbb5e37bc4d0d43c6ddd846b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Par ailleurs, les cas exceptionnels mentionnés par\\nla Commission européenne, qui seraient considérés par nature comme à haut-risque, et ce, quel que\\nsoit l’évaluation des risques selon les critères cumulatifs réalisée, peut être perçue comme créant un\\nvéritable flou dans la détermination du risque et l’application de la règlementation spécifique, et donc\\ncomme un facteur important d’insécurité juridique.\\nIl conviendrait également de relativiser les attentes de performance en matière d’IA, car bien que tout\\npuisse être fait pour minimiser les risques et les erreurs, les algorithmes servant au système d’IA\\npeuvent être biaisés ou comporter des erreurs, cela relevant du caractère inhérent de l’algorithme,\\nconsistant à fournir des résultats statistiques et des probabilités basés sur des données. La Commission\\neuropéenne rappelle d’ailleurs dans son livre blanc que les biais et discriminations ne sont pas propres\\nà la machine et sont inhérents à toute société et activité économique.\\nEnfin, il semble qu’une nomenclature plus précise de la donnée permettrait également aux entreprises\\nd’apprécier plus finement la notion de risque et d’élaborer des stratégies de normalisation adaptées.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 23, 'page': 7, '_split_overlap': [{'doc_id': '5334fc67fbb5e37bc4d0d43c6ddd846b', 'range': (0, 407)}, {'doc_id': '15658d8ef0272722d65defb2560a021', 'range': (993, 1195)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ceb19fd25e755311f4fe1de8da911a01'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Enfin, il semble qu’une nomenclature plus précise de la donnée permettrait également aux entreprises\\nd’apprécier plus finement la notion de risque et d’élaborer des stratégies de normalisation adaptées.\\nExigences obligatoires pour les applications d’IA à haut risque\\nLa Commission européenne évoque des exigences et obligations légales imposées aux développeurs\\net aux utilisateurs professionnels de l’IA, qui ne s’appliqueraient que dans les cas d’applications IA\\nconsidérées comme à haut risque. Le livre blanc indique que ces obligations seront précisées dans un\\nsecond temps.\\nAu vu des obligations envisagées, il convient d’être vigilant quant à l’élaboration de ces règles et\\nquant à leur interprétation pratique : il est important que cela soit réalisé avec pragmatisme et que\\nles exigences soient applicables en pratique par les entreprises, au risque de freiner drastiquement\\nl’innovation.\\nToute réflexion quant à une obligation de conservation des donnés devra ainsi tenir compte des\\nexigences du RGPD et du respect des droits de propriété intellectuelle qui pourrait être associés à ces\\ndonnées.\\x0c8\\nConformité et mise en application\\nLa Commission européenne propose que les applications d’IA à haut risque fassent l’objet d’une\\névaluation de conformité préalable visant à s’assurer que les exigences obligatoires sont bien\\nrespectées. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 24, 'page': 7, '_split_overlap': [{'doc_id': 'ceb19fd25e755311f4fe1de8da911a01', 'range': (0, 202)}, {'doc_id': '9d229783d32b24d497219326eadab770', 'range': (1106, 1343)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '15658d8ef0272722d65defb2560a021'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: 8\\nConformité et mise en application\\nLa Commission européenne propose que les applications d’IA à haut risque fassent l’objet d’une\\névaluation de conformité préalable visant à s’assurer que les exigences obligatoires sont bien\\nrespectées. Ce « prior assessment » pourrait inclure des procédures de test, d’inspection ou de\\ncertification, voire des vérifications des algorithmes et des datas sets utilisés dans la phase de\\ndéveloppement.\\nLes entreprises peuvent s’inquiéter de la mise en place d’une telle procédure de conformité préalable.\\nEn effet, de nombreuses questions concrètes émergent, auxquelles il sera important d’apporter des\\nprécisions. Par exemple, quid de l’application rétroactive d’une telle procédure à des produits déjà mis\\nsur le marché ? A ce jour, le livre blanc n’exclut pas formellement cette possibilité.\\nLa question de la pertinence des jeux de données d’entrainement est par ailleurs une question large,\\nqui ne devrait pas se résumer à l’origine géographique de ces données.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 25, 'page': 8, '_split_overlap': [{'doc_id': '15658d8ef0272722d65defb2560a021', 'range': (0, 237)}, {'doc_id': '289c5e3de953947a3a160c247ff23029', 'range': (829, 1000)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9d229783d32b24d497219326eadab770'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: La question de la pertinence des jeux de données d’entrainement est par ailleurs une question large,\\nqui ne devrait pas se résumer à l’origine géographique de ces données.\\nDes alternatives efficaces à cette évaluation de conformité préalable, et pouvant être mises en œuvre\\nplus facilement par les entreprises, pourraient être envisagées, sur la base par exemple de ce qui existe\\ndans le cadre du RGPD en matière d’évaluation des impacts sur la protection des données (« impact\\nassessment »). De même, la combinaison d’évaluations par les entreprises des risques ex ante et ex\\npost, pourrait permettre d’évaluer la conformité aux exigences obligatoires, sans imposer de charges\\nsupplémentaires trop lourdes aux entreprises, s’appuyant par exemple sur des pratiques juridiques ou\\néthiques.\\nPar ailleurs, une démarche de certification devrait davantage viser les processus mis en œuvre dans\\nla phase de développement, comme c’est le cas par exemple dans les industries sensibles, que les\\nproduits finis.\\nLabélisation volontaire pour les applications IA à faible risque\\nLe schéma de labélisation volontaire pourrait être un élément contribuant à renforcer la confiance des\\nutilisateurs dans les systèmes d’IA, en facilitant ainsi l’adoption. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 26, 'page': 8, '_split_overlap': [{'doc_id': '9d229783d32b24d497219326eadab770', 'range': (0, 171)}, {'doc_id': 'c48db78cb30e40fd49580d7365b319a4', 'range': (1002, 1238)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '289c5e3de953947a3a160c247ff23029'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Labélisation volontaire pour les applications IA à faible risque\\nLe schéma de labélisation volontaire pourrait être un élément contribuant à renforcer la confiance des\\nutilisateurs dans les systèmes d’IA, en facilitant ainsi l’adoption. Ce système de compliance devrait\\nlaisser aux entreprises la flexibilité de choisir les outils les plus pertinents pour attester de leur\\ncompliance. Des outils concrets tels que les codes de conduite, les certifications, le concept de privacy\\nby design/ by default, permettraient aux entreprises de bénéficier de cette flexibilité. L’adoption par\\nles entreprises, notamment les start-ups et les PME, de ce système de labélisation dépendra de cette\\nflexibilité (être labélisé ne devrait en pratique pas impliquer de répondre aux mêmes exigences que\\ncelles définies pour les applications IA à haut risque).\\n3- Implications de l’IA, de l’IoT et de la robotique en matière de\\nsécurité et de responsabilité\\nDe façon générale, il est important pour les législateurs de se prémunir en matière de responsabilité\\ncontre la tentation d’essentialiser les algorithmes d’IA. Ces derniers sont en effet conçus par des\\ncerveaux humains, et ils fonctionnent avant tout comme outils d’aide à la décision destinés à des\\nhumains et peuvent, le cas échéant, venir aussi corriger des défaillances humaines.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 27, 'page': 8, '_split_overlap': [{'doc_id': '289c5e3de953947a3a160c247ff23029', 'range': (0, 236)}, {'doc_id': 'eeb24507fd37a5d191afcf10a1263197', 'range': (1098, 1321)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c48db78cb30e40fd49580d7365b319a4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Ces derniers sont en effet conçus par des\\ncerveaux humains, et ils fonctionnent avant tout comme outils d’aide à la décision destinés à des\\nhumains et peuvent, le cas échéant, venir aussi corriger des défaillances humaines.\\x0c9\\nOr, la législation actuelle apparaît suffisamment souple pour prendre en considération la majorité des\\nrisques existants liés à l’utilisation de ces technologies émergentes. C’est pourquoi la notion de\\n« risque » liée à l’IA ne doit pas être envisagée sous un angle plus large, ce qui pourrait avoir pour\\nconséquence de créer des contraintes trop importantes et donc de freiner l’innovation.\\nToutefois, il est vrai que certains risques, comme ceux relatifs à la cybersécurité, sont d’autant plus\\nimportants dans un monde en constante transformation numérique. Ces risques peuvent d’ailleurs\\nêtre amenés à évoluer dans le temps et, dans le cadre de la cybersécurité, une faille inexistante à\\nl’origine peut apparaître au cours de la vie du produit. Dans cet exemple, la security by design pourrait\\nne pas être suffisante. Conscients de cet enjeu, les développeurs de solution IA font régulièrement des\\nmises à jour de leurs produits. Une autorégulation en la matière existe donc et mérite d’être\\nsoulignée. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 28, 'page': 8, '_split_overlap': [{'doc_id': 'c48db78cb30e40fd49580d7365b319a4', 'range': (0, 223)}, {'doc_id': '88a4faca6622b32719ca779bcd51c28d', 'range': (1047, 1231)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'eeb24507fd37a5d191afcf10a1263197'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: Conscients de cet enjeu, les développeurs de solution IA font régulièrement des\\nmises à jour de leurs produits. Une autorégulation en la matière existe donc et mérite d’être\\nsoulignée. Elle est d’ailleurs fondamentale pour les entreprises dont les clients sont de plus en plus\\nexigeants en matière de sécurité, et cette confiance que le client peut accorder dans le produit\\nencourage les bonnes pratiques dans le métier.\\nPar ailleurs, dans le cadre des réflexions sur la mise en place de nouvelles procédures d’évaluation des\\nrisques pour les produits, la réflexion devrait s’engager selon deux axes, qui sont fonction du type\\nd’IA en question. En effet, pour les systèmes d’IA apprenant sur des jeux dits « statiques », le produit\\nfinal en résultant n’a pas vocation à évoluer davantage après sa mise sur le marché. En revanche, pour\\nles systèmes d’IA qui continuent d’apprendre sur des jeux d’essais, ils peuvent parfois évoluer au point\\nde parvenir à des ruptures si fortes dans le comportement du système que le produit final peut en être\\nmodifié. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 29, 'page': 9, '_split_overlap': [{'doc_id': 'eeb24507fd37a5d191afcf10a1263197', 'range': (0, 184)}, {'doc_id': 'e408d50342de8478a9b113d14583b4d2', 'range': (817, 1051)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '88a4faca6622b32719ca779bcd51c28d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: En revanche, pour\\nles systèmes d’IA qui continuent d’apprendre sur des jeux d’essais, ils peuvent parfois évoluer au point\\nde parvenir à des ruptures si fortes dans le comportement du système que le produit final peut en être\\nmodifié. Ainsi, dans le premier cas, il ne serait pas nécessaire de mettre en place de nouvelles\\nprocédures d’évaluation des risques, puisque le produit fini n’aura pas vocation à être modifié ou\\naltéré. Mettre en place cette procédure pourrait même constituer un frein à l’innovation. Il convient\\nen effet de relativiser l’évolutivité des algorithmes d’IA dans ce cas puisque les technologies sont\\nstabilisées. C’est d’ailleurs à juste titre que la Commission européenne conditionne la certification aux\\n« changements importants [subis par le produit] au cours de sa durée de vie, par exemple, une fonction\\nde produit différente que le fabricant n’avait pas prévue dans son évaluation initiale des risques ». En\\nrevanche, dans le second cas, l’enjeu est différent. En tout état de cause et comme évoqué supra, une\\ndémarche de certification devrait en effet davantage viser les processus mis en œuvre que les\\nproduits finis.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 30, 'page': 9, '_split_overlap': [{'doc_id': '88a4faca6622b32719ca779bcd51c28d', 'range': (0, 234)}, {'doc_id': 'e29e55f2fd7b93abfab3f22ea34adf83', 'range': (992, 1150)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e408d50342de8478a9b113d14583b4d2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: TECH IN France, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: France, document_date: 12-06-2020 17:18, language: French, \\n\\nPassage: En tout état de cause et comme évoqué supra, une\\ndémarche de certification devrait en effet davantage viser les processus mis en œuvre que les\\nproduits finis.\\n[A propos de TECH IN France]\\nCréée en 2005, TECH IN France est une association professionnelle de loi 1901 qui a pour but de\\nrassembler et de représenter les éditeurs de logiciels, de services internet et de plateformes en France.\\nPorte-parole de l’industrie numérique, TECH IN France compte 400 entreprises adhérentes : de la\\nstartup à la multinationale en passant par la PME et les grands groupes français ; soit 8 milliards d’euros\\net 90 000 emplois. TECH IN France s’est donnée pour mission de mener une réflexion permanente sur\\nl’évolution de l’industrie numérique et promouvoir l’attractivité du secteur.\\nwww.techinfrance.fr', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', 'stakeholder_name': 'TECH IN France', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'France', 'stakeholder_scope': nan, 'document_date': '12-06-2020 17:18', 'language': 'French', 'document_reference': 'F530135', 'document_name': 'F530135-Contribution_consultation_Livre_blanc_IA-_TECH_IN_France-_12-06-2020.pdf', '_split_id': 31, 'page': 9, '_split_overlap': [{'doc_id': 'e408d50342de8478a9b113d14583b4d2', 'range': (0, 158)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e29e55f2fd7b93abfab3f22ea34adf83'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Council of European Professional Informatics Societies (CEPIS), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 14:35, language: English, \\n\\nPassage: 1\\nCEPIS 2020\\nComments on the White Paper on Artificial Intelligence1\\nPresented by CEPIS in an open public consultation\\nThe Council of European Professional Informatics Societies (CEPIS) welcomes the digital\\npackage published by the European Commission on 19 February 2020. In the frame of an\\nopen public consultation CEPIS presents the following comments:\\n1. CEPIS supports the adoption of the European Commission´s White Paper on Artificial\\nIntelligence (AI) which we treat as one of the most important tools in digital transformation of\\nEurope and in close connection to the European Strategy on Data. Many Member States have\\nadopted special strategies on AI, including France, Germany, Finland and others. The role of\\nEurope in this area is irreplaceable. We agree with the two building blocks of the White Paper:\\necosystem of excellence and ecosystem of trust.\\nEcosystem of excellence\\n2. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529958-CEPIS-Comments-on-White-Paper-on-AI.pdf', 'stakeholder_name': 'Council of European Professional Informatics Societies (CEPIS)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 14:35', 'language': 'English', 'document_reference': 'F529958', 'document_name': 'F529958-CEPIS-Comments-on-White-Paper-on-AI.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': 'a8a911f9ee2a78cd31101398937ada8', 'range': (759, 891)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '773c1027d5abd47d80a302f920c8cec1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Council of European Professional Informatics Societies (CEPIS), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 14:35, language: English, \\n\\nPassage: We agree with the two building blocks of the White Paper:\\necosystem of excellence and ecosystem of trust.\\nEcosystem of excellence\\n2. Regarding the Member States and their specific AI strategies, CEPIS supports the European\\nrevision of the Coordinated Plan of the EU and Member States in AI to be adopted until the\\nend of 2020 as well as the ambition to boost investment in AI in Europe beyond the possibilities\\nof any single Member State and to use AI to tackle the most pressing problems in the green\\ntransformation of Europe.\\n3. Besides the European lighthouse centre of research, innovation and expertise CEPIS\\nconsiders it very important to support also the centres of excellence and testing in areas where\\nEurope can become world leader, thus reflecting the possibility to pool the regional potential,\\nknowledge and expertise.\\n4. CEPIS is aware that, despite all efforts and financial support, the level of digital skills is\\nincreasing very slowly. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529958-CEPIS-Comments-on-White-Paper-on-AI.pdf', 'stakeholder_name': 'Council of European Professional Informatics Societies (CEPIS)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 14:35', 'language': 'English', 'document_reference': 'F529958', 'document_name': 'F529958-CEPIS-Comments-on-White-Paper-on-AI.pdf', '_split_id': 1, 'page': 1, '_split_overlap': [{'doc_id': '773c1027d5abd47d80a302f920c8cec1', 'range': (0, 132)}, {'doc_id': '887f913d5e1d4762c7a7da68ec1d65e9', 'range': (832, 953)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a8a911f9ee2a78cd31101398937ada8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Council of European Professional Informatics Societies (CEPIS), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 14:35, language: English, \\n\\nPassage: 4. CEPIS is aware that, despite all efforts and financial support, the level of digital skills is\\nincreasing very slowly. Therefore, we support the update of the Skills Agenda for Europe and\\nthe Digital Education Action Plan in 2020 in order to bring the measures for real improvement\\non the level of digital skills2 in general, and in AI skills in particular, together with the social\\npartners. This will need to develop the AI professional and ethical standards mainly on MSc\\nlevel, against which graduates can evidence that they have obtained the appropriate level of\\nskills to work with AI products and services. The skills improvement will enable ICT\\nprofessionals to work more effectively with ICT and special AI technologies and prepare\\ncitizens to be aware of the decisions which will be more and more influenced by AI.\\n5. CEPIS supports the ambition of the White Paper to broaden the adoption of AI in private\\nand public sectors. AI can boost innovation, especially in SMEs, and by stronger public-private\\npartnership. In public sector it should be used more widely with special focus on healthcare\\nand transportation together with smart city solutions. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529958-CEPIS-Comments-on-White-Paper-on-AI.pdf', 'stakeholder_name': 'Council of European Professional Informatics Societies (CEPIS)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 14:35', 'language': 'English', 'document_reference': 'F529958', 'document_name': 'F529958-CEPIS-Comments-on-White-Paper-on-AI.pdf', '_split_id': 2, 'page': 1, '_split_overlap': [{'doc_id': 'a8a911f9ee2a78cd31101398937ada8', 'range': (0, 121)}, {'doc_id': 'ab1686318d071f20f6433a77d25b295c', 'range': (1028, 1162)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '887f913d5e1d4762c7a7da68ec1d65e9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Council of European Professional Informatics Societies (CEPIS), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 14:35, language: English, \\n\\nPassage: In public sector it should be used more widely with special focus on healthcare\\nand transportation together with smart city solutions. Nonetheless, particularly in the public\\nsector, AI usage must be subject to strict regulation, testing and editing procedures in order to\\navoid discrimination and undesirable environmental effects.\\n1 On Artificial Intelligence - A European approach to excellence and trust, COM(2020) 65 final, 19.2.2020\\n2 The European Union must act immediately to improve the level of digital skills, CEPIS position paper, 2020\\nRef. Ares(2020)3358110 - 26/06/2020\\x0c2\\nCEPIS 2020\\nEcosystem of trust\\n6. CEPIS respects the non-binding Guidelines of the High-level Expert Group on ethical\\nprinciples of AI based on the values of privacy, reliability and transparency, which need to be\\nimplemented in practice. At the same time, CEPIS supports the adoption of a clear European\\nregulatory framework which will bring trust among consumers and businesses in AI and\\ncompliance with European principles and values. A European regulatory framework will protect\\nEuropean citizens and create a more efficient internal market for further development and\\nuptake of AI.\\n7. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529958-CEPIS-Comments-on-White-Paper-on-AI.pdf', 'stakeholder_name': 'Council of European Professional Informatics Societies (CEPIS)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 14:35', 'language': 'English', 'document_reference': 'F529958', 'document_name': 'F529958-CEPIS-Comments-on-White-Paper-on-AI.pdf', '_split_id': 3, 'page': 1, '_split_overlap': [{'doc_id': '887f913d5e1d4762c7a7da68ec1d65e9', 'range': (0, 134)}, {'doc_id': 'cfd50d68d4e6adc04f94bb3d25aadee', 'range': (1023, 1174)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ab1686318d071f20f6433a77d25b295c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Council of European Professional Informatics Societies (CEPIS), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 14:35, language: English, \\n\\nPassage: A European regulatory framework will protect\\nEuropean citizens and create a more efficient internal market for further development and\\nuptake of AI.\\n7. The legislative framework should address the risks of AI deployment, especially the changes\\nin the concept of safety and liability, the changing functionality of AI applications during their\\nlifecycle and clear responsibility of different economic operators in the supply chain.\\n8. CEPIS supports the scope of future AI European legislation as proposed in the White Paper\\ntogether with the requirements on the high-risk AI applications. The legislation should be\\nbinding for all AI products regardless of whether they were produced in the EU. It should be\\nenforced within the frame of conformity assessment mechanisms that already exist for the\\nlarge number of products circulating in the EU internal market, with special provisions for AI\\nproducts.\\n9. CEPIS strongly supports the aim of the European Commission to regulate limitations of the\\nusage of AI technologies in the public sphere regarding fundamental rights, particularly the use\\nof facial recognition technology for remote biometric identification in public spaces.\\n10. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529958-CEPIS-Comments-on-White-Paper-on-AI.pdf', 'stakeholder_name': 'Council of European Professional Informatics Societies (CEPIS)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 14:35', 'language': 'English', 'document_reference': 'F529958', 'document_name': 'F529958-CEPIS-Comments-on-White-Paper-on-AI.pdf', '_split_id': 4, 'page': 2, '_split_overlap': [{'doc_id': 'ab1686318d071f20f6433a77d25b295c', 'range': (0, 151)}, {'doc_id': '298c32b151bb85ad75e9f9f50630c8c', 'range': (905, 1182)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'cfd50d68d4e6adc04f94bb3d25aadee'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Council of European Professional Informatics Societies (CEPIS), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 14:35, language: English, \\n\\nPassage: CEPIS strongly supports the aim of the European Commission to regulate limitations of the\\nusage of AI technologies in the public sphere regarding fundamental rights, particularly the use\\nof facial recognition technology for remote biometric identification in public spaces.\\n10. CEPIS supports the creation of a governance structure in the form of a framework for\\ncooperation of the responsible national authorities which should play a key role in the\\nimplementation of AI legislation by issuing guidance and opinions, exchanging information and\\nbest practice, and advising on improvement of standardisation, testing and certification.\\n11. Alongside thousands of experts3, CEPIS is convinced that the EU should ban lethal\\nautonomous weapons based on AI technologies. CEPIS believes that such technology poses\\ngreat risk for civil liberties and peace and supports the drafted idea of those bans.\\n12. CEPIS agrees that AI is a strategic technology that offers many benefits for citizens,\\ncompanies and society as a whole, provided it is human-centric, ethical and sustainable and\\nrespects fundamental rights and values. CEPIS is ready to cooperate with the European\\nCommission in the work outlined in the White Paper and provide the feedback of IT\\nprofessionals from CEPIS Member States all over Europe.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529958-CEPIS-Comments-on-White-Paper-on-AI.pdf', 'stakeholder_name': 'Council of European Professional Informatics Societies (CEPIS)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 14:35', 'language': 'English', 'document_reference': 'F529958', 'document_name': 'F529958-CEPIS-Comments-on-White-Paper-on-AI.pdf', '_split_id': 5, 'page': 2, '_split_overlap': [{'doc_id': 'cfd50d68d4e6adc04f94bb3d25aadee', 'range': (0, 277)}, {'doc_id': 'f439571b6d0a9766094b65bf7a749e18', 'range': (1117, 1300)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '298c32b151bb85ad75e9f9f50630c8c'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Council of European Professional Informatics Societies (CEPIS), stakeholder_type: NGO (Non-governmental organisation), stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 11-06-2020 14:35, language: English, \\n\\nPassage: CEPIS is ready to cooperate with the European\\nCommission in the work outlined in the White Paper and provide the feedback of IT\\nprofessionals from CEPIS Member States all over Europe.\\nThe Council of European Professional Informatics Societies (CEPIS) was established 30 years ago to\\nrepresent European informatics professionals and to act as their voice. Our ambition is that informatics\\nprofessionals' voice be heard and paid regard to. Being an institution of civil society, we care about the\\nsocial impact of information technology and feel obliged to raise our voice when an issue is close to the\\ncontent of our concern.\\n3 https://futureoflife.org/open-letter-autonomous-weapons/\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F529958-CEPIS-Comments-on-White-Paper-on-AI.pdf', 'stakeholder_name': 'Council of European Professional Informatics Societies (CEPIS)', 'stakeholder_type': 'NGO (Non-governmental organisation)', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '11-06-2020 14:35', 'language': 'English', 'document_reference': 'F529958', 'document_name': 'F529958-CEPIS-Comments-on-White-Paper-on-AI.pdf', '_split_id': 6, 'page': 2, '_split_overlap': [{'doc_id': '298c32b151bb85ad75e9f9f50630c8c', 'range': (0, 183)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f439571b6d0a9766094b65bf7a749e18'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Confederation of Finnish Industries EK, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Finland, document_date: 11-06-2020 09:49, language: English, \\n\\nPassage: Legal Affairs and Administration\\nSanna-Maria Bertell June 11, 2020 1 (2)\\nEUROPEAN COMMISSION\\nCONSULTATION ON COMMISSION WHITE PAPER ON AI\\nConfederation of Finnish Industries (“EK”) is the leading business organization in Finland.1 EK\\nrepresents the entire private sector and companies of all sizes. It serves over 15,300 member\\ncompanies across all business sectors. EK thanks for the opportunity to participate in the\\nconsultation and presents the following remarks.\\n1. Terminology and scope: Organizations and citizens need to have a clear understanding when/if\\nsomething applies to them. Any regulation should have a clear definition of the scope, context,\\nand specific properties that trigger its application. There are several proposals for definitions of\\nAI, which is also recognized in the White Paper, and there is a clear need to develop these for\\nlegal language purposes. Preferably for interoperability reasons, the terminology should also\\nreflect a wide consensus globally. Where needed, more precise references should be made to\\ntype of AI technology, depending on the context (machine learning, neural networks, etc.).\\n- Recommendation: follow closely global standardization work and for example OECD\\ndevelopments in this area.\\n2. Risk-based approach: We welcome the principle of risk-based approach. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529929-AI_White_Paper_position_paper_EK_FINAL.pdf', 'stakeholder_name': 'Confederation of Finnish Industries EK', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Finland', 'stakeholder_scope': nan, 'document_date': '11-06-2020 09:49', 'language': 'English', 'document_reference': 'F529929', 'document_name': 'F529929-AI_White_Paper_position_paper_EK_FINAL.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': '821526e3a22303bd4228764965227899', 'range': (1133, 1314)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '476ebdef617a439ca1669b72b482cc98'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Confederation of Finnish Industries EK, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Finland, document_date: 11-06-2020 09:49, language: English, \\n\\nPassage: - Recommendation: follow closely global standardization work and for example OECD\\ndevelopments in this area.\\n2. Risk-based approach: We welcome the principle of risk-based approach. Regulation in general,\\nand AI regulation specifically, needs to address only recognized and real risks or otherwise risk\\nunwanted market distortion. “One-size-fits-all” does not really work for AI; defining applicable\\nhigh-risk sector and high-risk use combinations exhaustively upfront is not likely going to be\\nunivocally clear and predictable in a fast-moving technology environment. There already are\\nsectoral rules for several identified use cases (e.g. transport, health). Additionally, referring to\\nconsumer applications qualifying as high risk seems overly broad and somewhat unqualified.\\n- Recommendation: align risk-management in principle-based manner based on objective,\\ntechnology-neutral and more nuanced criteria (vs. approaching it from strictly sectoral or\\nuser group perspective).\\n3. Data – personal and non-personal: AI is as good as the data sets it uses. Further clarity is\\nneeded on how handle different data rights, especially what type of IPR protection data enjoys\\nin AI context. The new Digital Single Market directive enables data mining, under specific\\ncopyright exceptions for limited purposes under certain terms, but other IPR aspects also need\\nto be assessed. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529929-AI_White_Paper_position_paper_EK_FINAL.pdf', 'stakeholder_name': 'Confederation of Finnish Industries EK', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Finland', 'stakeholder_scope': nan, 'document_date': '11-06-2020 09:49', 'language': 'English', 'document_reference': 'F529929', 'document_name': 'F529929-AI_White_Paper_position_paper_EK_FINAL.pdf', '_split_id': 1, 'page': 1, '_split_overlap': [{'doc_id': '476ebdef617a439ca1669b72b482cc98', 'range': (0, 181)}, {'doc_id': 'b8540f78686fbdfcb28589cdb809fa3b', 'range': (1187, 1373)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '821526e3a22303bd4228764965227899'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Confederation of Finnish Industries EK, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Finland, document_date: 11-06-2020 09:49, language: English, \\n\\nPassage: The new Digital Single Market directive enables data mining, under specific\\ncopyright exceptions for limited purposes under certain terms, but other IPR aspects also need\\nto be assessed. Looking at other key issues mentioned in data context (personal data, privacy\\nand non-discrimination, etc.), it seems clear that while AI may have triggered these discussions,\\nit does not automatically follow from that these issues should be dealt with a general AI\\nlegislation. Therefore, certain challenges should be dealt in context of (and in relation to)\\nother legislation, especially concerning the interaction with the General Data Protection\\nRegulation.\\n- Recommendation: Trade secrets, data base rights and interactions with the GDPR need to\\nbe clarified in AI context.\\n1 EU transparency register number 1274604847-34\\nRef. Ares(2020)3359747 - 26/06/2020\\x0cLegal Affairs and Administration\\nSanna-Maria Bertell June 11, 2020 2 (2)\\n4. Ex ante / pre-market approval and governance: We are forced to take a very critical stand to\\npre-market assessment and authority approvals for AI technology. Such approach would likely\\nseverely stifle innovation and competitiveness in critical sectors. It is not even clear if current\\nMember State government systems would be up for the task. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529929-AI_White_Paper_position_paper_EK_FINAL.pdf', 'stakeholder_name': 'Confederation of Finnish Industries EK', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Finland', 'stakeholder_scope': nan, 'document_date': '11-06-2020 09:49', 'language': 'English', 'document_reference': 'F529929', 'document_name': 'F529929-AI_White_Paper_position_paper_EK_FINAL.pdf', '_split_id': 2, 'page': 1, '_split_overlap': [{'doc_id': '821526e3a22303bd4228764965227899', 'range': (0, 186)}, {'doc_id': 'b5fd08dad7a0f406b8d0c6f316634ff7', 'range': (1084, 1268)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b8540f78686fbdfcb28589cdb809fa3b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Confederation of Finnish Industries EK, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Finland, document_date: 11-06-2020 09:49, language: English, \\n\\nPassage: Such approach would likely\\nseverely stifle innovation and competitiveness in critical sectors. It is not even clear if current\\nMember State government systems would be up for the task. Such governance would require\\nexperts in various fields (combinations of legal, engineering, coding and sectoral) and generally\\ndeep knowledge of different algorithm, data set and AI technologies. Creating such capacities\\nwould require considerable investment in time, resources, and highly skilled workforce, which\\nis already in high demand.\\nThere is a better way, and market operators should drive the development of trust-\\nmechanisms (agreements, sandboxes, labelling etc.) to ensure agile approach and adaptation\\nof best risk-management measures. We strongly encourage the Commission to support\\nnational, European, and international tools for development and use of AI.\\n- Recommendation:\\no Support sandbox-initiatives for certain more sensitive sectors and uses to promote\\nunderstanding for needed regulations together with developers and users;\\no Support business-driven standardisation work for technical and administrational\\nstandards, to promote softer guiding instruments as part of regulatory framework.\\n5. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529929-AI_White_Paper_position_paper_EK_FINAL.pdf', 'stakeholder_name': 'Confederation of Finnish Industries EK', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Finland', 'stakeholder_scope': nan, 'document_date': '11-06-2020 09:49', 'language': 'English', 'document_reference': 'F529929', 'document_name': 'F529929-AI_White_Paper_position_paper_EK_FINAL.pdf', '_split_id': 3, 'page': 2, '_split_overlap': [{'doc_id': 'b8540f78686fbdfcb28589cdb809fa3b', 'range': (0, 184)}, {'doc_id': 'e9b5612bf0f7306a310030467f4cdf00', 'range': (859, 1201)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b5fd08dad7a0f406b8d0c6f316634ff7'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Confederation of Finnish Industries EK, stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Medium (< 250 employees), stakeholder_country: Finland, document_date: 11-06-2020 09:49, language: English, \\n\\nPassage: - Recommendation:\\no Support sandbox-initiatives for certain more sensitive sectors and uses to promote\\nunderstanding for needed regulations together with developers and users;\\no Support business-driven standardisation work for technical and administrational\\nstandards, to promote softer guiding instruments as part of regulatory framework.\\n5. Labelling: can be an appealing alternative and a softer approach compared to regulating, but it\\nmust be ensured that any program, even if voluntary, does not create undue cost or\\nadministrative burden and that it follows the risk-based approach. Labelling may have\\nunintended consequence and become de facto mandatory certification scheme. This could be\\na clear hindrance, especially to SMEs.\\n- Recommendation: Promote voluntary labelling programs, but only where this is\\nmeaningful for users, consumers, and developers alike.\\n6. Safety and liability: We welcome efforts to assess product safety and liability regulations also\\nfrom AI perspective, as long as the overall aim is that safety and liability regulation remains\\ntechnology neutral. Only specific, identified needs backed by strong evidence and clear gaps in\\ncurrent regulations should be addressed.\\n- Recommendation: any development in this area should maintain a careful balance\\nbetween EU-level harmonization and national liability regimes and procedural rules.', 'content_type': 'text', 'score': None, 'meta': {'name': 'F529929-AI_White_Paper_position_paper_EK_FINAL.pdf', 'stakeholder_name': 'Confederation of Finnish Industries EK', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Medium (< 250 employees)', 'stakeholder_country': 'Finland', 'stakeholder_scope': nan, 'document_date': '11-06-2020 09:49', 'language': 'English', 'document_reference': 'F529929', 'document_name': 'F529929-AI_White_Paper_position_paper_EK_FINAL.pdf', '_split_id': 4, 'page': 2, '_split_overlap': [{'doc_id': 'b5fd08dad7a0f406b8d0c6f316634ff7', 'range': (0, 342)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e9b5612bf0f7306a310030467f4cdf00'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: Consultation on the European Commission’s\\nWhite Paper on Artificial Intelligence: a European approach to\\nexcellence and trust\\nSubmission of the Centre for the Governance of AI,\\nFuture of Humanity Institute, University of Oxford\\nJune 2020\\nRef. Ares(2020)3357339 - 26/06/2020\\x0cTable of Contents\\nIntroduction 1\\nExecutive Summary 2\\nRegulatory scope 4\\nTypes of requirements 6\\nCompliance and enforcement 7\\nGovernance 8\\nInternational aspects 9\\nIntroduction\\nThe Centre for the Governance of AI, part of the Future of Humanity Institute, University of\\nOxford, strives to help humanity capture the benefits while managing the risks of artificial\\nintelligence (AI). We conduct research and advise decision-makers on some of the most\\nimportant and neglected issues of AI governance, drawing on political science, international\\nrelations, computer science, economics, law, and philosophy.\\nIn this response, we focus our analysis and recommendations on the proposed “ecosystem of\\ntrust” and associated international efforts. We believe these measures can mitigate the risks\\nthat this technology poses to the safety and rights of Europeans. Trustworthy technology also\\ncontributes to the long-term competitiveness of the European AI sector. Accidents and misuse\\nwould risk undermining the trust necessary for this industry to flourish. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': 'c8d537faeab9d3e92d0b9a029f4e488c', 'range': (1125, 1319)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bae34ee0b76517b26549a809f163b87f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: Trustworthy technology also\\ncontributes to the long-term competitiveness of the European AI sector. Accidents and misuse\\nwould risk undermining the trust necessary for this industry to flourish. There is evidence that a\\n1\\nmajority of Europeans already want AI technology to be carefully managed and believe a public\\npolicy response is required. At the same time, any regulatory framework on AI needs to be\\n2\\nproportionate and flexible. Without such a careful approach, we risk stifling the innovation\\nneeded to reap the benefits from further development and adoption of this technology.\\n1 The public response to the Three Mile Island Nuclear Accident, for instance, contributed significantly to the\\nsubsequent slowdown of the U.S. nuclear power industry. See Hultman & Koomey (2013). “Three Mile Island: The\\ndriver of US nuclear power’s decline?” Bulletin of the Atomic Scientists, 69 (3). DOI: 10.1177/0096340213485949.\\n2 TNS opinion & social (2017). “Attitudes towards the impact of digitisation and automation on daily life.” Special\\nEurobarometer 460. Retrieved from: https://data.europa.eu/euodp/en/data/dataset/S2160_87_1_460_ENG.\\nKantar (2019). “Europeans and Artificial Intelligence.” Standard Eurobarometer 92. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 1, 'page': 2, '_split_overlap': [{'doc_id': 'bae34ee0b76517b26549a809f163b87f', 'range': (0, 194)}, {'doc_id': '697a9ee6509b78aaebe70a9c8c8bd0c5', 'range': (952, 1219)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c8d537faeab9d3e92d0b9a029f4e488c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: “Attitudes towards the impact of digitisation and automation on daily life.” Special\\nEurobarometer 460. Retrieved from: https://data.europa.eu/euodp/en/data/dataset/S2160_87_1_460_ENG.\\nKantar (2019). “Europeans and Artificial Intelligence.” Standard Eurobarometer 92. Retrieved from:\\nhttps://ec.europa.eu/commfrontoffice/publicopinionmobile/index.cfm/Survey/getSurveyDetail/surveyKy/2255\\n1\\x0cExecutive Summary\\nRegulatory scope.\\u200b We support the proposed cumulative risk-based approach, which combines\\na risk assessment of different sectors with an assessment of intended uses since it allows for\\nrequirements that are proportionate to the risks posed by a given application. We make several\\nrecommendations to clarify the proposed system. We also suggest incorporating additional\\naspects into the risk assessment procedure to better account for risks from applications with\\nlarge-scale effects.\\n● Clarify the definition of risk as a function of the likelihood of a harmful scenario occurring\\nand the severity of that harm.\\n● Clarify the assessment of multi-sector AI applications.\\n● Consider incorporating harm to public interests in the risk assessment.\\n● Consider incorporating the scale of use (number of users, frequency of use) of a given AI\\napplication into the risk assessment procedure.\\nType of requirements.\\u200b We agree with the spirit of the proposed requirements. We make two\\nrecommendations to address particular failure modes of AI applications.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 2, 'page': 2, '_split_overlap': [{'doc_id': 'c8d537faeab9d3e92d0b9a029f4e488c', 'range': (0, 267)}, {'doc_id': '579f86f47e542c65c74039273716edd5', 'range': (1292, 1453)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '697a9ee6509b78aaebe70a9c8c8bd0c5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: Type of requirements.\\u200b We agree with the spirit of the proposed requirements. We make two\\nrecommendations to address particular failure modes of AI applications.\\n● Consider adding specific robustness requirements for AI applications operating in tightly\\ncoupled systems prone to emergent behaviour patterns.\\n● Consider requiring disclosures of conflicts of interest between AI applications and their\\nusers.\\nCompliance and enforcement. \\u200bWe are generally supportive of the proposed compliance and\\nenforcement mechanisms. Our recommendations focus on ensuring the development of tools\\nand expertise required for putting them into practice.\\n● Support research on testing, evaluation, verification, and validation (VVT&E) of AI\\napplications.\\n● Support research on the interpretability of AI applications.\\n● Support social science research on the impact and governance of AI systems.\\nGovernance. \\u200bWe agree with the need for a flexible regulatory framework and make\\nrecommendations for evaluation and monitoring efforts, intended to inform future adjustments.\\n● Regularly review and amend the regulatory framework.\\n● Consider establishing a database for the sharing of information on AI incidents.\\n2\\x0cInternational aspects. \\u200bWe support the cooperative stance of the Commission and make\\nconcrete recommendations for increased international collaborations.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 3, 'page': 3, '_split_overlap': [{'doc_id': '697a9ee6509b78aaebe70a9c8c8bd0c5', 'range': (0, 161)}, {'doc_id': 'f8d53460ffee933dff0da4f18f134714', 'range': (1108, 1346)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '579f86f47e542c65c74039273716edd5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: ● Consider establishing a database for the sharing of information on AI incidents.\\n2\\x0cInternational aspects. \\u200bWe support the cooperative stance of the Commission and make\\nconcrete recommendations for increased international collaborations.\\n● Initiate and support international efforts for developing a shared understanding of the\\npotential benefits and risks from AI.\\n● Facilitate exchange with global players on best practices for the assessments, testing,\\nand regulation of AI applications.\\n● Contribute to the setting of global AI technology standards.\\n● Explore the possibility of establishing an international database for the sharing of\\ninformation on AI incidents.\\n● Explore international partnerships for the proposed lighthouse research centre in\\nEurope.\\nRegulatory scope\\nWe are supportive of a risk-based framework, ensuring “that the regulatory intervention is\\nproportionate” (p. 17). For the risk assessment, the two cumulative criteria proposed in the\\n3\\nWhite Paper are reasonable. Allowing for exceptional instances that are to be considered\\n“high-risk” as such is sensible.\\nWe believe that a few aspects of the assessment procedure would benefit from clarifications,\\nwhich we outline below. We also suggest incorporating additional factors into the risk\\nassessment procedure to better account for risks from applications with large-scale effects.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 4, 'page': 3, '_split_overlap': [{'doc_id': '579f86f47e542c65c74039273716edd5', 'range': (0, 238)}, {'doc_id': 'f18b21ee20dbb11336e4c6822dda277c', 'range': (1205, 1360)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f8d53460ffee933dff0da4f18f134714'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: We also suggest incorporating additional factors into the risk\\nassessment procedure to better account for risks from applications with large-scale effects.\\nClarify the definition of risk as a function of the likelihood of a harmful scenario\\noccurring and the severity of that harm. \\u200bThe Commission suggests that a sector is to be\\nconsidered “high-risk”, if, “given the characteristics of the activities typically undertaken,\\nsignificant risks can be expected to occur” (p. 17). Furthermore, the specific uses have to be\\nsuch that “significant risks are likely to arise” (p. 17). This approach does not seem to follow\\nother existing risk assessment methodologies, which usually define risk in a given scenario as a\\nfunction of the “combination of the probability of occurrence of a hazard generating harm in a\\ngiven scenario and the severity of that harm.” Concretely, we are concerned that this approach\\n4\\ndoes not sufficiently take into account potentially catastrophic risks involving AI systems since\\nthese are usually \\u200bunlikely\\u200b to occur. For instance, risks from the use of AI applications in nuclear\\npower plants might not be “expected to occur” but should still be considered sufficiently serious\\nto merit the designation as a “high-risk” application. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 5, 'page': 4, '_split_overlap': [{'doc_id': 'f8d53460ffee933dff0da4f18f134714', 'range': (0, 155)}, {'doc_id': '925aa822a0b5bd8e491e9c58e506d31f', 'range': (1043, 1258)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f18b21ee20dbb11336e4c6822dda277c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: For instance, risks from the use of AI applications in nuclear\\npower plants might not be “expected to occur” but should still be considered sufficiently serious\\nto merit the designation as a “high-risk” application. Preventing and mitigating such risks\\nthrough appropriate measures is particularly important since even just one occurrence would\\ncause harm on a large scale.\\n3 If not indicated otherwise, direct quotes are from: European Commission (2019). “White Paper: On Artificial\\nIntelligence - A European approach to excellence and trust” (EN). Retrieved from:\\nhttps://ec.europa.eu/info/sites/info/files/commission-white-paper-artificial-intelligence-feb2020_en.pdf.\\n4 European Commission (2015): “EU general risk assessment methodology” (EN), p. 4. Retrieved from:\\nhttp://ec.europa.eu/DocsRoom/documents/17107/attachments/1/translations/\\n3\\x0cClarify the assessment of multi-sector AI applications. \\u200bThe cumulative risk assessment\\nprocedure proposed by the Commission is appropriate for assessing narrow AI applications that\\ncan be situated within a single sector. However, we are concerned that this will result in legal\\nuncertainties for systems that can be employed within multiple sectors (e.g., AI-enabled\\ncybersecurity applications) or have general capabilities that extend across sectors (e.g.,\\nAI-enabled personal assistants). The current phrasing of the risk assessment procedure is\\n5\\nambiguous with regard to how to handle such cases. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 6, 'page': 4, '_split_overlap': [{'doc_id': 'f18b21ee20dbb11336e4c6822dda277c', 'range': (0, 215)}, {'doc_id': '65e64d0fb7ab6ec5e233fa8de32627ff', 'range': (1303, 1447)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '925aa822a0b5bd8e491e9c58e506d31f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: ,\\nAI-enabled personal assistants). The current phrasing of the risk assessment procedure is\\n5\\nambiguous with regard to how to handle such cases. Such systems might evade regulatory\\n6\\nscrutiny, even though they pose more risks than applications employed in just one sector.\\nConsider incorporating harm to public interests in the risk assessment\\u200b. The Commission\\nacknowledges that “the impact of AI systems should be considered not only from an individual\\nperspective, but also from the perspective of society as a whole.” (p. 2) The risk assessment in\\nits current outline does not reflect this. It is our understanding that it is solely focused on legal\\nentities. Some applications, however, will pose structural risks to public interests that would not\\nnecessarily be reflected in an assessment of the harm to persons or other legal subjects. For\\ninstance, AI-enabled recommendation algorithms on social media platforms could shape public\\ndiscourse in ways that are harmful to our democratic system while not clearly harming the safety\\nor violating the rights of any particular person. So the Commission could consider “protecting a\\nwider range of ‘subjects’ [than consumers]. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 7, 'page': 5, '_split_overlap': [{'doc_id': '925aa822a0b5bd8e491e9c58e506d31f', 'range': (0, 144)}, {'doc_id': '5ecdd30a44efc9e331718fddef7a54', 'range': (843, 1176)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '65e64d0fb7ab6ec5e233fa8de32627ff'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: For\\ninstance, AI-enabled recommendation algorithms on social media platforms could shape public\\ndiscourse in ways that are harmful to our democratic system while not clearly harming the safety\\nor violating the rights of any particular person. So the Commission could consider “protecting a\\nwider range of ‘subjects’ [than consumers]. [...] These ‘subjects’ are normally the overall public\\ninterests covered by the relevant Union harmonisation legislation.” We suggest, however, to\\n7\\nproceed carefully since attributing influence and harm in this domain is difficult. 8\\nConsider incorporating the scale of use (number of users, frequency of use) of a given AI\\napplication into the risk assessment procedure\\u200b. The White Paper suggests that the\\n“assessment of the level of risk of a given use could be based on the impact on the affected\\nparties” (p. 17). We generally support such an impact-based assessment. We are concerned,\\nhowever, about an analysis that is exclusively based on the “risk of a given use.” For\\ndetermining whether oversight and regulation for a given application are appropriate (i.e.,\\nwhether a system should be considered “high-risk”), what matters is not only the risk posed by a\\ngiven use but also the overall risk posed by the application. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 8, 'page': 5, '_split_overlap': [{'doc_id': '65e64d0fb7ab6ec5e233fa8de32627ff', 'range': (0, 333)}, {'doc_id': '9b319546eb33cdf74fbca0e3c23a469d', 'range': (1102, 1262)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5ecdd30a44efc9e331718fddef7a54'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: ,\\nwhether a system should be considered “high-risk”), what matters is not only the risk posed by a\\ngiven use but also the overall risk posed by the application. This overall risk increases with the\\nnumber of users and interactions of a given AI application. Applications interacting with millions\\nof Europeans every day should face more scrutiny and oversight compared to applications\\ninteracting with hundreds of Europeans once a week, all else being equal. Such an approach\\n5 While not necessarily common today, such systems may become more prevalent in the future. There are some\\nindications that AI algorithms are becoming increasingly general in their capabilities (e.g., GPT-3, Alpha Zero,\\nAgent57). It is likely that such advances will be reflected in future commercial AI systems as well. Personal assistant\\nsoftware can already perform tasks across a range of domains.\\n6 There is no ambiguity only with regard to biometric identification applications and AI applications for recruitment\\nprocesses. They are designated as exceptional instances of “high-risk” applications as such.\\n7 European Commission (2015): “EU general risk assessment methodology” (EN), p. 9. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 9, 'page': 5, '_split_overlap': [{'doc_id': '5ecdd30a44efc9e331718fddef7a54', 'range': (0, 160)}, {'doc_id': 'e142ddde9fe02c0463a1bd6a8ebdf26c', 'range': (1007, 1171)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9b319546eb33cdf74fbca0e3c23a469d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: They are designated as exceptional instances of “high-risk” applications as such.\\n7 European Commission (2015): “EU general risk assessment methodology” (EN), p. 9. Retrieved from:\\nhttp://ec.europa.eu/DocsRoom/documents/17107/attachments/1/translations/\\n8 For instance, many media reports had claimed that the YouTube recommendation algorithm suggested increasingly\\nradical content to users of the platform. So far, however, this has not held up on closer inspection: Ledwich & Zaitsev\\n(2019). “Algorithmic Extremism: Examining YouTube’s Rabbit Hole of Radicalization.” arXiv:1912.11211.\\n4\\x0ccould also reduce the regulatory burden faced by Small and Medium Enterprises (SME). We\\nacknowledge that in some cases determining scale can be hard. Current risk assessment\\nprocedures, however, require similarly difficult estimates of the probability that a given harmful\\nscenario will occur. We believe that reasonable estimates can be made. These can be adjusted\\nas we learn more about the development of specific technologies.\\nTypes of requirements\\nWe agree with the spirit of the requirements laid out in Section D of the White Paper. We make\\ntwo recommendations to address particular failure modes of AI applications.\\nConsider adding specific robustness requirements for AI applications operating in tightly\\ncoupled systems prone to emergent behaviour patterns\\u200b. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 10, 'page': 5, '_split_overlap': [{'doc_id': '9b319546eb33cdf74fbca0e3c23a469d', 'range': (0, 164)}, {'doc_id': '2a395b79def7d669e0c7bb5e3702f272', 'range': (1130, 1358)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e142ddde9fe02c0463a1bd6a8ebdf26c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: We make\\ntwo recommendations to address particular failure modes of AI applications.\\nConsider adding specific robustness requirements for AI applications operating in tightly\\ncoupled systems prone to emergent behaviour patterns\\u200b. Such emergent patterns can cause\\nharmful outcomes, in a manner not easily foreseen by consideration of any one AI application in\\nisolation. In the 2010 “flash crash” of the U.S. stock market, for instance, such interactions\\n9\\namong trading algorithms led to a sudden trillion-dollar decline in U.S. financial market value. 10\\nThe markets quickly returned to pre-crash levels, partly as a result of mandatory “circuit\\nbreakers”, a requirement that the Securities and Exchange Commission had introduced after the\\nstock market crash of Black Monday in 1987. Such failures, however, might be extremely\\nharmful and irreversible in other sectors, such as defence and cybersecurity. Requiring\\n11\\napplications to be sufficiently robust in this respect could prevent such outcomes to some\\nextent. For instance, testing of such systems should not take place in isolation but mirror the\\ntight coupling of the environment they will be employed in.\\nConsider requiring disclosures of conflicts of interest between AI applications and their\\nusers\\u200b. Users increasingly consult AI applications for information, advice, and recommendations\\n(e.g.', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 11, 'page': 6, '_split_overlap': [{'doc_id': 'e142ddde9fe02c0463a1bd6a8ebdf26c', 'range': (0, 228)}, {'doc_id': '415f61bd7982e7c435737f8337965df3', 'range': (1165, 1355)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2a395b79def7d669e0c7bb5e3702f272'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: Consider requiring disclosures of conflicts of interest between AI applications and their\\nusers\\u200b. Users increasingly consult AI applications for information, advice, and recommendations\\n(e.g., via personal assistants, search results, or user feeds). They may reasonably expect that\\nalgorithms providing advice or recommendations are aligned with their best interests.\\nDevelopers, however, are often incentivised to align the algorithm with their commercial\\ninterests, which track the best interests of their clients only imperfectly. For instance,\\n12\\ncompanies may have their virtual assistants promote their own products, even if a better product\\nwas available for the user. Given the strong information asymmetry inherent in the use of such\\napplications, users on their own will be in a poor position to identify such misalignment.\\nRequiring the disclosures of such conflicts of interest will empower users to make more\\n9 Maas (2018). “Regulating for 'Normal AI Accidents': Operational Lessons for the Responsible Governance of\\nArtificial Intelligence Deployment.” AAAI/ACM Conference. DOI: 10.1145/3278721.3278766.\\n10 U.S. Commodity Futures Trading Commission, and U.S. Securities & Exchange Commission (2010). \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 12, 'page': 6, '_split_overlap': [{'doc_id': '2a395b79def7d669e0c7bb5e3702f272', 'range': (0, 190)}, {'doc_id': '8926bee8e27c8ee33a25afe0f55374ba', 'range': (937, 1213)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '415f61bd7982e7c435737f8337965df3'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: “Regulating for 'Normal AI Accidents': Operational Lessons for the Responsible Governance of\\nArtificial Intelligence Deployment.” AAAI/ACM Conference. DOI: 10.1145/3278721.3278766.\\n10 U.S. Commodity Futures Trading Commission, and U.S. Securities & Exchange Commission (2010). “Findings\\nRegarding the Market Events of May 6, 2010: Report of the Staffs of the CFTC and SEC to the Joint Advisory\\nCommittee on Emerging Regulatory Issues.” Retrieved from:\\nhttps://www.sec.gov/news/studies/2010/marketevents-report.pdf\\n11 Scharre (2018). “Army of None: Autonomous Weapons and the Future of War.” W. W. Norton & Company.\\nFeldman, Dant & Massey (2019). “Integrating Artificial Intelligence into Weapon Systems.” arXiv:1905.03899v1.\\n12Aguirre, Dempsey, Surden & Reiner (2020). “AI loyalty: A New Paradigm for Aligning Stakeholder Interests.” U of\\nColorado Law Legal Studies Research Paper No. 20-18. Retrieved from: http://dx.doi.org/10.2139/ssrn.3560653\\n5\\x0cinformed decisions about their engagement with such applications. Such requirements may\\ninvolve disclosing the basic business model and types of revenue generated by a given\\napplication. They may also include labelling advertisements and sponsored content or results to\\nthe users of a given application.\\nCompliance and enforcement\\nWe support an independent conformity assessment of “high-risk” applications prior to market\\nentry to ensure that they meet the requirements set out in the regulatory framework.\\n\", 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 13, 'page': 6, '_split_overlap': [{'doc_id': '415f61bd7982e7c435737f8337965df3', 'range': (0, 276)}, {'doc_id': '9e3ec5bc9f46f56b502b3a5257baa544', 'range': (1253, 1456)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8926bee8e27c8ee33a25afe0f55374ba'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: Compliance and enforcement\\nWe support an independent conformity assessment of “high-risk” applications prior to market\\nentry to ensure that they meet the requirements set out in the regulatory framework.\\nSelf-assessment by businesses themselves would not be sufficient or fair, given the potentially\\ncatastrophic risks included in the “high-risk” classification and the burden self-assessments\\nwould impose on SME. Additional controls after applications have already entered the market\\n13\\nare particularly important for “certain AI systems evolve and learn from experience” (p. 23).\\nOur recommendations focus on ensuring the development of tools and expertise required for\\neffective compliance and enforcement.\\nSupport research on testing, evaluation, verification, and validation (VVT&E) of AI\\napplications. \\u200bConformity assessments will require testing, evaluation, verification, and\\nvalidation (VVT&E) of AI applications, especially for verifying conformity with robustness\\nrequirements. Unfortunately, the “current state of AI VVT&E is nowhere close to ensuring the\\nperformance and safety of AI applications, particularly where safety-critical systems are\\nconcerned.” Methods used for ensuring the safety and reliability of traditional software, e.g.,\\n14\\nformal verification, can currently not be applied to machine learning systems. Advancing this\\nfield will be crucial for establishing an effective assessment scheme. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 14, 'page': 7, '_split_overlap': [{'doc_id': '8926bee8e27c8ee33a25afe0f55374ba', 'range': (0, 203)}, {'doc_id': 'd45f6eddd6091dd90ce11a7a1afabb04', 'range': (1253, 1422)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9e3ec5bc9f46f56b502b3a5257baa544'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: ,\\n14\\nformal verification, can currently not be applied to machine learning systems. Advancing this\\nfield will be crucial for establishing an effective assessment scheme. We suggest the\\nCommission support such work through its Framework Programmes. Test centres could also be\\ngiven support to conduct research where necessary.\\nSupport research on the interpretability of AI applications. Progress on the interpretability\\n15\\nof machine learning systems would likely contribute to a well-functioning liability regime since it\\nwould make it easier for claimants to establish a cause-and-effect relationship between model\\nand harm. It would also improve our predictions of the output of AI systems ex-ante, which\\nwould be helpful for developers designing more trustworthy applications as well as making risk\\nassessments and conformity assessments more reliable. Unfortunately, “there is very little\\nconsensus on what interpretable machine learning is and how it should be measured.” 16\\nEstablishing clear definitions and benchmarks for interpretable AI applications will be important\\n13 If the risk classification scheme was more fine-grained, self-assessment might be appropriate for some tiers.\\n14 Tarraf et al. (2019): “The Department of Defense Posture for Artificial Intelligence.” RAND report, p. 36. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 15, 'page': 7, '_split_overlap': [{'doc_id': '9e3ec5bc9f46f56b502b3a5257baa544', 'range': (0, 169)}, {'doc_id': '9c6a47b0e5c4be7ad3ebf79cf58059f2', 'range': (857, 1301)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd45f6eddd6091dd90ce11a7a1afabb04'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: Unfortunately, “there is very little\\nconsensus on what interpretable machine learning is and how it should be measured.” 16\\nEstablishing clear definitions and benchmarks for interpretable AI applications will be important\\n13 If the risk classification scheme was more fine-grained, self-assessment might be appropriate for some tiers.\\n14 Tarraf et al. (2019): “The Department of Defense Posture for Artificial Intelligence.” RAND report, p. 36. Retrieved\\nfrom: https://doi.org/10.7249/RR4229\\n15 For an interview of interpretability research: Gilpin et al. (2019). “Explaining Explanations: An Overview of\\nInterpretability of Machine Learning.” 5th IEEE International Conference on Data Science and Advanced Analytics\\n(DSAA 2018). arXiv:1806.00069.\\n16 Doshi-Velez, Kim (2017). “Towards A Rigorous Science of Interpretable Machine Learning.” arXiv:1702.08608.\\n6\\x0cfor enabling progress in the field. We suggest the Commission support such work through its\\nFramework Programmes. 17\\nSupport social science research on the impact and governance of AI systems.\\u200b We agree\\nwith the Commission that “authorities should be in a position to investigate individual cases, but\\nalso to assess the impact on society” (p. 23). Such research into the social effects of AI systems\\nand how to address them through appropriate governance systems is still in its infancy.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 16, 'page': 7, '_split_overlap': [{'doc_id': 'd45f6eddd6091dd90ce11a7a1afabb04', 'range': (0, 444)}, {'doc_id': 'bbac1ae8f217a8df1451e81c9ba2a983', 'range': (1209, 1348)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9c6a47b0e5c4be7ad3ebf79cf58059f2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: Such research into the social effects of AI systems\\nand how to address them through appropriate governance systems is still in its infancy.\\nAdvancing research in this field would be important for informing the work of the relevant\\nnational and European authorities as well as guide the further development of the regulatory\\nframework. We suggest the Commission support such work through its Framework\\nProgrammes.\\nGovernance\\nAI is a rapidly evolving field. In light of this, we agree with the Commission that “the regulatory\\nframework must leave room to cater for further developments” (p. 10), instead of trying to create\\na regulatory framework that anticipates all such eventualities. Addressing future developments\\n18\\nwill require thorough evaluation and monitoring efforts, which is the focus of our\\nrecommendations.\\nRegularly review and amend the regulatory framework\\u200b. We trust the Commission to set up\\nfrequent and timely evaluations as well as appropriate monitoring mechanisms, following its\\nguidance as laid out in the \\u200bBetter Regulation Guidelines\\u200b. We are supportive of the stakeholder\\n19\\nconsultation procedures outlined in Section H of the White Paper.\\nConsider establishing a database for the sharing of information on AI incidents. \\u200bA central\\nrepository of “AI incidents”, i.e.', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 17, 'page': 8, '_split_overlap': [{'doc_id': '9c6a47b0e5c4be7ad3ebf79cf58059f2', 'range': (0, 139)}, {'doc_id': '35786e7259f96e246d1a06aacfe8e592', 'range': (1060, 1291)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bbac1ae8f217a8df1451e81c9ba2a983'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: We are supportive of the stakeholder\\n19\\nconsultation procedures outlined in Section H of the White Paper.\\nConsider establishing a database for the sharing of information on AI incidents. \\u200bA central\\nrepository of “AI incidents”, i.e., instances of undesired or unexpected and (potentially) harmful\\nbehaviour by an AI application, would improve the implementation and further development of\\nthe regulatory framework. The appropriate national authorities and independent testing centres\\ncould build up shared institutional knowledge of common failure modes. The Commission would\\nalso be in a better position to adjust the scope and requirements of the framework. Such a\\ndatabase has been proposed by a broad coalition of researchers and the Partnership on AI has\\nalready launched such a database. Widespread use would be crucial for its success, but\\n20\\nbusinesses might be wary of submitting incident reports for fear of reputational or other costs.\\n17 Brundage, Avin, Wang, Belfield, Krueger, et al. (2020). “Toward Trustworthy AI Development: Mechanisms for\\nSupporting Verifiable Claims.” arXiv:2004.07213.\\n18 Bostrom, Dafoe & Flynn (2016). “Policy Desiderata for Superintelligent AI: A Vector Field Approach.” Forthcoming\\nin Liao, S.M. (ed.): Ethics of Artificial Intelligence (Oxford University Press). Retrieved from:\\nhttps://pdfs.semanticscholar.org/9601/74bf6c840bc036ca7c621e9cda20634a51ff.pdf\\n19 European Commission (2017). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 18, 'page': 8, '_split_overlap': [{'doc_id': 'bbac1ae8f217a8df1451e81c9ba2a983', 'range': (0, 231)}, {'doc_id': '858352a74852d586bf5d58e95fbed230', 'range': (1140, 1429)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '35786e7259f96e246d1a06aacfe8e592'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: “Policy Desiderata for Superintelligent AI: A Vector Field Approach.” Forthcoming\\nin Liao, S.M. (ed.): Ethics of Artificial Intelligence (Oxford University Press). Retrieved from:\\nhttps://pdfs.semanticscholar.org/9601/74bf6c840bc036ca7c621e9cda20634a51ff.pdf\\n19 European Commission (2017). “Better Regulation Guidelines.” SWD (2017) 350. Retrieved from:\\nhttps://ec.europa.eu/info/sites/info/files/better-regulation-guidelines.pdf\\n20 Brundage, Avin, Wang, Belfield, Krueger, et al. (2020). “Toward Trustworthy AI Development: Mechanisms for\\nSupporting Verifiable Claims.” arXiv:2004.07213. For the database, see Partnership on AI. “AI Incidents Database.”\\nAvailable at: http://aiid.partnershiponai.org/\\n7\\x0cSeveral measures could be taken to address such concerns, e.g., by ensuring anonymity,\\nsecurity, and privacy. Submitting incident reports could be further incentivised, e.g., through\\nregulatory requirements or monetary incentives for developers, users, or third parties\\n(“bounties”). Similar models for such information-sharing arrangements have been set up in\\n21\\nother areas. As part of European pharmacovigilance efforts, the European Medicines Agency,\\nfor instance, established a central electronic repository for periodic safety update reports by\\nfirms in the pharmaceutical industry. The Commission could apply best practices from similar\\n22\\nsuch registries, where applicable.\\nInternational aspects\\nAll nations will face both competitive and cooperative pressures in the international environment\\nwith regard to AI technology. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 19, 'page': 8, '_split_overlap': [{'doc_id': '35786e7259f96e246d1a06aacfe8e592', 'range': (0, 289)}, {'doc_id': '5115a1079b9212ae46665fce70f284cd', 'range': (1386, 1535)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '858352a74852d586bf5d58e95fbed230'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: International aspects\\nAll nations will face both competitive and cooperative pressures in the international environment\\nwith regard to AI technology. Competitive dynamics arise out of national interests for relative\\neconomic and military advantage, favouring speed and innovation over safety and stability.\\nCooperative dynamics arise out of a shared interest in innovation, growth, safe technology, and\\ninternational stability. Without trust and coordination, however, cooperative dynamics will be\\ndifficult to sustain. We, therefore, encourage the Commission to continue its commitment “to\\ncooperate with like-minded countries, but also with global players, on AI, based on an approach\\nbased on EU rules and values” (p. 8). In our recommendations, we focus on concrete areas of\\ncollaboration.\\nInitiate and support international efforts for developing a shared understanding of\\npotential risks from AI. \\u200bThere appear to be differences in the conception and terminology of AI\\nrisks and safety among different countries. Arriving at shared definitions and understanding\\n23\\ncould prevent miscommunication and lay groundwork for further collaboration in the area of\\ntrustworthy AI. Convening relevant (technical) experts and policymakers from global players\\ncould be the first step. The Pugwash Conferences could serve as a model. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 20, 'page': 9, '_split_overlap': [{'doc_id': '858352a74852d586bf5d58e95fbed230', 'range': (0, 149)}, {'doc_id': 'ffaec15b240e205e87a41502ea4199a6', 'range': (1178, 1326)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5115a1079b9212ae46665fce70f284cd'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: Convening relevant (technical) experts and policymakers from global players\\ncould be the first step. The Pugwash Conferences could serve as a model. These regular,\\ninformal conventions with participants from the United States and the Soviet Union during the\\nCold War very likely contributed significantly to several international arms control agreements. 24\\nFacilitate exchange with global players on best practices for the assessments, testing,\\nand regulation of AI applications. \\u200bPolicymakers and auditors across the world face similar\\nregulatory and technical challenges for ensuring the trustworthiness of AI applications. Mutual\\n21 Brundage, Avin, Wang, Belfield, Krueger, et al. (2020). “Toward Trustworthy AI Development: Mechanisms for\\nSupporting Verifiable Claims.” arXiv:2004.07213\\n22 European Commission (2016). “Pharmacovigilance related activities of Member States and the European\\nMedicines Agency concerning medicinal products for human use (2012 – 2014).” COM(2016) 498 final. Retrieved\\nfrom:\\nhttps://ec.europa.eu/health//sites/health/files/files/pharmacovigilance/pharmacovigilance-report-2012-2014_en.pdf\\n23 \\u200bImbrie, Kania (2019). “AI Safety, Security, and Stability Among Great Powers: Options, Challenges, and Lessons\\nLearned for Pragmatic Engagement.” Center for Security and Emerging Technology Policy Brief. Retrieved from:\\nhttps://cset.georgetown.edu/research/ai-safety-security-and-stability-among-great-powers-options-challenges-and-les\\nsons-learned-for-pragmatic-engagement/\\n24 Rubinson (2019). “Pugwash Literature Review.” Urban Institute. Retrieved from:\\nhttps://www.urban.org/sites/default/files/pugwash_literature_review.pdf\\n8\\x0clearning could improve the development and implementation of regulatory frameworks as well\\nas contribute to regulatory convergence. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 21, 'page': 9, '_split_overlap': [{'doc_id': '5115a1079b9212ae46665fce70f284cd', 'range': (0, 148)}, {'doc_id': '7b3a46f60a37be5f9f5aa1d6c65201fc', 'range': (1568, 1789)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ffaec15b240e205e87a41502ea4199a6'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: Retrieved from:\\nhttps://www.urban.org/sites/default/files/pugwash_literature_review.pdf\\n8\\x0clearning could improve the development and implementation of regulatory frameworks as well\\nas contribute to regulatory convergence. The Commission could facilitate the convening of\\ntechnical experts from regulatory authorities, standards organisations as well as independent\\nauditors and testing centres. They could work towards the development of global standards for\\nthe assessment and certification of specific AI applications.\\nContribute to the setting of global AI technology standards.\\u200b International standards\\norganisations like the ISO, the IEC, and the ITU are important multilateral fora in the context of\\nAI because they include all global players. The White Paper does not sufficiently emphasise\\n25\\nthe constructive and influential role that the Europe Union could play in these international\\norganisations through the respective cooperation agreements of CEN and CENELEC. With its\\n26\\nregulatory and technical expertise, European influence could contribute to more robust\\nstandards, which are also in line with European values.\\nExplore the possibility of establishing an international database for the sharing of\\ninformation on AI incidents \\u200b(see “Governance” section). Bringing on additional international\\npartners for this project could improve the safe development and deployment of AI systems\\naround the world. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 22, 'page': 9, '_split_overlap': [{'doc_id': 'ffaec15b240e205e87a41502ea4199a6', 'range': (0, 221)}, {'doc_id': '779cd5a3c4e3a64d2b0315501843e0fb', 'range': (1272, 1416)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7b3a46f60a37be5f9f5aa1d6c65201fc'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: Bringing on additional international\\npartners for this project could improve the safe development and deployment of AI systems\\naround the world. The International Atomic Energy Agency, for instance, maintains a similar\\ndatabase for incident reports related to the operation of nuclear power plants. 27\\nExplore international partnerships for the proposed lighthouse research centre in\\nEurope\\u200b. As a result of projects like ITER and CERN, the EU has experience bringing together\\ndifferent, even competing, nations for large-scale research projects for the benefit of humanity.\\nFocusing the lighthouse research centre on shared interests like trustworthy AI (e.g., research\\non interpretability or privacy-preserving machine learning) would distribute the costs for\\nproviding a public good and ensure that the collaboration is in the interest of a broad\\ninternational coalition. The resulting increase in funding could also establish the project as a\\nleading research lab in the world.\\n25 Cihon (2019). “Standards for AI Governance: International Standards to Enable Global Coordination in AI Research\\n& Development.” Technical Report, Centre for the Governance of AI. Retrieved from:\\nhttps://www.fhi.ox.ac.uk/wp-content/uploads/Standards_-FHI-Technical-Report.pdf\\n26 Büthe, Mattli (2011). “The New Global Rulers: The Privatization of Regulation in the World Economy” (p. 138-9).\\nPrinceton University Press.\\n27 International Atomic Energy Agency. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 23, 'page': 10, '_split_overlap': [{'doc_id': '7b3a46f60a37be5f9f5aa1d6c65201fc', 'range': (0, 144)}, {'doc_id': '55aa84a02ffdd5749cbc401124c9d017', 'range': (1286, 1442)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '779cd5a3c4e3a64d2b0315501843e0fb'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: Centre for the Governance of AI (Future of Humanity Institute, University of Oxford), stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United Kingdom, document_date: 14-06-2020 22:55, language: English, \\n\\nPassage: “The New Global Rulers: The Privatization of Regulation in the World Economy” (p. 138-9).\\nPrinceton University Press.\\n27 International Atomic Energy Agency. “Incident Reporting Systems for Nuclear Installations.” Available at:\\nhttps://www.iaea.org/resources/databases/irsni\\n9', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', 'stakeholder_name': 'Centre for the Governance of AI (Future of Humanity Institute, University of Oxford)', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United Kingdom', 'stakeholder_scope': nan, 'document_date': '14-06-2020 22:55', 'language': 'English', 'document_reference': 'F530401', 'document_name': 'F530401-EU_White_Paper_Consultation_Submission_-_GovAI_Oxford.pdf', '_split_id': 24, 'page': 10, '_split_overlap': [{'doc_id': '779cd5a3c4e3a64d2b0315501843e0fb', 'range': (0, 156)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '55aa84a02ffdd5749cbc401124c9d017'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The European Committee for Interoperable Systems (\"ECIS\"), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 12-06-2020 11:29, language: English, \\n\\nPassage: The European Committee for Interoperable Systems\\' Submission on the European\\nCommission\\'s White Paper on Artificial Intelligence – a European approach to\\nexcellence and trust\\nThe European Committee for Interoperable Systems (\"ECIS\") welcomes the European\\nCommission\\'s White Paper on Artificial Intelligence and believes that artificial intelligence (\"AI\")\\nis an opportunity which the EU should embrace. The EU should be allowed to innovate and care\\nshould be taken in order to avoid overregulating AI in the EU. If innovation is allowed to thrive,\\nAI can offer enormous benefits. ECIS will however, discuss below some of the potential issues\\nwhich AI may bring about if care is not taken at an early stage. ECIS will focus specifically on\\ncompetition issues associated with AI, and liability concerns regarding AI.\\nAI and Competition Law\\nAI is, broadly speaking, a good thing and is beneficial to consumers. To ensure that consumers\\nbenefit from AI, it is crucial that companies can freely compete and innovate in AI technologies.\\nTo maximise the potential of AI, it is essential to foster open standards to prevent vendor lock-\\nin, and the consumer harm it leads to. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530025-AI_consultation_note_final.pdf', 'stakeholder_name': 'The European Committee for Interoperable Systems (\"ECIS\")', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '12-06-2020 11:29', 'language': 'English', 'document_reference': 'F530025', 'document_name': 'F530025-AI_consultation_note_final.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': '4fd07cde617dc2cec2061a89aaee1f95', 'range': (1031, 1167)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '98392a344d077b12130f488b41d57a67'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The European Committee for Interoperable Systems (\"ECIS\"), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 12-06-2020 11:29, language: English, \\n\\nPassage: To maximise the potential of AI, it is essential to foster open standards to prevent vendor lock-\\nin, and the consumer harm it leads to. Open standards in AI are crucial to promoting innovation,\\ndriving competition on the merits, creating consumer trust, and accelerating the scaling of\\ninteroperable AI solutions. Although companies should, under normal circumstances, not be\\npermitted to exchange competitively sensitive information, in order to help spread the results of\\nresearch into AI, collaborative research should be promoted. Therefore, companies should be\\nencouraged and permitted under EU competition law to collaborate for the purposes of\\nundertaking AI research activities.\\nNotwithstanding the benefits and potential of AI and collaborative research, AI may raise some\\ncompetition law concerns, and possibly enable collusive conduct. It may be feasible for\\ncompetitors in a market to program their AI algorithms in a way that causes them to engage in\\nunlawful collusive conduct, for instance by determining that the most profitable way to respond\\nto a price increase by a competitor would be to increase one\\'s own price. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530025-AI_consultation_note_final.pdf', 'stakeholder_name': 'The European Committee for Interoperable Systems (\"ECIS\")', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '12-06-2020 11:29', 'language': 'English', 'document_reference': 'F530025', 'document_name': 'F530025-AI_consultation_note_final.pdf', '_split_id': 1, 'page': 1, '_split_overlap': [{'doc_id': '98392a344d077b12130f488b41d57a67', 'range': (0, 136)}, {'doc_id': '67323d509628c1d872f7d2e4dc1cd041', 'range': (848, 1134)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4fd07cde617dc2cec2061a89aaee1f95'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The European Committee for Interoperable Systems (\"ECIS\"), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 12-06-2020 11:29, language: English, \\n\\nPassage: It may be feasible for\\ncompetitors in a market to program their AI algorithms in a way that causes them to engage in\\nunlawful collusive conduct, for instance by determining that the most profitable way to respond\\nto a price increase by a competitor would be to increase one\\'s own price. AI might also be used\\nto enable an undertaking to abuse their dominance such as where an AI machine determines\\nhow it can for instance maximise revenue by using a strategy of loyalty discounts, which can be\\nunlawful in certain circumstances. Therefore, competition authorities should closely monitor AI\\ndevelopments to ensure that competitors are not unlawfully foreclosed from markets.\\nAccess to data has a crucial role in ensuring companies can freely innovate in AI. Indeed, the\\nbest algorithms out there cannot achieve good results if they have insufficient data from which\\nto learn and improve on their results. A particularly salient illustration of this is provided by\\nonline search services. Due to the particular machine-learning nature of a search engine, it is\\nquery scale – not technology – that is the primary driver of search engine profitability and\\ncompetitiveness. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530025-AI_consultation_note_final.pdf', 'stakeholder_name': 'The European Committee for Interoperable Systems (\"ECIS\")', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '12-06-2020 11:29', 'language': 'English', 'document_reference': 'F530025', 'document_name': 'F530025-AI_consultation_note_final.pdf', '_split_id': 2, 'page': 1, '_split_overlap': [{'doc_id': '4fd07cde617dc2cec2061a89aaee1f95', 'range': (0, 286)}, {'doc_id': '2995014b0bc38bc113f264ee114bf475', 'range': (987, 1168)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '67323d509628c1d872f7d2e4dc1cd041'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The European Committee for Interoperable Systems (\"ECIS\"), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 12-06-2020 11:29, language: English, \\n\\nPassage: Due to the particular machine-learning nature of a search engine, it is\\nquery scale – not technology – that is the primary driver of search engine profitability and\\ncompetitiveness. Search algorithms learn from user queries and how users interact with search\\nresults, and the higher the number of queries (in particular the so-called \"long tail\" queries), the\\nmore relevant results the search engine will be able to show to users. This helps explain why\\nbarriers to entry can be so high in a search engine market where one company has an\\noverwhelming advantage in scale of queries. If dominance is achieved via scale in data, a\\nRef. Ares(2020)3359805 - 26/06/2020\\x0c2\\ncompany has an incentive to undertake conduct to preserve its position and prevent others from\\nobtaining requisite scale to compete – and such conduct can be anticompetitive. This conduct\\nmay enable markets for AI to be foreclosed by dominant undertakings at an early stage. The\\nEuropean Commission should seek to ensure that in the EU, data does not act as a barrier to\\ninnovation in AI, preventing companies from undertaking research and benefitting European\\nconsumers.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530025-AI_consultation_note_final.pdf', 'stakeholder_name': 'The European Committee for Interoperable Systems (\"ECIS\")', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '12-06-2020 11:29', 'language': 'English', 'document_reference': 'F530025', 'document_name': 'F530025-AI_consultation_note_final.pdf', '_split_id': 3, 'page': 1, '_split_overlap': [{'doc_id': '67323d509628c1d872f7d2e4dc1cd041', 'range': (0, 181)}, {'doc_id': '95ae2e927a21b5d1329c65c7d7499099', 'range': (941, 1137)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2995014b0bc38bc113f264ee114bf475'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The European Committee for Interoperable Systems (\"ECIS\"), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 12-06-2020 11:29, language: English, \\n\\nPassage: The\\nEuropean Commission should seek to ensure that in the EU, data does not act as a barrier to\\ninnovation in AI, preventing companies from undertaking research and benefitting European\\nconsumers.\\nExtra-contractual liability in relation to AI and the Internet of Things\\nRecent developments have led to AI systems providing remarkable levels of progress and value\\nin different areas – from robotics in manufacturing and supply chain, to social networks and e-\\ncommerce, and systems that underpin society such as health diagnostics. As with any technology\\nthere is an initial period of hype, with excessive expectations and then a period of reality and\\nmeasurable results – we are at the beginning of such a period right now. Our comments concern\\nmachine learning systems that are trained with data sets and algorithms, and not the so-called\\nArtificial General Intelligence.\\nAs with similar technological developments in the past, it is important that the industry is left\\nfree to develop, and that technology evolves in time according to the needs of businesses and\\nconsumers. Intervening at such an early stage would have a detrimental impact on the evolution\\nof this technology, and should therefore be avoided. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530025-AI_consultation_note_final.pdf', 'stakeholder_name': 'The European Committee for Interoperable Systems (\"ECIS\")', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '12-06-2020 11:29', 'language': 'English', 'document_reference': 'F530025', 'document_name': 'F530025-AI_consultation_note_final.pdf', '_split_id': 4, 'page': 2, '_split_overlap': [{'doc_id': '2995014b0bc38bc113f264ee114bf475', 'range': (0, 196)}, {'doc_id': '42a0e59dcfa1d7a2852d333c8b35850f', 'range': (1076, 1212)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '95ae2e927a21b5d1329c65c7d7499099'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The European Committee for Interoperable Systems (\"ECIS\"), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 12-06-2020 11:29, language: English, \\n\\nPassage: Intervening at such an early stage would have a detrimental impact on the evolution\\nof this technology, and should therefore be avoided. Nonetheless, there is a need for a strong\\nethical approach as to how AI should be applied, which should be properly set out at EU level (if\\nnot at global level). For this reason, ECIS supports the European Commission’s White Paper on\\nArtificial Intelligence in seeking to promote ethical guidelines and the ethical use of AI.\\nFor the development of AI technology, we consider it essential that the algorithm used for AI\\npurposes is transparent (in the sense of Recital 71 of the General Data Protection Regulation),\\nwhich means that where there is unintended bias, this bias can be addressed. Moreover, it is\\nappropriate that AI systems are subjected to extensive testing on the basis of appropriate data\\nsets as such systems need to be \"trained\" to gain equivalence to human decision making. With\\nregard to liability, it is important among other aspects, to consider the complex supply chain in\\nAI services. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530025-AI_consultation_note_final.pdf', 'stakeholder_name': 'The European Committee for Interoperable Systems (\"ECIS\")', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '12-06-2020 11:29', 'language': 'English', 'document_reference': 'F530025', 'document_name': 'F530025-AI_consultation_note_final.pdf', '_split_id': 5, 'page': 2, '_split_overlap': [{'doc_id': '95ae2e927a21b5d1329c65c7d7499099', 'range': (0, 136)}, {'doc_id': 'fc4f0d333f8a84fcb5a3871d89995f52', 'range': (730, 1045)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '42a0e59dcfa1d7a2852d333c8b35850f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The European Committee for Interoperable Systems (\"ECIS\"), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 12-06-2020 11:29, language: English, \\n\\nPassage: Moreover, it is\\nappropriate that AI systems are subjected to extensive testing on the basis of appropriate data\\nsets as such systems need to be \"trained\" to gain equivalence to human decision making. With\\nregard to liability, it is important among other aspects, to consider the complex supply chain in\\nAI services. Software algorithms and data sets which are used to train the software are important\\nelements but other aspects need to be considered, such as the purpose of the AI application,\\nand the sector specific norms that are in place. In addition, algorithms should be inspected at a\\ntechnical level, so that the reasons for malfunctions can be established. Rules that impose\\nliability on parties in the AI supply chain that do not have control over the final product should\\nbe avoided. In this respect, we support the Commission’s decision not to take up this issue in\\nits White Paper, maintaining its policy of taking a targeted approach to the issue of AI liability.\\nAbout ECIS\\nECIS is an international non-profit association founded in 1989 that endeavours to promote a\\nfavourable environment for interoperable ICT solutions. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530025-AI_consultation_note_final.pdf', 'stakeholder_name': 'The European Committee for Interoperable Systems (\"ECIS\")', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '12-06-2020 11:29', 'language': 'English', 'document_reference': 'F530025', 'document_name': 'F530025-AI_consultation_note_final.pdf', '_split_id': 6, 'page': 2, '_split_overlap': [{'doc_id': '42a0e59dcfa1d7a2852d333c8b35850f', 'range': (0, 315)}, {'doc_id': '668757a7afa6cc07f418588953974872', 'range': (978, 1137)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fc4f0d333f8a84fcb5a3871d89995f52'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The European Committee for Interoperable Systems (\"ECIS\"), stakeholder_type: Business Association, stakeholder_scope: nan, stakeholder_size: Micro (< 10 employees), stakeholder_country: Belgium, document_date: 12-06-2020 11:29, language: English, \\n\\nPassage: About ECIS\\nECIS is an international non-profit association founded in 1989 that endeavours to promote a\\nfavourable environment for interoperable ICT solutions. It has actively represented its members\\nregarding issues related to interoperability and competition before European, international and\\nnational fora, including the EU institutions and WIPO. ECIS’ members include large and smaller\\ninformation and communications technology hardware and software providers. The association\\nstrives to promote market conditions in the ICT sector that ensure there is vigorous competition\\non the merits and a diversity of consumer choice.', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530025-AI_consultation_note_final.pdf', 'stakeholder_name': 'The European Committee for Interoperable Systems (\"ECIS\")', 'stakeholder_type': 'Business Association', 'stakeholder_size': 'Micro (< 10 employees)', 'stakeholder_country': 'Belgium', 'stakeholder_scope': nan, 'document_date': '12-06-2020 11:29', 'language': 'English', 'document_reference': 'F530025', 'document_name': 'F530025-AI_consultation_note_final.pdf', '_split_id': 7, 'page': 2, '_split_overlap': [{'doc_id': 'fc4f0d333f8a84fcb5a3871d89995f52', 'range': (0, 159)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '668757a7afa6cc07f418588953974872'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: RESPONSE TO THE PUBLIC CONSULTATION FOR THE EUROPEAN COMMISSION’S\\nWHITE PAPER ON A EUROPEAN APPROACH TO ARTIFICIAL INTELLIGENCE\\nNigel Cory | June 12, 2020\\nCONTENTS\\nIntroduction ....................................................................................................................... 2\\nOverview: Despite the Interdependences of AI, Europe Decides to Go It Alone .......................... 2\\n1. AI Doesn’t Fit Well with Ex-Ante Conformity Assessment Frameworks .................................. 5\\nExisting Conformity Testing Frameworks for Cybersecurity, Marketing Products, and Medical\\nDevices are Not a Good, Nor Fair, Model to Replicate ......................................................... 7\\nExisting Conformity Assessment Mechanism are Onerous, Restrictive, and at their Core,\\nDiscriminatory for Foreign Firms, Products, and non-EU International Standards ............... 8\\nThe EU’s Framework for Cybersecurity: A Work in Progress with Many Unresolved Issues ... 9\\nLessons to Learn From: The Case of the EU’s Medical Device Regulation ........................ 10\\n2. Ex-Ante AI Conformity Tests Will Be a New Non-Tariff Barrier to Digital Trade .................... 12\\n3. Conformity Assessments and Mandatory Source Code Disclosure: A Barrier to Trade the EU\\n(Rightly) Opposes in Other Countries .................................................................................. 15\\n4. Mutual Recognition and Access to Testing as a Market Access Barrier ............................... 16\\n5. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': 'd77b00bcb908111868909bb2071eb108', 'range': (1193, 1511)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '682de0980372f982515ac0c71291f6ce'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Conformity Assessments and Mandatory Source Code Disclosure: A Barrier to Trade the EU\\n(Rightly) Opposes in Other Countries .................................................................................. 15\\n4. Mutual Recognition and Access to Testing as a Market Access Barrier ............................... 16\\n5. Recommendations ........................................................................................................ 18\\n5.1 Learn from Experience & Pursue a Lengthy, Thorough, Multi-Stakeholder Policy\\nDevelopment Process .................................................................................................... 18\\n5.2 Build a Truly Cooperative and Internationally Accessible Approach .............................. 19\\nConclusion ...................................................................................................................... 21\\nReferences ...................................................................................................................... 22\\nRef. Ares(2020)3359947 - 26/06/2020\\x0c2\\nINTRODUCTION\\nThe Information Technology and Innovation Foundation (ITIF) welcomes the opportunity to provide this\\nsubmission to the European Commission (EC) in response to its white paper On Artificial Intelligence: A\\nEuropean approach to excellence and trust (referred to herein as ‘the white paper’).1 ITIF continues to\\nappreciate the opportunity to engage with the European Union (EU), the EC, European parliamentarians,\\nand member states on how to support the EU’s digital economy, innovation, and international trade.\\nOur submission focuses on the whitepaper’s proposal for an ex ante conformity assessment framework to\\nverify and ensure that certain mandatory requirements applicable to high-risk applications of artificial\\nintelligence (AI) are met and how this would act as a barrier to trade. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 1, 'page': 1, '_split_overlap': [{'doc_id': '682de0980372f982515ac0c71291f6ce', 'range': (0, 318)}, {'doc_id': '4d9ac3f7863ab7ce07231effe90c283b', 'range': (1579, 1857)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd77b00bcb908111868909bb2071eb108'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Our submission focuses on the whitepaper’s proposal for an ex ante conformity assessment framework to\\nverify and ensure that certain mandatory requirements applicable to high-risk applications of artificial\\nintelligence (AI) are met and how this would act as a barrier to trade. In addition, ITIF’s Center for Data\\nInnovation is separately submitting a response that details issues with the impact that the white paper will\\nhave on innovation.\\nOVERVIEW: DESPITE THE INTERDEPENDENCES OF AI, EUROPE DECIDES TO GO IT ALONE\\nThe white paper’s introduction mentions the fierce global competition for AI advantage, one that it wants to\\nbe based on European values, yet it fails to recognize the likelihood that a new restrictive conformity\\nassessment framework is likely to further undermine the EU’s position.2 Europe is already struggling in this\\nrace. As the Center for Data Innovation’s report Who Is Winning the AI Race: China, the EU or the United\\nStates? shows, the United States leads the global race for AI, with China in second, and the EU lagging\\nbehind.3 At the heart of this race is the ability of people and firms to engage in data-driven innovation. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 2, 'page': 2, '_split_overlap': [{'doc_id': 'd77b00bcb908111868909bb2071eb108', 'range': (0, 278)}, {'doc_id': '7abba70cd81f3205d09312afe7a49e66', 'range': (955, 1157)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4d9ac3f7863ab7ce07231effe90c283b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: shows, the United States leads the global race for AI, with China in second, and the EU lagging\\nbehind.3 At the heart of this race is the ability of people and firms to engage in data-driven innovation. Yet,\\nsimilar to the General Data Protection Regulation (GDPR), the proposed AI conformity assessment\\nframework imposes a constraint on the use of new AI-based technologies that will be developed in significant\\npart by non-Europeans, rather than focusing on supporting the actual development of data-driven innovation.\\nIn contrast to Europe, China has created a vast, protected domestic market and extensive government support\\nmechanisms, including a concerted effort to help its tech firms and their products and standards go global.4\\nChina’s efforts to influence global standards builds on its firms’ ability to develop these new technologies, not\\nthe other way around. The same for the United States.\\nThe whitepaper’s central problem is twofold. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 3, 'page': 2, '_split_overlap': [{'doc_id': '4d9ac3f7863ab7ce07231effe90c283b', 'range': (0, 202)}, {'doc_id': '72ed7a1a8c28f6cf18a84a47238aad25', 'range': (521, 950)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7abba70cd81f3205d09312afe7a49e66'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: In contrast to Europe, China has created a vast, protected domestic market and extensive government support\\nmechanisms, including a concerted effort to help its tech firms and their products and standards go global.4\\nChina’s efforts to influence global standards builds on its firms’ ability to develop these new technologies, not\\nthe other way around. The same for the United States.\\nThe whitepaper’s central problem is twofold. First, the EC is rushing to apply the precautionary principle—\\nthe idea that innovations must be proven safe before they are deployed—based on the widespread but\\nincorrect beliefs that there is something inherently suspect about the technology, that organizations will have\\nstrong incentives to use the technology in ways that harm individuals, and that existing laws are insufficient to\\neffectively oversee the use of this technology. Indeed, fears that algorithms could exhibit and exacerbate\\nhuman bias, including facilitating discrimination and exploitation, have dominated discussions about how\\npolicymakers and regulators should treat algorithmic decision-making.5 But the likelihood of these risks\\ncoming to fruition is often overstated, as advocates incorrectly assume market forces would not prevent early\\nerrors or flawed systems from reaching widespread deployment.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 4, 'page': 2, '_split_overlap': [{'doc_id': '7abba70cd81f3205d09312afe7a49e66', 'range': (0, 429)}, {'doc_id': 'f4109f5de74145d8d522111797f3939e', 'range': (866, 1306)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '72ed7a1a8c28f6cf18a84a47238aad25'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Indeed, fears that algorithms could exhibit and exacerbate\\nhuman bias, including facilitating discrimination and exploitation, have dominated discussions about how\\npolicymakers and regulators should treat algorithmic decision-making.5 But the likelihood of these risks\\ncoming to fruition is often overstated, as advocates incorrectly assume market forces would not prevent early\\nerrors or flawed systems from reaching widespread deployment.\\x0c3\\nMoreover, it is early days, as policymakers, academics, and experts from around the world discuss the best\\napproach to the governance of AI. Many proposed solutions are a poor fit, inadequate, and/or ineffective.6\\nThere may well be a role for some government-designed or approved process to test certain applications of AI\\nin various sectors. Whether conformity assessments can work for AI in a way that relies on the same legal\\nsystem and testing infrastructure that the EU applies to the product safety testing of physical goods, like toys,\\nraises significant questions regarding practicality, viability, and technical application.7 For all of these reasons,\\nit’s a mistake for the EC to rush ahead and enact a framework without much more research and extensive,\\nproactive international cooperation.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 5, 'page': 2, '_split_overlap': [{'doc_id': '72ed7a1a8c28f6cf18a84a47238aad25', 'range': (0, 440)}, {'doc_id': '4c4ab1017f5db5fb8a68c9f4ed9bbe27', 'range': (786, 1244)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f4109f5de74145d8d522111797f3939e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Whether conformity assessments can work for AI in a way that relies on the same legal\\nsystem and testing infrastructure that the EU applies to the product safety testing of physical goods, like toys,\\nraises significant questions regarding practicality, viability, and technical application.7 For all of these reasons,\\nit’s a mistake for the EC to rush ahead and enact a framework without much more research and extensive,\\nproactive international cooperation.\\nWhich raises the second major problem with the whitepaper: The EC does not seem inclined to recognize\\nthat AI creates interdependencies with other countries.8 This should make cooperation with broadly like-\\nminded partners a necessary prerequisite (not an afterthought or minor component) in terms of developing a\\nregulatory framework that addresses shared policy goals, while supporting each country’s firms’ ability to\\ninnovate and trade as part of global production networks and value chains (both of which are increasingly\\nservices and digital intensive). The white paper states that the EU “will continue to cooperate with like-\\nminded countries, but also with global players, on AI, based on an approach based on EU rules and values\\n(e.g. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 6, 'page': 3, '_split_overlap': [{'doc_id': 'f4109f5de74145d8d522111797f3939e', 'range': (0, 458)}, {'doc_id': '82fbd8637190815c1d9b38bb3633b18b', 'range': (1019, 1203)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4c4ab1017f5db5fb8a68c9f4ed9bbe27'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: The white paper states that the EU “will continue to cooperate with like-\\nminded countries, but also with global players, on AI, based on an approach based on EU rules and values\\n(e.g. supporting upward regulatory convergence, accessing key resources including data, and creating a level\\nplaying field).” Yet this is hardly reflected in either the whitepaper or in recent policies.\\nThe whitepaper states that the EC “will closely monitor the policies of third countries that limit data flows\\nand will address undue restrictions in bilateral trade negotiations and through action in the context of the\\nWorld Trade Organization (WTO).”9 Even if well-intentioned, an ex-ante conformity assessment framework\\nwould do just this.\\nThe proposal, whose design is presumably founded on the EU’s New Legislative Framework and its approach\\nto standardization (outlined in Regulation No. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 7, 'page': 3, '_split_overlap': [{'doc_id': '4c4ab1017f5db5fb8a68c9f4ed9bbe27', 'range': (0, 184)}, {'doc_id': 'bfde9e70fbfec96abd1559999f93a0e0', 'range': (724, 874)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '82fbd8637190815c1d9b38bb3633b18b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: The proposal, whose design is presumably founded on the EU’s New Legislative Framework and its approach\\nto standardization (outlined in Regulation No. 1025/2012), reinforces the EU’s regional—and not global—\\napproach to standards and conformity assessment in that it advantages its own intra-regional regulatory\\nstandards and a select, designated group of European standards bodies, with a secondary, more limited and\\nonerous lane for firms and products that use a body or standard from outside Europe.10 In addition, for those\\nAI products that require a third-party test, the EU legal framework limits these to designated bodies (“notified\\nbodies”) located in the territory of an EU member state. With respect to localization requirements for testing\\nbodies (i.e., non-recognition of testing reports from international conformity assessment bodies), this is\\nprecisely the kind of localization barrier to trade that the EC advocates against in forums like the WTO. Its\\napplication to new technology stands to exacerbate its negative impact on trade and interoperability.\\nSuch Europe-specific conformity testing for data-driven applications represents a mechanism for localization\\nand discrimination between local and foreign firms and their digital products. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 8, 'page': 3, '_split_overlap': [{'doc_id': '82fbd8637190815c1d9b38bb3633b18b', 'range': (0, 150)}, {'doc_id': 'd84baf7fed177ebad4b127afe4228997', 'range': (1071, 1258)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bfde9e70fbfec96abd1559999f93a0e0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Such Europe-specific conformity testing for data-driven applications represents a mechanism for localization\\nand discrimination between local and foreign firms and their digital products. For example, in the context of\\nforeign AI developed by firms in authoritarian countries (presumably China and Russia), Commissioner for\\nthe Internal Market Thierry Breton said manufacturers could be forced to “retrain algorithms locally in\\x0c4\\nEurope with European data,” adding that “We could be ready to do this if we believe it is appropriate for our\\nneeds and our security.”11 This is a slippery slope to rush down. The EC should also be aware of the risk that\\nin the future its own firms will likely be affected as other countries copy-and-paste and repurpose the EU’s\\nown rushed approach in enacting their own opaque and arbitrary conformity assessment frameworks for AI.\\nUltimately, the spread of these frameworks will act as a barrier to the development of a more productive and\\ninnovative global digital economy given the central and growing role of AI.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 9, 'page': 3, '_split_overlap': [{'doc_id': 'bfde9e70fbfec96abd1559999f93a0e0', 'range': (0, 187)}, {'doc_id': 'fd8878feee4de98c25ed8c06982a566d', 'range': (864, 1048)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd84baf7fed177ebad4b127afe4228997'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Ultimately, the spread of these frameworks will act as a barrier to the development of a more productive and\\ninnovative global digital economy given the central and growing role of AI.\\nThe EC is obviously within its rights to determine what regulations it wants to enact in pursuing its legitimate\\npolicy goals, however, as with all domestic regulation and trade issues, this must be proportionate and\\nnondiscriminatory so that it doesn’t act as a barrier to trade. The conformity testing framework will almost\\ncertainly reduce trade both in the extensive margin (the decision by exporters to enter a market) and the\\nintensive margin (the quantitative decision of how much to export). Trade policy research shows how\\ndifferent and incompatible regulations across jurisdictions, however slight, can impede trade in goods and\\nservices. The time and money firms invest in abiding by differential testing processes can be significant,\\nespecially for small and medium-sized firms. Differential regulatory requirements have proven costly with\\ntraditional trade in physical goods. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 10, 'page': 4, '_split_overlap': [{'doc_id': 'd84baf7fed177ebad4b127afe4228997', 'range': (0, 184)}, {'doc_id': '2fda6226ef8e55f8dc7dc6ae17368ee6', 'range': (834, 1073)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fd8878feee4de98c25ed8c06982a566d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: The time and money firms invest in abiding by differential testing processes can be significant,\\nespecially for small and medium-sized firms. Differential regulatory requirements have proven costly with\\ntraditional trade in physical goods. Expanding this to digital economic activity (where the distinction between\\ngoods, services, and even processes is unclear in the EU’s proposal) creates a whole other realm of potential\\ntrade disputes given it involves far more dynamic and complex technologies and assessments.\\nThe proposed institutional framework for administrating this framework is equally problematic in how it\\noutlines a new horizontal regulatory framework will lay on top of respective sectoral regulations and\\nenforcement agencies at the EU level and in each member country. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 11, 'page': 4, '_split_overlap': [{'doc_id': 'fd8878feee4de98c25ed8c06982a566d', 'range': (0, 239)}, {'doc_id': '3da6ec5312a2004098284cbbba0a62a0', 'range': (517, 787)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2fda6226ef8e55f8dc7dc6ae17368ee6'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: The proposed institutional framework for administrating this framework is equally problematic in how it\\noutlines a new horizontal regulatory framework will lay on top of respective sectoral regulations and\\nenforcement agencies at the EU level and in each member country. Creating or designating completely new\\nagencies or offices, competencies, and coordination mechanisms is costly and complicated.12 It also presumes\\nthe competency and appropriateness of notified bodies—many of which are private sector entities that have\\nbeen formally designated by competent member state authorities and the EC—to carry out the assessment of\\nhigh-risk applications of AI (however this is ultimately defined and applied that looks like).13 This is exactly\\nthe issue that arose in the context of the Medical Devices Regulation/In-vitro Diagnostics Regulation\\n(MDR/IVDR) Roadmap (explained in a case study below), where not only are there insufficient standards,\\nbut insufficient EU-based testing capacity. In this way, the whitepaper fails to learn some key lessons from the\\nregion’s recent experience in enacting similar new regulatory frameworks.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 12, 'page': 4, '_split_overlap': [{'doc_id': '2fda6226ef8e55f8dc7dc6ae17368ee6', 'range': (0, 270)}, {'doc_id': 'c39a0f840d79a0c81b2a07448a9a3143', 'range': (992, 1134)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3da6ec5312a2004098284cbbba0a62a0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: In this way, the whitepaper fails to learn some key lessons from the\\nregion’s recent experience in enacting similar new regulatory frameworks.\\nThe EU’s Executive Vice-President Margrethe Vestager stated that an assessment will be made in the future as\\nto whether this approach is effective or not.14 The EC would be better served to fundamentally reconsider its\\nconformity testing-based approach to regulating AI and instead work with like-minded partners on the best\\napproach to address shared concerns about AI in high-risk sectors. If it does proceed with a conformity\\nassessment framework, the EC should at least consider the international impact from the start, along with\\ndetails about how it will build mechanisms for regulatory cooperation and interoperability (whether these are\\ngovernment-to-government or global, industry-driven, voluntary consensus standards).\\x0c5\\nUnfortunately, in this the whitepaper EU disregards careful policy development in rushing to seize what it\\nthinks will provide it a first mover regulatory advantage on digital issues; all to the detriment of its local firms\\nand economies and international trade and the global economy. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 13, 'page': 4, '_split_overlap': [{'doc_id': '3da6ec5312a2004098284cbbba0a62a0', 'range': (0, 142)}, {'doc_id': 'f0bbf6dc8deab7c4d2ea62bb36ea33bc', 'range': (873, 1160)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c39a0f840d79a0c81b2a07448a9a3143'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: 5\\nUnfortunately, in this the whitepaper EU disregards careful policy development in rushing to seize what it\\nthinks will provide it a first mover regulatory advantage on digital issues; all to the detriment of its local firms\\nand economies and international trade and the global economy. But Europe shouldn’t focus on being first\\nwith new digital rules, it should focus on creating and implementing rules that allow AI-driven businesses and\\ninnovations to flourish in Europe, and in other likeminded nations that embrace the principles of rules-\\ngoverned, enterprise-led, market-based trade. European policies should be designed to enable and promote\\nhealth and robust competition in digital industries, for doing so will have a powerful effect on promoting\\nEuropean productivity and economic growth.15 The rush to regulation and implementation, without waiting\\non international discussions on AI and standards to evolve, indicates that the EU is willing to use AI\\nregulation as a protectionist and expansionist strategy rather than building bridges between common\\napproaches that each address shared public policy interests. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 14, 'page': 5, '_split_overlap': [{'doc_id': 'c39a0f840d79a0c81b2a07448a9a3143', 'range': (0, 287)}, {'doc_id': '33fe91bec2a506e0d3f445b50048c8c8', 'range': (592, 1125)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f0bbf6dc8deab7c4d2ea62bb36ea33bc'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: European policies should be designed to enable and promote\\nhealth and robust competition in digital industries, for doing so will have a powerful effect on promoting\\nEuropean productivity and economic growth.15 The rush to regulation and implementation, without waiting\\non international discussions on AI and standards to evolve, indicates that the EU is willing to use AI\\nregulation as a protectionist and expansionist strategy rather than building bridges between common\\napproaches that each address shared public policy interests. Following on from previous regulations such as\\nGDPR, the EU is determined to set a standard to define what “good” AI regulation is, but this strategy risks\\nnot achieving the actual objective, while impeding innovation, competitiveness, and trade for itself and\\nits partners.\\nThe submission analyzes a number of these issues in detail and then provides recommendations, as follows:\\n1. It explains how the regulation of AI does not fit well with ex-ante conformity assessment frameworks.\\nIt explains how using existing conformity assessment frameworks (for cybersecurity and marketing\\nproducts) as a model for AI is neither desirable nor fair. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 15, 'page': 5, '_split_overlap': [{'doc_id': 'f0bbf6dc8deab7c4d2ea62bb36ea33bc', 'range': (0, 533)}, {'doc_id': '9f758737598a23679786754130f1a014', 'range': (1020, 1175)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '33fe91bec2a506e0d3f445b50048c8c8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: It explains how using existing conformity assessment frameworks (for cybersecurity and marketing\\nproducts) as a model for AI is neither desirable nor fair. To substantiate this, it includes a case study\\nof how the EU’s recent experience with implementing the MDR/IVDR roadmap provides many\\nrelevant lessons for the EU as it contemplates a conformity assessment framework for AI.\\n2. It looks at how ex-ante conformity tests for AI would become a new non-tariff barrier to digital trade.\\n3. It analyzes how limited access for conformity certification is a barrier to market entry, one which the\\nEU and the United States have already had to deal with in other sectors.\\n4. It looks how conformity assessments raise the prospect of mandatory source code disclosure, which is\\nanother potential barrier to trade.\\n5. It provides three main sets of recommendations: one focuses on core issues to consider as part of its\\npolicy debate moving forward; a second on the steps to build a truly cooperative and internationally\\naccessible approach to AI regulation; and a third that outlines the need for international cooperation\\non developing standards for new and emerging technology with trading partners that share its values.\\n1. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 16, 'page': 5, '_split_overlap': [{'doc_id': '33fe91bec2a506e0d3f445b50048c8c8', 'range': (0, 155)}, {'doc_id': 'a9c6fbbc3f83cef9b05639b370f53c6c', 'range': (809, 1218)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9f758737598a23679786754130f1a014'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: It provides three main sets of recommendations: one focuses on core issues to consider as part of its\\npolicy debate moving forward; a second on the steps to build a truly cooperative and internationally\\naccessible approach to AI regulation; and a third that outlines the need for international cooperation\\non developing standards for new and emerging technology with trading partners that share its values.\\n1. AI DOESN’T FIT WELL WITH EX-ANTE CONFORMITY ASSESSMENT FRAMEWORKS\\nThe white paper requires “an objective, prior conformity assessment … to verify and ensure that certain of\\nthe … requirements applicable to high-risk applications … are complied with.” These ex ante reviews would\\nbe mandatory for all developers and deployers of high-risk AI systems, “regardless of their place of\\nestablishment.” These assessments might need to be “repeated” in the case of AI systems that “evolve and\\x0c6\\nlearn from experience.” If the AI system does not satisfy “the requirements relating to the data used to train\\nit,” the remedy might be “re-training the system in the EU.” The whitepaper also calls for “competent\\nauthorities” to not only investigate individual cases, but also to assess the impact on society.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 17, 'page': 5, '_split_overlap': [{'doc_id': '9f758737598a23679786754130f1a014', 'range': (0, 409)}, {'doc_id': '415037f39b88708b7203abe98b82e016', 'range': (410, 1206)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a9c6fbbc3f83cef9b05639b370f53c6c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: AI DOESN’T FIT WELL WITH EX-ANTE CONFORMITY ASSESSMENT FRAMEWORKS\\nThe white paper requires “an objective, prior conformity assessment … to verify and ensure that certain of\\nthe … requirements applicable to high-risk applications … are complied with.” These ex ante reviews would\\nbe mandatory for all developers and deployers of high-risk AI systems, “regardless of their place of\\nestablishment.” These assessments might need to be “repeated” in the case of AI systems that “evolve and\\x0c6\\nlearn from experience.” If the AI system does not satisfy “the requirements relating to the data used to train\\nit,” the remedy might be “re-training the system in the EU.” The whitepaper also calls for “competent\\nauthorities” to not only investigate individual cases, but also to assess the impact on society.\\nThis section analyzes two key concerns:\\n• The challenge to develop a completely new criteria and standard (no comparable approach exists) for\\nnotified bodies to use to test AI—a dynamic technology, that may be a product, service, or process—\\nin high-risk sectors (where a third-party certification is required). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 18, 'page': 5, '_split_overlap': [{'doc_id': 'a9c6fbbc3f83cef9b05639b370f53c6c', 'range': (0, 796)}, {'doc_id': 'a9901040f032770c2eadf964ed2eb205', 'range': (797, 1108)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '415037f39b88708b7203abe98b82e016'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: This section analyzes two key concerns:\\n• The challenge to develop a completely new criteria and standard (no comparable approach exists) for\\nnotified bodies to use to test AI—a dynamic technology, that may be a product, service, or process—\\nin high-risk sectors (where a third-party certification is required). These criteria would need to be\\nclear and detailed so that firms could build towards the final harmonized standard—no easy fit for\\nAI; and\\n• The challenge to set up a sound institutional framework, especially regarding the needed mobilization\\nof competencies and capabilities of member states’ oversight agencies and notifying bodies, and the\\nprocess to designate and certify notifying bodies. The whitepaper seems doomed to repeat many\\nmistakes the EC has already encountered when creating similar frameworks for other harmonized\\nstandards in the EU. It also doubles down on localism, by promoting the use of Europe-based testing\\nbodies, which is inherently discriminatory to foreign firms and products.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 19, 'page': 6, '_split_overlap': [{'doc_id': '415037f39b88708b7203abe98b82e016', 'range': (0, 311)}, {'doc_id': '1273c19b5f9f0bce4ca59034ead8a534', 'range': (864, 1016)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a9901040f032770c2eadf964ed2eb205'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: It also doubles down on localism, by promoting the use of Europe-based testing\\nbodies, which is inherently discriminatory to foreign firms and products.\\nThe big question that looms over the EC’s strategy to use conformity testing for AI is how, or whether it’s\\npossible, to come up with tests and criteria for dynamic technologies and risks and for notified bodies to\\nadminister these efficiently and effectively.16 For example, conformity testing for a dynamic, learning AI\\nsystem does not lend itself to the paper’s proposal that firms provide a static snapshot of information about\\nthe AI’s capabilities and limitations, the conditions under which they’re intended to function, and the\\nexpected level of accuracy. The criteria and benchmark that authorities will use in certifying AI as “safe” is a\\nhuge unknown. These would need to be made clear (in EU harmonized standards and for alternative pathway\\nassessments) to firms so that they would have something to build and test toward. But this is extremely\\ndifficult. By what measure could AI be assessed as having a negative impact (for example, on demographic\\nminorities) and how would firms determine that a dataset used to develop this AI is biased? ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 20, 'page': 6, '_split_overlap': [{'doc_id': 'a9901040f032770c2eadf964ed2eb205', 'range': (0, 152)}, {'doc_id': '8953879f7792ca228bbb685e22773208', 'range': (1021, 1206)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1273c19b5f9f0bce4ca59034ead8a534'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: By what measure could AI be assessed as having a negative impact (for example, on demographic\\nminorities) and how would firms determine that a dataset used to develop this AI is biased? Notified bodies\\nwill be tasked with making very technical assessments about AI applications as well as broad assessments\\naimed at determining whether an AI application does or does not have a negative impact on society. Who will\\nbe involved, and what criteria will they use, to make such a broad socio-political assessment?\\nThe whitepaper also raises major questions about the capacity and technical competency of the conformity\\ntesting bodies (the notified bodies), oversight agencies, and national accreditation bodies to do the actual\\ncertification, designation of competent laboratories, and accreditation currently required under EU law,\\nrespectively. This involves complex reviews of both the algorithm and the datasets used to develop it. Local\\nauthorities, national accreditation bodies, and competent notified bodies would need to understand the\\nprogramming and training methodologies, processes, and technologies to build, test, and validate AI systems.\\x0c7\\nIt takes specific expertise in programming and statistics to evaluate the fairness and robustness of AI models\\nand to try to suggest remedies should an issue be identified. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 21, 'page': 6, '_split_overlap': [{'doc_id': '1273c19b5f9f0bce4ca59034ead8a534', 'range': (0, 185)}, {'doc_id': '2492ef33cac5ba0d982ed0e5370e8e6', 'range': (1150, 1324)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8953879f7792ca228bbb685e22773208'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: 7\\nIt takes specific expertise in programming and statistics to evaluate the fairness and robustness of AI models\\nand to try to suggest remedies should an issue be identified. And there can be tens of thousands of algorithms\\ndeveloped every year. How exactly are EU bodies supposed to keep up with this? What if there are regulatory\\nbacklogs (which are likely)? Does this mean developers would have to wait to come to market, ceding\\npotential advantage to foreign competitors?\\nAll these concerns will simultaneously play out in each EU member state, given each may be responsible for\\ndesignating and overseeing notified bodies within their territories. The whitepaper states that: “Europe equips\\nitself progressively with the capacity needed for testing and certification of AI-enabled products and services.”\\nBut the rush to establish a framework is in direct conflict with the need to ensure testing is done consistently\\nand is based on clear guidelines\\nAs the case study below on Europe’s updated medical devices regulations shows, building this type of capacity\\nand competency represents a tremendous challenge. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 22, 'page': 7, '_split_overlap': [{'doc_id': '8953879f7792ca228bbb685e22773208', 'range': (0, 174)}, {'doc_id': '3814527e4dd87a4e285f4189b1cbd614', 'range': (652, 1114)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2492ef33cac5ba0d982ed0e5370e8e6'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: The whitepaper states that: “Europe equips\\nitself progressively with the capacity needed for testing and certification of AI-enabled products and services.”\\nBut the rush to establish a framework is in direct conflict with the need to ensure testing is done consistently\\nand is based on clear guidelines\\nAs the case study below on Europe’s updated medical devices regulations shows, building this type of capacity\\nand competency represents a tremendous challenge. This challenge only gets harder given it would also\\nrequire extensive coordination between conformity testing bodies and other domestic and regional agencies\\ninvolved in certain issues where there is regulatory overlap. This highlights the risk of costly duplicative\\nregulatory requirements given existing structures for finance, pharmaceuticals, aviation, medical devices,\\nconsumer protection, and data protection. There’s also the potential for different notified bodies and EU\\nmember states making differing conformity assessment determinations (as would inevitably be the case),\\nwhich leads to a patchwork of regulations for AI across Europe.\\nFortunately, the whitepaper recognizes that some of its requirements don’t fit well with conformity testing.\\nThis could signal a recognition that the EC is open to holding extended, detailed discussions with all\\nstakeholders on these issues before proceeding. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 23, 'page': 7, '_split_overlap': [{'doc_id': '2492ef33cac5ba0d982ed0e5370e8e6', 'range': (0, 462)}, {'doc_id': 'cc79f63f8e4b67decae5793094a8c532', 'range': (1219, 1369)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3814527e4dd87a4e285f4189b1cbd614'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: This could signal a recognition that the EC is open to holding extended, detailed discussions with all\\nstakeholders on these issues before proceeding. There may be a way to come up with a clear, objective criteria\\nfor notified bodies, under the purview of national accreditation bodies and notifying authorities, to test AI\\napplications. But the EU needs to factor in a lot more time for discussion and research.\\nMoreover, the entire focus is based on a faulty premise: currently the EU does not regulate software (except as\\ndescribed below for security), it regulates the use of the software in certain applications. AI is no different.\\nThe regulatory focus should not be on AI algorithms, it should be on areas of EU society and economy that\\nelected officials charge regulators with crafting regulations to protect the public interest. Whether the software\\nis capable of learning or not should be irrelevant.\\nExisting Conformity Testing Frameworks for Cybersecurity, Marketing Products, and Medical\\nDevices are Not a Good, Nor Fair, Model to Replicate\\nThe whitepaper implies that the framework would be based on existing arrangements, explicitly referring to\\ntwo key models: Decision 768/2008/EC and the Regulation (EU) 2019/881 (Cybersecurity Act). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 24, 'page': 7, '_split_overlap': [{'doc_id': '3814527e4dd87a4e285f4189b1cbd614', 'range': (0, 150)}, {'doc_id': '6115e7241cf4797c716fbe8180bc04f3', 'range': (911, 1251)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'cc79f63f8e4b67decae5793094a8c532'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Existing Conformity Testing Frameworks for Cybersecurity, Marketing Products, and Medical\\nDevices are Not a Good, Nor Fair, Model to Replicate\\nThe whitepaper implies that the framework would be based on existing arrangements, explicitly referring to\\ntwo key models: Decision 768/2008/EC and the Regulation (EU) 2019/881 (Cybersecurity Act). The EC\\nshould not adapt or replicate existing conformity assessment frameworks (for testing, inspection, or\\ncertification) for any potential AI-focused system as these are inherently discriminatory in how they preference\\x0c8\\nlocal standards and testing centers. The EC should learn the lesson from the frameworks it references as\\nmodels and avoid making the same mistakes in a new AI-focused system.\\nThese existing models raise several issues:\\n• Can the EU and its members design and apply clear, objective, and harmonized standards to test\\ndynamic technologies that involve dynamic outcomes, risks, and threats, such as with cybersecurity\\nand AI?\\n• Existing frameworks are inherently discriminatory in preferencing local standards and testing\\ncenters.17 This goes against the whitepaper’s stated goal that any system should be non-\\ndiscriminatory.\\n• Creating an EU-wide certification framework is a hugely complicated process in creating country-\\nlevel technical capacity and capabilities. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 25, 'page': 7, '_split_overlap': [{'doc_id': 'cc79f63f8e4b67decae5793094a8c532', 'range': (0, 340)}, {'doc_id': '7f6237e8f90bc86070cd9cdbf96d6a00', 'range': (987, 1329)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6115e7241cf4797c716fbe8180bc04f3'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: • Existing frameworks are inherently discriminatory in preferencing local standards and testing\\ncenters.17 This goes against the whitepaper’s stated goal that any system should be non-\\ndiscriminatory.\\n• Creating an EU-wide certification framework is a hugely complicated process in creating country-\\nlevel technical capacity and capabilities. An EU-wide framework may well end up becoming\\nfragmented, or at least divergent, over time given it’ll depend in no small part on the capabilities of\\neach EU member’s national cybersecurity agency and their competency in accrediting and auditing\\nconformity assessment bodies.\\nExisting Conformity Assessment Mechanism are Onerous, Restrictive, and at their Core,\\nDiscriminatory for Foreign Firms, Products, and non-EU International Standards\\nIf the EU follows its existing approach, a “presumption of conformity”—meaning that a firm can assume it\\nhas met the requirements of the corresponding directive by complying with the specifications in the\\nstandard(s) required by a particular directive—will be granted to a harmonized European standard for a given\\nset of regulatory requirements (such as a particular application of AI in a high-risk sector).18 Where third party\\nconformity assessment is required, both EU and non-EU firms can avail themselves of the presumption of\\nconformity accorded to the corresponding harmonized EU standard(s).\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 26, 'page': 8, '_split_overlap': [{'doc_id': '6115e7241cf4797c716fbe8180bc04f3', 'range': (0, 342)}, {'doc_id': '94a60669385b4c329a69cb88d83c5e15', 'range': (619, 1383)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7f6237e8f90bc86070cd9cdbf96d6a00'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Existing Conformity Assessment Mechanism are Onerous, Restrictive, and at their Core,\\nDiscriminatory for Foreign Firms, Products, and non-EU International Standards\\nIf the EU follows its existing approach, a “presumption of conformity”—meaning that a firm can assume it\\nhas met the requirements of the corresponding directive by complying with the specifications in the\\nstandard(s) required by a particular directive—will be granted to a harmonized European standard for a given\\nset of regulatory requirements (such as a particular application of AI in a high-risk sector).18 Where third party\\nconformity assessment is required, both EU and non-EU firms can avail themselves of the presumption of\\nconformity accorded to the corresponding harmonized EU standard(s).\\nThis is where the EU’s approach is inherently discriminatory. Firstly, if a firm decides to build, program, or\\ndevelop to a standard(s) other than the harmonized EU standard(s) granted a presumption of conformity\\nunder an EU directive, it cannot benefit from the presumption of conformity and must demonstrate\\ncompliance directly with corresponding regulatory requirements by working with a notified body. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 27, 'page': 8, '_split_overlap': [{'doc_id': '7f6237e8f90bc86070cd9cdbf96d6a00', 'range': (0, 764)}, {'doc_id': 'a306a4b5facfcc427f9e9fc18b5fdeb6', 'range': (827, 1170)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '94a60669385b4c329a69cb88d83c5e15'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Firstly, if a firm decides to build, program, or\\ndevelop to a standard(s) other than the harmonized EU standard(s) granted a presumption of conformity\\nunder an EU directive, it cannot benefit from the presumption of conformity and must demonstrate\\ncompliance directly with corresponding regulatory requirements by working with a notified body. The\\npresumption of conformity is a major benefit as it means that, in principle, a firm need not interact with a\\nnotified body and that it’d only need to present compliance documentation (such as a supplier’s declaration of\\nconformity) in the event that a government authority required it for market surveillance purposes. Where\\nthird-party testing is required and the firm must build to harmonized European standards, the notified body\\neffectively faces no legal liability in establishing that the product is in line with EU law (i.e. the firm has a\\nglide path to compliance).\\x0c9\\nThe alternative pathway to demonstrating compliance—where a firm decides not to build to EU harmonized\\nstandards—is widely viewed as more onerous, restrictive, and uncertain. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 28, 'page': 8, '_split_overlap': [{'doc_id': '94a60669385b4c329a69cb88d83c5e15', 'range': (0, 343)}, {'doc_id': 'f142f59d85171a16fcf5ed0e98627fe1', 'range': (922, 1098)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a306a4b5facfcc427f9e9fc18b5fdeb6'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: 9\\nThe alternative pathway to demonstrating compliance—where a firm decides not to build to EU harmonized\\nstandards—is widely viewed as more onerous, restrictive, and uncertain. Even if a firm does not technically\\nthink its product requires testing under EU regulations, it may feel compelled to work with a notified body\\nfor the added assurance that its design is still in compliance with the essential requirements of relevant EU\\nlegislation. However, in comparison to the presumption of conformity pathway, the notified body has no real\\nincentive (and/or capability) to make this alternative a comparable experience as it assumes additional legal\\nrisk in making an independent determination that the product conforms to EU essential requirements (which\\nmay be relatively general). Hence their reliance and preference for firms to use EU harmonized standards.\\nThis is a big part of the reason why many firms and policymakers characterize harmonized EU standards as de\\nfacto mandatory.\\nSecond, the EU approach is restrictive: notified bodies have to be based in the EU, accredited by the\\ncorresponding EU-based national accreditation body, and designated by the relevant member state regulatory\\nauthority (Notifying Authority) as well as the EC. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 29, 'page': 9, '_split_overlap': [{'doc_id': 'a306a4b5facfcc427f9e9fc18b5fdeb6', 'range': (0, 176)}, {'doc_id': '403e1bbed4328cb25c24b76ebe6d305b', 'range': (986, 1245)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f142f59d85171a16fcf5ed0e98627fe1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Second, the EU approach is restrictive: notified bodies have to be based in the EU, accredited by the\\ncorresponding EU-based national accreditation body, and designated by the relevant member state regulatory\\nauthority (Notifying Authority) as well as the EC. Absent a government-to-government mutual recognition\\nagreement (MRA), these EU-based notified bodies are the only ones legally able to test to harmonized EU\\nproduct requirements (where third party conformity assessment is required, as it presumably would be for\\nhigh-risk applications of AI).19\\nThe fear of this foundational discrimination is founded on existing EU policy as the whitepaper references\\nDecision 768/2008/EC (on a common framework for the marketing of products), which creates these\\ntechnical barriers to trade in the form of localized testing requirements. Article R17 on “requirements relating\\nto notified bodies” states that a “a conformity assessment body shall be established under national law and\\nhave legal personality.”20 This is commonly understood to mean that the assessment body has to be based in\\nthe EU and be approved by the EC. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 30, 'page': 9, '_split_overlap': [{'doc_id': 'f142f59d85171a16fcf5ed0e98627fe1', 'range': (0, 259)}, {'doc_id': '5ecb2593c1c1666e13ddef1f818675bd', 'range': (833, 1119)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '403e1bbed4328cb25c24b76ebe6d305b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Article R17 on “requirements relating\\nto notified bodies” states that a “a conformity assessment body shall be established under national law and\\nhave legal personality.”20 This is commonly understood to mean that the assessment body has to be based in\\nthe EU and be approved by the EC. The EC recently reinforced its use of local testing bodies clear in recent\\nnegotiations with the United Kingdom, in pointing out how UK notified bodies will lose their status\\ndue to Brexit.21\\nThe EU’s Framework for Cybersecurity: A Work in Progress with Many Unresolved Issues\\nThe white paper also identifies the Cybersecurity Act as a potential framework to replicate as it is also based of\\nthe EU’s existing conformity assessment framework and deals with a similarly new, digital issue. The EC\\nshould not replicate the Cybersecurity Act’s approach as it’s still very much a work in progress, and one which\\nalready exposes several issues that the EC should want to avoid in regulating AI. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 31, 'page': 9, '_split_overlap': [{'doc_id': '403e1bbed4328cb25c24b76ebe6d305b', 'range': (0, 286)}, {'doc_id': '719baad0bbba1b0c065d9093a79c003c', 'range': (776, 976)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5ecb2593c1c1666e13ddef1f818675bd'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: The EC\\nshould not replicate the Cybersecurity Act’s approach as it’s still very much a work in progress, and one which\\nalready exposes several issues that the EC should want to avoid in regulating AI. The Cybersecurity Act\\ndesignates and strengthens a central European agency (the EU Agency for Cybersecurity, or ENISA) and\\nestablishes an EU-wide certification framework for specific ICT products, services, or processes.22 It requires\\nEU member states to designate one or more national cybersecurity certification authorities, who subsequently\\nauthorize assessment bodies to assess the conformity of certain products, services, and processes before being\\nplaced on the market.23\\x0c10\\nThe EC has tasked ENISA to prepare draft certification schemes involving national accreditation bodies and\\nconformity assessment bodies, which is a hugely complicated process involving one or more assurance levels\\n(basic, substantial, or high), based on the level of risk associated with the product, service, or process. While\\nthe certification is in principle voluntary, it seeks to set a central standard for the framework to avoid\\ndivergent approaches among member states. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 32, 'page': 9, '_split_overlap': [{'doc_id': '5ecb2593c1c1666e13ddef1f818675bd', 'range': (0, 200)}, {'doc_id': '16a320d0402bf018e712e4f9f477e476', 'range': (1005, 1159)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '719baad0bbba1b0c065d9093a79c003c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: While\\nthe certification is in principle voluntary, it seeks to set a central standard for the framework to avoid\\ndivergent approaches among member states. However, the EC has indicated in some areas, such as 5G and\\ncybersecurity, that testing requirements will be mandatory (which may depend on each member state’s\\ntechnical regulations, which again raises the prospects for differential regulations among members).24\\nThis approach creates a new, significant, and complicated institutional challenge as it requires new country-\\nlevel capacity and capabilities to review what would be a complicated process in a consistent way across\\nEurope. The Annex to the Cybersecurity Act sets forth requirements for accreditation as a conformity\\nassessment body, but ultimately, these depend on the country’s respective national cybersecurity\\nauthorities, who are authorized to conduct audits of conformity assessment bodies and holders of EU\\ncybersecurity certificates.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 33, 'page': 10, '_split_overlap': [{'doc_id': '719baad0bbba1b0c065d9093a79c003c', 'range': (0, 154)}, {'doc_id': '86630dbcc6e2c1ba5f95ca8ee59041bb', 'range': (641, 958)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '16a320d0402bf018e712e4f9f477e476'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: The Annex to the Cybersecurity Act sets forth requirements for accreditation as a conformity\\nassessment body, but ultimately, these depend on the country’s respective national cybersecurity\\nauthorities, who are authorized to conduct audits of conformity assessment bodies and holders of EU\\ncybersecurity certificates.\\nAt best, the Cybersecurity Act is a premature model to replicate as it hasn’t answered many of the same\\ncritical questions that need to be answered before creating another system for AI conformity assessments,\\nnamely: can governments design and apply some objective criteria to testing a dynamic technology and a\\ndynamic threat and risk; and can EU member states set up the governance and build the capacity and\\ncompetency to administer a highly complicated and unproven process?25 This is why it’s critical for the EC to\\nsupport global, voluntary, and industry-led standardization discussions for AI, cybersecurity, and other digital\\nissues given the critical role they play in addressing shared concerns, supporting innovation and trade, and\\nbridging different regulatory regimes.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 34, 'page': 10, '_split_overlap': [{'doc_id': '16a320d0402bf018e712e4f9f477e476', 'range': (0, 317)}, {'doc_id': 'ccdc4d4f089d4e612219d3b48b90352f', 'range': (318, 1100)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '86630dbcc6e2c1ba5f95ca8ee59041bb'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: At best, the Cybersecurity Act is a premature model to replicate as it hasn’t answered many of the same\\ncritical questions that need to be answered before creating another system for AI conformity assessments,\\nnamely: can governments design and apply some objective criteria to testing a dynamic technology and a\\ndynamic threat and risk; and can EU member states set up the governance and build the capacity and\\ncompetency to administer a highly complicated and unproven process?25 This is why it’s critical for the EC to\\nsupport global, voluntary, and industry-led standardization discussions for AI, cybersecurity, and other digital\\nissues given the critical role they play in addressing shared concerns, supporting innovation and trade, and\\nbridging different regulatory regimes.\\nLessons to Learn From: The Case of the EU’s Medical Device Regulation\\nRecent experience shows that the EC should avoid or at least be cautious when greatly considering expanding\\nrequirements for third-party conformity assessment, particularly in areas of new technology. Europe’s\\nMDR/IVDR roadmap (referred to as “the roadmap”) was agreed on May 5, 2017. The MDR’s\\nimplementation date was recently extended by a year from May 26, 2020 to May 26, 2021. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 35, 'page': 10, '_split_overlap': [{'doc_id': '86630dbcc6e2c1ba5f95ca8ee59041bb', 'range': (0, 782)}, {'doc_id': 'a622367026590ecd58b5be3b23f80d8c', 'range': (1054, 1234)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ccdc4d4f089d4e612219d3b48b90352f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Europe’s\\nMDR/IVDR roadmap (referred to as “the roadmap”) was agreed on May 5, 2017. The MDR’s\\nimplementation date was recently extended by a year from May 26, 2020 to May 26, 2021. IVDR has a five-\\nyear transitional period (until May 26, 2022). The roadmap applies to all medical devices for humans,\\nincluding digital health. The roadmap aims to establish a modernized EU legislative framework to ensure\\nbetter protection of public health and patient safety, by improving the quality, safety and reliability of medical\\ndevices, strengthening transparency of information for consumers, and improving market surveillance.26\\nThe roadmap was updated and enacted to keep pace with technological innovation, and to address differential\\ninterpretations and application of the rules across EU member states, some of which were associated with\\nhigh-profile incidents involving failed medical devices. Its scope is broad in that it covers hundreds of\\nthousands of different medical devices and organizations that manufacture, import, and distribute them. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 36, 'page': 10, '_split_overlap': [{'doc_id': 'ccdc4d4f089d4e612219d3b48b90352f', 'range': (0, 180)}, {'doc_id': '47774669bfeb5e8da0fa1382e1a05dd8', 'range': (892, 1044)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a622367026590ecd58b5be3b23f80d8c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Its scope is broad in that it covers hundreds of\\nthousands of different medical devices and organizations that manufacture, import, and distribute them. It\\nalso extends to data in that it specifies requirements for the data collection of clinical investigations on\\x0c11\\nmedical devices, which have been aligned with the requirements for clinical trials on medicinal products.27 In\\na scenario that would inevitably arise with any new AI conformity test, beyond introducing new testing\\nrequirements, it also requires producers to get existing devices re-certified to abide by the roadmap.\\nA big difference between the MDR/IVDR roadmap and any potential framework for AI is that the former is\\nabout physical devices—AI is not a physical product. Yet, even with a physical product, this case shows just\\nhow complicated and challenging it is to develop new EU harmonized standards and to apply these as part of\\na updated conformity assessment framework.\\nPreparation for this huge and complicated process across every EU member state has been lagging. COVID-\\n19 forced a delay in implementation that many stakeholders had already been calling for due to many issues\\nwith this new system. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 37, 'page': 10, '_split_overlap': [{'doc_id': 'a622367026590ecd58b5be3b23f80d8c', 'range': (0, 152)}, {'doc_id': 'fb0c255450af98b463a8bfa0b0824c68', 'range': (1044, 1179)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '47774669bfeb5e8da0fa1382e1a05dd8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: COVID-\\n19 forced a delay in implementation that many stakeholders had already been calling for due to many issues\\nwith this new system. Indicative of this, a 2019 study found that just 27 percent of 230 medical device makers\\nsurveyed expect to be in full compliance.28 Of those surveyed, 46 percent said they planned to use the\\nMDR/IVDR roadmap’s transitional provisions to be able to sell their products in the EU until 2024, while\\nworking on their compliance programs. As of May 2019—when the survey closed, a year before it was\\ninitially due to come into effect—there were only five notified bodies in the entire EU designated to test the\\nconformity of hundreds of thousands of medical devices.29\\nFollowing this, in January 2020—five months from MDR/IVDR roadmap’s initial implementation date—\\nmedical device trade association MedTech Europe outlined several major issues that could just as easily apply\\nto a hastily developed AI conformity assessment framework:\\n• Most of the (current) 55 notified bodies were still awaiting their MDR designation, and thus were\\nnot yet able to certify devices to the new regulation. Furthermore, even with their designation, each\\nnotified body needs at least six months for each certification. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 38, 'page': 11, '_split_overlap': [{'doc_id': '47774669bfeb5e8da0fa1382e1a05dd8', 'range': (0, 135)}, {'doc_id': '235199ae6cef5fd9c15f0588efa541a6', 'range': (471, 1231)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fb0c255450af98b463a8bfa0b0824c68'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: As of May 2019—when the survey closed, a year before it was\\ninitially due to come into effect—there were only five notified bodies in the entire EU designated to test the\\nconformity of hundreds of thousands of medical devices.29\\nFollowing this, in January 2020—five months from MDR/IVDR roadmap’s initial implementation date—\\nmedical device trade association MedTech Europe outlined several major issues that could just as easily apply\\nto a hastily developed AI conformity assessment framework:\\n• Most of the (current) 55 notified bodies were still awaiting their MDR designation, and thus were\\nnot yet able to certify devices to the new regulation. Furthermore, even with their designation, each\\nnotified body needs at least six months for each certification. As executive director of the Regulatory\\nAffairs Professionals Society Paul Brooks stated: “If there are too few notifying bodies or their\\ncapacity to assess devices under EU MDR is inadequate to meet the demand, it will create\\nbottlenecks that could result in product shortages, including for critically important and high-risk\\ndevices patients depend on.”30\\n• Notified bodies lacked the capacity to setup new arrangements for MDR and continue ongoing\\nwork, such as conducting surveillance of devices currently in the market.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 39, 'page': 11, '_split_overlap': [{'doc_id': 'fb0c255450af98b463a8bfa0b0824c68', 'range': (0, 760)}, {'doc_id': '99c3e04fb9bfc63032fb421a9f062f21', 'range': (761, 1286)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '235199ae6cef5fd9c15f0588efa541a6'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: As executive director of the Regulatory\\nAffairs Professionals Society Paul Brooks stated: “If there are too few notifying bodies or their\\ncapacity to assess devices under EU MDR is inadequate to meet the demand, it will create\\nbottlenecks that could result in product shortages, including for critically important and high-risk\\ndevices patients depend on.”30\\n• Notified bodies lacked the capacity to setup new arrangements for MDR and continue ongoing\\nwork, such as conducting surveillance of devices currently in the market.\\n• Notified bodies have not setup expert panels, meaning MDR is essentially inaccessible to various,\\nhigh-tech devices, such as innovative implants and medicine-administering devices.\\n• Implementing laws and regulations (as called for under MDR) are still lacking, meaning that MDR\\ncertification is inaccessible for certain devices. Similarly, there is a lack of guidance from the EU on\\nkey obligations under MDR that notified bodies and manufacturers need to understand and apply for\\nthe first time for re-certification and new certifications.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 40, 'page': 11, '_split_overlap': [{'doc_id': '235199ae6cef5fd9c15f0588efa541a6', 'range': (0, 525)}, {'doc_id': 'c80b36d954881594b9497f6739eec484', 'range': (858, 1069)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '99c3e04fb9bfc63032fb421a9f062f21'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Similarly, there is a lack of guidance from the EU on\\nkey obligations under MDR that notified bodies and manufacturers need to understand and apply for\\nthe first time for re-certification and new certifications.\\x0c12\\n• Given notified bodies are overworked and unable to accept applications from additional\\nmanufacturers (such as those whose notified bodies will not receive an MDR designation soon), a\\nlarge number of devices will likely not be certified (leading to de facto orphaned devices).\\n• Given notified bodies are overworked, they do not have the capacity to assess applications for new\\nand innovative products, which restricts innovation and negatively impact European patients.31\\nThe time and complexity to develop and approve harmonized standards for use across the EU under the\\nMDR/IVDR roadmap (that would be granted a presumption of conformity) is another lesson for EU\\npolicymakers in considering a similar system for AI. These harmonized standards are critical in that they are\\nused to establish or claim conformity with the roadmap’s requirements. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 41, 'page': 11, '_split_overlap': [{'doc_id': '99c3e04fb9bfc63032fb421a9f062f21', 'range': (0, 211)}, {'doc_id': '477666bb0754b4c9f5f07a9a94f38d73', 'range': (493, 1063)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c80b36d954881594b9497f6739eec484'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: • Given notified bodies are overworked, they do not have the capacity to assess applications for new\\nand innovative products, which restricts innovation and negatively impact European patients.31\\nThe time and complexity to develop and approve harmonized standards for use across the EU under the\\nMDR/IVDR roadmap (that would be granted a presumption of conformity) is another lesson for EU\\npolicymakers in considering a similar system for AI. These harmonized standards are critical in that they are\\nused to establish or claim conformity with the roadmap’s requirements. Firms need these standards to show\\nhow they will establish conformity in their products, services, and processes.32 The release of these\\nharmonized standards for the roadmap was slow and inconsistent.33 In March, 2020, MedTech Europe\\nsounded the alarm in pointing out that many harmonized standards would be available by the (then)\\nimplementation date of May 2020. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 42, 'page': 12, '_split_overlap': [{'doc_id': 'c80b36d954881594b9497f6739eec484', 'range': (0, 570)}, {'doc_id': '4af922a8589ac0ed1d78553af6a31cde', 'range': (571, 935)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '477666bb0754b4c9f5f07a9a94f38d73'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Firms need these standards to show\\nhow they will establish conformity in their products, services, and processes.32 The release of these\\nharmonized standards for the roadmap was slow and inconsistent.33 In March, 2020, MedTech Europe\\nsounded the alarm in pointing out that many harmonized standards would be available by the (then)\\nimplementation date of May 2020. At this time (before the extension through 2021) MedTech Europe\\nadvised its members that they may need to use multiple standards (a potentially costly and complicated\\nprocess) to demonstrate compliance given the absence of harmonized standards.34 It is also worth mentioning\\nthat delays and issues with harmonized standards was also a problem with the EU’s radio equipment directive\\nin 2016.\\nIn this instance, Europe should consider the innovative approach the U.S. Food and Drug Administration\\n(FDA) has taken toward regulating medical devices that use AI. Not only has the agency created a Digital\\nHealth Unit, it’s (pilot) pre-certification program would move from individual product review to a firm-based\\nreview for medical devices and the software they use, including AI. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 43, 'page': 12, '_split_overlap': [{'doc_id': '477666bb0754b4c9f5f07a9a94f38d73', 'range': (0, 364)}, {'doc_id': '133ff183cc7bd6b02b975955d76e07ff', 'range': (923, 1142)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4af922a8589ac0ed1d78553af6a31cde'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Not only has the agency created a Digital\\nHealth Unit, it’s (pilot) pre-certification program would move from individual product review to a firm-based\\nreview for medical devices and the software they use, including AI. Further, a recent FDA whitepaper\\nreimagines regulation of devices with AI/ML software, including allowing pre-market certifications\\nanticipating change protocols permitting autonomous updates of medical devices using AI.35 In general, the\\nFDA seeks a flexible regulatory approach that can enable medical devices to dynamically learn and improve\\nwithout having to be constantly reapproved. This allows firms to use data and AI to improve their products\\non a daily basis. Do EU regulators really want to recertify products every single day? It also recognizes that\\nthere are different tiers of medical devices, such that regulations should be tighter, for instance, on\\nimplantable cardiac devices, while being more flexible, for instance, with Fitbits or wearable monitoring\\ndevices. But in general, the FDA approach tries to empower medical device innovation using AI, while\\nensuring adequate safety standards.\\n2. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 44, 'page': 12, '_split_overlap': [{'doc_id': '4af922a8589ac0ed1d78553af6a31cde', 'range': (0, 219)}, {'doc_id': 'b5669afec12744b6715e309db0a7bbee', 'range': (1002, 1132)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '133ff183cc7bd6b02b975955d76e07ff'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: But in general, the FDA approach tries to empower medical device innovation using AI, while\\nensuring adequate safety standards.\\n2. EX-ANTE AI CONFORMITY TESTS WILL BE A NEW NON-TARIFF BARRIER TO DIGITAL TRADE\\nThere is a risk that if the EU goes forward with this, that discriminatory treatment against foreign firms and\\ntheir AI-based digital products will become a new non-tariff barrier to trade. While created in an era of trade\\ndominated by physical goods, the simple principle at the heart of the General Agreement on Tariffs and\\nTrade (GATT) is just as important to modern services and digital-based trade in its goal of achieving both\\n“the substantial reduction of tariffs and other barriers to trade” and the elimination of “discriminatory\\x0c13\\ntreatment in international commerce.” These behind-the-border regulations are becoming more common and\\nconsequential as trade becomes more digital and services-based. The EC should consider the direct trade\\nimpact any of its regulatory proposals will have on its own firms and economies, but also the indirect impact\\non its firms if its (flawed) approach is subsequently copied in other countries (such as for cybersecurity\\nin Brazil).\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 45, 'page': 12, '_split_overlap': [{'doc_id': '133ff183cc7bd6b02b975955d76e07ff', 'range': (0, 130)}, {'doc_id': '25f7b2cb3cd204e71118051e5fe45ef0', 'range': (918, 1186)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b5669afec12744b6715e309db0a7bbee'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: The EC should consider the direct trade\\nimpact any of its regulatory proposals will have on its own firms and economies, but also the indirect impact\\non its firms if its (flawed) approach is subsequently copied in other countries (such as for cybersecurity\\nin Brazil).\\nIn the context of WTO agreements, especially the Agreement on Technical Barriers to Trade (the TBT\\nAgreement), members have regulatory autonomy to choose the measures best suited to address their national\\npolicy concerns of public health and safety, environmental protection, and consumer information, amongst\\nothers, provided these measures are non-discriminatory, no more trade restrictive than necessary, and if firms\\ncan access of suppliers to assessments of conformity.36 In essence, the TBT Agreement ensures regulations or\\nstandards do not become unnecessary or discriminatory trade barriers.37\\nAs trade becomes more intangible, more countries are using standards as a cover for protectionism. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 46, 'page': 13, '_split_overlap': [{'doc_id': 'b5669afec12744b6715e309db0a7bbee', 'range': (0, 268)}, {'doc_id': '5f20dfd0207e6739c51995dfbbacfe8f', 'range': (269, 969)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '25f7b2cb3cd204e71118051e5fe45ef0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: In the context of WTO agreements, especially the Agreement on Technical Barriers to Trade (the TBT\\nAgreement), members have regulatory autonomy to choose the measures best suited to address their national\\npolicy concerns of public health and safety, environmental protection, and consumer information, amongst\\nothers, provided these measures are non-discriminatory, no more trade restrictive than necessary, and if firms\\ncan access of suppliers to assessments of conformity.36 In essence, the TBT Agreement ensures regulations or\\nstandards do not become unnecessary or discriminatory trade barriers.37\\nAs trade becomes more intangible, more countries are using standards as a cover for protectionism. While\\nstandards setting often reflects a genuine need to address a market failure of some kind or to achieve certain\\nsocietal objectives, it can also be influenced by political economy forces, and, consequently, there is a risk the\\nprocess is used as a tool for protectionism.38 This “standards protectionism” is evident when countries or\\nregions do not recognize testing results of safety tests performed in laboratories of exporters’ home countries\\nand demanding duplicate tests at specially assigned assessment bodies.39 National or regional standards,\\nespecially when rendered mandatory, act as barriers to trade, either deliberately or inadvertently, if they fail to\\nprovide fair access to foreign firms and their products, such as through equal recognition to comparable\\ninternational standards.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 47, 'page': 13, '_split_overlap': [{'doc_id': '25f7b2cb3cd204e71118051e5fe45ef0', 'range': (0, 700)}, {'doc_id': 'a33a3a3f4ffc7f5b2fb4ffdb99f9aeb4', 'range': (701, 1502)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5f20dfd0207e6739c51995dfbbacfe8f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: While\\nstandards setting often reflects a genuine need to address a market failure of some kind or to achieve certain\\nsocietal objectives, it can also be influenced by political economy forces, and, consequently, there is a risk the\\nprocess is used as a tool for protectionism.38 This “standards protectionism” is evident when countries or\\nregions do not recognize testing results of safety tests performed in laboratories of exporters’ home countries\\nand demanding duplicate tests at specially assigned assessment bodies.39 National or regional standards,\\nespecially when rendered mandatory, act as barriers to trade, either deliberately or inadvertently, if they fail to\\nprovide fair access to foreign firms and their products, such as through equal recognition to comparable\\ninternational standards.\\nThe EU is no stranger to this voluntary, but in effect mandatory, situation. The EU’s approach to\\nstandardization (in EU Regulation No. 1025/2012), affirmed by recent rulings of the European Court of\\nJustice, shows how harmonized European standards (i.e., those granted a presumption of conformity) hold\\nlegal significance under EU law and may therefore be considered as de facto mandatory.40\\nTrade policy is an important tool to help ensure standards are transparent, predictable, proportionate, and\\nnon-discriminatory. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 48, 'page': 13, '_split_overlap': [{'doc_id': '5f20dfd0207e6739c51995dfbbacfe8f', 'range': (0, 801)}, {'doc_id': '1167c5955753701547b779718231b85d', 'range': (1056, 1322)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a33a3a3f4ffc7f5b2fb4ffdb99f9aeb4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: , those granted a presumption of conformity) hold\\nlegal significance under EU law and may therefore be considered as de facto mandatory.40\\nTrade policy is an important tool to help ensure standards are transparent, predictable, proportionate, and\\nnon-discriminatory. The WTO reports that duplication, delays or discrimination in conformity assessment\\nprocedures (CAPs) can significantly increase trade costs, and this risk is reflected in the growing importance of\\nCAPs in WTO discussions and bilateral and regional free trade agreements.41 A WTO review of the issue\\namong members from 2010-2014 shows that CAPs raise proportionally more concern among WTO\\nMembers than technical regulations do and that testing and certification are the procedures that most\\nfrequently give rise to trade problems.42 In response to this, recent trade agreements such as the United States-\\nMexico-Canada Agreement (USMCA) and Comprehensive and Progressive Agreement for Trans-Pacific\\nPartnership emphasize regulatory disciplines and highlight the central role of institutional structures, which\\ntogether, help to provide regulatory coherence for digital issues.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 49, 'page': 13, '_split_overlap': [{'doc_id': 'a33a3a3f4ffc7f5b2fb4ffdb99f9aeb4', 'range': (0, 266)}, {'doc_id': '59c51e6a8cd49701675c765d053c1ecc', 'range': (267, 1143)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1167c5955753701547b779718231b85d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: The WTO reports that duplication, delays or discrimination in conformity assessment\\nprocedures (CAPs) can significantly increase trade costs, and this risk is reflected in the growing importance of\\nCAPs in WTO discussions and bilateral and regional free trade agreements.41 A WTO review of the issue\\namong members from 2010-2014 shows that CAPs raise proportionally more concern among WTO\\nMembers than technical regulations do and that testing and certification are the procedures that most\\nfrequently give rise to trade problems.42 In response to this, recent trade agreements such as the United States-\\nMexico-Canada Agreement (USMCA) and Comprehensive and Progressive Agreement for Trans-Pacific\\nPartnership emphasize regulatory disciplines and highlight the central role of institutional structures, which\\ntogether, help to provide regulatory coherence for digital issues.\\x0c14\\nLimited and discriminatory conformity assessment procedures (like those in the whitepaper and used\\nelsewhere in the EU) mean higher market entry costs for foreign firms, as they not only need to adapt their\\nproducts to meet de facto mandatory local standards, but also have them tested in multiple different countries\\nand regions. As noted, this affects both the extensive and intensive margins of trade.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 50, 'page': 13, '_split_overlap': [{'doc_id': '1167c5955753701547b779718231b85d', 'range': (0, 876)}, {'doc_id': '5dccdda8490a457a8278bff38eb7a628', 'range': (877, 1284)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '59c51e6a8cd49701675c765d053c1ecc'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: 14\\nLimited and discriminatory conformity assessment procedures (like those in the whitepaper and used\\nelsewhere in the EU) mean higher market entry costs for foreign firms, as they not only need to adapt their\\nproducts to meet de facto mandatory local standards, but also have them tested in multiple different countries\\nand regions. As noted, this affects both the extensive and intensive margins of trade.\\nThe trade impacts of a discriminatory ex-ante conformity assessment framework for AI would depend on how\\ndifferent the regulations are in the importing and exporting country, and whether local firms would have a\\ncomparative advantage (over foreign, importing firms) in meeting stricter regulations. For example, large\\nforeign firms with local subsidiaries will have an advantage, while foreign small and medium-sized firms will\\nbe most affected as they lack the resources and expertise to deal with multiple different foreign\\nconformity assessments.\\nThe impact will likely be prohibitive for firms from developing countries. Indeed, their governments and\\nfirms are typically characterized by a lack of access to information, technology, managerial capacity, and\\nfinance, which impedes their businesses’ ability to adapt product development and delivery processes quickly\\nand adequately enough. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 51, 'page': 14, '_split_overlap': [{'doc_id': '59c51e6a8cd49701675c765d053c1ecc', 'range': (0, 407)}, {'doc_id': '478d2b88911a5179ad843e2b22b7fceb', 'range': (1033, 1301)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5dccdda8490a457a8278bff38eb7a628'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Indeed, their governments and\\nfirms are typically characterized by a lack of access to information, technology, managerial capacity, and\\nfinance, which impedes their businesses’ ability to adapt product development and delivery processes quickly\\nand adequately enough. They are less likely to meet the EU’s onerous requirements. Added to this is the cost\\nand complexity of obtaining testing and certification services from only a select number of EU-based firms in\\norder to demonstrate conformity.\\nThe EC should carefully consider the impact that restrictive and discriminatory conformity assessment\\nprocedures will have on trade. While empirical evidence on the relationship between regulatory cooperation\\nand trade is scarce, available studies suggest that regulatory divergence can generate substantial trade costs in\\nsome areas, and reduces trade. This suggests ex-ante conformity tests for AI would likely have a similar impact\\non modern services and digital trade. For example:\\n• Shepherd (2007) found that an increase in the number of standards in textiles and clothing, for\\ninstance, reduces a trading partner’s export variety. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 52, 'page': 14, '_split_overlap': [{'doc_id': '5dccdda8490a457a8278bff38eb7a628', 'range': (0, 268)}, {'doc_id': '7612c83bb976b682e7a89cb10f2793c5', 'range': (971, 1135)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '478d2b88911a5179ad843e2b22b7fceb'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: For example:\\n• Shepherd (2007) found that an increase in the number of standards in textiles and clothing, for\\ninstance, reduces a trading partner’s export variety. When EU standards align to international\\nstandards (for example, International Organization for Standardization), the study found a small\\nincrease in the variety of imports from trading partners.43\\n• Reyes (2011, 2012) used a detailed database of U.S. firm-level data, trade data, and EU product\\nstandards to show that aligning EU products with international standards increases US exports to the\\nEU through an increase in the number of US firms entering the EU market. While fixed entry costs\\ndid not have an immediate impact on prices and volumes, they acted as entry barriers for exporters,\\nmeaning that instead of merely making products more expensive, they reduce the likelihood of\\nexporting.44\\n• Foletti and Shingal (2014) found that harmonization leads to greater trade at both the intensive and\\nextensive margins. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 53, 'page': 14, '_split_overlap': [{'doc_id': '478d2b88911a5179ad843e2b22b7fceb', 'range': (0, 164)}, {'doc_id': '600212134e33f622a1f3a44663aa45d9', 'range': (635, 986)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7612c83bb976b682e7a89cb10f2793c5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: While fixed entry costs\\ndid not have an immediate impact on prices and volumes, they acted as entry barriers for exporters,\\nmeaning that instead of merely making products more expensive, they reduce the likelihood of\\nexporting.44\\n• Foletti and Shingal (2014) found that harmonization leads to greater trade at both the intensive and\\nextensive margins. Regulatory heterogeneity is a greater impediment in the probability of exporting\\nthan in volumes.45\\x0c15\\n• Cadot and Gourdon (2015) used prices to measure the impact of non-tariff measures (NTMs),\\nfinding that regional trade agreements with provisions related to harmonization or mutual\\nrecognition agreements reduce the impact that NTMs generally have on price. Essentially, they found\\nthat such regulatory cooperation initiatives reduce compliance costs. They also note that mutual\\nrecognition agreements on conformity assessment have the most significant effect in reducing\\ncompliance costs and the impact on trade.46\\n• Fontagné et al. (2013) examines sanitary and phytosanitary (SPS) measures that are raised as specific\\ntrade concerns in the WTO SPS Committee, showing that these have a negative effect on both the\\nextensive and intensive margins of trade as they involve compliance costs that increase unit values and\\nprohibit market entry. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 54, 'page': 14, '_split_overlap': [{'doc_id': '7612c83bb976b682e7a89cb10f2793c5', 'range': (0, 351)}, {'doc_id': 'b92404ddc9f8aae467d3e191f94d13e', 'range': (989, 1296)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '600212134e33f622a1f3a44663aa45d9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: (2013) examines sanitary and phytosanitary (SPS) measures that are raised as specific\\ntrade concerns in the WTO SPS Committee, showing that these have a negative effect on both the\\nextensive and intensive margins of trade as they involve compliance costs that increase unit values and\\nprohibit market entry. Importantly, the study also found that harmonization of MRL regulation\\nfosters decisions to export within the EU as well as agri-trade into the EU from\\ndeveloping countries.47\\n3. CONFORMITY ASSESSMENTS AND MANDATORY SOURCE CODE DISCLOSURE: A BARRIER TO\\nTRADE THE EU (RIGHTLY) OPPOSES IN OTHER COUNTRIES\\nWhile the way in which notified bodies would assess AI applications remains unclear, it may be fair to assume\\nthat firms would need to share proprietary data sets, algorithms, or source code as a means of demonstrating\\nconformity with EU regulatory requirements. This is particularly problematic given the localization\\nrequirement for notified bodies. It also would appear to contravene the EU’s trade policy approach in third\\ncountries. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 55, 'page': 15, '_split_overlap': [{'doc_id': '600212134e33f622a1f3a44663aa45d9', 'range': (0, 307)}, {'doc_id': '362e8c258aac79d18d9a53a42d8625fc', 'range': (874, 1048)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b92404ddc9f8aae467d3e191f94d13e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: This is particularly problematic given the localization\\nrequirement for notified bodies. It also would appear to contravene the EU’s trade policy approach in third\\ncountries. The EU has agreed on provisions that prohibit mandatory source code disclosure in the EU-Japan\\nEconomic Partnership Agreement and proposed similar provisions at WTO ecommerce negotiations.48\\nSource code—the coded instructions at the heart of a computer program—enables computer technology to\\ndo the amazing things it does. For companies developing software, protecting source code is necessary to\\nprevent other entities from stealing and free riding on the large R&D costs associated with software\\ndevelopment. Indicative of the sensitivity around source code is the fact that when one purchases software or\\ngoods with software embedded, the software is generally compiled in “object code” form, and not with the\\nactual source code, as this would make it much easier for thieves, hackers, and others to copy and misuse. In\\nother cases, software firms use open-source licensing arrangements to disclose source code in order to allow\\nothers to modify and build on the source code, but such a decision is made by each individual or firm.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 56, 'page': 15, '_split_overlap': [{'doc_id': 'b92404ddc9f8aae467d3e191f94d13e', 'range': (0, 174)}, {'doc_id': 'ec16e2f6173657c01a2da341caad08d8', 'range': (995, 1209)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '362e8c258aac79d18d9a53a42d8625fc'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: In\\nother cases, software firms use open-source licensing arrangements to disclose source code in order to allow\\nothers to modify and build on the source code, but such a decision is made by each individual or firm.\\nFrom a commercial perspective, not disclosing source code is standard practice, given intellectual property\\nand security considerations. AI-based products often involve high-fixed costs for research and development to\\nbring the first copy to market, but low marginal costs in subsequent copies. Hence why they represent an\\nattractive target for foreign governments trying to collect and pass along the intellectual property to help local\\nfirms. Trade law provisions like the ones the EU and the United States support are important for trade and\\ndata-driven innovation as they reduce the risk of parties using concerns over “cybersecurity” or “algorithmic\\ntransparency” as an excuse to enact requirements that they hand over source code as a condition of market\\x0c16\\nentry market entry, which allows them to pass on this valuable intellectual property to domestic firms. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 57, 'page': 15, '_split_overlap': [{'doc_id': '362e8c258aac79d18d9a53a42d8625fc', 'range': (0, 214)}, {'doc_id': 'e27a457ed420a3544f59dccedfe995b3', 'range': (660, 1082)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ec16e2f6173657c01a2da341caad08d8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Trade law provisions like the ones the EU and the United States support are important for trade and\\ndata-driven innovation as they reduce the risk of parties using concerns over “cybersecurity” or “algorithmic\\ntransparency” as an excuse to enact requirements that they hand over source code as a condition of market\\x0c16\\nentry market entry, which allows them to pass on this valuable intellectual property to domestic firms. China\\nand other countries have proposed regulations that would require companies to transfer or allow access to\\nsource code as a condition of market entry—effectively acting as a barrier to trade.49\\nSimilar to the EU, Australia, New Zealand, Singapore, the United States, and others have enacted new trade\\nlaw provisions to protect source code. However, these provisions do not affect the scenarios where source code\\nis disclosed as a matter of business (after entry), such as in commercial contracts, government procurement,\\npatent applications, legal discovery, and for regulatory concerns (such as environmental). For these trade and\\ninnovation reasons, the EC should avoid including source code disclosure as part of pre-market conformity\\nassessments.\\n4. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 58, 'page': 15, '_split_overlap': [{'doc_id': 'ec16e2f6173657c01a2da341caad08d8', 'range': (0, 422)}, {'doc_id': '607dbd168ea7a1c1795082db2ee4bf30', 'range': (1040, 1181)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e27a457ed420a3544f59dccedfe995b3'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: For these trade and\\ninnovation reasons, the EC should avoid including source code disclosure as part of pre-market conformity\\nassessments.\\n4. MUTUAL RECOGNITION AND ACCESS TO TESTING AS A MARKET ACCESS BARRIER\\nThe whitepaper states that: “Economic operators established in third countries wanting to enter the internal\\nmarket could either make use of designated bodies established in the EU or, subject to mutual recognition\\nagreements with third countries, have recourse to third-country bodies designated to carry out\\nsuch assessment.”50\\nUnfortunately, the EU has reiterated their embrace of the precautionary principle’s current use of conformity\\nassessment testing frameworks shows that these mutual recognition agreements are limited and definitely not\\nprioritized by the EU. The EU has a limited number of mutual recognition agreements (MRAs) with\\nAustralia, Canada, Israel, Japan, New Zealand, Switzerland, and the United States.51 However, overall, while\\nthese MRAs are highly valuable, they’re not widely used (as they are relatively difficult to achieve). Nor are\\nMRAs an efficient or practicable means of facilitating the acceptance of reliable test results by bodies based\\noutside of the EU.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 59, 'page': 16, '_split_overlap': [{'doc_id': 'e27a457ed420a3544f59dccedfe995b3', 'range': (0, 141)}, {'doc_id': 'c095d781ae30992cf5844a211d6f3602', 'range': (1066, 1203)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '607dbd168ea7a1c1795082db2ee4bf30'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Nor are\\nMRAs an efficient or practicable means of facilitating the acceptance of reliable test results by bodies based\\noutside of the EU.\\nFor example, the United States and the EU have shown that (while challenging) they can find ways to build\\nregulatory compatibility, thus reducing the negative impact of regulatory differences.52 MRAs are one tool for\\nthis. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 60, 'page': 16, '_split_overlap': [{'doc_id': '607dbd168ea7a1c1795082db2ee4bf30', 'range': (0, 137)}, {'doc_id': '20d182c927c2807012d25d3da1c473b8', 'range': (138, 360)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c095d781ae30992cf5844a211d6f3602'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: For example, the United States and the EU have shown that (while challenging) they can find ways to build\\nregulatory compatibility, thus reducing the negative impact of regulatory differences.52 MRAs are one tool for\\nthis. For example, the European Medicines Agency has signed MRAs with seven other countries, including\\nthe United States.53 The EU and United States have an MRA that covers marine equipment, medical devices,\\nelectromagnetic compatibility testing services, electrical equipment, and telecommunications.54 Under the\\ntelecommunications annex, for instance, the U.S. National Institute of Standards and Technology (NIST)\\ncan effectively perform the role of an EU member state notifying authority, and designate a notified body\\nunder the EUC Radio Equipment Directive.55 When the main package of MRAs was agreed to in six sectors\\nin 1997, the U.S. government estimated that the package (covering $47 billion in trade at that time)\\neliminated costs equivalent to two or three percentage points of tariffs.56 The Peterson Institute for\\nInternational Economics’ report International Trade Meets Domestic Regulation: Negotiating the US-EU\\nMutual Recognition Agreements provides a detailed background on these past efforts.57 This past cooperation\\nshows that cooperation is possible and significant for trade relations.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 61, 'page': 16, '_split_overlap': [{'doc_id': 'c095d781ae30992cf5844a211d6f3602', 'range': (0, 222)}, {'doc_id': '159224ad84e6b019d7d1a688154f4db9', 'range': (223, 1326)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '20d182c927c2807012d25d3da1c473b8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: For example, the European Medicines Agency has signed MRAs with seven other countries, including\\nthe United States.53 The EU and United States have an MRA that covers marine equipment, medical devices,\\nelectromagnetic compatibility testing services, electrical equipment, and telecommunications.54 Under the\\ntelecommunications annex, for instance, the U.S. National Institute of Standards and Technology (NIST)\\ncan effectively perform the role of an EU member state notifying authority, and designate a notified body\\nunder the EUC Radio Equipment Directive.55 When the main package of MRAs was agreed to in six sectors\\nin 1997, the U.S. government estimated that the package (covering $47 billion in trade at that time)\\neliminated costs equivalent to two or three percentage points of tariffs.56 The Peterson Institute for\\nInternational Economics’ report International Trade Meets Domestic Regulation: Negotiating the US-EU\\nMutual Recognition Agreements provides a detailed background on these past efforts.57 This past cooperation\\nshows that cooperation is possible and significant for trade relations.\\x0c17\\nTo their credit, the EU and the United States have tried to build on this earlier success, for instance in 2017,\\nthey negotiated an MRA on Pharmaceutical Good Manufacturing Practices (GMPs).58 Most recently, in\\n2019, the EC published its proposal for agreement on conformity assessments with the United States (under\\none of the actions agreed under the EU-U.S. Joint Statement of July 25, 2018), in which it suggested\\nprovisions to ensure the EU and United States would accept the conformity assessment results of each other’s\\nassessment bodies, thus certifying products against the legal requirement of the other side.59 The proposal\\ncovers all relevant industrial sectors where third-party conformity assessment is required by either side.60 The\\nproposal would not mean that U.S. standards would be made equivalent to the EU’s, simply that U.S. bodies\\ncould inspect, test, and certify goods under EU technical regulations.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 62, 'page': 16, '_split_overlap': [{'doc_id': '20d182c927c2807012d25d3da1c473b8', 'range': (0, 1103)}, {'doc_id': '29b1b5bbe874455108c63e66f4003c14', 'range': (1104, 2031)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '159224ad84e6b019d7d1a688154f4db9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: 17\\nTo their credit, the EU and the United States have tried to build on this earlier success, for instance in 2017,\\nthey negotiated an MRA on Pharmaceutical Good Manufacturing Practices (GMPs).58 Most recently, in\\n2019, the EC published its proposal for agreement on conformity assessments with the United States (under\\none of the actions agreed under the EU-U.S. Joint Statement of July 25, 2018), in which it suggested\\nprovisions to ensure the EU and United States would accept the conformity assessment results of each other’s\\nassessment bodies, thus certifying products against the legal requirement of the other side.59 The proposal\\ncovers all relevant industrial sectors where third-party conformity assessment is required by either side.60 The\\nproposal would not mean that U.S. standards would be made equivalent to the EU’s, simply that U.S. bodies\\ncould inspect, test, and certify goods under EU technical regulations.\\nEssentially, it allows producers to test in the United States to EU standards and tests in the EU to U.S.\\nstandards, which would go some way to addressing the problem of there being limited accessibility to only\\nEU-based testing bodies. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 63, 'page': 17, '_split_overlap': [{'doc_id': '159224ad84e6b019d7d1a688154f4db9', 'range': (0, 927)}, {'doc_id': '413b430a0cd4b79468b11e25d770d0a2', 'range': (928, 1164)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '29b1b5bbe874455108c63e66f4003c14'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Essentially, it allows producers to test in the United States to EU standards and tests in the EU to U.S.\\nstandards, which would go some way to addressing the problem of there being limited accessibility to only\\nEU-based testing bodies. At the heart of the EU’s proposal was the recognition (even if implied) that its\\nconformity system is non-reciprocal, so it (rightly) seeks to establish the ability for non-EU assessment bodies\\nto help ease foreign market access to the EU market.61 This is where the EU’s approach falls short: non-EU\\ncertification and testing arrangements are far more limited and onerous for foreign firms and their products.\\nHowever, it is an imperfect solution that in an ideal world wouldn’t be necessary, as it ultimately stems from\\nthe EU’s pursuit of localized standards and restrictive conformity assessment testing. These MRAs essentially\\nplaces demands on the U.S. government (and U.S. firms) to mirror the system of approvals and oversight that\\nthe EU uses in designating notified bodies in its market. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 64, 'page': 17, '_split_overlap': [{'doc_id': '29b1b5bbe874455108c63e66f4003c14', 'range': (0, 236)}, {'doc_id': '5c2694eb38e6b4a1a05f8e4928d2eb08', 'range': (846, 1034)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '413b430a0cd4b79468b11e25d770d0a2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: These MRAs essentially\\nplaces demands on the U.S. government (and U.S. firms) to mirror the system of approvals and oversight that\\nthe EU uses in designating notified bodies in its market. Put differently, NIST, or another U.S. government\\nauthority, would have to assume a role comparable to that of a notifying authority in an EU Member\\nState, rather than just having U.S.-based conformity assessment bodies apply directly to EU-based\\ngovernmental authorities.\\nThis elaborate mechanism wouldn’t be necessary if the EU didn’t have a localization requirement in the first\\nplace. That is not to say that all U.S. regulatory authorities accept international test results—it depends on the\\nspecific regulatory or statutory authority—but the United States does not have a blanket requirement for\\nlocalization of conformity assessment bodies. Taking this a step further, absent an MRA or “conformity\\nassessment protocol” (like the one in Comprehensive Economic and Trade Agreement (CETA) between\\nCanada and the EU, which is reportedly having its own issues), there is currently no way in the EU system to\\nleverage international accreditation schemes to allow for acceptance of international test results. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 65, 'page': 17, '_split_overlap': [{'doc_id': '413b430a0cd4b79468b11e25d770d0a2', 'range': (0, 188)}, {'doc_id': 'fa591b288f84980b6cc23204cf1afd90', 'range': (837, 1198)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5c2694eb38e6b4a1a05f8e4928d2eb08'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Taking this a step further, absent an MRA or “conformity\\nassessment protocol” (like the one in Comprehensive Economic and Trade Agreement (CETA) between\\nCanada and the EU, which is reportedly having its own issues), there is currently no way in the EU system to\\nleverage international accreditation schemes to allow for acceptance of international test results. This in spite\\nof the fact that the EC lobbies foreign governments to accept test results from labs accredited by the\\nInternational Laboratory Accreditation Cooperation and International Accreditation Forum (detailed below).\\nGiven their trade and economic relationship, it’s sensible that the EU works with the United States to expand\\ntesting options. But the EU’s approach to AI highlights a broader, troubling goal of European regulatory\\nimperialism in that it typically reflects an attempt to force developing countries, especially those with smaller\\nmarkets, to conform to Brussels’ standards. This is damaging to these economies, as their local government\\x0c18\\nmay not have the capacity to establish standards at all, whether their own or those of others. In general,\\nmutual recognition agreements should be easier when countries are at similar levels of development. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 66, 'page': 17, '_split_overlap': [{'doc_id': '5c2694eb38e6b4a1a05f8e4928d2eb08', 'range': (0, 361)}, {'doc_id': 'e6aed8f5fa33a3fc7dfb9f4b41f258d2', 'range': (959, 1231)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fa591b288f84980b6cc23204cf1afd90'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: This is damaging to these economies, as their local government\\x0c18\\nmay not have the capacity to establish standards at all, whether their own or those of others. In general,\\nmutual recognition agreements should be easier when countries are at similar levels of development. But as\\nthe challenges between the United States and the EU show, this is by no means assured. This is indicative of\\nthe difficult (if not impossible) bar that the EU sets for developing countries in outlining the potential use of\\nMRAs for AI.62\\nFor this reason, among others, MRAs are not a great tool for achieving broad regulatory compatibility. A\\nmore innovation-friendly and better regulatory approach would be for the EC to leverage a broader range of\\nglobal standards as a way of demonstrating compliance with regulatory requirements, accompanied by more\\nresources for regulators. This would provide more flexibility for producers in weighing up the best options for\\nviable, high-standard international test results. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 67, 'page': 17, '_split_overlap': [{'doc_id': 'fa591b288f84980b6cc23204cf1afd90', 'range': (0, 272)}, {'doc_id': '71b0b4a3c93548a012111e3122677ca0', 'range': (621, 995)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e6aed8f5fa33a3fc7dfb9f4b41f258d2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: A\\nmore innovation-friendly and better regulatory approach would be for the EC to leverage a broader range of\\nglobal standards as a way of demonstrating compliance with regulatory requirements, accompanied by more\\nresources for regulators. This would provide more flexibility for producers in weighing up the best options for\\nviable, high-standard international test results. If nothing else, the EC should ensure that any AI conformity\\nassessment framework consider how it will include expanded access to testing around the world to avoid\\nlimiting the use, development, deployment, and adoption of one of the key technologies of the 21st century.\\n5. RECOMMENDATIONS\\nThe EC should take the time to carefully reconsider the technical, governance, trade, and international\\ncooperation and coordination aspects of its proposal for a conformity testing framework for AI, particularly\\none rooted in a legislative framework designed largely to facilitate intra-EU movement of industrial goods.\\nMore importantly the EU should reconsider whether it even needs such an expansive approach to AI\\nregulation, in the absence of virtually any harms to date. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 68, 'page': 18, '_split_overlap': [{'doc_id': 'e6aed8f5fa33a3fc7dfb9f4b41f258d2', 'range': (0, 374)}, {'doc_id': 'c568454f1b5d59c282ebb1dd6a029aa4', 'range': (987, 1142)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '71b0b4a3c93548a012111e3122677ca0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: More importantly the EU should reconsider whether it even needs such an expansive approach to AI\\nregulation, in the absence of virtually any harms to date. Rather than jump ahead with a precautionary\\nprinciple-based regime that will reduce AI innovation in the EU and distort trade, the EU should carefully\\nmonitor private sector action and only act if it appears that AI-specific regulation is truly necessary, which at\\nthis point in time it does not appear to be the case.\\nThe recommendations below detail a few major parts for the EC’s consideration as it moves forward.\\n5.1 Learn from Experience & Pursue a Lengthy, Thorough, Multi-Stakeholder Policy\\nDevelopment Process\\nThe EC should consider the core points below, many of which come from the OECD’s work on how\\ngovernments can ensure successful international regulatory cooperation:63\\n• The EC should wait. AI as a tool is too nascent for governments to jump headfirst into technology-\\nspecific regulation, at least in the vast majority of applications.\\n• The EC should allow time for a series of open discussions about all available policy proposals. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 69, 'page': 18, '_split_overlap': [{'doc_id': '71b0b4a3c93548a012111e3122677ca0', 'range': (0, 155)}, {'doc_id': 'dd000a397f55e2c750503378a4069ed3', 'range': (864, 1108)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c568454f1b5d59c282ebb1dd6a029aa4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: AI as a tool is too nascent for governments to jump headfirst into technology-\\nspecific regulation, at least in the vast majority of applications.\\n• The EC should allow time for a series of open discussions about all available policy proposals. The\\nEC should not rush to enact a framework that will have long-lasting domestic and international\\nimplications on trade, innovation, its own competitiveness, and that of other economies.\\n• The EC should develop a common taxonomy on AI for use as part of discussions, given the proposal\\ncovers a broad range of economies, sectors, and technologies.\\x0c19\\n• The EC should do a comparative assessment of past and related regulatory frameworks and their\\ndevelopment. As this submission details, these will likely hold valuable lessons for the EC as it\\nconsiders a new region-wide framework.\\n• The EC should pursue a detailed cost-benefit analysis of policy proposals, including on the impact on\\ncompetitiveness, economic growth, and trade.\\n• Any AI regulatory framework should incorporate mechanisms that provide flexibility for future\\nadaptation given the impact that fast-changing technologies and business practices have on a given\\npublic policy objective. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 70, 'page': 18, '_split_overlap': [{'doc_id': 'c568454f1b5d59c282ebb1dd6a029aa4', 'range': (0, 244)}, {'doc_id': 'f878cbcc02734f6dc9436c5508c84c3b', 'range': (979, 1198)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'dd000a397f55e2c750503378a4069ed3'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: • Any AI regulatory framework should incorporate mechanisms that provide flexibility for future\\nadaptation given the impact that fast-changing technologies and business practices have on a given\\npublic policy objective. The EC should learn this lesson from GDPR’s stringent rules, which provide\\nlittle room or opportunity for future adaptation.\\n5.2 Build a Truly Cooperative and Internationally Accessible Approach\\nThe EC should ensure international regulatory cooperation (IRC) is a central part of any proposal to\\nregulate AI.\\nKey recommendations:\\n• The EC should heed its own advice to other countries and discontinue its localization requirement\\nfor testing bodies and its built-in, de facto reliance on regional standards (some of which are fine, in\\nthat they are based on a limited subset of international standards). Firms in the EU simply won’t be\\nable to keep pace technologically if they apply their existing legislative framework for industrial\\nproducts to emerging technology, and they risk hamstringing much of the rest of the world in the\\nprocess given the critical role that trade and market scale plays in supporting innovation.\\n• The EC should build in (or least include the potential for) mechanisms to facilitate international\\nregulatory cooperation and interoperability with major, like-minded trading partners. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 71, 'page': 19, '_split_overlap': [{'doc_id': 'dd000a397f55e2c750503378a4069ed3', 'range': (0, 219)}, {'doc_id': 'b04ac3782cad4efb2c86ed4d329a5631', 'range': (1145, 1331)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f878cbcc02734f6dc9436c5508c84c3b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: • The EC should build in (or least include the potential for) mechanisms to facilitate international\\nregulatory cooperation and interoperability with major, like-minded trading partners. The EC should\\ngive greater priority to international interoperability in creating numerous clear, fair, and predictable\\ntesting options for foreign firms and their products.\\n• The EC should consider how its proposed framework will allow (or not) firms in developing\\ncountries to have their products certified to conform with EU rules. The EC should also consider\\nhow it can help developing countries build and strengthen their own capacity for regulatory quality\\nand reform, including as it relates to any potential AI conformity framework.\\n• The EC should double down EU support for the work and processes of international standards\\ndevelopment bodies including and beyond the Geneva-based intergovernmental standards\\ndevelopment organizations, such as the International Standards Organization, the International\\nElectrotechnical Commission, and International Telecommunications Union.\\x0c20\\n• The EC should support global, voluntary, and industry-led standardization discussions given the\\ncritical role they play in addressing shared concerns, supporting innovation and trade, and bridging\\ndifferent regulatory regimes. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 72, 'page': 19, '_split_overlap': [{'doc_id': 'f878cbcc02734f6dc9436c5508c84c3b', 'range': (0, 186)}, {'doc_id': '24321f3fa581308378ad2b4d5be6f588', 'range': (1074, 1305)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b04ac3782cad4efb2c86ed4d329a5631'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: 20\\n• The EC should support global, voluntary, and industry-led standardization discussions given the\\ncritical role they play in addressing shared concerns, supporting innovation and trade, and bridging\\ndifferent regulatory regimes. For example, it should build on the work of limited, past initiatives, like\\nthe European Multi-Stakeholder Platform for ICT Standardization to ensure that its regulatory\\nauthorities and industry have recourse to the broadest, most modern array of technology standards.64\\nThe EC is not alone in debating how best to address the risks associated with the commercial use of AI.\\nBrazil, the United States, Canada, and many others are developing national AI plans and weighing up how to\\nmaximize the benefits while mitigating the risks. Europe has much in common with many of these countries\\nin terms of shared values and interests like trust, fairness, accountability, and effectiveness.65 Given the\\nnegative impact of regulatory divergence on traditional trade, and the growing importance of AI and data to\\nproductivity and innovation, it’s critical that the EU and its partners pro-actively work to avoid more such\\nfragmentation among AI regulatory proposals. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 73, 'page': 20, '_split_overlap': [{'doc_id': 'b04ac3782cad4efb2c86ed4d329a5631', 'range': (0, 231)}, {'doc_id': '37b81c005aefa1aa7a2fa225338bbd0f', 'range': (764, 1189)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '24321f3fa581308378ad2b4d5be6f588'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Europe has much in common with many of these countries\\nin terms of shared values and interests like trust, fairness, accountability, and effectiveness.65 Given the\\nnegative impact of regulatory divergence on traditional trade, and the growing importance of AI and data to\\nproductivity and innovation, it’s critical that the EU and its partners pro-actively work to avoid more such\\nfragmentation among AI regulatory proposals. They all need to consider adopting common light-touch\\napproaches that wait for potential problems to emerge, rather than buy into the fear that many in civil society\\nhave been promulgating that AI is something fundamentally new and dangerous absent a strong regulatory\\nhand of government. Absent that, they should build bridges between different frameworks. The EU could\\ntake the lead in doing so as part of a broad, global policy debate, such as the Global Partnership on AI within\\nthe Group of Seven.66\\nIRC refers to the design of appropriate mechanisms, such as those on transparency, mutual recognition, and\\ndevelopment and acceptance of global, industry-driven, voluntary consensus standards. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 74, 'page': 20, '_split_overlap': [{'doc_id': '24321f3fa581308378ad2b4d5be6f588', 'range': (0, 425)}, {'doc_id': '823c54ae547457ac4ca033a9d0e5d809', 'range': (784, 1123)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '37b81c005aefa1aa7a2fa225338bbd0f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: The EU could\\ntake the lead in doing so as part of a broad, global policy debate, such as the Global Partnership on AI within\\nthe Group of Seven.66\\nIRC refers to the design of appropriate mechanisms, such as those on transparency, mutual recognition, and\\ndevelopment and acceptance of global, industry-driven, voluntary consensus standards. At the heart of IRC is\\na shared interest in maximizing joint welfare, by ensuring a balance between the welfare costs related to\\nregulatory changes and the benefits resulting from reducing regulation-related economic and trade costs.\\nReducing regulatory heterogeneity leads to lower prices for consumers, while an increase in the number of\\nfirms in a market should lead to greater competition and lower mark-ups. IRC mechanisms can be economy-\\nwide or sector specific. Research from the Organization for Economic Co-operation and Development\\n(OECD) and others shows that IRC mechanisms have a positive impact on trade and are driven by political\\nconsiderations and path dependency. 67 The EC should consider these tools from the start so as to avoid\\nputting the region on a path that will undermine its domestic economy and makes it much harder to work\\nwith its trade partners in the future.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 75, 'page': 20, '_split_overlap': [{'doc_id': '37b81c005aefa1aa7a2fa225338bbd0f', 'range': (0, 339)}, {'doc_id': 'd7c16efb757ab913050b8ac5c8319654', 'range': (1022, 1231)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '823c54ae547457ac4ca033a9d0e5d809'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: 67 The EC should consider these tools from the start so as to avoid\\nputting the region on a path that will undermine its domestic economy and makes it much harder to work\\nwith its trade partners in the future.\\nThe EU has considerable experience in tackling the complexities of regulatory differences with the United\\nStates and other trading partners. The EU should actively avoid adding more fragmentation by imposing\\nspecific rules for AI. It should apply lessons learnt from comparable policies and initiatives up front. The EC\\nshould either discontinue its proposal for localized testing requirements or at least build in (or include the\\npotential for) bridging mechanisms, which may result from negotiations with its trade partners. A clear goal\\nfor the EC should be to allow and create numerous, clear, and predictable testing options for foreign firms\\nand their products. Developing these options should be to be factored in from the start, and not left as\\nan afterthought.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 76, 'page': 20, '_split_overlap': [{'doc_id': '823c54ae547457ac4ca033a9d0e5d809', 'range': (0, 209)}, {'doc_id': '5b5c841d03c9c0dc1b7e6eee4c6a75b3', 'range': (737, 979)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd7c16efb757ab913050b8ac5c8319654'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: A clear goal\\nfor the EC should be to allow and create numerous, clear, and predictable testing options for foreign firms\\nand their products. Developing these options should be to be factored in from the start, and not left as\\nan afterthought.\\x0c21\\nWhile differential and discriminatory regulations are challenging for U.S.-EU relations and between the EU\\nand the select other group of developed countries with which they’ve signed MRAs, they represent a much\\nbigger barrier to trade for firms in developing countries. The EC should consider up front how its framework\\nwill allow laboratories in developing countries to be certified to conform with EU rules so that foreign firms\\nhave a clearer path to conformity.\\nAs part of this, the EC should consider how to factor in government-approved international accreditation\\nschemes. A few of which exist, but these are generally underutilized. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 77, 'page': 20, '_split_overlap': [{'doc_id': 'd7c16efb757ab913050b8ac5c8319654', 'range': (0, 242)}, {'doc_id': '8662e6b100a0c69ca792ff72a4ac5d55', 'range': (712, 886)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5b5c841d03c9c0dc1b7e6eee4c6a75b3'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: As part of this, the EC should consider how to factor in government-approved international accreditation\\nschemes. A few of which exist, but these are generally underutilized. One example is the IEC System of\\nConformity Assessment Schemes for Electrotechnical Equipment and Components (CB Scheme), an\\ninternational system for mutual acceptance of test reports and certificates dealing with the safety of electrical\\nand electronic components, equipment and products.68 Another example is the International Laboratory\\nAccreditation Cooperation (ILAC), the international organization for accreditation bodies using various\\nISO/IEC standards to assess calibration, testing, and medical testing laboratories and inspection bodies.69\\nAccreditation bodies are peer evaluated and have to sign regional and international mutual recognition\\narrangements to demonstrate their competence.70 Similarly, the International Accreditation Forum (IAF) is\\nthe international organization for the accreditation of certification bodies.71 Both organizations have formal\\nand informal connections to a broad range of multilateral and regional organizations involved in standards\\nand conformity assessments, such as the International Organization for Standardization (ISO) and\\nInternational Telecommunications Union (ITU).72 At the moment, being a signatory to ILAC or IAF is part\\nof the criteria that non-EU-based accreditation bodies can present in order to be recognized under an EU\\nconformity assessment protocol.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 78, 'page': 21, '_split_overlap': [{'doc_id': '5b5c841d03c9c0dc1b7e6eee4c6a75b3', 'range': (0, 174)}, {'doc_id': '6d5e08be20a66a108386e24ced15c187', 'range': (175, 1491)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8662e6b100a0c69ca792ff72a4ac5d55'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: One example is the IEC System of\\nConformity Assessment Schemes for Electrotechnical Equipment and Components (CB Scheme), an\\ninternational system for mutual acceptance of test reports and certificates dealing with the safety of electrical\\nand electronic components, equipment and products.68 Another example is the International Laboratory\\nAccreditation Cooperation (ILAC), the international organization for accreditation bodies using various\\nISO/IEC standards to assess calibration, testing, and medical testing laboratories and inspection bodies.69\\nAccreditation bodies are peer evaluated and have to sign regional and international mutual recognition\\narrangements to demonstrate their competence.70 Similarly, the International Accreditation Forum (IAF) is\\nthe international organization for the accreditation of certification bodies.71 Both organizations have formal\\nand informal connections to a broad range of multilateral and regional organizations involved in standards\\nand conformity assessments, such as the International Organization for Standardization (ISO) and\\nInternational Telecommunications Union (ITU).72 At the moment, being a signatory to ILAC or IAF is part\\nof the criteria that non-EU-based accreditation bodies can present in order to be recognized under an EU\\nconformity assessment protocol.\\nCONCLUSION\\nGlobal trade involving a digital component—which covers a lot of modern trade—is increasingly fraught with\\ncompliance issues, whether it’s data privacy (GDPR) or cybersecurity (the EU Cybersecurity Act). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 79, 'page': 21, '_split_overlap': [{'doc_id': '8662e6b100a0c69ca792ff72a4ac5d55', 'range': (0, 1316)}, {'doc_id': '81ed50893fd79e903b0806b102a412c5', 'range': (1317, 1531)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6d5e08be20a66a108386e24ced15c187'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: CONCLUSION\\nGlobal trade involving a digital component—which covers a lot of modern trade—is increasingly fraught with\\ncompliance issues, whether it’s data privacy (GDPR) or cybersecurity (the EU Cybersecurity Act). This is\\nmost definitely the case for EU-U.S. trade. These rules are constantly evolving, which also presents a learning\\ncurve that may be too steep and costly for many firms.73 For firms in developing countries, it’s even more\\nsignificant. The whitepaper’s proposed framework will have a major impact on those developing and\\ndeploying AI. The EC and EU member states should take the time to learn from past experience and carefully\\nconsider whether they even need to regulate a technology that is so critical to its economic competitiveness\\nand the future of trade, and if they decide to regulate, do it as part of broader efforts with industry and\\nlikeminded partners.\\nNigel Cory is associate director for trade policy at the Information Technology and Innovation Foundation (ITIF).\\x0c22\\nREFERENCES\\n1. European Commission, White Paper: On Artificial Intelligence—A European approach to excellence and trust,\\n(Brussels: European Commission, February 19, 2020), https://ec.europa.eu/info/sites/info/files/commission-\\nwhite-paper-artificial-intelligence-feb2020_en.pdf.\\n2. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 80, 'page': 21, '_split_overlap': [{'doc_id': '6d5e08be20a66a108386e24ced15c187', 'range': (0, 214)}, {'doc_id': '8c14fc5d8f1db082f9b028c7400f01cf', 'range': (1016, 1283)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '81ed50893fd79e903b0806b102a412c5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: European Commission, White Paper: On Artificial Intelligence—A European approach to excellence and trust,\\n(Brussels: European Commission, February 19, 2020), https://ec.europa.eu/info/sites/info/files/commission-\\nwhite-paper-artificial-intelligence-feb2020_en.pdf.\\n2. Daniel Castro, Michael McLaughlin, and Eline Chivot, “Who Is Winning the AI Race: China, the EU or the\\nUnited States?” (Center for Data Innovation, August 19, 2019), https://www.datainnovation.org/2019/08/who-\\nis-winning-the-ai-race-china-the-eu-or-the-united-states/.\\n3. Ibid.\\n4. For a detailed review of China’s approach to global standards, see: Nigel Cory and Robert Atkinson, “Why and\\nHow to Mount a Strong, Trilateral Response to China’s Innovation Mercantilism (The Information Technology\\nand Innovation Foundation, January 13, 2020), https://itif.org/publications/2020/01/13/why-and-how-mount-\\nstrong-trilateral-response-chinas-innovation-mercantilism.\\n5. Jeremy Jun, “Big Data Algorithms Can Discriminate, and It’s Not Clear What to Do About It,” The\\nConversation, August 13, 2015, http://theconversation.com/big-data-algorithms-can-discriminate-and-its-not-\\nclear-what-to -do-about-it -45849; Ramona Pringle, “When Technology Discriminates: How Algorithmic Bias\\nCan Make an Impact,” CBC, August 10, 2017, http://www.cbc.ca/news/technology/algorithms-hiring-bias-\\nramona-pringle-1.4241031.\\n6. Joshua New and Daniel Castro, “How Policymakers Can Foster Algorithmic Accountability” (Center for Data\\nInnovation, May 21, 2018), http://www2.datainnovation.org/2018-algorithmic-accountability.pdf;\\nhttps://www.eib.org/en/essays/artificial-intelligence.\\n7. “Toy Safety in the EU,” European Commission website, accessed June 11, 2020,\\nhttps://ec.europa.eu/growth/sectors/toys/safety_en.\\n8. Alan Beattie, “The EU Cannot Build a Foreign Policy on Regulatory Power Alone,” Chatham House – Expert\\nComment, February 11, 2020, https://www.chathamhouse.org/expert/comment/eu-cannot-build-foreign-policy-\\nregulatory-power-alone.\\n9. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 81, 'page': 22, '_split_overlap': [{'doc_id': '81ed50893fd79e903b0806b102a412c5', 'range': (0, 267)}, {'doc_id': '7708a1aa6cf240ab5203c470d115162', 'range': (1759, 1992)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8c14fc5d8f1db082f9b028c7400f01cf'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Alan Beattie, “The EU Cannot Build a Foreign Policy on Regulatory Power Alone,” Chatham House – Expert\\nComment, February 11, 2020, https://www.chathamhouse.org/expert/comment/eu-cannot-build-foreign-policy-\\nregulatory-power-alone.\\n9. European Commission, White Paper: On Artificial Intelligence—A European approach to excellence and trust.\\n10. Whether these are European Standards Organizations (CEN, CENELEC and ETSI) or Europe-based\\ninternational organizations (ISO, IEC, ITU, etc.). Also reinforced by the European Court of Justice ruling in the\\nso-called Global Garden Case: ““Admittedly, the Commission’s interpretation does not create a legal vacuum,\\nsince the manufacturers and their representatives have means other than resorting to harmonised standards whose\\nreferences have been published in order to conform with the essential health and safety requirements set out in the\\nrelevant directive with respect to the machinery that they wish to market. However, it must be noted that those\\nother means are more onerous. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 82, 'page': 22, '_split_overlap': [{'doc_id': '8c14fc5d8f1db082f9b028c7400f01cf', 'range': (0, 233)}, {'doc_id': '1caf910f390605a5710f4541e6d633b0', 'range': (486, 1026)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7708a1aa6cf240ab5203c470d115162'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Also reinforced by the European Court of Justice ruling in the\\nso-called Global Garden Case: ““Admittedly, the Commission’s interpretation does not create a legal vacuum,\\nsince the manufacturers and their representatives have means other than resorting to harmonised standards whose\\nreferences have been published in order to conform with the essential health and safety requirements set out in the\\nrelevant directive with respect to the machinery that they wish to market. However, it must be noted that those\\nother means are more onerous. Consequently, the Commission’s position does not contribute, at least during a\\ncertain period, to facilitating the free movement of goods in the internal market whilst ensuring a high level of\\nprotection of health and safety of users, as is required by the legal basis of Directive 2006/42, namely Article 114\\nTFEU.” Judgement of the General Court: Global Garden Products Italy SpA (GGP Italy),” January 26, 2017,\\nhttp://curia.europa.eu/juris/document/document.jsf?text=&docid=187179&pageIndex=0&doclang=EN&mode=l\\nst&dir=&occ=first&part=1&cid=3572055; “New legislative framework,” European Commission website,\\naccessed June 11, 2020, https://ec.europa.eu/growth/single-market/goods/new-legislative-framework_en.\\x0c23\\n11. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 83, 'page': 22, '_split_overlap': [{'doc_id': '7708a1aa6cf240ab5203c470d115162', 'range': (0, 540)}, {'doc_id': '8c09fd4da888265d6606ce48141cd8c0', 'range': (541, 1259)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1caf910f390605a5710f4541e6d633b0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Consequently, the Commission’s position does not contribute, at least during a\\ncertain period, to facilitating the free movement of goods in the internal market whilst ensuring a high level of\\nprotection of health and safety of users, as is required by the legal basis of Directive 2006/42, namely Article 114\\nTFEU.” Judgement of the General Court: Global Garden Products Italy SpA (GGP Italy),” January 26, 2017,\\nhttp://curia.europa.eu/juris/document/document.jsf?text=&docid=187179&pageIndex=0&doclang=EN&mode=l\\nst&dir=&occ=first&part=1&cid=3572055; “New legislative framework,” European Commission website,\\naccessed June 11, 2020, https://ec.europa.eu/growth/single-market/goods/new-legislative-framework_en.\\x0c23\\n11. Samuel Stolton, “High-risk Artificial Intelligence to be ‘certified, tested and controlled,’ Commission says,”\\nEuractiv, February 19, 2020, https://www.euractiv.com/section/digital/news/high-risk-artificial-intelligence-to-be-\\ncertified-tested-and-controlled-commission-says/; It also doesn’t make sense to use EU/European data as a\\nbenchmark for fairness/representativity of an AI system’s dataset. For example, see: \"Consultation on the white\\npaper on AI — A European approach: Google’s submission\" (Google, May 28, 2020),\\nhttps://www.blog.google/documents/77/Googles_submission_to_EC_AI_consultation_1.pdf, p.34; and Daniel\\nCastro and Eline Chivot, \"How the EU Should Revise its AI White Paper Before it is Published\" (Center for\\nData Innovation, February 1, 2020), https://www.datainnovation.org/2020/02/how-the-eu-should-revise-its-ai-\\nwhite-paper-before-it-is-published/.\\n12. In terms of EU-level harmonized frameworks, this would presumably include the radio equipment directive,\\nmachinery directive, product liability directive, and others.\\n13. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 84, 'page': 22, '_split_overlap': [{'doc_id': '1caf910f390605a5710f4541e6d633b0', 'range': (0, 718)}, {'doc_id': '3e30c24fd75efdafb5be08e0f380e5d1', 'range': (1601, 1771)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8c09fd4da888265d6606ce48141cd8c0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: In terms of EU-level harmonized frameworks, this would presumably include the radio equipment directive,\\nmachinery directive, product liability directive, and others.\\n13. There are major concerns about broad definition of “high-risk” for AI and for sectors in the white paper. See:\\n\"Consultation on the white paper on AI — A European approach: Google’s submission,\" Google, May 28, 2020,\\nhttps://www.blog.google/documents/77/Googles_submission_to_EC_AI_consultation_1.pdf, p.34; Daniel\\nCastro and Eline Chivot, \"How the EU Should Revise its AI White Paper Before it is Published\" (Center for\\nData Innovation, February 1, 2020), https://www.datainnovation.org/2020/02/how-the-eu-should-revise-its-ai-\\nwhite-paper-before-it-is-published/.\\n14. Samuel Stolton, “High-risk Artificial Intelligence to be ‘certified, tested and controlled,’ Commission says,”\\nEuractiv, February 19, 2020, https://www.euractiv.com/section/digital/news/high-risk-artificial-intelligence-to-be-\\ncertified-tested-and-controlled-commission-says/;\\n15. Robert Atkinson and Stephen Ezell, “Promoting European Growth, Productivity, and Competitiveness By\\nTaking Advantage of the Next Digital Technology Wave” (The Information Technology and Innovation\\nFoundation, March, 2019), http://www2.itif.org/2019-europe-digital-age.pdf.\\n16. \"Consultation on the white paper on AI — A European approach: Google’s submission,\" Google; Castro and\\nChivot, \"How the EU Should Revise its AI White Paper Before it is Published.\\n17. Page 23, footnote 59. European Commission, White Paper: On Artificial Intelligence—A European approach to\\nexcellence and trust, (Brussels: European Commission, February 19, 2020),\\nhttps://ec.europa.eu/info/sites/info/files/commission-white-paper-artificial-intelligence-feb2020_en.pdf.\\n18. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 85, 'page': 23, '_split_overlap': [{'doc_id': '8c09fd4da888265d6606ce48141cd8c0', 'range': (0, 170)}, {'doc_id': '907d5c4d166e53a3e600af3305aaf355', 'range': (1505, 1772)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3e30c24fd75efdafb5be08e0f380e5d1'}>,\n",
              "  <Document: {'content': \"Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: European Commission, White Paper: On Artificial Intelligence—A European approach to\\nexcellence and trust, (Brussels: European Commission, February 19, 2020),\\nhttps://ec.europa.eu/info/sites/info/files/commission-white-paper-artificial-intelligence-feb2020_en.pdf.\\n18. As laid out in the New Legislative Framework and Reg. 1025/2012.\\n19. “Decision No 768/2008/EC of the European Parliament and of the Council of 9 July 2008 on a common\\nframework for the marketing of products, and repealing Council Decision 93/465/EEC,” EUR-Lex website,\\nhttps://eur-lex.europa.eu/legal-content/EN/ALL/?uri=CELEX%3A32008D0768.\\n20. Ibid.\\n21. “Notice to Stakeholders: Withdrawal of the United Kingdom and EU Rules in the Field of Industrial Products,”\\nEuropean Commission, January 22, 2018,\\nhttps://ec.europa.eu/info/sites/info/files/file_import/industrial_products_en_1.pdf.\\n22. Simon Shooter and Stephanie Lopes, “European Union's new Cybersecurity act: what do you need to know?”\\nBird&Bird blog post, April, 2019, https://www.twobirds.com/en/news/articles/2019/global/european-unions-\\nnew-cybersecurity-act.\\n23. “The EU Cybersecurity Act,” European Commission, https://ec.europa.eu/digital-single-market/en/eu-\\ncybersecurity-act.\\x0c24\\n24. “Cybersecurity of 5G networks,” European Commission, https://ec.europa.eu/digital-single-\\nmarket/en/news/cybersecurity-5g-networks.\\n25. It also hasn’t published a single scheme or formally established its expert stakeholder consultation group.\\n26. “New EU rules on medical devices to enhance patient safety and modernise public health,” European\\nCommission, April 4, 2017, https://ec.europa.eu/growth/content/new-eu-rules-medical-devices-enhance-patient-\\nsafety-and-modernise-public-health_en.\\n27. Tammy Lovell, “Medical device manufacturers face challenges preparing for ‘stringent’ new EU Regulation,”\\nMobi Health News, February 12, 2020, https://www.mobihealthnews.com/news/europe/medical-device-\\nmanufacturers-face-challenges-preparing-stringent-new-eu-regulation.\\n28. \", 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 86, 'page': 23, '_split_overlap': [{'doc_id': '3e30c24fd75efdafb5be08e0f380e5d1', 'range': (0, 267)}, {'doc_id': '62daafd1d7937cd48565587783d3821', 'range': (1718, 1992)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '907d5c4d166e53a3e600af3305aaf355'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Tammy Lovell, “Medical device manufacturers face challenges preparing for ‘stringent’ new EU Regulation,”\\nMobi Health News, February 12, 2020, https://www.mobihealthnews.com/news/europe/medical-device-\\nmanufacturers-face-challenges-preparing-stringent-new-eu-regulation.\\n28. Tammy Lovell, “Just 27% of medical device makers expect to be in full compliance with EU standard by May\\ndeadline, study finds,” Mobi Health News, September 30, 2019,\\nhttps://www.mobihealthnews.com/news/europe/just-27-medical-device-makers-expect-be-full-compliance-eu-\\nstandard-may-deadline-study.\\n29. Lovell, “Medical device manufacturers face challenges preparing for ‘stringent’ new EU Regulation.”\\n30. Lovell, “Just 27% of medical device makers expect to be in full compliance with EU standard by May deadline,\\nstudy finds.”\\n31. MedTech Europe, “Implementation Status of the Medical Devices Regulation (December 2019),” (industry\\nassociation paper, January, 2020), https://www.medtecheurope.org/wp-\\ncontent/uploads/2020/01/Implementation-Status-of-the-MDR.pdf.\\n32. Anne Matousek, “Harmonized standards under the MDR,” August 29, 2019, https://www.regulatory-\\naffairs.org/en/regulatory-affairs/news-page/harmonised-standards-under-the-mdr-ra0/.\\n33. Eamonn Hoxey, “Harmonization of standards under the regulations for medical devices moves forward slowly,”\\nCompliance Navigator blog post, August 16, 2019,\\nhttps://compliancenavigator.bsigroup.com/en/medicaldeviceblog/harmonization-of-standards-under-the-\\nregulations-for-medical-devices-moves-forward-slowly/.\\n34. www.medtecheurope.orgPage 1of 6Use of international generally acknowledged state-of-the-art standards in the\\nabsence of harmonised standardsunder the IVDR and MDR, Medtech Europe Position Paper, March 20, 2020,\\nhttps://www.medtecheurope.org/wp-content/uploads/2020/03/20200225_PositionPaper_MTE_State-of-the-art-\\nstandards-in-the-absence-of-harmonised-standards_PUB.pdf.\\n35. “Artificial Intelligence and Machine Learning in Software as a Medical Device,” U.S. Food and Drug\\nAdministration, January 28, 2020, https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-\\nintelligence-and-machine-learning-software-medical-device.\\n36. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 87, 'page': 24, '_split_overlap': [{'doc_id': '907d5c4d166e53a3e600af3305aaf355', 'range': (0, 274)}, {'doc_id': 'be7fa2f4a2f6e766d958280f36ff7346', 'range': (1918, 2190)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '62daafd1d7937cd48565587783d3821'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: “Artificial Intelligence and Machine Learning in Software as a Medical Device,” U.S. Food and Drug\\nAdministration, January 28, 2020, https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-\\nintelligence-and-machine-learning-software-medical-device.\\n36. Technical Barriers to Trade Agreement: ‘5.1.1 Conformity assessment procedures are prepared, adopted and\\napplied so as to grant access for suppliers of like products originating in the territories of other Members under\\nconditions no less favourable than those accorded to suppliers of like products of national origin or originating in\\nany other country, in a comparable situation; access entails suppliers’ right to an assessment of conformity under\\nthe rules of the procedure, including, when foreseen by this procedure, the possibility to have conformity\\nassessment activities undertaken at the site of facilities and to receive the mark of the system;\\n37. Devin McDaniels and Marianna Karttunen, Trade, Testing, and Toasters: Conformity Assessment Procedures and the\\nTBT Committee, (Geneva: World Trade Organization Working Paper ERSD-2016-09),\\nhttps://www.wto.org/english/res_e/reser_e/ersd201609_e.pdf.\\x0c25\\n38. Bernard Hoekman and Petros C. Mavroidis, “Regulatory Spillovers and the Trading System: From Coherence to\\nCooperation” (Geneva: The E15 Initiative, Task Force on Regulatory Systems Coherence, April 2015),\\nhttp://e15initiative.org/wp-content/uploads/2015/04/E15-Regulatory-OP-Hoekman-and-Mavroidis-FINAL.pdf.\\n39. Hosuk Lee-Makiyama, “Future Proofing World Trade in Technology” (Brussels: European Center for\\nInternational Political Economy, April, 2011), https://ecipe.org/wp-content/uploads/2014/12/WP201104.pdf.\\n40. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 88, 'page': 24, '_split_overlap': [{'doc_id': '62daafd1d7937cd48565587783d3821', 'range': (0, 272)}, {'doc_id': 'e25a2e9e5f37020879a46811aaa4b5ed', 'range': (1498, 1706)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'be7fa2f4a2f6e766d958280f36ff7346'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: 39. Hosuk Lee-Makiyama, “Future Proofing World Trade in Technology” (Brussels: European Center for\\nInternational Political Economy, April, 2011), https://ecipe.org/wp-content/uploads/2014/12/WP201104.pdf.\\n40. “Regulation (EU) No 1025/2012 of the European Parliament and of the Council of 25 October 2012 on\\nEuropean standardization,” European Commission, October 7, 2015, https://eur-lex.europa.eu/legal-\\ncontent/EN/TXT/?uri=celex%3A32012R1025.\\n41. The TBT Agreement defines a CAP as ‘any procedure used, directly or indirectly, to determine that relevant\\nrequirements in technical regulations or standards are fulfilled.’ McDaniels and Karttunen, Trade, Testing, and\\nToasters: Conformity Assessment Procedures and the TBT Committee.\\n42. Ibid.\\n43. Ben Shepard, “Product Standards, Harmonization, and Trade: Evidence from the Extensive Margin” (World\\nBank Policy Research Working Paper No. 4390, April 20, 2016),\\nhttps://papers.ssrn.com/sol3/papers.cfm?abstract_id=1029850.\\n44. Jose-Daniel Reyes, “International Harmonization of Product Standards and Firm Heterogeneity in International\\nTrade” (World Bank Policy Research working paper no. WPS 5677, 2011),\\nhttps://openknowledge.worldbank.org/handle/10986/3442; Jose-Daniel Reyes, “The Pro-Competitive Effect of\\nInternational Harmonization of Product Standards,” (In Non-tariff Measures: A Fresh Look at Trade Policy’s New\\nFrontier, O. Cadot, and M. Malouche (eds.), London/Washington, DC: CEPR/ World Bank, 2012),\\nhttp://documents.worldbank.org/curated/en/771511557742730116/Non-Tariff-Measures-A-Fresh-Look-at-\\nTrade-Policy-s-New-Frontier.\\n45. Liliana Foletti and Anirudh Shingal, \"Trade effects of MRL harmonization in the EU\" (World Trade Institute\\nPaper, 720, 2014), https://ideas.repec.org/p/wti/papers/720.html.\\n46. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 89, 'page': 25, '_split_overlap': [{'doc_id': 'be7fa2f4a2f6e766d958280f36ff7346', 'range': (0, 208)}, {'doc_id': '9acc5cf07a32ab3d30a49fc8659174f', 'range': (1595, 1771)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e25a2e9e5f37020879a46811aaa4b5ed'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Liliana Foletti and Anirudh Shingal, \"Trade effects of MRL harmonization in the EU\" (World Trade Institute\\nPaper, 720, 2014), https://ideas.repec.org/p/wti/papers/720.html.\\n46. Olivier Cadot and Julien Gourdon, “NTMs, Preferential Trade Agreements, and Prices: New evidence” (Centre\\nd’Etudes Prospectives et d’Informations Internationales (CEPII) working paper, 2015),\\nhttp://www.cepii.fr/PDF_PUB/wp/2015/wp2015-01.pdf.\\n47. Lionel Fontagné, Gianluca Orefice, Roberta Piermartini, and NadiaRochac, “Product standards and margins of\\ntrade: Firm-level evidence,” Journal of International Economics, Volume 97, Issue 1, September 2015,\\nhttps://www.sciencedirect.com/science/article/abs/pii/S0022199615000823.\\n48. “EU releases proposal on new WTO rules for electronic commerce,” European Commission, May 3, 2019,\\nhttp://trade.ec.europa.eu/doclib/press/index.cfm?id=2016.\\n49. For example, China’s Securities Regulatory Commission regulations on information security\\nmanagement requests access to source code for review and testing (Article 14). Also see: U.S.-\\nChina Economic and Security Review Commission, 2015 Report to Congress (Washington, DC:\\nU.S.-China Economic and Security Review Commission, November 2015),\\nhttps://news.usni.org/wp-content/uploads/2015/11/2015-Annual-Report-to-Congress.pdf.\\n50. Page 25: European Commission, White Paper: On Artificial Intelligence—A European approach to excellence\\nand trust.\\n51. “Mutual Recognition Agreements,” European Commission, https://ec.europa.eu/growth/single-\\nmarket/goods/international-aspects/mutual-recognition-agreements/.\\x0c26\\n52. “The US-EU Mutual Recognition Agreements,” (Peterson Institute for International Economics),\\nhttps://www.piie.com/publications/chapters_preview/392/07iie3624.pdf\\n53. “Mutual recognition agreements,” European Medicines Agency,\\nhttps://www.nist.gov/system/files/documents/2019/09/23/nist_red_nb_requirements_and_app_v3_final_-\\n_access.pdf.\\n54. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 90, 'page': 25, '_split_overlap': [{'doc_id': 'e25a2e9e5f37020879a46811aaa4b5ed', 'range': (0, 176)}, {'doc_id': '5837d63692769d5013cf124c86078280', 'range': (1583, 1924)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9acc5cf07a32ab3d30a49fc8659174f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: “The US-EU Mutual Recognition Agreements,” (Peterson Institute for International Economics),\\nhttps://www.piie.com/publications/chapters_preview/392/07iie3624.pdf\\n53. “Mutual recognition agreements,” European Medicines Agency,\\nhttps://www.nist.gov/system/files/documents/2019/09/23/nist_red_nb_requirements_and_app_v3_final_-\\n_access.pdf.\\n54. “U.S.-EU MRA and the U.S.–EEA EFTA States Mutual Recognition Agreements,” U.S. National Institute for of\\nStandards and Technology, https://www.nist.gov/standardsgov/us-eu-mra-and-us-eea-efta-states-mutual-\\nrecognition-agreements.\\n55. “Mutual recognition agreements,” European Medicines Agency.\\n56. Ellen Frost, “The Transatlantic Economic Partnership” (The Peterson Institute for International Economics,\\nSeptember 1998), https://www.piie.com/publications/policy-briefs/transatlantic-economic-partnership#note3.\\n57. “The US-EU Mutual Recognition Agreements,” (Peterson Institute for International Economics),\\nhttps://www.piie.com/publications/chapters_preview/392/07iie3624.pdf.\\n58. Annex to the Commission Decision on determining the Union position for a Decision of the Joint Committee set\\nup under Article 14 of the Agreement on Mutual Recognition between the European Community and the United\\nStates of America, in order to amend the Sectoral Annex on Pharmaceutical Good Manufacturing Practices,”\\nEuropean Commission, March 1, 2017,\\nhttps://ec.europa.eu/health/sites/health/files/eu_world/docs/c2017_1323_en.pdf.\\n59. “Commission publishes proposal for agreement on conformity assessment with United States,” European\\nCommission, November 22, 2019, https://trade.ec.europa.eu/doclib/press/index.cfm?id=2085.\\n60. “Agreement between the European Union and the United States of America on the mutual acceptance of results\\nof conformity assessment,” European Commission, October 25, 2019,\\nhttps://trade.ec.europa.eu/doclib/docs/2019/november/tradoc_158448.pdf.\\n61. Ibid.\\n62. “The US-EU Mutual Recognition Agreements,” (Peterson Institute for International Economics).\\n63. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 91, 'page': 26, '_split_overlap': [{'doc_id': '9acc5cf07a32ab3d30a49fc8659174f', 'range': (0, 341)}, {'doc_id': '4c4716d6ec7b2dc8315e44e1b352f7bb', 'range': (1658, 2013)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5837d63692769d5013cf124c86078280'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: “Agreement between the European Union and the United States of America on the mutual acceptance of results\\nof conformity assessment,” European Commission, October 25, 2019,\\nhttps://trade.ec.europa.eu/doclib/docs/2019/november/tradoc_158448.pdf.\\n61. Ibid.\\n62. “The US-EU Mutual Recognition Agreements,” (Peterson Institute for International Economics).\\n63. The Organization for Economic Cooperation and Development (OECD), International Regulatory Co-operation\\n(Paris: OECD, Policy Brief, October 2018), https://www.oecd.org/gov/regulatory-policy/international-\\nregulatory-cooperation-policy-brief-2018.pdf.\\n64. “European Multi Stakeholder Platform on ICT Standardisation,” European Commission,\\nhttps://ec.europa.eu/digital-single-market/en/european-multi-stakeholder-platform-ict-standardisation.\\n65. Joshua New and Daniel Castro, “How Policymakers Can Foster Algorithmic Accountability” (The Information\\nTechnology and Innovation Foundation, May 21, 2018), https://itif.org/publications/2018/05/21/how-\\npolicymakers-can-foster-algorithmic-accountability; “ITIF Technology Explainer: What Is Artificial Intelligence?”\\n(The Information Technology and Innovation Foundation, September 4, 2018),\\nhttps://itif.org/publications/2018/09/04/itif-technology-explainer-what-artificial-intelligence.\\n66. “US Joins G7 Artificial Intelligence Group to Counter China,” Associated Press, May 28, 2020,\\nhttps://www.nytimes.com/aponline/2020/05/28/business/bc-us-white-house-g7-artificial-intelligence.html.\\n67. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 92, 'page': 26, '_split_overlap': [{'doc_id': '5837d63692769d5013cf124c86078280', 'range': (0, 355)}, {'doc_id': '8544f9ae1295679e471223d312803452', 'range': (801, 1495)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4c4716d6ec7b2dc8315e44e1b352f7bb'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: Joshua New and Daniel Castro, “How Policymakers Can Foster Algorithmic Accountability” (The Information\\nTechnology and Innovation Foundation, May 21, 2018), https://itif.org/publications/2018/05/21/how-\\npolicymakers-can-foster-algorithmic-accountability; “ITIF Technology Explainer: What Is Artificial Intelligence?”\\n(The Information Technology and Innovation Foundation, September 4, 2018),\\nhttps://itif.org/publications/2018/09/04/itif-technology-explainer-what-artificial-intelligence.\\n66. “US Joins G7 Artificial Intelligence Group to Counter China,” Associated Press, May 28, 2020,\\nhttps://www.nytimes.com/aponline/2020/05/28/business/bc-us-white-house-g7-artificial-intelligence.html.\\n67. Céline Kauffmann and Nikolai Malyshev, “International Regulatory Co-operation: The Menu of Approaches”\\n(The E15 Initiative, Task Force on Regulatory Systems Coherence, October 2015), http://e15initiative.org/wp-\\ncontent/uploads/2015/09/E15-Regulatory-Kauffmann-and-Malyshev-final.pdf; “International Regulatory Co-\\noperation - Adapting rules to an interconnected world,” the Organization for Economic Cooperation and\\nDevelopment, https://www.oecd.org/gov/regulatory-policy/irc.htm; Maggie Xiaoyang Chen and Aaditya Mattoo,\\x0c27\\n“Regionalism in standards: good or bad for trade?” Canadian Journal of Economics, Volume 41, Issue 3, July 9,\\n2008, https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-5982.2008.00488.x; Frank van Tongeren,\\nVéronique Bastien, and Martin von Lampe, “International Regulatory Cooperation, a Trade-Facilitating\\nMechanism” (The E15 Initiative, Task Force on Regulatory Systems Coherence, October 2015),\\nhttp://e15initiative.org/publications/international-regulatory-cooperation-a-trade-facilitating-mechanism/; Liliana\\nFoletti and Anirudh Shingal, \"Trade effects of MRL harmonization in the EU\" (World Trade Institute Paper,\\n720, 2014), https://ideas.repec.org/p/wti/papers/720.html.\\n68. “What is the IECEE CB Scheme?,” https://www.iecee.org/about/cb-scheme/.\\n69. “About ILAC,” https://ilac.org/about-ilac/\\n70. “ILAC MRA and Signatories,” https://ilac.org/ilac-mra-and-signatories/.\\n71. “Insertional Accreditation Forum,” https://www.iaf.nu/\\n72. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 93, 'page': 26, '_split_overlap': [{'doc_id': '4c4716d6ec7b2dc8315e44e1b352f7bb', 'range': (0, 694)}, {'doc_id': '17ce2c758619f93339ea4f3092b6a057', 'range': (1908, 2165)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8544f9ae1295679e471223d312803452'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: The Information Technology and Innovation Foundation (ITIF)., stakeholder_type: Academic/Research Institution, stakeholder_scope: nan, stakeholder_size: Small (< 50 employees), stakeholder_country: United States, document_date: 12-06-2020 19:08, language: English, \\n\\nPassage: “What is the IECEE CB Scheme?,” https://www.iecee.org/about/cb-scheme/.\\n69. “About ILAC,” https://ilac.org/about-ilac/\\n70. “ILAC MRA and Signatories,” https://ilac.org/ilac-mra-and-signatories/.\\n71. “Insertional Accreditation Forum,” https://www.iaf.nu/\\n72. “ILAC: International Partners,” https://ilac.org/about-ilac/partnerships/international-partners/\\n73. Jody Westby, “EU Cybersecurity Certification Schemes Will Surprise U.S. Businesses,” Forbes, October 21, 2019,\\nhttps://www.forbes.com/sites/jodywestby/2019/10/21/eu-cybersecurity-certification-schemes-will-surprise-us-\\nbusinesses/#38c9dffe3802.', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', 'stakeholder_name': 'The Information Technology and Innovation Foundation (ITIF).', 'stakeholder_type': 'Academic/Research Institution', 'stakeholder_size': 'Small (< 50 employees)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '12-06-2020 19:08', 'language': 'English', 'document_reference': 'F530168', 'document_name': 'F530168-20200612_ITIF_-_Nigel_Cory_-_EC_Submission_-_AI_and_Conformity_Assessments.pdf', '_split_id': 94, 'page': 27, '_split_overlap': [{'doc_id': '8544f9ae1295679e471223d312803452', 'range': (0, 257)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '17ce2c758619f93339ea4f3092b6a057'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Az.: 7-0271.0/2 IM, Abtl. 7, Ref. 72\\nName: Nadine Emendörfer\\nDatum: 19.05.2020\\nKonsultation der EU Kommission zu KI Weißbuch\\n- Anlagen\\nInhaltsverzeichnis\\n1. Anlage 1 - Freitextfelder des Fragebogens ...................................... Seite 02\\n2. Anlage 2 - Ergänzende Stellungnahme des Ministeriums für\\nWirtschaft, Arbeit und Wohnungsbau Baden-Württemberg………...Seite 10\\n3. Anlage 3 - Ergänzende Stellungnahme des Ministeriums der Justiz\\nund für Europa Baden-Württemberg…..……………………...……... Seite 12\\n4. Anlage 4 - KI Strategie des Landes Baden-Württemberg ................ Seite 14\\n1\\nRef. Ares(2020)3358503 - 26/06/2020\\x0cAnlage 1 – Freitextfelder des Fragebogens\\nAbschnitt 1 - Ökosystem für Exzellenz\\nWie wichtig sind Ihrer Meinung nach die sechs Maßnahmen, die in Abschnitt 4 des\\nWeißbuchs zur KI vorgeschlagen werden? (Übergeordnete Frage)\\nGibt es andere Maßnahmen, die in Betracht gezogen werden sollten? (Freitext)\\n\\uf0b7 Massiver Ausbau und europaweite Vernetzung von anwendungsorientierten\\nKI-Forschungs- und Transferinfrastrukturen, die eine Brückenfunktion\\nzwischen exzellenter Grundlagenforschung und den mittelständischen\\nUnternehmen einnehmen und den Transfer von Wissen in Wertschöpfung\\nerheblich beschleunigen. Steigerung der KI-Wertschöpfung insb. in den\\nFeldern, in denen hohes Wachstumspotential steckt.\\n\\uf0b7 Die verstärkte Implementierung von KI-Methoden im öffentlichen Sektor\\ndürfte eines der wesentlichen Zukunftsziele in der Landesverwaltung sein.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 0, 'page': 1, '_split_overlap': [{'doc_id': '72eadbf438e2e2c878a2cfc777286532', 'range': (1258, 1461)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c397037c9d18f8baf276a752f69219d1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: in den\\nFeldern, in denen hohes Wachstumspotential steckt.\\n\\uf0b7 Die verstärkte Implementierung von KI-Methoden im öffentlichen Sektor\\ndürfte eines der wesentlichen Zukunftsziele in der Landesverwaltung sein.\\nBeispielsweise wurden bei der Polizei Baden-Württemberg im Jahr 2019 für\\ndie Digitalisierung der Kriminaltechnik des Landeskriminalamtes\\nFinanzmittel in Höhe von 6,5 Mio. Euro zur Verfügung gestellt, um dort\\nerste Grundlagen für eine künftige Nutzung von KI zu schaffen und\\nbestimmte KI-Anwendungen gezielt zu erproben. Hierdurch soll u. a. in den\\nBereichen der forensischen Kriminaltechnik die Verfahrensökonomie der\\nStrafverfolgungsbehörden verbessert werden (bspw. Erkennung und\\nBewertung von Fälschungsmerkmalen bei Dokumenten, Filterung und\\nAufbereitung von Massendaten oder verfahrensbegleitende Auswertung in\\nFällen der schweren Kriminalität).\\nWie wichtig ist es Ihrer Meinung nach in jedem dieser Bereiche, die politischen\\nStrategien anzugleichen und die Koordination zu verstärken, wie in Abschnitt 4.A des\\nWeißbuchs beschrieben? (Übergeordnete Frage)\\nGibt es andere Bereiche, die in Betracht gezogen werden sollten? (Freitext)\\n\\uf0b7 Stärkung der Exzellenz im Transfer von KI-Forschungsergebnissen in den\\nWirtschaftssektor für mehr Wertschöpfung. Dies gilt auch für die frühe\\nVerzahnung von Forschung, Entwicklung und Innovation mit KI-relevanten\\nSchlüsseltechnologien wie dem im Weißbuch ebenfalls erwähnten\\nQuantencomputing.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 1, 'page': 2, '_split_overlap': [{'doc_id': 'c397037c9d18f8baf276a752f69219d1', 'range': (0, 203)}, {'doc_id': 'f0ad45cd5e17e55d47affbaa4c7678f5', 'range': (1256, 1435)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '72eadbf438e2e2c878a2cfc777286532'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Dies gilt auch für die frühe\\nVerzahnung von Forschung, Entwicklung und Innovation mit KI-relevanten\\nSchlüsseltechnologien wie dem im Weißbuch ebenfalls erwähnten\\nQuantencomputing.\\n\\uf0b7 Verstärkte anwendungsorientierte Forschung zu Chancen und Risiken der KI\\nim Zusammenhang mit Cybersicherheit (Cybersicherheit, IT-Sicherheit,\\nInformationssicherheit, Datenschutz)\\n2\\x0cWie wichtig sind Ihrer Meinung nach die drei Maßnahmen, die in den Abschnitten\\n4.B, 4.C und 4.E des Weißbuchs zur KI vorgeschlagen werden? (Übergeordnete\\nFrage)\\nGibt es weitere Maßnahmen zur Stärkung der Forschungs- und\\nInnovationsgemeinschaft, denen Priorität eingeräumt werden sollte? (Freitext)\\n\\uf0b7 Das Weißbuch setzt einen starken Akzent auf die Anwendung von KI. Dies ist\\nwichtig, wird aber ohne exzellente Grundlagen- und Methodenforschung nicht\\nausreichen, um eine wettbewerbsfähige „KI made in Europe“ in Wirtschaft und\\nWissenschaft zu generieren. Unsere IT Infrastrukturen (z. B. Internet) sind\\nbereits von amerikanischen Unternehmen dominiert – um insoweit nicht in\\ndauerhafte Abhängigkeiten zu geraten, ist es unerlässlich, europäische KI-und\\nIT Methodenkompetenz auf höchstem Standard zu gewährleisten. Europa\\nmuss deshalb den besten Köpfen konkurrenzfähige Arbeitsbedingungen\\nbieten.\\n\\uf0b7 Massiver Ausbau und europaweite Vernetzung von anwendungsorientierten\\nKI-Forschungs- und Transferinfrastrukturen, die eine Brückenfunktion\\nzwischen exzellenter Grundlagenforschung und den mittelständischen\\nUnternehmen einnehmen.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 2, 'page': 2, '_split_overlap': [{'doc_id': '72eadbf438e2e2c878a2cfc777286532', 'range': (0, 179)}, {'doc_id': '7a6f5822a4e0022df155ffe0cfd39435', 'range': (1258, 1488)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f0ad45cd5e17e55d47affbaa4c7678f5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: \\uf0b7 Massiver Ausbau und europaweite Vernetzung von anwendungsorientierten\\nKI-Forschungs- und Transferinfrastrukturen, die eine Brückenfunktion\\nzwischen exzellenter Grundlagenforschung und den mittelständischen\\nUnternehmen einnehmen.\\n\\uf0b7 Förderung europäischer Testzentren von Weltrang\\n\\uf0b7 Cyber Valley Tübingen: Herausragende KI-Forschungsstandorte wie das\\nCyber Valley Tübingen als Baustein eines europäischen Leitzentrums der KI-\\nExzellenz nutzen\\n\\uf0b7 IT-Region Karlsruhe: Vertrauenswürdige, sichere KI setzt kontinuierliche,\\nexzellente Forschung zu technologischen Lösungen voraus, die mit neuen\\nMethoden Schritt halten. Diese Forschung sollte an bereits sichtbaren\\nStandorten wie z.B. der IT-Region Karlsruhe mit dem Kompetenzzetrum\\nKASTEL am KIT ausgebaut und langfristig gefördert werden.\\nAbschnitt 2 - Ökosystem des Vertrauens\\nWie erheblich sind Ihrer Meinung nach die folgenden Bedenken in Bezug auf KI (1 -\\n5: 1 - überhaupt nicht erheblich, 5 - sehr erheblich)? (Übergeordnete Frage)\\nHaben Sie weitere Bedenken in Bezug auf KI, die hier nicht erwähnt wurden?\\n(Freitext)\\n\\uf0b7 Der Einsatz von KI wird perspektivisch alle Bereiche des wirtschaftlichen,\\ngesellschaftlichen und privaten Lebens betreffen. Damit einhergehenden\\nRisiken stehen Sicherheitsgewinne insbesondere im Bereich der\\nCybersicherheit (Detektion und Abwehr von Cybergefahren) sowie\\nsicherheitserhöhende Potentiale bei der Nutzung von KI-Anwendungen durch\\ndie Sicherheitsbehörden gegenüber. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 3, 'page': 3, '_split_overlap': [{'doc_id': 'f0ad45cd5e17e55d47affbaa4c7678f5', 'range': (0, 230)}, {'doc_id': '8174b41f84cea7becfcd8f3b5dd42295', 'range': (1197, 1450)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7a6f5822a4e0022df155ffe0cfd39435'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Damit einhergehenden\\nRisiken stehen Sicherheitsgewinne insbesondere im Bereich der\\nCybersicherheit (Detektion und Abwehr von Cybergefahren) sowie\\nsicherheitserhöhende Potentiale bei der Nutzung von KI-Anwendungen durch\\ndie Sicherheitsbehörden gegenüber. Durch gesetzgeberische Maßnahmen\\nsowie die verwaltungsseitige Umsetzung sind die Rahmenbedingungen für\\nden Einsatz von KI so zu gestalten, dass die Risiken beherrschbar bleiben\\nkönnen.\\n3\\x0c\\uf0b7 Die Entwicklung von KI oder AI könnte intransparent sein. Hier sollte eine\\nweitestgehende Transparenz in den Entwicklungen angestrebt werden.\\nSind Sie der Ansicht, dass die oben genannten Bedenken durch bereits geltendes\\nEU-Recht ausgeräumt werden können? (Übergeordnete Frage)\\nWenn nicht, sollten Ihrer Meinung nach spezifische neue Vorschriften für KI-Systeme\\neingeführt werden? (Freitext)\\n\\uf0b7 Ein einheitlicher europäischer Regulierungsrahmen für KI, der auf einem\\nrisikobasierten Ansatz beruht, wird begrüßt. Der KI-spezifische Rechtsrahmen\\nmuss so ausgestaltet werden, dass die Innovations- und Wettbewerbsfähigkeit\\nder europäischen Wirtschaft in der Schlüsseltechnologie KI unterstützt wird.\\nDas ist die Voraussetzung für die technologische Souveränität und die\\nFähigkeit Europas, auf europäischen Werten beruhende Regeln im Umgang\\nmit dieser Technologie zu etablieren und durchzusetzen.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 4, 'page': 3, '_split_overlap': [{'doc_id': '7a6f5822a4e0022df155ffe0cfd39435', 'range': (0, 253)}, {'doc_id': '57749544e03534a135d2b73be73f0ed2', 'range': (1139, 1334)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8174b41f84cea7becfcd8f3b5dd42295'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Das ist die Voraussetzung für die technologische Souveränität und die\\nFähigkeit Europas, auf europäischen Werten beruhende Regeln im Umgang\\nmit dieser Technologie zu etablieren und durchzusetzen.\\nWenn Sie der Ansicht sind, dass neue Vorschriften für KI-Systeme erforderlich sind,\\nsind Sie der Auffassung, dass die Einführung neuer verbindlicher Auflagen sich nur\\nauf Anwendungen mit hohem Risiko beziehen sollte (wo das KI-System potenziell\\neinen besonders großen Schaden verursachen kann)? (Freitext bei Angabe\\n„Sonstiges“)\\n\\uf0b7 KI-Anwendungen der öffentlichen Hand, insbesondere im Bereich der\\nGefahrenabwehr und der Strafverfolgung, dürften sehr wahrscheinlich\\nden angedachten Hochrisikoregelungen unterfallen\\n\\uf0b7 Mit Blick auf die Belange einer effektiven Gefahrenabwehr und\\nStrafverfolgung wird es erforderlich sein, Ausnahmetatbestände für\\nSicherheitsbehörden zu den angedachten Hochrisikoregelungen zu\\nschaffen. Insbesondere aus den Transparenz- und\\nKennzeichnungsvorgaben könnten sich durch das Bekanntwerden\\nsicherheitskritischer Informationen nachteilige Auswirkungen auf die\\nArbeit der Sicherheitsbehörden und den dortigen Einsatz von KI-\\ngestützten Systemen ergeben.\\n\\uf0b7 Die strikte Unterscheidung in Anwendungen mit oder ohne hohem Risiko\\nkann in diesem Bezug problematisch sein. Auch eine Anwendung mit\\nniedrigem Risiko kann bei entsprechender Verbreitung einen großen\\nSchaden bewirken. KI stellt eine zukunftsweisende Schlüsseltechnologie\\ndar, dementsprechend sollte der rechtliche Rahmen unabhängig vom\\nRisikofaktor des Anwendungsszenarios klar abgesteckt werden. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 5, 'page': 4, '_split_overlap': [{'doc_id': '8174b41f84cea7becfcd8f3b5dd42295', 'range': (0, 195)}, {'doc_id': 'f40cb5b222489f7890ff7aee61a69d96', 'range': (1286, 1572)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '57749544e03534a135d2b73be73f0ed2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Auch eine Anwendung mit\\nniedrigem Risiko kann bei entsprechender Verbreitung einen großen\\nSchaden bewirken. KI stellt eine zukunftsweisende Schlüsseltechnologie\\ndar, dementsprechend sollte der rechtliche Rahmen unabhängig vom\\nRisikofaktor des Anwendungsszenarios klar abgesteckt werden. (Hier\\nwurde eigentlich Nein angekreuzt und aber trotzdem das Freitextfeld\\nbefüllt)\\n4\\x0cStimmen Sie dem in Abschnitt 5.B des Weißbuchs vorgeschlagenen Ansatz zur\\nErmittlung von KI-Anwendungen mit hohem Risiko zu? (Freitext bei Angabe\\n„Sonstiges“)\\n\\uf0b7 Eine übermäßige Regulierung von KI-Systemen kann dazu führen,\\nInnovationen zu verlangsamen oder ganz zu verhindern. Der\\nregulatorische Rahmen muss daher für Transparenz und Klarheit sorgen,\\nwelcher Regulierung eine bestimmte Anwendung unterworfen ist und\\nwelche Anforderungen bei Entwicklung und Nutzung damit einhergehen.\\nEs muss sichergestellt werden, dass KMU und Startups durch angepasste\\nund neue regulatorische Anforderungen nicht übermäßig belastet werden.\\nWenn gewünscht, können Sie hier die KI-Anwendung oder den Einsatz von KI\\nangeben, die bzw. der aus Ihrer Sicht am problematischsten („hochriskant“) ist:\\n\\uf0b7 KI im Gesundheitswesen, wenn die Daten Krankenkassen zur\\nVerfügung gestellt werden.\\n\\uf0b7 KI-Einsatz durch Nachrichtendiensten fremder Staaten oder krimineller\\nOrganisationen\\nSind Sie der Ansicht, dass für den Einsatz biometrischer\\nFernidentifikationssysteme (z. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 6, 'page': 4, '_split_overlap': [{'doc_id': '57749544e03534a135d2b73be73f0ed2', 'range': (0, 286)}, {'doc_id': '16c9643c6d5334b1a07d93bcced7f23d', 'range': (1236, 1410)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f40cb5b222489f7890ff7aee61a69d96'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: \\uf0b7 KI-Einsatz durch Nachrichtendiensten fremder Staaten oder krimineller\\nOrganisationen\\nSind Sie der Ansicht, dass für den Einsatz biometrischer\\nFernidentifikationssysteme (z. B. Gesichtserkennung) und anderer\\nTechnologien, die in öffentlichen Räumen eingesetzt werden können,\\nzusätzlich zu den bestehenden EU-Rechtsvorschriften, insbesondere der\\nDatenschutz-Grundverordnung und der Richtlinie über den Datenschutz bei der\\nStrafverfolgung bzw. gegebenenfalls den oben genannten neuen,\\nmöglicherweise verbindlichen Auflagen (siehe obige Frage), weitere Leitlinien\\noder Vorschriften auf EU-Ebene gelten sollten? (Übergeordnete Frage)\\nBitte präzisieren Sie Ihre Antwort: (Freitextfeld)\\n\\uf0b7 Es muss sichergestellt werden, dass der Einsatz biometrischer\\nFernidentifikationssysteme nur gestattet werden darf, wenn der betreffende\\nGebrauch hinreichend begründet, verhältnismäßig sowie geeignete Garantien\\ngewährleistet sind. Es muss schnellstmöglich eine spezifische Leitlinie oder\\nRechtsvorschrift erarbeitet und verabschiedet werden, die den besonderen\\nRisiken solcher Systeme Rechnung trägt.\\n\\uf0b7 Das berechtigte Interesse der Bürgerinnen und Bürger sich im öffentlichen\\nRaum frei und unbeobachtet bewegen zu können, ist von grundlegender\\nBedeutung. Ungeachtet dessen kann sich die öffentliche Wahrnehmung\\nhinsichtlich der Erfassung und Auswertung biometrischer Daten zum Zweck\\nder Fernidentifikation in besonderen Ausnahmesituationen (z.B. Serientäter in\\nder Region) auch sehr schnell ändern. Die allgemeinen, bestehenden\\nRegularien sollten bzgl. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 7, 'page': 5, '_split_overlap': [{'doc_id': 'f40cb5b222489f7890ff7aee61a69d96', 'range': (0, 174)}, {'doc_id': 'd8ad79f362b9348d293ee4d9a2b34d47', 'range': (1240, 1537)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '16c9643c6d5334b1a07d93bcced7f23d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Ungeachtet dessen kann sich die öffentliche Wahrnehmung\\nhinsichtlich der Erfassung und Auswertung biometrischer Daten zum Zweck\\nder Fernidentifikation in besonderen Ausnahmesituationen (z.B. Serientäter in\\nder Region) auch sehr schnell ändern. Die allgemeinen, bestehenden\\nRegularien sollten bzgl. der biometrischen Fernidentifikation mit darauf\\n5\\x0caufbauender KI dahingehend ergänzt und spezialisiert werden, um dem\\nbesonderen Handlungsfeld der Technik sowohl Spielräume wie auch Grenzen\\nzu setzen.\\n\\uf0b7 Aufgrund der unmittelbaren Betroffenheit von EU-Bürger/innen sollte zur\\nNachvollziehbarkeit und Rechtssicherheit eine Leitlinie /Rechts-\\nvorschrift vorhanden sein.\\nSind Sie der Ansicht, dass für KI-Systeme, die nicht als hochriskant eingestuft\\nwerden, zusätzlich zu den bestehenden Rechtsvorschriften ein freiwilliges\\nKennzeichnungssystem (vgl. Abschnitt 5.G des Weißbuchs) nützlich wäre?\\n(Übergeordnete Frage)\\nHaben Sie weitere Vorschläge für ein freiwilliges Kennzeichnungssystem? (Freitext)\\n\\uf0b7 KI-Systeme sollten als sicher und vertrauenswürdig gekennzeichnet werden\\nkönnen, wenn sie bestimmte Voraussetzungen erfüllen, da der Anwender\\nkeine eigene Prüfung vornehmen kann.\\n\\uf0b7 Es sollte erwogen werden, die Kennzeichnung so in der Öffentlichkeit zu\\netablieren, dass sie als verpflichtendes Gütesiegel wahrgenommen wird.\\nWie lässt sich am besten sicherstellen, dass KI vertrauenswürdig und sicher ist und\\ndass bei ihrem Einsatz die Achtung der europäischen Werte und Vorschriften\\ngewährleistet ist? ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 8, 'page': 5, '_split_overlap': [{'doc_id': '16c9643c6d5334b1a07d93bcced7f23d', 'range': (0, 297)}, {'doc_id': '7c8aa64596a533769cac9f89b79f7948', 'range': (1321, 1498)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd8ad79f362b9348d293ee4d9a2b34d47'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Wie lässt sich am besten sicherstellen, dass KI vertrauenswürdig und sicher ist und\\ndass bei ihrem Einsatz die Achtung der europäischen Werte und Vorschriften\\ngewährleistet ist? (Freitext bei „Sonstiges“)\\nSonstiges Durchsetzungssystem:\\n\\uf0b7 Die Vor- und Nachteile einer ex-ante und ex-post Konformitätsprüfung müssen\\nintensiv geprüft werden und eine schnelle und unkomplizierte Prüfung durch\\ndie zuständigen Stellen sichergestellt wird.\\n6\\x0cAbschnitt 3 - Auswirkungen von KI, des Internets der Dinge und der\\nRobotik auf Sicherheit und Haftung\\nDie geltenden Produktsicherheitsvorschriften unterstützen bereits ein erweitertes\\nKonzept des Schutzes vor allen Arten von Risiken, die von dem Produkt je nach\\nseiner Verwendung ausgehen können. Welche besonderen Risiken, die sich aus der\\nNutzung von KI ergeben, sollten Ihrer Meinung nach jedoch weiter präzisiert werden,\\num mehr Rechtssicherheit zu schaffen? (Übergeordnete Frage)\\nGibt es Ihrer Meinung nach weitere Risiken, die näher ausgeführt werden\\nmüssten, um für mehr Rechtssicherheit zu sorgen? (Freitext)\\n\\uf0b7 Vgl. hierfür Anlage 3 in diesem Dokument: „Ergänzende Stellungnahme des\\nMinisteriums der Justiz und für Europa Baden-Württemberg“\\nSind Sie der Ansicht, dass innerhalb des Rechtsrahmens für die\\nSicherheitsfragen neue Risikobewertungsverfahren für Produkte vorgesehen\\nwerden sollten, die während ihrer Lebensdauer erheblichen Änderungen\\nunterliegen? (Übergeordnete Frage)\\nHaben Sie weitere Anmerkungen zu den Risikobewertungsverfahren? ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 9, 'page': 6, '_split_overlap': [{'doc_id': 'd8ad79f362b9348d293ee4d9a2b34d47', 'range': (0, 177)}, {'doc_id': '46bfdedda9dba67022c6e551cb5ead2c', 'range': (1060, 1488)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7c8aa64596a533769cac9f89b79f7948'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: hierfür Anlage 3 in diesem Dokument: „Ergänzende Stellungnahme des\\nMinisteriums der Justiz und für Europa Baden-Württemberg“\\nSind Sie der Ansicht, dass innerhalb des Rechtsrahmens für die\\nSicherheitsfragen neue Risikobewertungsverfahren für Produkte vorgesehen\\nwerden sollten, die während ihrer Lebensdauer erheblichen Änderungen\\nunterliegen? (Übergeordnete Frage)\\nHaben Sie weitere Anmerkungen zu den Risikobewertungsverfahren? (Freitext)\\n\\uf0b7 Je nach Ausgestaltung des Rechtsrahmens könnte z.B. die Zertifizierung\\neiner risikoreichen KI-Anwendung eine Wiederholungsprüfung nach einem\\ngewissen Zeitraum vorsehen, wenn absehbar ist, dass sich erhebliche\\nÄnderungen ergeben könnten (z.B. aufgrund der verwendeten Daten)\\n\\uf0b7 Nach Artikel 7 e) der Produkthaftungs-Richtlinie (vgl. § 1 Absatz 2 Nummer 5\\ndes deutschen Produkthaftungsgesetzes) ist die Ersatzpflicht des Herstellers\\nausgeschlossen, wenn der Fehler nach dem Stand der Wissenschaft und\\nTechnik in dem Zeitpunkt, in dem der Hersteller das Produkt in den Verkehr\\nbrachte, nicht erkannt werden konnte. Ob die Bewertung von Haftungsrisiken,\\ndie mit der Veränderlichkeit von Produkten bei selbstlernenden Produkten\\neinhergehen, angemessen sind, bedarf näherer Prüfung. Diese hat die\\nArbeitsgruppe „Digitaler Neustart“ der Bundesländer nicht vorgenommen, da\\nselbstlernende gefahrträchtige Produkte auf absehbare Zeit wohl noch nicht\\nzulassungsreif und damit noch nicht marktbereit scheinen.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 10, 'page': 7, '_split_overlap': [{'doc_id': '7c8aa64596a533769cac9f89b79f7948', 'range': (0, 428)}, {'doc_id': '970d89b8857e61ef7b1d6f98c2756dcf', 'range': (1218, 1438)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '46bfdedda9dba67022c6e551cb5ead2c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Diese hat die\\nArbeitsgruppe „Digitaler Neustart“ der Bundesländer nicht vorgenommen, da\\nselbstlernende gefahrträchtige Produkte auf absehbare Zeit wohl noch nicht\\nzulassungsreif und damit noch nicht marktbereit scheinen.\\n\\uf0b7 Eine Art von „Re-Zertifizierung“ für KI-basierte Anwendungen und Dienste\\nkönnte erwogen werden, analog zu ähnlichen Verfahren im Bereich der IT-\\nSicherheit.\\n7\\x0cSind Sie der Ansicht, dass der derzeitige EU-Rechtsrahmen im Bereich\\nProdukthaftung (Produkthaftungsrichtlinie) geändert werden sollte, um mit\\nbestimmten KI-Anwendungen verbundene Risiken besser abzudecken?\\n(Übergeordnete Frage)\\nHaben Sie weitere Anmerkungen zu obigen Fragen? (Freitext)\\n\\uf0b7 Eine Klarstellung wäre im Hinblick auf die streitige Frage wünschenswert, ob\\nSoftware als Produkt im Sinne des Artikel 2 Satz 1 der\\nProdukthaftungsrichtlinie gilt und somit von deren Regelungen umfasst ist.\\nDie diesbezüglich bestehende rechtliche Unsicherheit steht in Widerspruch zu\\nder Bedeutung, die Software für Anwendungen Künstlicher Intelligenz\\nzukommt. Im Zuge dessen sollte auch die Abgrenzung von digitalen\\nProdukten zu digitalen Dienstleistungen in den Blick genommen werden.\\nSind Sie der Ansicht, dass die derzeitigen nationalen Haftungsvorschriften im\\nHinblick auf den Einsatz von KI angepasst werden sollten, um einen angemessenen\\nSchadensersatz und eine gerechte Aufteilung der Haftung zu gewährleisten?\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 11, 'page': 7, '_split_overlap': [{'doc_id': '46bfdedda9dba67022c6e551cb5ead2c', 'range': (0, 220)}, {'doc_id': '568567b5dc09ac7aba5014ebb2ed2b24', 'range': (1159, 1390)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '970d89b8857e61ef7b1d6f98c2756dcf'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Sind Sie der Ansicht, dass die derzeitigen nationalen Haftungsvorschriften im\\nHinblick auf den Einsatz von KI angepasst werden sollten, um einen angemessenen\\nSchadensersatz und eine gerechte Aufteilung der Haftung zu gewährleisten?\\n(Übergeordnete Frag)\\nBitte geben Sie die entsprechende KI-Anwendung an: (Freitext)\\n\\uf0b7 Nationale Haftungsvorschriften sollten insbesondere dort angepasst und\\neuropaweit einheitlich harmonisiert werden, wo unterschiedliche\\nRegulierungen zu Unsicherheit und übermäßigem regulatorischen\\nAufwand führen und Innovationen in Europa behindern.\\n\\uf0b7 Vgl. hierfür Anlage 3 in diesem Dokument: „Ergänzende Stellungnahme\\ndes Ministeriums der Justiz und für Europa Baden-Württemberg“\\nHaben Sie weitere Anmerkungen zu obigen Fragen?\\n\\uf0b7 Zur Wahrung der Innovations- und Wettbewerbsfähigkeit europäischer\\nUnternehmen müssen Sicherheits- und Haftungsaspekte, die aus den\\nspezifischen Eigenschaften von KI-Systemen resultieren, eindeutig und\\nnachvollziehbar geregelt werden. Es sollte eine weitgehende Harmonisierung\\nder europäischen Vorschriften angestrebt werden, um den entstehenden\\neuropäischen Digitalen Binnenmarkt zu stärken und den Anreiz für\\nUnternehmen zu steigern, Innovationen bevorzugt in der EU zu\\nkommerzialisieren.\\n\\uf0b7 Das Ministerium der Justiz und für Europa begrüßt, dass die Europäische\\nKommission sich mit der Frage befasst, ob und inwieweit die bestehenden\\neuropäischen Produktsicherheits- und Produkthaftungsvorschriften ergänzt\\nund angepasst werden müssen, um den mit der Anwendung Künstlicher\\nIntelligenz einhergehenden Sicherheits- und Haftungsrisiken angemessen zu\\nbegegnen.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 12, 'page': 8, '_split_overlap': [{'doc_id': '970d89b8857e61ef7b1d6f98c2756dcf', 'range': (0, 231)}, {'doc_id': 'bd1f050941da61d798c5f9e506f564b0', 'range': (1240, 1608)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '568567b5dc09ac7aba5014ebb2ed2b24'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: \\uf0b7 Das Ministerium der Justiz und für Europa begrüßt, dass die Europäische\\nKommission sich mit der Frage befasst, ob und inwieweit die bestehenden\\neuropäischen Produktsicherheits- und Produkthaftungsvorschriften ergänzt\\nund angepasst werden müssen, um den mit der Anwendung Künstlicher\\nIntelligenz einhergehenden Sicherheits- und Haftungsrisiken angemessen zu\\nbegegnen.\\n8\\x0c\\uf0b7 Das deutsche Recht verfügt mit dem Deliktsrecht und dem\\nGefährdungshaftungsrecht, hier etwa dem Straßenverkehrsgesetz und dem\\nProdukthaftungsgesetz, über ein produktbezogen differenziertes\\nHaftungssystem, um mögliche Schadenskonstellationen unter Beteiligung\\nKünstlicher Intelligenz angemessen zu bewältigen. So kann etwa im\\nUnterschied zur Situation bei automatisierten und autonomen Systemen in\\nKraftfahrzeugen beim Einsatz solcher Systeme in der Medizintechnik kein\\nDritter, sondern nur derjenige von Schadensfällen betroffen werden, der\\nnach Aufklärung über den Einsatz und die Risiken dem Einsatz des\\nSystems ausdrücklich zugestimmt hat. Daraus rechtfertigt sich, dass es\\nbeim Betrieb von Kraftfahrzeugen zugunsten der Dritten eine\\nGefährdungshaftung, beim Einsatz von Medizintechnik dagegen über die\\nProdukthaftung hinaus nur eine Verschuldenshaftung des über das System\\nAufklärenden und des das System Einsetzenden gibt.\\n\\uf0b7 Sollte die Kommission Bedarf für eine Regulierung auf europäischer Ebene\\nsehen, sollte ein Legislativvorschlag der Kommission daher unser\\nbestehendes, produktbezogen gut funktionierendes System nicht\\nschwächen.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 13, 'page': 8, '_split_overlap': [{'doc_id': '568567b5dc09ac7aba5014ebb2ed2b24', 'range': (0, 368)}, {'doc_id': 'cabf4c3cb45f2e9ac681848003e3693f', 'range': (1301, 1513)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bd1f050941da61d798c5f9e506f564b0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: \\uf0b7 Sollte die Kommission Bedarf für eine Regulierung auf europäischer Ebene\\nsehen, sollte ein Legislativvorschlag der Kommission daher unser\\nbestehendes, produktbezogen gut funktionierendes System nicht\\nschwächen.\\n\\uf0b7 Ausdrücklich zu begrüßen ist in diesem Zusammenhang jedoch die von der\\nEuropäischen Kommission im begleitenden Bericht angekündigte rechtliche\\nKlarstellung der hoch streitigen Frage, ob Software als Produkt im Sinne des\\nArtikel 2 Satz 1 der Produkthaftungsrichtlinie gilt und somit von deren\\nRegelungen umfasst ist. Die diesbezüglich bestehende rechtliche\\nUnsicherheit steht in Widerspruch zu der Bedeutung, die Software für\\nAnwendungen Künstlicher Intelligenz zukommt. Im Zuge dessen sollte auch\\ndie Abgrenzung von digitalen Produkten zu digitalen Dienstleistungen in den\\nBlick genommen werden.\\n9\\x0cAnlage 2 – Ergänzende Stellungnahme des Ministeriums für\\nWirtschaft, Arbeit und Wohnungsbau Baden-Württemberg\\nKonsultationsprozess der EU-Kommission zum KI-Weißbuch:\\nEin europäisches Konzept für Exzellenz und Vertrauen\\n1. Das Land Baden-Württemberg begrüßt, dass die Kommission mit dem\\nWeißbuch zur Künstlichen Intelligenz (KI) sowie der zeitgleich veröffentlichten\\nMitteilung über eine europäische Datenstrategie eine rasche und sichere\\nEntwicklung der KI in Europa unter uneingeschränkter Achtung der Werte und\\nRechte der europäischen Bürgerinnen und Bürger weiter vorantreiben will.\\n2. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 14, 'page': 9, '_split_overlap': [{'doc_id': 'bd1f050941da61d798c5f9e506f564b0', 'range': (0, 212)}, {'doc_id': 'bbd9828eb47ad63e9acb976c0d7ca19a', 'range': (1035, 1401)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'cabf4c3cb45f2e9ac681848003e3693f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Das Land Baden-Württemberg begrüßt, dass die Kommission mit dem\\nWeißbuch zur Künstlichen Intelligenz (KI) sowie der zeitgleich veröffentlichten\\nMitteilung über eine europäische Datenstrategie eine rasche und sichere\\nEntwicklung der KI in Europa unter uneingeschränkter Achtung der Werte und\\nRechte der europäischen Bürgerinnen und Bürger weiter vorantreiben will.\\n2. Das Land Baden-Württemberg teilt die Auffassung der Kommission, dass\\nEuropa nicht nur als Anwender, sondern auch als Urheber und Hersteller\\ndieser Technologie über die Voraussetzungen zum Ausschöpfen des\\nPotenzials von KI verfügt. Europa kann es sich nicht leisten, die Innovations-\\nund Wertschöpfungspotenziale der KI ungenutzt zu lassen.\\n3. Eine wesentliche Voraussetzung hierfür ist die Etablierung eines\\nRegulierungsrahmens für KI, der Rechtssicherheit für Entwickler und\\nAnwender schafft und die Entstehung von Innovationen in Europa fördert.\\nDas Land Baden-Württemberg begrüßt, dass die Kommission einen\\neinheitlichen Regulierungsrahmen für den Binnenmarkt schaffen will, der dem\\nMarktortprinzip folgen und dazu beitragen soll, einen souveränen\\n„europäischen Weg“ bei der Entwicklung und Anwendung von KI zu\\nbeschreiten.\\n4. Das Land Baden-Württemberg begrüßt den Vorschlag der Kommission für\\neine risikobasierte Regulierung von Systemen der KI im Binnenmarkt, die sich\\nspeziell auf Anwendungen mit hohen Risiken konzentriert und bei der\\nDefinition konkreter Anforderungen sektoren- sowie anwendungsspezifische\\nBesonderheiten berücksichtigt. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 15, 'page': 10, '_split_overlap': [{'doc_id': 'cabf4c3cb45f2e9ac681848003e3693f', 'range': (0, 366)}, {'doc_id': '681b346f9b042d18415baacd51fb563d', 'range': (1197, 1513)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bbd9828eb47ad63e9acb976c0d7ca19a'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Das Land Baden-Württemberg begrüßt den Vorschlag der Kommission für\\neine risikobasierte Regulierung von Systemen der KI im Binnenmarkt, die sich\\nspeziell auf Anwendungen mit hohen Risiken konzentriert und bei der\\nDefinition konkreter Anforderungen sektoren- sowie anwendungsspezifische\\nBesonderheiten berücksichtigt. Das vorgeschlagene Qualitätslabel für\\nAnwendungen mit geringem Risiko kann ein geeignetes Instrument sein, um\\nAkzeptanz und Vertrauen in der Bevölkerung und bei den Unternehmen zu\\nverbessern.\\n5. Das Land Baden-Württemberg weist jedoch auch darauf hin, dass eine\\nübermäßige Regulierung von Systemen der KI dazu führen kann,\\nInnovationen in dieser Schlüsseltechnologie zu verlangsamen oder ganz zu\\n10\\x0cverhindern. Dies hätte nicht nur negative Auswirkungen auf die\\nWettbewerbsfähigkeit der europäischen Wirtschaft, sondern auch auf die\\ntechnologische Souveränität und die Fähigkeit Europas, auf europäischen\\nWerten beruhende Regeln im Umgang mit dieser Technologie zu etablieren\\nund durchzusetzen.\\n6. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 16, 'page': 10, '_split_overlap': [{'doc_id': 'bbd9828eb47ad63e9acb976c0d7ca19a', 'range': (0, 316)}, {'doc_id': '6bd2e944f9757d7353783572e6f6c6ee', 'range': (728, 1014)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '681b346f9b042d18415baacd51fb563d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Dies hätte nicht nur negative Auswirkungen auf die\\nWettbewerbsfähigkeit der europäischen Wirtschaft, sondern auch auf die\\ntechnologische Souveränität und die Fähigkeit Europas, auf europäischen\\nWerten beruhende Regeln im Umgang mit dieser Technologie zu etablieren\\nund durchzusetzen.\\n6. Das Land Baden-Württemberg bittet die Kommission deshalb darum, unter\\nBeachtung der Ergebnisse des Konsultationsprozesses bei der weiteren\\nKonkretisierung darauf zu achten, dass\\n\\uf0b7 der regulatorische Rahmen für Transparenz und Klarheit sorgt, welcher\\nRegulierung eine bestimmte Anwendung unterworfen ist und welche\\nAnforderungen damit einhergehen, so dass Unternehmen\\nRechtssicherheit bei der Entwicklung und Nutzung dieser Anwendung\\nerhalten,\\n\\uf0b7 ein Augenmerk darauf gelegt wird, dass kleine und mittlere\\nUnternehmen sowie Start-ups durch angepasste und neue\\nregulatorischen Anforderungen nicht übermäßig belastet werden\\nund dass sie, wo erforderlich, bei der Erfüllung der administrativen\\nUmsetzung in geeigneter Form unterstützt werden,\\n\\uf0b7 Geschäftsgeheimnisse im Rahmen von Prüf- und Offenlegungspflichten\\ngewahrt bleiben sowie dass\\n\\uf0b7 die Vor- und Nachteile einer ex-ante und ex-post Konformitätsprüfung\\nintensiv geprüft werden und eine schnelle und unkomplizierte Prüfung\\ndurch die zuständigen Stellen sichergestellt wird.\\n7. Das Land Baden-Württemberg begrüßt die Absicht der Kommission, die\\nVerfügbarkeit von Daten für die Entwicklung und Anwendung von KI zu\\nverbessern. Datenkooperationen zwischen Unternehmen können hierbei eine\\nwichtige Rolle spielen. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 17, 'page': 11, '_split_overlap': [{'doc_id': '681b346f9b042d18415baacd51fb563d', 'range': (0, 286)}, {'doc_id': '20d650c4ec754a5c047d79817414a167', 'range': (1315, 1545)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6bd2e944f9757d7353783572e6f6c6ee'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Das Land Baden-Württemberg begrüßt die Absicht der Kommission, die\\nVerfügbarkeit von Daten für die Entwicklung und Anwendung von KI zu\\nverbessern. Datenkooperationen zwischen Unternehmen können hierbei eine\\nwichtige Rolle spielen. Das Land Baden-Württemberg bittet die Kommission\\ndarum, sich für eine Verbesserung der Rechtssicherheit beim Austausch von\\nDaten auf europäischer Ebene einzusetzen.\\n11\\x0cAnlage 3 – Ergänzende Stellungnahme des Ministeriums der\\nJustiz und für Europa Baden-Württemberg\\nDie Bundesländer haben in der von der Justizministerkonferenz eingesetzten Arbeits-\\ngruppe „Digitaler Neustart“ unter Vorsitz Baden-Württembergs die in Deutschland be-\\nstehenden Haftungsregeln mit Blick auf Fragen der Anwendung Künstlicher Intelli-\\ngenz untersucht und dabei speziell die Bereiche Kraftfahrzeugverkehr und Medizin-\\nprodukte in den Blick genommen. Nach dem im Abschlussbericht dargestellten Er-\\ngebnis der Untersuchung reichen die Haftungsregeln des deutschen Rechts nach\\nderzeitiger Erkenntnis auf absehbare Zeit grundsätzlich aus, um effektive Haftungs-\\nansprüche zu sichern, wenn Schäden durch Anwendungen Künstlicher Intelligenz\\nverursacht werden. Das deutsche Recht verfügt mit dem Deliktsrecht und dem Ge-\\nfährdungshaftungsrecht, hier etwa dem Straßenverkehrsgesetz und dem Produkthaf-\\ntungsgesetz, über ein ausreichend differenziertes – produktbezogenes – Haftungs-\\nsystem, um mögliche Schadenskonstellationen unter Beteiligung Künstlicher Intelli-\\ngenz rechtlich angemessen zu bewältigen.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 18, 'page': 11, '_split_overlap': [{'doc_id': '6bd2e944f9757d7353783572e6f6c6ee', 'range': (0, 230)}, {'doc_id': '3b16a80952a5f2923d4fdceb77ade48b', 'range': (1163, 1507)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '20d650c4ec754a5c047d79817414a167'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Das deutsche Recht verfügt mit dem Deliktsrecht und dem Ge-\\nfährdungshaftungsrecht, hier etwa dem Straßenverkehrsgesetz und dem Produkthaf-\\ntungsgesetz, über ein ausreichend differenziertes – produktbezogenes – Haftungs-\\nsystem, um mögliche Schadenskonstellationen unter Beteiligung Künstlicher Intelli-\\ngenz rechtlich angemessen zu bewältigen.\\nAllein in der Herstellung und dem Inverkehrbringen eines automatisierten oder auto-\\nnomen Systems liegt keine „besondere Gefahr“, die eine über die derzeit geltenden\\nHaftungsnormen hinausgehende allgemeine eigene Gefährdungshaftung für Künstli-\\nche Intelligenz erforderlich machen könnte. Ob dies auch für die schadensträchtige-\\nren selbstlernenden Systeme gilt, kann noch nicht abschließend beurteilt werden,\\nweil diese noch nicht in relevantem Umfang marktreif sind. Dennoch ist für das deut-\\nsche Recht derzeit eine relevante Schutzlücke nicht zu erkennen, nicht zuletzt, weil\\nden Gefahren der Anwendung Künstlicher Intelligenz auch mit dem Zulassungsrecht\\neffektiv begegnet wird, welches von vorneherein verhindert, dass Produkte mit allzu\\ngroßen Haftungsrisiken auf den Markt kommen. Zudem ermöglicht das zivil-\\nprozessuale Institut der Beweiserleichterungen bis hin zur Beweislastumkehr die\\nflexible und rechtlich konsistente Behandlung von Beweisschwierigkeiten für den\\nGeschädigten, die sich aus der Komplexität von Systemen Künstlicher Intelligenz\\nergeben können. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 19, 'page': 12, '_split_overlap': [{'doc_id': '20d650c4ec754a5c047d79817414a167', 'range': (0, 344)}, {'doc_id': '8d1c933f7e506a40cc03e6ba1afdfff9', 'range': (1134, 1417)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3b16a80952a5f2923d4fdceb77ade48b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Zudem ermöglicht das zivil-\\nprozessuale Institut der Beweiserleichterungen bis hin zur Beweislastumkehr die\\nflexible und rechtlich konsistente Behandlung von Beweisschwierigkeiten für den\\nGeschädigten, die sich aus der Komplexität von Systemen Künstlicher Intelligenz\\nergeben können. Wir sind der Auffassung, dass die Frage, ob Beweiserleichte-\\nrungen gewährt werden müssen, aufgrund der technischen Vielgestaltigkeit mögli-\\ncher Anwendungsbereiche Künstlicher Intelligenz dabei nicht generell, sondern\\nproduktbezogen beurteilt werden kann.\\nWir begrüßen, dass die Europäische Kommission sich intensiv mit der Frage befasst,\\nob und inwieweit die bestehenden europäischen Produktsicherheits- und Produkthaf-\\n12\\x0ctungsvorschriften ergänzt und angepasst werden müssen, um den mit der Anwendung\\nKünstlicher Intelligenz einhergehenden Sicherheits- und Haftungsrisiken ange-\\nmessen zu begegnen. Nach Auffassung der erwähnten Arbeitsgruppe „Digitaler\\nNeustart“ sollte dabei aber eine produktbezogene Betrachtung erfolgen. So kann\\netwa im Unterschied zur Situation bei automatisierten und autonomen Systemen in\\nKraftfahrzeugen beim Einsatz solcher Systeme in der Medizintechnik kein Dritter,\\nsondern nur derjenige von Schadensfällen betroffen werden, der nach Aufklärung\\nüber den Einsatz und die Risiken dem Einsatz des Systems ausdrücklich\\nzugestimmt hat. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 20, 'page': 12, '_split_overlap': [{'doc_id': '3b16a80952a5f2923d4fdceb77ade48b', 'range': (0, 283)}, {'doc_id': '247384642be6f58867e41e1963e05ec', 'range': (1013, 1346)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8d1c933f7e506a40cc03e6ba1afdfff9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: So kann\\netwa im Unterschied zur Situation bei automatisierten und autonomen Systemen in\\nKraftfahrzeugen beim Einsatz solcher Systeme in der Medizintechnik kein Dritter,\\nsondern nur derjenige von Schadensfällen betroffen werden, der nach Aufklärung\\nüber den Einsatz und die Risiken dem Einsatz des Systems ausdrücklich\\nzugestimmt hat. Daraus rechtfertigt sich, dass es beim Betrieb von Kraftfahrzeugen\\nzugunsten der Dritten eine Gefährdungshaftung, beim Einsatz von Medizintechnik\\ndagegen über die Produkthaftung hinaus nur eine Verschuldenshaftung des über\\ndas System Aufklärenden und des das System Einsetzenden gibt. Sollte die\\nKommission Bedarf für eine Regulierung auf europäischer Ebene sehen, darf ein\\nLegislativvorschlag der Kommission dieses bestehende, sehr gut funktionierende\\nproduktbezogen differenzierte System nicht schwächen.\\nAusdrücklich zu begrüßen ist in diesem Zusammenhang jedoch die von der Europäi-\\nschen Kommission im begleitenden Bericht angekündigte rechtliche Klarstellung der\\nstreitigen Frage, ob Software als Produkt im Sinne des Artikel 2 Satz 1 der Produkt-\\nhaftungsrichtlinie gilt und somit von deren Regelungen umfasst ist. Die diesbezüglich\\nbestehende rechtliche Unsicherheit steht in Widerspruch zu der Bedeutung, die Soft-\\nware für Anwendungen Künstlicher Intelligenz zukommt. Im Zuge dessen sollte auch\\ndie Abgrenzung von digitalen Produkten zu digitalen Dienstleistungen in den Blick\\ngenommen werden.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 21, 'page': 13, '_split_overlap': [{'doc_id': '8d1c933f7e506a40cc03e6ba1afdfff9', 'range': (0, 333)}, {'doc_id': '82151a2ce90a0d10c0e641347c9d7db7', 'range': (1156, 1437)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '247384642be6f58867e41e1963e05ec'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Die diesbezüglich\\nbestehende rechtliche Unsicherheit steht in Widerspruch zu der Bedeutung, die Soft-\\nware für Anwendungen Künstlicher Intelligenz zukommt. Im Zuge dessen sollte auch\\ndie Abgrenzung von digitalen Produkten zu digitalen Dienstleistungen in den Blick\\ngenommen werden.\\nAbschließend möchten wir unsere Bereitschaft zum Ausdruck bringen, die bereits in\\nder Arbeitsgruppe „Digitaler Neustart“ gezeigte Erfahrung weiterhin auf Europäischer\\nEbene einzusetzen.\\n13\\x0cAnlage 4 – KI Strategie des Landes Baden-Württemberg\\n14\\x0cAUF DEM WEG ZUR LEITREGION\\nDES DIGITALEN WANDELS\\nBADEN-WÜRTTEMBERG\\nGEHT BEI DER\\nKÜNSTLICHEN INTELLIGENZ VORAN\\x0cAUF DEM WEG ZUR LEITREGION\\nDES DIGITALEN WANDELS\\nBADEN-WÜRTTEMBERG\\nGEHT BEI DER\\nKÜNSTLICHEN INTELLIGENZ VORAN\\nINHALT\\n1. BADEN-WÜRTTEMBERG WIRD VORREITER S. 3 - 8\\nFÜR KÜNSTLICHE INTELLIGENZ\\n2. ONLINE-KONSULTATION DER BUNDESREGIERUNG: S. 9 - 31\\nPOSITIONSPAPIER DER LANDESREGIERUNG\\n3. ANLAGE ZUM POSITIONSPAPIER S. 32 - 46\\n2\\x0cBADEN-WÜRTTEMBERG\\nWIRD VORREITER FÜR\\nKÜNSTLICHE INTELLIGENZ\\nUNSERE STÄRKEN AUF EINEN BLICK\\nUnter dem Dach der landesweiten Digitalisierungsstrategie digital@bw will Baden-\\nWürttemberg weltweite Leitregion des digitalen Wandels werden und setzt dabei\\nmit Nachdruck auf Künstliche Intelligenz (KI). Mit unseren ausgewie-senen\\nStärken werden wir uns mit voller Kraft in die Umsetzung einer nationalen KI-\\nStrategie und in europäische KI-Vorhaben einbringen. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 22, 'page': 13, '_split_overlap': [{'doc_id': '247384642be6f58867e41e1963e05ec', 'range': (0, 281)}, {'doc_id': '888f7099e35c1f964852c8ae9bfd04d2', 'range': (1256, 1413)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '82151a2ce90a0d10c0e641347c9d7db7'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Mit unseren ausgewie-senen\\nStärken werden wir uns mit voller Kraft in die Umsetzung einer nationalen KI-\\nStrategie und in europäische KI-Vorhaben einbringen. In Baden-Württemberg\\nlassen sich die Potenziale der Künstlichen Intelligenz entlang der gesamten\\nWert-schöpfungskette heben (siehe Ziffer 2 und 3). Die Bundesregierung kann\\ndarauf aufbauen, um innovative Projekte schnell zu skalieren und so ein\\nGegengewicht zu den USA und zu Asien aufzubauen. Wir sind entschlossen, als\\nstrategischer KI-Partner der Bundesregierung erheblich in gemeinsame\\nModellvorhaben und Projekte zu investieren und die dazu erforderliche Ko-\\nFinanzierung vorzuhalten. Dafür hat die Landesregierung in Ergänzung der\\nnachstehenden Maßnahmen im aktuellen Nachtragshaushalt in einem ersten\\nSchritt kurzfristig zusätzliche Mittel in Höhe von jeweils zehn Millionen Euro für\\nProjekte des Wirtschafts- und des Wissenschaftsministeriums zur Verfügung\\ngestellt. Zudem wird die Möglichkeit geschaffen, Beträge für die Ko-Finanzierung\\nvon Projekten im Rahmen einer Bundesstrategie zur Künstlichen Intelligenz und\\nfür Batterieforschung in Höhe von 100 Millionen Euro einzusetzen.\\n1.\\n3\\x0c1.1.\\nWIR WOLLEN EIN EINZIGARTIGES ÖKOSYSTEM\\nFÜR KÜNSTLICHE INTELLIGENZ SCHAFFEN\\nBaden-Württemberg verfügt über herausragende Ausgangsbedingungen, um grundlagen- und anwendungs-\\norientierte Forschung, Wissenschaft und Wirtschaft zu einem einzigartigen Ökosystem für Künstliche\\nIntelligenz zu verbinden. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 23, 'page': 17, '_split_overlap': [{'doc_id': '82151a2ce90a0d10c0e641347c9d7db7', 'range': (0, 157)}, {'doc_id': 'e6c51283d3e14514ff007d3ef7482128', 'range': (1158, 1454)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '888f7099e35c1f964852c8ae9bfd04d2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: WIR WOLLEN EIN EINZIGARTIGES ÖKOSYSTEM\\nFÜR KÜNSTLICHE INTELLIGENZ SCHAFFEN\\nBaden-Württemberg verfügt über herausragende Ausgangsbedingungen, um grundlagen- und anwendungs-\\norientierte Forschung, Wissenschaft und Wirtschaft zu einem einzigartigen Ökosystem für Künstliche\\nIntelligenz zu verbinden. Neben Unternehmen von Weltruf verfügen wir auch über einen hochinnovativen\\nMittelstand mit herausragenden Kompetenzen in zentralen Anwendungsfeldern von KI, insbesondere im\\nProduzierenden Gewerbe, im Maschinen- und Anlagenbau, Automobilsektor, in der Gesundheitswirtschaft, bei\\nden industrienahen Dienstleistungen sowie in der Softwareentwicklung. In keiner anderen europäischen Region\\nsind die Chancen so groß, um Künstliche Intelligenz von Deutschland aus auf ein weltweit führendes\\nNiveau zu heben.\\nAuf diese Stärken können wir in Baden-Württemberg u. a. bauen:\\n→ Mit dem „Cyber Valley“ haben wir zusammen mit der Max-Planck-\\nGesellschaft, den Universitäten Stuttgart und Tübingen sowie den\\nUnternehmen Amazon, BMW, Bosch, Daimler, IAV, Porsche und\\nZF Friedrichshafen ein europaweit einmaliges Forschungszentrum\\nfür intelligente Systeme auf den Weg gebracht, das mit seiner\\nForschungsexzellenz und der Vernetzung mit globalen Unternehmen\\nsowie dem Transfer in Anwendung und Gründungen schon heute\\nzu den Top-Adressen weltweit gehört.\\n→ Im Rahmen des „Digital Hubs Artificial Intelligence“ in der Techno-\\nlogieregion Karlsruhe treiben wir KI-Anwendungen insbesondere\\nin den Anwendungsfeldern Energie, Mobilität, Medizin und Produk-\\ntion voran.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 24, 'page': 18, '_split_overlap': [{'doc_id': '888f7099e35c1f964852c8ae9bfd04d2', 'range': (0, 296)}, {'doc_id': 'be38e4df69fa8f1b4a727df9699e933d', 'range': (1334, 1542)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e6c51283d3e14514ff007d3ef7482128'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: → Im Rahmen des „Digital Hubs Artificial Intelligence“ in der Techno-\\nlogieregion Karlsruhe treiben wir KI-Anwendungen insbesondere\\nin den Anwendungsfeldern Energie, Mobilität, Medizin und Produk-\\ntion voran.\\n→ Eine besondere Stärke Baden-Württembergs liegt in der\\nErforschung und Anwendung von cyber-physischen Systemen.\\n→ Transfereinrichtungen wie beispielsweise der Stuttgarter\\nTechnologie- und Innovationscampus (S-TEC) sind speziell auf die\\nBedürfnisse des Mittelstands ausgerichtet.\\nDiese Stärken wollen wir ausbauen, um Sprunginnovationen aus\\nBaden-Württemberg und Deutschland mit hohem Tempo voranzutreiben.\\n→ Bei der Spitzenforschung werden wir das Cyber Valley als\\nExzellenzzentrum für Technologie und Unternehmertum weiter\\nausbauen und es dadurch zum Nukleus für KI-Sprunginnovationen\\nin Deutschland und Europa machen.\\nWir wollen:\\n\\uf0b7 die Spitzenforschung im Land weiter durch Personal und\\nInfrastruktur stärken,\\nBADEN-WÜRTTEMBERG WIRD VORREITER FÜR KÜNSTLICHE INTELLIGENZ 4\\x0cBADEN-WÜRTTEMBERG WIRD VORREITER FÜR KÜNSTLICHE INTELLIGENZ 5\\n\\uf0b7 Kooperationen und Netzwerkbildung in der Spitzen-\\nforschung auf nationaler und europäischer Ebene voran-\\ntreiben, wie zum Beispiel das Kompetenzzentrum\\nMaschinelles Lernen, die Zusammenarbeit mit weiteren\\nUnternehmen, beispielsweise Industry-on-Campus,\\nfördern,\\n\\uf0b7 Gründertum und Unternehmertum noch gezielter\\nfördern, um zu einer herausragenden Plattform für KI-\\nStart-ups zu werden.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 25, 'page': 18, '_split_overlap': [{'doc_id': 'e6c51283d3e14514ff007d3ef7482128', 'range': (0, 208)}, {'doc_id': '49065422584ea981d8c75adb8cda2009', 'range': (830, 1431)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'be38e4df69fa8f1b4a727df9699e933d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Wir wollen:\\n\\uf0b7 die Spitzenforschung im Land weiter durch Personal und\\nInfrastruktur stärken,\\nBADEN-WÜRTTEMBERG WIRD VORREITER FÜR KÜNSTLICHE INTELLIGENZ 4\\x0cBADEN-WÜRTTEMBERG WIRD VORREITER FÜR KÜNSTLICHE INTELLIGENZ 5\\n\\uf0b7 Kooperationen und Netzwerkbildung in der Spitzen-\\nforschung auf nationaler und europäischer Ebene voran-\\ntreiben, wie zum Beispiel das Kompetenzzentrum\\nMaschinelles Lernen, die Zusammenarbeit mit weiteren\\nUnternehmen, beispielsweise Industry-on-Campus,\\nfördern,\\n\\uf0b7 Gründertum und Unternehmertum noch gezielter\\nfördern, um zu einer herausragenden Plattform für KI-\\nStart-ups zu werden.\\n→ Wir werden darüber hinaus bestehende Stärken in der anwendungs-\\norientierten KI-Forschung gezielt ausbauen, um den Transfer von\\nForschungsergebnissen in die Wirtschaft auch in der Breite weiter\\nzu beschleunigen, etwa in der kognitiven Robotik.\\n→ Den „de:hub Artificial Intelligence“ werden wir zu einer Plattform\\nfür die Anwendung und Kommerzialisierung von KI ausbauen und\\ndabei auch die deutsch-französische Zusammenarbeit forcieren.\\n→ Wir werden die Errichtung weiterer, mit unseren Wissenschafts-\\nstandorten verknüpften Strukturen prüfen. Ein Beispiel dafür sind\\ngroße „Innovationsparks KI“, die internationale Strahlkraft haben\\nund als Wertschöpfungszentren für Kommerzialisierung sowie als\\nTestfelder für die Praxistauglichkeit dienen.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 26, 'page': 18, '_split_overlap': [{'doc_id': 'be38e4df69fa8f1b4a727df9699e933d', 'range': (0, 601)}, {'doc_id': '5fb933f89b0871d892dd9e1e068267b4', 'range': (1147, 1345)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '49065422584ea981d8c75adb8cda2009'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Ein Beispiel dafür sind\\ngroße „Innovationsparks KI“, die internationale Strahlkraft haben\\nund als Wertschöpfungszentren für Kommerzialisierung sowie als\\nTestfelder für die Praxistauglichkeit dienen.\\n→ Wir werden ein Mittelstandsprogramm mit Schwerpunkt KI ins\\nLeben rufen und setzen uns für eine Ko-Finanzierung durch den\\nBund ein, um mit wegweisenden Angeboten einen schnellen und\\nflächendeckenden Wissenstransfer in kleine und mittlere Unter-\\nnehmen sicherzustellen.\\x0cBADEN-WÜRTTEMBERG WIRD VORREITER FÜR KÜNSTLICHE INTELLIGENZ 6\\n1.2.\\nTOP-TALENTE ANWERBEN\\nUND KI-KOMPETENZEN\\nIN DER BREITE STÄRKEN\\nWir wollen Top-KI-Experten ausbilden und Baden-Württemberg als attraktiven Standort weiterentwickeln, der Top-\\nTalente und Experten aus aller Welt für Wissenschaft und Wirtschaft anzieht.\\nAuf diese Stärken können wir in Baden-Württemberg u. a. bauen:\\n→ Wir bilden exzellente Wissenschaftler und Nachwuchskräfte für\\ndie Wirtschaft an unseren Hochschulen und Forschungseinrich-\\ntungen aus. Wir schaffen 20 neue Professuren mit Schwerpunkt KI\\nim Land.\\n→ Mit unseren Lernfabriken 4.0 schaffen wir ein bundesweit einzig-\\nartiges Netz von Lernorten, an denen praxisnah Trainings auf Basis\\nrealer Industriestandards durchgeführt werden.\\n→ An den Schulen unseres Landes haben wir den Informatik-Unter-\\nricht verbindlich eingeführt und stärken die KI-Kompetenzen der\\nSchülerinnen und Schüler.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 27, 'page': 19, '_split_overlap': [{'doc_id': '49065422584ea981d8c75adb8cda2009', 'range': (0, 198)}, {'doc_id': '2803be87819b2ff1bc8240ad40992ceb', 'range': (1228, 1381)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5fb933f89b0871d892dd9e1e068267b4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: → An den Schulen unseres Landes haben wir den Informatik-Unter-\\nricht verbindlich eingeführt und stärken die KI-Kompetenzen der\\nSchülerinnen und Schüler.\\nDiese Stärken wollen wir weiter ausbauen und die Grundlagen dafür schaffen, dass Top-Talente in Baden-\\nWürttemberg an KI forschen und Forschungsergebnisse in vielfältige KI-Anwendungen umsetzen:\\n→ Wir wollen internationale Spitzenkräfte und junge Talente aus aller\\nWelt anziehen. Daher werden wir weitere Anstrengungen unter-\\nnehmen, damit das Cyber Valley die notwendige kritische Masse\\nerreicht, um genügend Strahl- und Anziehungskraft für die klügs-\\nten Köpfe aus der ganzen Welt zu entfalten.\\n→ Das Innovationscamp BW im Silicon Valley ist ein sehr gut geeigne-\\nter Ansatz, um auch Spitzenleute zurück nach Baden-Württemberg zu\\nholen.\\n→ Wir wollen die KI-Schwerpunkte im Studium im ganzen Land ver-\\nstärken. Mit speziellen Förderprogrammen werden wir gezielt\\nauch Frauen für ein Studium mit Schwerpunkt KI gewinnen.\\n→ Die Weiterbildungs- und Qualifizierungsangebote insbesondere für\\nkleine und mittlere Unternehmen im Land werden wir weiter aus-\\nbauen. Wir setzen uns dafür ein, dass die Bundesregierung – nach\\ndem Vorbild der Lernfabriken 4.0 – gemeinsam mit den Unterneh-\\nmen vor Ort KI-Lernlabore und KI-Lernfabriken fördert.\\x0c1.3.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 28, 'page': 20, '_split_overlap': [{'doc_id': '5fb933f89b0871d892dd9e1e068267b4', 'range': (0, 153)}, {'doc_id': 'fd507a3e5113c1b3338b6e60efbc24d6', 'range': (1111, 1291)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2803be87819b2ff1bc8240ad40992ceb'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Wir setzen uns dafür ein, dass die Bundesregierung – nach\\ndem Vorbild der Lernfabriken 4.0 – gemeinsam mit den Unterneh-\\nmen vor Ort KI-Lernlabore und KI-Lernfabriken fördert.\\x0c1.3.\\nSTANDARDS SETZEN:\\nMIT CYBERSICHERHEIT,\\nDATENSCHUTZ UND ETHIK\\nIm weltweiten Wettbewerb müssen wir in Deutschland und Europa auf die Entwicklung einer KI setzen, die\\nauf den Menschen und seine Rechte bezogen ist, dem Gemeinwohl dient und mit unseren\\nWertvorstellungen im Einklang steht. Technologische Abhängigkeiten von Ländern, die über andere\\nWertesysteme verfügen, müssen vermieden werden. In Baden-Württemberg erachten wir leistungsfähige KI-\\nTechnologien, die Daten-und Persönlichkeitsrechte schützen und sicher vor Cyberangriffen sind, als einen\\nentscheidenden Wettbe-werbsvorteil.\\nAuf diese Stärken können wir in Baden-Württemberg u. a. bauen:\\n→ Unsere Leuchtturm-Vorhaben – angefangen von den Zentren für\\nPersonalisierte Medizin bis hin zu Smart City-Wettbewerben –\\nbauen auf KI-Lösungen, die sicher sind und die Privatsphäre\\nschützen. Den Schutz der Persönlichkeitsrechte machen wir zum\\nGütesiegel unserer Digitalisierungsstrategie digital@bw.\\n→ KI stellt Wirtschaft und Staat bei Cybersicherheit vor neue Heraus-\\nforderungen. Wir investieren in Forschung und Wissenstransfer bei\\nsoftware- und hardwarebasierten KI-Lösungen, wie z. B. neuro-\\nmorphe Chips, die nach dem Beispiel natürlicher Nervenzellen\\ngebaut werden. Damit unterstützen wir besonders mittelstän-\\ndische Unternehmen und kritische Infrastrukturen.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 29, 'page': 20, '_split_overlap': [{'doc_id': '2803be87819b2ff1bc8240ad40992ceb', 'range': (0, 180)}, {'doc_id': '36ff06a91abde2bd6d7cfb6004a53582', 'range': (1321, 1501)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fd507a3e5113c1b3338b6e60efbc24d6'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: B. neuro-\\nmorphe Chips, die nach dem Beispiel natürlicher Nervenzellen\\ngebaut werden. Damit unterstützen wir besonders mittelstän-\\ndische Unternehmen und kritische Infrastrukturen.\\nDiese Stärken werden wir weiter ausbauen. Wir werden weitere Maßnahmen zum Schutz von\\nPersönlich-keitsrechten und Cybersicherheit ergreifen und wollen dabei eng mit der Bundesregierung\\nzusammenarbei-ten:\\n→ Ohne Sicherheit ist alles nichts. Wir machen uns dafür stark, dass\\ndie Bundesregierung Forschung und Wissenstransfer im Bereich\\nIT-Security verstärkt. Das Kompetenzzentrum KASTEL am Karls-\\nruher Institut für Technologie (KIT) sollte als nationaler Leucht-\\nturm unter Beteiligung des Landes verstetigt und ausgebaut\\nwerden.\\n→ Wir werden Forschungs- und Transferprojekte mit Schwerpunkten\\nAnwendungsmöglichkeiten und Cybersicherheit zu verschiedenen\\nThemenschwerpunkten wie z. B. Gesundheit, Mobilität, Produktion\\nund Nachhaltigkeit sowie Kritischen Infrastrukturen weiter aus-\\nbauen.\\n→ Im Juli 2018 haben wir den Forschungsverbund „Gesellschaft im\\ndigitalen Wandel“ ausgeschrieben. Neben dem ethischen Orientie-\\nBADEN-WÜRTTEMBERG WIRD VORREITER FÜR KÜNSTLICHE INTELLIGENZ 7\\x0cBADEN-WÜRTTEMBERG WIRD VORREITER FÜR KÜNSTLICHE INTELLIGENZ 8\\nrungswissen geht es uns darum, dass die Bürgerinnen und Bürger\\nin die Gestaltung des digitalen Wandels aktiv einbezogen werden.\\nWir wollen die transdisziplinäre Kooperation der Geistes- und\\nSozialwissenschaften mit den Technikwissenschaften sowie den\\nBürgerinnen und Bürgern fördern. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 30, 'page': 21, '_split_overlap': [{'doc_id': 'fd507a3e5113c1b3338b6e60efbc24d6', 'range': (0, 180)}, {'doc_id': '3694dd7a11e420751a73b8fd332ab722', 'range': (1068, 1505)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '36ff06a91abde2bd6d7cfb6004a53582'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Neben dem ethischen Orientie-\\nBADEN-WÜRTTEMBERG WIRD VORREITER FÜR KÜNSTLICHE INTELLIGENZ 7\\x0cBADEN-WÜRTTEMBERG WIRD VORREITER FÜR KÜNSTLICHE INTELLIGENZ 8\\nrungswissen geht es uns darum, dass die Bürgerinnen und Bürger\\nin die Gestaltung des digitalen Wandels aktiv einbezogen werden.\\nWir wollen die transdisziplinäre Kooperation der Geistes- und\\nSozialwissenschaften mit den Technikwissenschaften sowie den\\nBürgerinnen und Bürgern fördern. Insbesondere wollen wir die Ver-\\nänderungen der Arbeitswelten und die nachhaltige Entwicklung in\\nden Blick nehmen.\\n1.4.\\nTREIBER IN DEUTSCHLAND\\nUND EUROPA\\nBaden-Württemberg wird seine Stärken im Verbund mit anderen Initiativen auf nationaler und europäischer Ebene\\neinbringen und steht als starker Partner für Kooperationen bereit.\\n→ Wir streben eine enge Kooperation mit der Bundesregierung bei\\ndem deutsch-französischen Netzwerk für KI an. Wir arbeiten\\nbereits aktiv an der Intensivierung der Zusammenarbeit mit\\nweiteren Standorten – dies sowohl auf Länderebene als auch im\\nfranzösischen und europäischen Kontext. Wir sind davon über-\\nzeugt, dass nur ein Spitzenverbund der besten Standorte die\\nnötige Signalwirkung für ein europäisches Leuchtturmprojekt er-\\nzeugen kann.\\n→ Um die Pläne der Bundesregierung für ein deutsch-französisches\\nNetzwerk zu unterstützen, haben wir mit potenziellen französi-\\nschen Partnern in den letzten Monaten einen Dialog begonnen.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 31, 'page': 21, '_split_overlap': [{'doc_id': '36ff06a91abde2bd6d7cfb6004a53582', 'range': (0, 437)}, {'doc_id': 'c57d9a102fa209f636c649a2241ad6e2', 'range': (1211, 1399)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3694dd7a11e420751a73b8fd332ab722'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: → Um die Pläne der Bundesregierung für ein deutsch-französisches\\nNetzwerk zu unterstützen, haben wir mit potenziellen französi-\\nschen Partnern in den letzten Monaten einen Dialog begonnen.\\nWir schlagen vor, die ELLIS-Initiative, eine Initiative der führenden\\neuropäischen KI-Forscher, als wichtigen Beitrag zur europäischen\\nVernetzung umzusetzen. Gemeinsam mit der Bundesregierung\\nwollen wir hierfür die Leistungsfähigkeit der Infrastrukturen für die\\nKI-Forschung stärken und europäisch vernetzen.\\n→ Wir unterstützen ausdrücklich, dass die Bundesregierung prüfen\\nwill, ob bei KI ein wichtiges Vorhaben von gemeinsamem euro-\\npäischem Interesse (Important Project of Common European Inter-\\nest, IPCEI) realisiert werden kann.\\x0cONLINE-KONSULTATION\\nDER BUNDESREGIERUNG\\n(POSITIONSPAPIER DER\\nLANDESREGIERUNG MIT ANLAGE)\\n2.\\n9\\x0c2.1.\\nBADEN-WÜRTTEMBERG\\nWIRD VORREITER FÜR\\nKÜNSTLICHE INTELLIGENZ\\nBaden-Württemberg soll zu einer weltweiten Leitregion des digitalen Wandels werden. Deshalb investieren\\nwir in Baden-Württemberg kraftvoll und nachhaltig in Grundlagenforschung sowie anwendungsnahe\\nForschung und Entwicklung, Anwendung und Kommerzialisierung der wichtigsten Schlüsseltechnologie des\\ndigitalen Wandels: in die Künstliche Intelligenz (KI).\\nAls erstes Land hat Baden-Württemberg eine umfassende und von allen Ressorts getragene Digitalisierungs-\\nstrategie vorgelegt: Unter dem Dach von digital@bw treiben wir mit 70 Maßnahmen die Digitalisierung im\\nLand voran. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 32, 'page': 22, '_split_overlap': [{'doc_id': '3694dd7a11e420751a73b8fd332ab722', 'range': (0, 188)}, {'doc_id': '568d324da4e4d6a72be8c9c7762f04e4', 'range': (1237, 1456)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c57d9a102fa209f636c649a2241ad6e2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Als erstes Land hat Baden-Württemberg eine umfassende und von allen Ressorts getragene Digitalisierungs-\\nstrategie vorgelegt: Unter dem Dach von digital@bw treiben wir mit 70 Maßnahmen die Digitalisierung im\\nLand voran. So wie die Digitalisierung alle Lebens- und Wirtschaftsbereiche verändert, packen wir die Heraus-\\nforderungen des digitalen Wandels umfassend an: von A wie autonomes Fahren bis Z wie Zukunftskommu-nen.\\nBis 2021 investieren wir rund eine Milliarde Euro. Dabei setzen wir auf die Entwicklung und Anwendung von KI-\\nTechnologien. Unter dem strategischen Dach von digital@bw haben wir deshalb:\\n→ Mit dem Cyber Valley ein europaweit einmaliges Forschungs-\\nzentrum für intelligente Systeme auf den Weg gebracht, das mit\\nseiner Forschungsexzellenz und der Vernetzung mit globalen\\nUnternehmen wie BOSCH, Daimler und Amazon sowie dem Trans-\\nfer in Anwendung und Gründungen schon heute zu den Top-\\nAdressen weltweit gehört. Damit bauen wir auf die langjährige\\nexzellente Forschung an den Max-Planck-Instituten und Univer-\\nsitäten des Landes – insbesondere in Stuttgart, Tübingen, Freiburg,\\nKarlsruhe – auf. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 33, 'page': 24, '_split_overlap': [{'doc_id': 'c57d9a102fa209f636c649a2241ad6e2', 'range': (0, 219)}, {'doc_id': '1b7a5c9647af91e9728f003a4e691d57', 'range': (933, 1115)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '568d324da4e4d6a72be8c9c7762f04e4'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Damit bauen wir auf die langjährige\\nexzellente Forschung an den Max-Planck-Instituten und Univer-\\nsitäten des Landes – insbesondere in Stuttgart, Tübingen, Freiburg,\\nKarlsruhe – auf. Durch neu eingerichtete Juniorprofessuren mit\\ndem Schwerpunkt auf KI, der BMBF-Förderung des Kompetenz-\\nzentrums für Maschinelles Lernen sowie dem jüngsten Förderent-\\nscheid für das Exzellenzcluster „Maschinelles Lernen: Neue Pers-\\npektiven für die Wissenschaft“ der Universität Tübingen wird\\nunsere einmalige Forschungslandschaft weiter gestärkt.\\n→ Unsere herausragenden Institute im Bereich der angewandten\\nKI-Forschung weiter gestärkt: Der Stuttgarter Technologie- und\\nInnovationscampus und die Technologieregion Karlsruhe mit dem\\nde:hub Artificial Intelligence stehen stellvertretend für die einma-\\nlige anwendungsorientierte Forschungslandschaft im Südwesten,\\ndie sich auch durch die enge Vernetzung mit unserer starken\\nSoftwarebranche und den hochinnovativen Unternehmen unserer\\nLeitbranchen auszeichnet.\\n→ Die Anwendung von KI in der Praxis vorangebracht: Im Testfeld\\nAutonomes Fahren werden Technologien des automatisierten\\nFahrens auf 250 km Länge im Straßenverkehr getestet. Zentren für\\npersonalisierte Medizin werden daran arbeiten, aus großen Daten-\\nmengen passgenaue Therapien für Patienten abzuleiten. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 34, 'page': 24, '_split_overlap': [{'doc_id': '568d324da4e4d6a72be8c9c7762f04e4', 'range': (0, 182)}, {'doc_id': 'ee140efb13c1a5ca7872ad52652b066e', 'range': (994, 1298)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1b7a5c9647af91e9728f003a4e691d57'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: → Die Anwendung von KI in der Praxis vorangebracht: Im Testfeld\\nAutonomes Fahren werden Technologien des automatisierten\\nFahrens auf 250 km Länge im Straßenverkehr getestet. Zentren für\\npersonalisierte Medizin werden daran arbeiten, aus großen Daten-\\nmengen passgenaue Therapien für Patienten abzuleiten. Mit\\nBEITRAG BADEN-WÜRTTEMBERGS ZUR ONLINE-KONSULTATION DER BUNDESREGIERUNG 10\\x0cBEITRAG BADEN-WÜRTTEMBERGS ZUR ONLINE-KONSULTATION DER BUNDESREGIERUNG 11\\nunserer landesweiten Initiative Wirtschaft 4.0 und der Allianz\\nIndustrie 4.0, die u. a. durch regionale Digital Hubs oder das Appli-\\nkationszentrum Industrie 4.0 den Mittelstand dabei unterstützen,\\ndie Chancen des digitalen Wandels zu ergreifen.\\n→ Mit der Landeskampagne Start-up BW, den Förderprogrammen\\n„Gründungskultur in Studium und Lehre“, „Junge Innovatoren“\\ngezielt auch die Förderung von (Aus-)Gründungen im Bereich KI\\ngestartet. An zahlreichen Hochschulen wurden „Innovations-\\nzentren“ und Inkubatoren etabliert, die Start-ups aus dem Wissen-\\nschaftsbereich mit ihren Ideen unterstützen: Von der ersten Be-\\nratung bis zur Vermittlung von Investoren.\\nDie angestoßenen Initiativen sind nur ein erster Schritt. Die Stärken Baden-Württembergs werden wir weiter\\nsystematisch ausbauen. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 35, 'page': 24, '_split_overlap': [{'doc_id': '1b7a5c9647af91e9728f003a4e691d57', 'range': (0, 304)}, {'doc_id': 'b76430c87127493c5b662657ebef859b', 'range': (895, 1245)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ee140efb13c1a5ca7872ad52652b066e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: An zahlreichen Hochschulen wurden „Innovations-\\nzentren“ und Inkubatoren etabliert, die Start-ups aus dem Wissen-\\nschaftsbereich mit ihren Ideen unterstützen: Von der ersten Be-\\nratung bis zur Vermittlung von Investoren.\\nDie angestoßenen Initiativen sind nur ein erster Schritt. Die Stärken Baden-Württembergs werden wir weiter\\nsystematisch ausbauen. Baden-Württemberg verfolgt das Ziel, auf zentralen Schlüsselfeldern der KI, Gesund-\\nheit, Mobilität, Energiewende und Nachhaltigkeit – u. a. mit dem Leitbild der Ultraeffizienzfabrik – zu den\\neuropäischen Leitregionen zu gehören und mit ihnen zusammen als Netzwerk das Zentrum der europäi-\\nschen KI-Entwicklung zu werden.\\nMit der strategischen Dachmarke von digital@bw wird die Landesregierung weiter große Anstrengungen\\nunternehmen und in zentrale Projekte entlang der gesamten Wertschöpfungskette von der Grundlagen-\\nforschung bis zur Anwendung investieren, um Baden-Württemberg zur Leitregion für den Digitalen Wandel\\nzu machen. Dabei werden wir auch in Zukunft einen besonderen Fokus auf die Erforschung, Anwendung\\nund Kommerzialisierung von KI und die branchenübergreifende Unterstützung von mittelständischen Unter -\\nnehmen und Start-ups legen, sowie die gesellschaftlichen Rahmenbedingungen und Herausforderungen\\ndes digitalen Wandels mit der Öffentlichkeit diskutieren.\\nMit unserem Leitbild einer menschenzentrierten KI wollen wir über die Ziele der KI-Anwendung, Akzeptanz der\\nTechnologien und deren gesetzliche wie ethische Rahmenbedingungen einen gesellschaftlichen Dialog führen. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 36, 'page': 25, '_split_overlap': [{'doc_id': 'ee140efb13c1a5ca7872ad52652b066e', 'range': (0, 350)}, {'doc_id': 'e13dbaae5f33de3d2b145024f603ef4e', 'range': (1329, 1542)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b76430c87127493c5b662657ebef859b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Mit unserem Leitbild einer menschenzentrierten KI wollen wir über die Ziele der KI-Anwendung, Akzeptanz der\\nTechnologien und deren gesetzliche wie ethische Rahmenbedingungen einen gesellschaftlichen Dialog führen. Wir wollen\\ndie wirtschaftlichen, gesellschaftlichen und nachhaltigen Chancen der KI zur Lösung ge-sellschaftlicher\\nHerausforderungen nutzen.\\nBaden-Württemberg ist bereit, seine besonderen Stärken im Verbund mit anderen Initiativen auf nationaler und\\neuropäischer Ebene einzubringen, damit Deutschland und Europa den Wettbewerb um die Gestaltung der\\ndigitalen Zukunft aktiv und erfolgreich bestreiten können und steht als starker Partner für Kooperationen bereit.\\nBaden-Württemberg ist mit seinen exzellenten Forschungs- und Transfereinrichtungen, dem großen\\nAnwenderpotenzial in hochinnovativen Produktions- und B2B-Dienstleistungsbranchen und seiner\\nstarken Softwareindustrie bereits heute ein herausragender Standort für KI, wo schon zahlreiche KI-basierte\\nAnwen-dungen erforscht, entwickelt und ausgerollt werden.\\nHierauf kann die Bundesregierung aufsetzen, um entsprechende Projekte wirkungsvoll zu skalieren. Damit\\nkönnten Deutschland und Europa schnell und sichtbar ein Gegengewicht zu globalen Wettbewerbern wie\\nUSA und China bilden.\\x0c2.2.\\nWARUM KÜNSTLICHE\\nINTELLIGENZ ALS SCHLÜSSELTECHNOLOGIE SO\\nWICHTIG IST\\nKI ist eine der zentralen Schlüsseltechnologien der Digitalisierung. Ob humanoide Roboter, selbstfahrende\\nFahrzeuge, personalisierte Medizin, Sprachassistenzsysteme oder digitale Plattformen: KI treibt Innovationen\\nin einem gewaltigen Tempo voran. Dabei entstehen große Chancen für Wissenschaft, Wirtschaft, Gesellschaft\\nund Umwelt.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 37, 'page': 25, '_split_overlap': [{'doc_id': 'b76430c87127493c5b662657ebef859b', 'range': (0, 213)}, {'doc_id': '24cf925a90be40cb6a14d9eaa0c69953', 'range': (1398, 1661)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e13dbaae5f33de3d2b145024f603ef4e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Ob humanoide Roboter, selbstfahrende\\nFahrzeuge, personalisierte Medizin, Sprachassistenzsysteme oder digitale Plattformen: KI treibt Innovationen\\nin einem gewaltigen Tempo voran. Dabei entstehen große Chancen für Wissenschaft, Wirtschaft, Gesellschaft\\nund Umwelt.\\nImmer mehr maschinenlesbare Daten, die dank gestiegener Rechenkapazitäten in Echtzeit analysiert werden\\nkönnen, revolutionieren mit neuen Geschäftsmodellen, Dienstleistungen und Produkten schon heute das\\nproduzierende Gewerbe in intelligenten Fabrikhallen und die Dienstleistungsbranche. Neue Algorithmen, die\\nin der Lage sind, in Daten Muster zu erkennen, selbständig zu lernen und so eigenständig Antworten auch\\nauf neue Fragen zu finden, eröffnen dabei neue Welten und Möglichkeiten. In den kommenden Jahren wird\\nKI in immer mehr Lebensbereichen Einzug halten und die Art und Weise wie wir leben und arbei ten\\nrevolutionie-ren.\\nKI wird zu einer der zentralen Zukunftsfragen für die wirtschaftliche Entwicklung und zu einer zentralen Quelle\\ngesellschaftlichen Wohlstands. Für ein Land wie Baden-Württemberg gilt es dabei, seine spezifische\\nAusgangsposition in den Blick zu nehmen, Stärken zu stärken und sich mit anderen exzellenten KI-Standorten\\nnational und international zu vernetzen.\\nWährend weltweit genutzte Digitalplattformen gewaltige Datenschätze sammeln und sich so einen großen\\nVorsprung bei personenbezogenen Dienstleistungen für private Kunden erarbeitet haben, setzen wir in\\nBaden-Württemberg auf die besonderen eigenen Stärken.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 38, 'page': 26, '_split_overlap': [{'doc_id': 'e13dbaae5f33de3d2b145024f603ef4e', 'range': (0, 263)}, {'doc_id': '44cf2b46bc0dd2e206e1af6fbdc15004', 'range': (1254, 1508)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '24cf925a90be40cb6a14d9eaa0c69953'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Während weltweit genutzte Digitalplattformen gewaltige Datenschätze sammeln und sich so einen großen\\nVorsprung bei personenbezogenen Dienstleistungen für private Kunden erarbeitet haben, setzen wir in\\nBaden-Württemberg auf die besonderen eigenen Stärken.\\n1 2\\x0cBEITRAG BADEN-WÜRTTEMBERGS ZUR ONLINE-KONSULTATION DER BUNDESREGIERUNG 13\\nDiese weltweit anerkannten Stärken liegen in den Bereichen Gesundheit, Mobilität und Nachhaltigkeit. Hierbei\\nverfügt Baden-Württemberg über große Kompetenzen in den Bereichen Grundlagenforschung, Maschinen-\\nund Automobilbau, industrienahe Dienstleistungen, der medizinischen Forschung, der pharma-zeutischen\\nIndustrie sowie der Energiewirtschaft – in Bereichen also, in denen gewaltige Mengen an Unter-nehmens-,\\nProdukt- und Prozessdaten entstehen, die mittels KI verarbeitet und wirtschaftlich genutzt werden\\nkönnen. Mit unserem starken, mittelständisch geprägten Industrie-Dienstleistungsverbund, der starken\\nSoftware- und IKT-Branche und einer engen Vernetzung von Wissenschaft und Wirtschaft verfügen wir über\\nhervorragende Ausgangsbedingungen. In diesen Bereichen eröffnet eine Kombination aus industriel-lem Know-\\nhow und KI-Technologien völlig neue Möglichkeiten und verschafft uns eine hervorragende Wettbewerbsposition\\ngegenüber, den USA und China.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 39, 'page': 26, '_split_overlap': [{'doc_id': '24cf925a90be40cb6a14d9eaa0c69953', 'range': (0, 254)}, {'doc_id': '55533733e8c41ae948abd0615b3d9eb0', 'range': (1082, 1290)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '44cf2b46bc0dd2e206e1af6fbdc15004'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: In diesen Bereichen eröffnet eine Kombination aus industriel-lem Know-\\nhow und KI-Technologien völlig neue Möglichkeiten und verschafft uns eine hervorragende Wettbewerbsposition\\ngegenüber, den USA und China.\\nDurch das von Land und Kommunen getragene Vorhaben der Geodateninfrastruktur Baden-Württemberg\\n(GDI-BW) verfolgen wir, eingebettet in die nationale und europäische Geodateninfrastruktur, das Ziel, die\\nhochwertigen Daten der Verwaltung nach (inter-)nationalen Normen und Standards über interoperable Web-\\nservices für automatisierte Analyse- und Entscheidungsverfahren bei räumlichen Beziehungen in Wirtschaft,\\nWissenschaft und Verwaltung nutzbar zu machen.\\nKI ist neben der Wissenschaft und Wirtschaft auch für die Gesellschaft von zentraler Bedeutung. Hier liegen\\ngroße Chancen und konkrete Herausforderungen. Wie KI gestaltet und eingesetzt wird, hat immense gesell-\\nschaftliche Folgen. Wir brauchen nur nach China schauen, wo KI schon heute für eine umfassende Kontrolle\\nvon Menschen eingesetzt wird. Weil wir eine KI wollen, die auf den Menschen und seine Rechte bezogen ist\\nund mit unseren Wertvorstellungen im Einklang steht, müssen wir ihre Entwicklung selbst vorantreiben – um\\nnicht abhängig zu sein von Ländern, die ganz andere Wertesysteme haben.\\nLeistungsfähige KI-Technologien, die Daten- und Persönlichkeitsrechte schützen, erachten wir dabei als\\neinen entscheidenden Wettbewerbsvorteil. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 40, 'page': 27, '_split_overlap': [{'doc_id': '44cf2b46bc0dd2e206e1af6fbdc15004', 'range': (0, 208)}, {'doc_id': '33faee7cadf8d6ac84547e504d0e12d8', 'range': (1013, 1409)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '55533733e8c41ae948abd0615b3d9eb0'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Weil wir eine KI wollen, die auf den Menschen und seine Rechte bezogen ist\\nund mit unseren Wertvorstellungen im Einklang steht, müssen wir ihre Entwicklung selbst vorantreiben – um\\nnicht abhängig zu sein von Ländern, die ganz andere Wertesysteme haben.\\nLeistungsfähige KI-Technologien, die Daten- und Persönlichkeitsrechte schützen, erachten wir dabei als\\neinen entscheidenden Wettbewerbsvorteil. Hier bedarf es eines europäischen Verständnisses, denn allein\\nwerden wir den globalen Wettbewerb nicht bestehen und keine Standards setzen können. Hierfür braucht es u.\\na. zeitnah ein einsatzfähiges europäisches KI-Netzwerk, das Forschung, Wissen und Know-how bündelt und\\nHerausforderungen im Dialog mit der Gesellschaft diskutiert.\\x0c2.3.\\nIMPULSE FÜR EINE SCHNELLE\\nIMPLEMENTIERUNG DER KI-STRATEGIE DER\\nBUNDESREGIERUNG\\nDas Land Baden-Württemberg hat sich auf den Weg gemacht, eine Leitregion für den digitalen Wandel zu sein.\\nBei der Erforschung und Entwicklung von KI besitzt das Land bereits heute Strahlkraft, die weit über die\\nLandesgrenzen hinausreicht. Mit einer „Wirtschaftsstrategie KI für Baden-Württemberg“ soll darüber hinaus auch\\ndie Anwendung und Kommerzialisierung branchenübergreifend und in der Fläche des Landes vorange -trieben\\nwerden. Gleichzeitig ist uns klar, dass wir angesichts der dramatischen Verschiebungen im Weltgefüge nicht zu\\nklein denken können. Deshalb wollen wir uns mit Partnern im Bundesgebiet und in Europa vernetzen und\\nzusammenarbeiten. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 41, 'page': 27, '_split_overlap': [{'doc_id': '55533733e8c41ae948abd0615b3d9eb0', 'range': (0, 396)}, {'doc_id': '76b859f6a2907455626d2913856abeac', 'range': (1249, 1469)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '33faee7cadf8d6ac84547e504d0e12d8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Gleichzeitig ist uns klar, dass wir angesichts der dramatischen Verschiebungen im Weltgefüge nicht zu\\nklein denken können. Deshalb wollen wir uns mit Partnern im Bundesgebiet und in Europa vernetzen und\\nzusammenarbeiten. Die Gestaltung des digitalen Wandels ist nicht zuletzt eine gemeinsame Aufgabe aller\\nEuropäer.\\nBaden-Württemberg ist aufgrund der hervorragenden Ausgangsbedingungen und des politischen Willens,\\neine führende Rolle bei der Erforschung, Entwicklung, Anwendung und Kommerzialisierung von KI zu erlan-\\ngen, prädestiniert als Standort für die Umsetzung von konkreten Maßnahmen aus der nationalen KI -Strategie.\\nDies gilt sowohl bei der Errichtung von KI-Leuchttürmen mit internationaler Strahlkraft als auch bei mittel-\\nstandsorientierten KI-Maßnahmen. Das Land bietet sich deshalb als Partner der Bundesregierung an.\\nDurch die Kooperation mit den baden-württembergischen Digital- und KI-Initiativen könnte die Bundesre-gierung viele\\nihrer Konzepte schnell, effektiv und sichtbar umsetzen.\\nWir sind der Meinung, dass für einen schnellen Rollout der KI-Strategie der Bundesregierung die erfolgreichen\\nKI-Projekte unseres Landes gestärkt werden sollten. So wie es weltweit Regionen sind, die Digitalisierung und KI-\\nTechnologien voranbringen, sollte Deutschland mit starken Ländern vorangehen. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 42, 'page': 28, '_split_overlap': [{'doc_id': '33faee7cadf8d6ac84547e504d0e12d8', 'range': (0, 220)}, {'doc_id': '45ab13e94d2300c12234af413b0ca976', 'range': (1006, 1307)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '76b859f6a2907455626d2913856abeac'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Wir sind der Meinung, dass für einen schnellen Rollout der KI-Strategie der Bundesregierung die erfolgreichen\\nKI-Projekte unseres Landes gestärkt werden sollten. So wie es weltweit Regionen sind, die Digitalisierung und KI-\\nTechnologien voranbringen, sollte Deutschland mit starken Ländern vorangehen. Für diese Herangehens-\\n14\\x0cBEITRAG BADEN-WÜRTTEMBERGS ZUR ONLINE-KONSULTATION DER BUNDESREGIERUNG 15\\nweise bietet Baden-Württemberg zahlreiche Anknüpfungspunkte:\\nKI IN FORSCHUNG UND ENTWICKLUNG:\\n→ Auf der Basis einer deutschlandweiten Potenzial- und Bestands-analyse regen wir an, dass die\\nBundesregierung die besten Digitali-sierungs- und KI-Initiativen der Länder in die Erarbeitung (im\\nRahmen des laufenden Konsultationsverfahrens und der Exper-tenworkshops)\\nund Umsetzung ihrer KI-Strategie einbindet. Denn das digitale Rad braucht nicht\\nimmer neu erfunden zu werden. Nur eine nationale und europäische Vernetzung\\nund auch budgetä-re Stärkung der besten Initiativen in den Ländern hat das Poten-\\nzial, ein Gegengewicht zu den Digital- und KI-Strategien der USA oder Asiens zu\\nbilden.\\nVon der Grundlagenforschung bis zum Transfer ist das Cyber Valley ein über die\\nLandesgrenzen hinaus strahlender KI-Leucht-turm, an dem bundesweit kein Weg\\nvorbeiführt. Darum wollen wir diese Stärken in die KI-Strategie der Bundesregierung\\nund das deutsch-französische Netzwerk einbringen. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 43, 'page': 28, '_split_overlap': [{'doc_id': '76b859f6a2907455626d2913856abeac', 'range': (0, 301)}, {'doc_id': 'de3dc149a957ab091c8756703394c180', 'range': (1089, 1377)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '45ab13e94d2300c12234af413b0ca976'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Von der Grundlagenforschung bis zum Transfer ist das Cyber Valley ein über die\\nLandesgrenzen hinaus strahlender KI-Leucht-turm, an dem bundesweit kein Weg\\nvorbeiführt. Darum wollen wir diese Stärken in die KI-Strategie der Bundesregierung\\nund das deutsch-französische Netzwerk einbringen. Um unsere Führungs-position zu\\nstärken, sind wir bereit, uns mit weiteren Investitionen in den zielgerichteten Ausbau\\nvon Cyber Valley, die vorhandenen Forschungskompetenzen und in\\nanwendungsorientierte For-schungsaktivitäten einzubringen. Wir wollen\\nSprungInnovationen in Deutschland und Europa vorantreiben.\\n→ Wir können hochattraktive Standorte für Neubaumaßnahmen sowie eine\\nschlagkräftige Umsetzung des Forschungsprojekts nach Kräften unterstützen. Um\\ninternationale Spitzenkräfte und junge Talente anziehen zu können, setzen wir\\nauf die Nähe zu führenden Wirtschafts-, Forschungs- und Bildungsstandorten sowie\\neine hohe Lebens- und Freizeitqualität.\\n→ Wir streben eine enge Kooperation mit der Bundesregierung an, um den weiteren\\nProzess der Entscheidungsfindung für das deutsch-französische Netzwerk für\\nKI voranzubringen. Wir arbeiten bereits aktiv an der Intensivierung der\\nZusammenarbeit mit weiteren Standorten – dies sowohl auf Länderebene als\\nauch im französischen und europäischen Kontext. Wir sind der Meinung, dass\\nnur ein Spitzenverbund der besten Standorte die nötige Signalwirkung für ein\\neuropäisches Leuchtturmprojekt er-zeugen kann. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 44, 'page': 29, '_split_overlap': [{'doc_id': '45ab13e94d2300c12234af413b0ca976', 'range': (0, 288)}, {'doc_id': 'b6e583765acc60244ef9910e2e1419e2', 'range': (1293, 1443)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'de3dc149a957ab091c8756703394c180'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Wir sind der Meinung, dass\\nnur ein Spitzenverbund der besten Standorte die nötige Signalwirkung für ein\\neuropäisches Leuchtturmprojekt er-zeugen kann. Dabei setzen wir auf eine\\nKooperation mit den großen Forschungsorganisationen wie die Max-Planck-\\nGesell-schaft, FraunhoferGesellschaft, Helmholtz-Gemeinschaft und mit der\\nWirtschaft, wie dies bereits beim Cyber Valley, bei S-TEC und in der\\nTechnologieregion Karlsruhe der Fall ist.\\n→ Um die Pläne der Bundesregierung für ein deutsch-französisches\\nNetzwerk zu unterstützen, hat das Land mit potenziellen französi-\\nschen Partnern in den letzten Monaten einen Dialog begonnen.\\nDamit soll die ELLIS-Initiative, eine Initiative der führenden\\x0cBEITRAG BADEN-WÜRTTEMBERGS ZUR ONLINE-KONSULTATION DER BUNDESREGIERUNG 16\\neuropäischen KI-Forscher, als wichtiger Beitrag zur Diskussion über\\neuropäische Vernetzung gestärkt werden. Entscheidend ist, dass die\\nBundesregierung die Leistungsfähigkeit der Infrastrukturen für die KI-\\nForschung stärkt.\\n→ Wir setzen uns dafür ein, dass Förderprogramme des Bundes aus-\\ngeweitet und deutliche KI-Schwerpunkte in den EU-Programmen, wie\\n„Horizon Europa“, gesetzt werden.\\n→ Die Bundesregierung sollte die Doktorandenförderung auswei-ten\\nund insbesondere auch Frauen in der KI-Forschung fördern. Wir\\nmachen uns dafür stark, dass der Bund mehr Förderprogramme für\\ndie Gewinnung von Spitzenforscherinnen und -forschern auf-\\nlegt. Dabei sollte auch die wissenschaftliche Weiterbildung vom\\nBund stärker gefördert werden.\\n→ Ohne Sicherheit ist alles nichts. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 45, 'page': 29, '_split_overlap': [{'doc_id': 'de3dc149a957ab091c8756703394c180', 'range': (0, 150)}, {'doc_id': '50536e1c1371af0e78f546a2262b05c6', 'range': (1274, 1530)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b6e583765acc60244ef9910e2e1419e2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Wir\\nmachen uns dafür stark, dass der Bund mehr Förderprogramme für\\ndie Gewinnung von Spitzenforscherinnen und -forschern auf-\\nlegt. Dabei sollte auch die wissenschaftliche Weiterbildung vom\\nBund stärker gefördert werden.\\n→ Ohne Sicherheit ist alles nichts. Die Bundesregierung sollte daher\\ndie Forschung im Bereich IT-Security verstärkt fördern. Das\\nKompetenzzentrum KASTEL am Karlsruher Institut für Techno-\\nlogie (KIT) sollte als nationaler Leuchtturm verstetigt und ausge-\\nbaut werden.\\n→ Auf Basis der vorhandenen Forschungskompetenzen sowie in\\nKooperation mit etablierten und starken Netzwerken zwischen\\nWissenschaft und Wirtschaft machen wir uns für eine gemeinsa-\\nme Umsetzung von Forschungsvorhaben in Anwendungsfeldern\\nmit hoher Relevanz für die Zukunftsfähigkeit des Wirtschafts-\\nstandorts Deutschland stark. Dabei denken wir u. a. an Industrie\\n4.0, intelligente Mobilität, medizinische Diagnoseverfahren,\\nintelligente Sensorik und Smart B2B Services. Aber auch an\\ndie für die Nachhaltigkeit im Naturraum wichtige Vorhaben\\nwie Landwirtschaft 4.0. Eine besondere Stärke Baden-\\nWürttembergs liegt in der Erforschung und Anwendung von cyber-\\nphysischen Systemen. Für das Industrieland Deutschland\\nbieten sich auf diesem Themenfeld zukunftsträchtige\\nAnwendungen sowohl für die KI-Forschung der\\nIngenieurwissenschaften als auch für erfolg-reiche Anwendungen\\nin zahlreichen Wirtschaftsbereichen wie etwa der Mobilität,\\nProduktions-, Medizin-, Umwelt- oder Energie-technik.\\n→ Wir wollen auch bei der wirtschaftsnahen Forschung eine Füh-\\nrungsrolle einnehmen. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 46, 'page': 30, '_split_overlap': [{'doc_id': 'b6e583765acc60244ef9910e2e1419e2', 'range': (0, 256)}, {'doc_id': '7b0c6b54428fe19944e6717f638d1a72', 'range': (1169, 1560)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '50536e1c1371af0e78f546a2262b05c6'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Für das Industrieland Deutschland\\nbieten sich auf diesem Themenfeld zukunftsträchtige\\nAnwendungen sowohl für die KI-Forschung der\\nIngenieurwissenschaften als auch für erfolg-reiche Anwendungen\\nin zahlreichen Wirtschaftsbereichen wie etwa der Mobilität,\\nProduktions-, Medizin-, Umwelt- oder Energie-technik.\\n→ Wir wollen auch bei der wirtschaftsnahen Forschung eine Füh-\\nrungsrolle einnehmen. Ein neues KI-Zentrum für angewandte\\nForschung hätte für Baden-Württemberg und Deutschland eine\\ninternationale Leuchtturmfunktion und würde die institutions-\\nübergreifende Kooperationen zwischen Wirtschaft, Forschung und\\nWissenschaft stärken.\\nKI IN DER ANWENDUNG UND KOMMERZIALISIERUNG:\\n→ Der de:hub für Angewandte Künstliche Intelligenz in Karlsruhe\\nbildet eine Blaupause, um auf der Basis der KI-Strategie der\\x0cBundesregierung zu einem Leuchtturm bundes- und EU-weit\\nweiterentwickelt zu werden. Der de:hub in Karlsruhe wird weitere\\nde:hubs der Bundesregierung und die regionalen Digital Hubs der\\nLandesregierung vernetzen, um KI-Technologien und „Use Cases“\\nzusammenzubringen und gemeinsame Kooperationsprojekte in\\nTechnologietransfer und Anwendung von KI umzusetzen.\\nDas Netzwerk aus de:hub KI und den regionalen Digital Hubs als\\nIdeen-, Experimentier- und Kollaborationsräumen könnte zur\\nPlattform für einen effektiven und effizienten Wissenstransfer an\\nkleine und mittlere Unternehmen (KMU) ausgebaut werden, um\\nso branchenübergreifend und in der Fläche des Landes die Ent-\\nwicklung, Anwendung und Kommerzialisierung von KI-Produkten\\nund KI-Dienstleistungen voranzutreiben.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 47, 'page': 30, '_split_overlap': [{'doc_id': '50536e1c1371af0e78f546a2262b05c6', 'range': (0, 391)}, {'doc_id': 'e1953198a5d43c60cdc36dc108dfbd94', 'range': (1160, 1568)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7b0c6b54428fe19944e6717f638d1a72'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Das Netzwerk aus de:hub KI und den regionalen Digital Hubs als\\nIdeen-, Experimentier- und Kollaborationsräumen könnte zur\\nPlattform für einen effektiven und effizienten Wissenstransfer an\\nkleine und mittlere Unternehmen (KMU) ausgebaut werden, um\\nso branchenübergreifend und in der Fläche des Landes die Ent-\\nwicklung, Anwendung und Kommerzialisierung von KI-Produkten\\nund KI-Dienstleistungen voranzutreiben.\\nMit Unterstützung der Bundesregierung könnte im Herzen der\\nTechnologieRegion Karlsruhe ein internationales Netzwerk für\\nangewandte KI eingerichtet werden. Der de:hub sollte daher als\\nLeuchtturmprojekt des Bundes auch direkt vom Bund finanziell\\nunterstützt werden.\\nWir wollen im Land die Kommerzialisierung von KI voranbringen und\\ndazu neues Wissen, KI-affine Unternehmen aus Deutschland,\\ninsbesondere dem Mittelstand, KI-Start-ups und internationale\\nUnternehmen noch näher zusammenbringen. Dazu prüft das Land\\nderzeit die Errichtung weiterer Strukturen, wie z. B. große „Innova-\\ntionsparks KI“ als Wertschöpfungszentren für Kommerzialisierung\\nmit internationaler Strahlkraft und als Testfelder für die Praxis-\\ntauglichkeit von KI-Anwendungen. Diese sollen die bestehenden\\nStrukturen sinnvoll ergänzen und erweitern.\\n→ Wir regen an, dass die Bundesregierung die Anwendungsfelder\\nvon KI auch auf die Themenfelder Gesundheit, Mobilität und\\nNachhaltigkeit (z. B. Stärkung der Energiewende, Ressourcen-\\neffizienz, gesellschaftliche Auswirkungen sowie die Schonung\\nnatürlicher und personeller Ressourcen) ausweitet. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 48, 'page': 31, '_split_overlap': [{'doc_id': '7b0c6b54428fe19944e6717f638d1a72', 'range': (0, 408)}, {'doc_id': 'aff9d4743b609cf1e2df4ae2f458d132', 'range': (1225, 1518)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e1953198a5d43c60cdc36dc108dfbd94'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: → Wir regen an, dass die Bundesregierung die Anwendungsfelder\\nvon KI auch auf die Themenfelder Gesundheit, Mobilität und\\nNachhaltigkeit (z. B. Stärkung der Energiewende, Ressourcen-\\neffizienz, gesellschaftliche Auswirkungen sowie die Schonung\\nnatürlicher und personeller Ressourcen) ausweitet. KI sollte in der\\nAnwendung gezielt vorangebracht werden und den Menschen in\\nunserem Land einen konkreten Nutzen stiften.\\nKI UND MITTELSTAND:\\n→ Wir brauchen ein Aktionsprogramm „KI für den Mittelstand“.\\nDamit gerade auch bei den mittelständischen Unternehmen die\\nAnwendung von KI erfolgreich umgesetzt werden kann, muss der\\nTransfer zwischen Forschungseinrichtungen und Unterneh-men\\nschneller werden. Das kann mit Wettbewerben für KI-Test-felder,\\nVerbundprojekten, einer „KI Innovation Challenge“ oder\\n„Regionalen KI-Labs“ vorangebracht werden.\\n→ Beim Wissens- und Technologietransfer und einer darauf aufbau-enden\\nKommerzialisierung von KI ist aus Sicht der Landesregie-\\nBEITRAG BADEN-WÜRTTEMBERGS ZUR ONLINE-KONSULTATION DER BUNDESREGIERUNG 17\\x0crung entscheidend, den Fokus auf eine gezielte Unterstützung des\\nMittelstands zu legen. Baden-Württemberg setzt bereits sehr\\nerfolgreich Instrumente wie die Digitalisierungsprämie oder Pop-\\nup-Labore ein, die mit Unterstützung des Bundes gezielt in\\nRichtung KI weiter ausgebaut werden können. Dies gilt auch für\\nTransfereinrichtungen wie BIEC (Business Innovation Engineering\\nCenter) und S-TEC, die speziell auf KMU ausgerichtet sind.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 49, 'page': 31, '_split_overlap': [{'doc_id': 'e1953198a5d43c60cdc36dc108dfbd94', 'range': (0, 293)}, {'doc_id': '4197d64da99a2520ba1480e8bc83135d', 'range': (1127, 1473)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'aff9d4743b609cf1e2df4ae2f458d132'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Baden-Württemberg setzt bereits sehr\\nerfolgreich Instrumente wie die Digitalisierungsprämie oder Pop-\\nup-Labore ein, die mit Unterstützung des Bundes gezielt in\\nRichtung KI weiter ausgebaut werden können. Dies gilt auch für\\nTransfereinrichtungen wie BIEC (Business Innovation Engineering\\nCenter) und S-TEC, die speziell auf KMU ausgerichtet sind.\\nMit der einzelbetrieblichen Fördermaßnahme Digitalisierungs-\\nprämie für kleinere KMU sind bereits aktuell Maßnahmen zur\\nAnwendung von KI förderfähig. Die förderfähigen Maßnahmen des\\nModellversuchs beinhalten u. a. die Vorhaben „Einführung von\\nMensch-Maschinen-Interaktion in der Produktion“ und „Einfüh-rung\\ndatenbasierter Dienstleistungen“. Aus Sicht der Landes-regierung\\nwäre eine Förderung des Bundes auch für größere KMU und\\nMidcaps wünschenswert.\\nAuch eine Ausweitung des ZIM im Hinblick auf die Entwicklung\\nvon KI-Innovationen wäre sinnvoll. Schließlich sollte die geplante\\nAgentur für Sprunginnovationen gerade auch die Umsetzung von\\nForschungs- und Entwicklungsergebnissen in marktfähige Produkte\\nund Dienstleistungen beschleunigen. In diesem Zusammenhang\\nsollten sowohl KMU als auch Midcaps in die Förderung einbezogen\\nwerden.\\nPopup-Labore sind in Baden-Württemberg ein sehr erfolgreiches\\nTransferformat. Die Labore werden temporär an verschiedenen\\nStandorten aufgebaut, um KMU Impulse und Know-how für Inno-\\nvationen zu vermitteln. Die Konzeption für pilothafte Durchfüh-\\nrung von speziellen KI-Popup-Laboren könnte aus Bundesmitteln\\nfinanziert werden.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 50, 'page': 32, '_split_overlap': [{'doc_id': 'aff9d4743b609cf1e2df4ae2f458d132', 'range': (0, 346)}, {'doc_id': 'e83db84fb9cc1af3e24d286c45589123', 'range': (1261, 1509)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4197d64da99a2520ba1480e8bc83135d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Die Labore werden temporär an verschiedenen\\nStandorten aufgebaut, um KMU Impulse und Know-how für Inno-\\nvationen zu vermitteln. Die Konzeption für pilothafte Durchfüh-\\nrung von speziellen KI-Popup-Laboren könnte aus Bundesmitteln\\nfinanziert werden.\\nDas BIEC (Business Innovation Engineering Center) soll Unter-\\nnehmen bei ihrem Transformationsprozess hin zu neuen digitalen\\nGeschäftsmodellen unterstützen. Neue technologische Entwick-\\nlungen (und damit u. a. auch KI) sollen eng begleitet werden, um\\ndiese schnellstmöglich in Richtung der Unternehmen zu trans-\\nportieren und für diese anwendbar zu machen (Technologie- und\\nWissenstransfer). Damit ist KI in BIEC angelegt und wird in diesem\\nRahmen berücksichtigt. Als komplementäre, spezialisierte Trans-\\nfereinrichtung könnte zudem ein anwendungsorientiertes Kompe-\\ntenzzentrum für KI-basierte Dienstleistungsinnovationen im\\nMittelstand errichtet werden. Für eine finanzielle Unterstützung\\ndurch die Bundesregierung macht sich die Landesregierung stark.\\nFür etwaige Testbeds, Versuchsfelder und pilothafte Technologie-\\ntransferinitiativen des Bundes würden sich die Fraunhofer-Insti-tute\\nsowie die Institute der Innovationsallianz Baden-Württemberg\\nhervorragend eignen. Das resultiert aus der starken Transferorien-\\ntierung dieser Institute und ihren umfangreichen Erfahrungen in der\\nZusammenarbeit mit Unternehmen, insbesondere KMU. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 51, 'page': 32, '_split_overlap': [{'doc_id': '4197d64da99a2520ba1480e8bc83135d', 'range': (0, 248)}, {'doc_id': '4c2bcaf4e4a08e18d9f302e888697486', 'range': (1220, 1383)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e83db84fb9cc1af3e24d286c45589123'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Das resultiert aus der starken Transferorien-\\ntierung dieser Institute und ihren umfangreichen Erfahrungen in der\\nZusammenarbeit mit Unternehmen, insbesondere KMU. Aus bereits\\numgesetzten Projekten wie dem Applikationszentrum\\nBEITRAG BADEN-WÜRTTEMBERGS ZUR ONLINE-KONSULTATION DER BUNDESREGIERUNG 18\\x0cBEITRAG BADEN-WÜRTTEMBERGS ZUR ONLINE-KONSULTATION DER BUNDESREGIERUNG 19\\nIndustrie 4.0 oder dem Testfeld Autonomes Fahren sind umfan-\\ngreiche Vorerfahrungen für die Umsetzung von Testbeds durch die\\nBundesregierung vorhanden.\\nKI UND START-UPS:\\n→ Die Bundesregierung sollte mehr Risikokapital für KI-getriebene\\nInnovationen bereitstellen. Eine zentrale Komponente beim Auf-\\nbau von KI-Ökosystemen und der Kommerzialisierung von KI sind\\ndie vielfältigen Initiativen der Landesregierung bei der Start-up-\\nFörderung, beispielsweise die Start-up-BW Acceleratoren, die\\ndiversen Förderprogramme an Hochschulen und Start-up-BW\\nPre-Seed. Eine Ko-Finanzierung des Bundes könnte einen wichtigen\\nBeitrag zur nachhaltigen Gestaltung dieser Angebote leisten.\\nKI-TALENTS:\\n→ In der Aus- und Weiterbildung von Fachkräften und Nachwuchs-\\nkräften muss KI systematisch eingebunden werden. Es braucht\\neine geeignete Qualifizierung, damit die Beschäftigten Daten-\\nbestände erfassen, analysieren und nutzbar machen können.\\nDazu sind Investitionen sowohl in die Ausstattung und Infrastruk-\\ntur der Bildungsträger als auch in das Know-how der Lehrkräfte er-\\nforderlich. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 52, 'page': 32, '_split_overlap': [{'doc_id': 'e83db84fb9cc1af3e24d286c45589123', 'range': (0, 163)}, {'doc_id': 'af109fe74bf04a4d63002d971fe0f64d', 'range': (1300, 1444)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4c2bcaf4e4a08e18d9f302e888697486'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Dazu sind Investitionen sowohl in die Ausstattung und Infrastruk-\\ntur der Bildungsträger als auch in das Know-how der Lehrkräfte er-\\nforderlich. Wir setzen uns dafür ein, dass die Bundesregierung –\\nnach dem Vorbild der Lernfabriken 4.0 – gemeinsam mit den\\nUnternehmen vor Ort KI-Lernlabore und KI-Lernfabriken fördert.\\nAußerdem regen wir an, dass die Bundesregierung mit neuen\\nInstrumenten die Aus- und Weiterbildung der Beschäftigten in der\\nFläche unterstützt.\\nZUKUNFT DER ARBEIT:\\n→ Unser Future Work Lab am Fraunhofer IAO/IPA eignet sich auf-grund des dort erarbeiteten\\nKnow-how und des bereits statt-findenden Transfers in die Wirtschaft hervorragend für\\nZentren-und Labs der Bundesregierung mit dem Thema Arbeit und Organisation im Bereich\\nKI.\\n→ Mit dem Förderprogramm für Lernfabriken 4.0 wurde ein bundes-\\nweit einzigartiges Netz von Lernorten geschaffen, an denen die\\nDigitalisierung der Wirtschaft in Aus- und Weiterbildung praktisch\\nfass- und erlebbar wird. Auf Basis dieses Konzepts kann jederzeit\\neine Erweiterung und Vertiefung in Richtung KI erfolgen. Die\\nLandesregierung von Baden-Württemberg ist offen für eine\\nKooperation mit dem Bund bei der Entwicklung innovativer\\nFormate der Aus- und Weiterbildung.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 53, 'page': 33, '_split_overlap': [{'doc_id': '4c2bcaf4e4a08e18d9f302e888697486', 'range': (0, 144)}, {'doc_id': 'df1170083e0066bff7b5bc7e7fb3451c', 'range': (1065, 1218)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'af109fe74bf04a4d63002d971fe0f64d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Die\\nLandesregierung von Baden-Württemberg ist offen für eine\\nKooperation mit dem Bund bei der Entwicklung innovativer\\nFormate der Aus- und Weiterbildung.\\x0cBEITRAG BADEN-WÜRTTEMBERGS ZUR ONLINE-KONSULTATION DER BUNDESREGIERUNG 20\\nKI UND RAHMENBEDINGUNGEN:\\n→ Deutschland und Europa brauchen rechtliche und gesellschaft-\\nliche Rahmenbedingungen für eine schnelle und effektive KI-\\nEntwicklung und deren Umsetzung. Dazu gehören auch Standards\\nfür IT-Sicherheit, Datenschutz in den Bereichen, die personenbezo-\\ngene Daten analysieren, z. B. im medizinischen Bereich, und inter-\\ndisziplinäre Forschungsprojekte sowie flächendeckende High-\\nSpeed-Netze. Ebenso gehört die Erforschung von Fragen der\\nAkzeptanz zu den wesentlichen Fragen.\\n→ KI stellt Wirtschaft und Staat bei Cybersicherheit vor neue Her-\\nausforderungen. Im Rahmen von Kooperationen zwischen Bund\\nund Land könnten diese neuen Herausforderungen insbesondere\\nfür mittelständische Unternehmen und kritische Infrastrukturen\\ngemeinsam adressiert werden.\\n→ Neben zukünftigen KI-Softwarelösungen ist auch die Kompetenz-\\nsicherung bei sicheren, hardwarebasierten KI-Lösungen äußerst\\nwichtig, um möglichst unabhängig von Drittanbietern zu bleiben.\\nUniversitäten und Forschungsinstituten der Innovationsallianz\\nBaden-Württemberg verfügen über das spezialisierte Know-how\\nbei hardwarebasierten KI-Lösungen und entsprechenden Schnitt-\\nstellen, beispielsweise den neuromorphen Chips. Hervorzuheben\\nist hier das mit einer Milliarde Euro von der EU-Kommission\\ngeförderte FET-Flagship „Human Brain“ (u. a. Uni Heidelberg) zum\\nneuromorphen Computing. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 54, 'page': 33, '_split_overlap': [{'doc_id': 'af109fe74bf04a4d63002d971fe0f64d', 'range': (0, 153)}, {'doc_id': 'f04e977807a7b8043d31a38f04b19923', 'range': (1427, 1589)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'df1170083e0066bff7b5bc7e7fb3451c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Hervorzuheben\\nist hier das mit einer Milliarde Euro von der EU-Kommission\\ngeförderte FET-Flagship „Human Brain“ (u. a. Uni Heidelberg) zum\\nneuromorphen Computing. Für die geplante Einrichtung von\\nKompetenzzentren bei hardwarebasierten KI-Lösungen durch die\\nBundesregierung würde sich das IMS Chips gemeinsam mit wei-\\nteren Instituten der Innovationsallianz Baden-Württemberg und\\nggf. mit Fraunhofer-Instituten des Landes hervorragend eignen.\\nEbenso entsprechende Forschungsgruppen an den Max-Planck-\\nInstituten.\\n→ Neben unseren Bemühungen, dass Baden-Württemberg eine\\nwesentliche Rolle bei dem von der Bundesregierung geplanten\\ndeutsch-französischen Zentrum für KI spielt, setzen wir uns dafür ein,\\ndie nationale und europäische Zusammenarbeit insgesamt zu\\nverstärken. Dies gilt es auch vor dem Hintergrund der KI-Strategien\\nder Bundesregierung und der EU gezielt anzugehen. Hierbei ist die\\nZugänglichkeit notwendiger Daten ein wesentliches Ziel anzu-\\nstrebender Kooperationsbemühungen. Das Land setzt sich seit\\nJahren für einen ermöglichenden Datenschutz in dem Bereich der\\nForschung ein.\\x0c2.4.\\nWIE BADEN-WÜRTTEMBERG BEI KI-TECHNOLOGIEN\\nVORANGEHT\\nWIR BAUEN UNSERE SPITZENSTELLUNG\\nBEI FORSCHUNG UND ENTWICKLUNG WEITER AUS1\\nBaden-Württemberg ist die Region mit der höchsten Innovationskraft innerhalb der Europäischen Union.\\nÜber 4,9 Prozent des Bruttoinlandsprodukts werden in Baden-Württemberg in Forschung und Entwicklung\\ninvestiert. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 55, 'page': 34, '_split_overlap': [{'doc_id': 'df1170083e0066bff7b5bc7e7fb3451c', 'range': (0, 162)}, {'doc_id': '27f84fb9cc98856b063a9aad1b08e4d8', 'range': (1095, 1434)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f04e977807a7b8043d31a38f04b19923'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: WIE BADEN-WÜRTTEMBERG BEI KI-TECHNOLOGIEN\\nVORANGEHT\\nWIR BAUEN UNSERE SPITZENSTELLUNG\\nBEI FORSCHUNG UND ENTWICKLUNG WEITER AUS1\\nBaden-Württemberg ist die Region mit der höchsten Innovationskraft innerhalb der Europäischen Union.\\nÜber 4,9 Prozent des Bruttoinlandsprodukts werden in Baden-Württemberg in Forschung und Entwicklung\\ninvestiert. Der hohe Anteil, der im Südwesten von Unternehmen und Land für Forschung und Entwicklung\\naufgewandt wird, bietet eine exzellente Ausgangsbasis für Baden-Württemberg, um auch im Digitalen\\nWandel ein führender Hochtechnologiestandort zu bleiben. Wir unternehmen daher besondere\\nAnstrengungen, um Forschung und Entwicklung im Bereich der KI zu fördern. Wir wollen, dass die\\nGrundlagen für KI in Baden-Württemberg erforscht werden und der oftmals kurze Weg aus der Forschung in\\ndie Anwendung bestmöglich gelingt.\\nCYBER VALLEY\\nMit dem Innovationscampus Cyber Valley haben wir in Baden-Württemberg ein europaweit einmaliges\\nForschungszentrum für intelligente Systeme geschaffen und zugleich einen Hotspot für wissenschaftliche Exzellenz,\\nder weltweit die besten Köpfe auf dem Gebiet der KI und des Maschinellen Lernens anzieht.\\n1 Handlungsfeld Forschung des KI-Eckpunktepapiers der Bundesregierung.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 56, 'page': 35, '_split_overlap': [{'doc_id': 'f04e977807a7b8043d31a38f04b19923', 'range': (0, 339)}, {'doc_id': '73a94bbcbaa31b0f2ce9eb8353a50abe', 'range': (849, 1232)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '27f84fb9cc98856b063a9aad1b08e4d8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: CYBER VALLEY\\nMit dem Innovationscampus Cyber Valley haben wir in Baden-Württemberg ein europaweit einmaliges\\nForschungszentrum für intelligente Systeme geschaffen und zugleich einen Hotspot für wissenschaftliche Exzellenz,\\nder weltweit die besten Köpfe auf dem Gebiet der KI und des Maschinellen Lernens anzieht.\\n1 Handlungsfeld Forschung des KI-Eckpunktepapiers der Bundesregierung.\\n21\\x0cBEITRAG BADEN-WÜRTTEMBERGS ZUR ONLINE-KONSULTATION DER BUNDESREGIERUNG 22\\nHier haben sich die Max-Planck-Gesellschaft (das Max-Planck-Institut für Intelligente Systeme, MPI), die\\nbeiden Universitäten Stuttgart und Tübingen, das Land BadenWürttemberg (Ministerium für Wissenschaft,\\nForschung und Kunst) sowie verschiedene Wirtschaftsunternehmen (BOSCH, Daimler, Porsche, BMW, IAV,\\nZF Friedrichshafen und Amazon) zu einem Innovationscampus zusammengeschlossen.\\nUnterstützt von Stiftungen werden die Cyber-Valley-Partner zusammen mehr als 140 Mio. Euro in den Stand-\\nort investieren.\\n→ Es erfolgt nicht nur exzellente Grundlagenforschung, wie sie am\\nMPI mit dem Leibniz-Preisträger von 2018, Prof. Bernhard Schölkopf,\\nund an den beiden Universitäten betrieben wird. Ebenso wichtig\\nist die Ausbildung von hochqualifizierten Nachwuchskräften für\\nWirtschaft und Wissenschaft. Erst kürzlich haben die Universität\\nTübingen und das MPI für Intelligente Systeme in der Ausschreibung\\ndes BMBF zu „Kompetenzzentren für maschinelles Lernen“ den\\nZuschlag für das Konzept „Tübinger Zentrum für Robustes Lernen“\\nerhalten. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 57, 'page': 35, '_split_overlap': [{'doc_id': '27f84fb9cc98856b063a9aad1b08e4d8', 'range': (0, 383)}, {'doc_id': 'de9cb5d8627427b47eebf40f6e39a48', 'range': (1257, 1492)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '73a94bbcbaa31b0f2ce9eb8353a50abe'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Erst kürzlich haben die Universität\\nTübingen und das MPI für Intelligente Systeme in der Ausschreibung\\ndes BMBF zu „Kompetenzzentren für maschinelles Lernen“ den\\nZuschlag für das Konzept „Tübinger Zentrum für Robustes Lernen“\\nerhalten. Das Exzellenzcluster „Maschinelles Lernen: Neue Pers-\\npektiven für die Wissenschaft“ wird im Rahmen der bundesweiten\\nExzellenzstrategie an der Universität Tübingen gefördert.\\n→ Erklärtes Ziel von Cyber Valley ist es, die Ergebnisse der Forschung\\nrasch zur Anwendung zu bringen, etwa indem Forschende dabei\\nunterstützt werden, ihre Erkenntnisse in Start-ups zu kommerziali-\\nsieren. Start-ups, die im Umfeld der Forschung entstehen, sind\\nMotoren des Technologietransfers in Wirtschaft und Gesellschaft.\\n→ In der internationalen Max-Planck-Graduiertenschule für Intelligente\\nSysteme sollen in den kommenden Jahren 100 Doktoranden aus-\\ngebildet werden. Es wurden vier Forschungsgruppen an den Uni-\\nversitäten Stuttgart und Tübingen und fünf weitere am MPI für\\nIntelligente Systeme eingerichtet.\\n→ Zehn neue Professuren mit Schwerpunkt KI werden alleine an den\\nUniversitäten Stuttgart und Tübingen zur Stärkung des Forschungs-\\nfelds geschaffen. Eine von BOSCH finanzierte Stiftungsprofessur\\nund eine weitere „Industry on Campus“ Professur haben ihre\\nwissenschaftliche Tätigkeit an der Universität Tübingen bereits\\nbegonnen. An der Universität Stuttgart wird zur Zeit eine von\\nDaimler finanzierte Stiftungsprofessur besetzt.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 58, 'page': 36, '_split_overlap': [{'doc_id': '73a94bbcbaa31b0f2ce9eb8353a50abe', 'range': (0, 235)}, {'doc_id': 'b295754049927be45cca15238a5964f1', 'range': (1176, 1454)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'de9cb5d8627427b47eebf40f6e39a48'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Eine von BOSCH finanzierte Stiftungsprofessur\\nund eine weitere „Industry on Campus“ Professur haben ihre\\nwissenschaftliche Tätigkeit an der Universität Tübingen bereits\\nbegonnen. An der Universität Stuttgart wird zur Zeit eine von\\nDaimler finanzierte Stiftungsprofessur besetzt.\\nSchon heute zeigt sich die besondere Strahlkraft dieses neuen Forschungszentrums: Der Raum Tübingen/\\nStuttgart liegt mit rund 24 Prozent bundesweit deutlich an erster Stelle bei den Veröffentlichungen zur KI.\\nBeim Maschinellen Lernen schafft es die Region sogar unter den TOP 10 in der Welt.\\nDass dennoch weit größere Anstrengungen nötig sind, zeigt der internationale Vergleich: Obwohl Deutsch land\\nin der KI-Forschung international anerkannte Ergebnisse aufweisen kann, müssen die Forschungsressour-cen\\nweiter aufgebaut werden. Vor allem muss es gelingen, dass Deutschland und Baden-Württemberg bei\\nForschung und der Kommerzialisierung von KI rasch voranschreiten, um an diesem stark wachsenden Ge-\\nschäftsfeld mit globalen Wachstumsraten von jährlich über 40 Prozent teilhaben zu können.\\x0cBEITRAG BADEN-WÜRTTEMBERGS ZUR ONLINE-KONSULTATION DER BUNDESREGIERUNG 23\\nWEITERE KI-PROFESSUREN EINGERICHTET\\nMit 6 Mio. Euro finanziert Baden-Württemberg insgesamt zehn Juniorprofessuren mit Ausstattungen im Be-reich\\nMethoden und Anwendungen der KI an den Universitäten Freiburg, Heidelberg, Hohenheim, Konstanz,\\nMannheim, Ulm und am Karlsruher Institut für Technologie (KIT). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 59, 'page': 36, '_split_overlap': [{'doc_id': 'de9cb5d8627427b47eebf40f6e39a48', 'range': (0, 278)}, {'doc_id': 'cb64eaa110dc7db5902aed60ec327c01', 'range': (1191, 1447)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b295754049927be45cca15238a5964f1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Euro finanziert Baden-Württemberg insgesamt zehn Juniorprofessuren mit Ausstattungen im Be-reich\\nMethoden und Anwendungen der KI an den Universitäten Freiburg, Heidelberg, Hohenheim, Konstanz,\\nMannheim, Ulm und am Karlsruher Institut für Technologie (KIT). Mit den neuen Professuren baue n wir Kom-\\npetenz im ganzen Land aus und verbreitern damit die KI-Forschungsförderung über die bisherigen Zentren\\nhinaus. Die Professuren sollen in leistungsstarken Forschungsfeldern der Universitäten auch außerhalb der\\nInformatik angesiedelt werden. So beispielsweise in den Bereichen IT-Sicherheit oder bei der Erforschung ge-\\nsellschaftlicher Rahmenbedingungen. Denn KI spielt über Fächergrenzen hinweg eine entscheidende Rolle.\\nHIGH PERFORMANCE COMPUTING\\nMit „Hazel Hen“ im Höchstleistungsrechenzentrum der Universität Stuttgart verfügen wir in Baden-Würt-\\ntemberg über einen der schnellsten Großrechner der Welt. Im ganzen Land sind leistungsstarke Großrechner\\nmiteinander vernetzt, um komplexe Rechenoperationen für Wissenschaft und Wirtschaft zu ermöglichen. Die\\nEbenen sind durchlässig und so organisiert, dass die von den Anwendern gestellten Anfragen nach Rechen-\\nkapazitäten immer gerade von den Rechnern bearbeitet werden, die für das jeweilige Problem geeignet sind.\\nDamit werden auf allen Ebenen die Kapazitäten optimal ausgelastet. Die HPC (High-Performance-Com-puting)-\\nLandesstrategie ist bundesweit einzigartig und wurde vom Wissenschaftsrat und der Deutschen\\nForschungsgemeinschaft als beispielgebend und innovativ bewertet.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 60, 'page': 37, '_split_overlap': [{'doc_id': 'b295754049927be45cca15238a5964f1', 'range': (0, 256)}, {'doc_id': 'fc80d81fdafd62bad5d4741ca078d8', 'range': (1335, 1531)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'cb64eaa110dc7db5902aed60ec327c01'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Die HPC (High-Performance-Com-puting)-\\nLandesstrategie ist bundesweit einzigartig und wurde vom Wissenschaftsrat und der Deutschen\\nForschungsgemeinschaft als beispielgebend und innovativ bewertet.\\nS-TEC\\nDer Stuttgarter Technologie- und Innovationscampus S-TEC der Fraunhofer Gesellschaft und der Universi-\\ntät Stuttgart ist ein weiterer Leuchtturm der anwendungsnahen KI-Forschung in Baden-Württemberg. S-TEC\\numfasst derzeit u. a. das „Leistungszentrum Mass Personalization“ und ein „Kompetenzzentrum für „Cyber\\nCognitive Intelligence“ mit\\nFokus auf den Einsatz neuer Technologien in der industriellen Produktion v. a. in den Bereichen\\nMaschinelles Lernen, Robotik und kognitive Intelligenz mit Anwendungsfeldern für KMU. Wir streben den\\nAusbau von S-TEC an.\\nTECHNOLOGIEREGION KARLSRUHE MIT DEM DIGITAL HUB ARTIFICIAL INTELLIGENCE (DE:HUB)\\nAm Karlsruher Institut für Technologie (KIT) als bundesweit größter, gemeinsam von Bund und Land getrage-ner\\nForschungseinrichtung, liegt ein weiterer Forschungsschwerpunkt auf angewandte KI, Informationstech-nik, Roboter und\\nCybersicherheit.\\nZusammen mit dem FZI Forschungszentrum Informatik, dem Fraunhofer-Institut für Optronik, Systemtechnik und\\nBildauswertung (IOSB) und der Wirtschaft treiben wir am Standort Karlsruhe vor allem auch anwen-\\ndungsorientierte Forschungs- und Entwicklungsvorhaben zum Einsatz von KI und Big-Data-Anwendungen voran.\\nHinzu kommen IT- und Cybersicherheit im Rahmen des BMBF-Kompetenzzentrums KASTEL sowie An-\\nwendungsdomänen der Industrie 4.0, an denen wir forschen. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 61, 'page': 37, '_split_overlap': [{'doc_id': 'cb64eaa110dc7db5902aed60ec327c01', 'range': (0, 196)}, {'doc_id': '217e0ce3737e3921d825bc9dd5ef128f', 'range': (1392, 1540)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fc80d81fdafd62bad5d4741ca078d8'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Hinzu kommen IT- und Cybersicherheit im Rahmen des BMBF-Kompetenzzentrums KASTEL sowie An-\\nwendungsdomänen der Industrie 4.0, an denen wir forschen. Cybersicherheit erachten wir als einen zentralen\\nSchlüssel, damit die Menschen in unserem Land KI-Anwendungen in der Breite nutzen und die Digitalisierung zu\\neinem Erfolg wird.\\nZentraler Pfeiler der herausragenden Forschungs- und Anwendungsstärke des Standorts Karlsruhe ist die An-\\nsiedlung des nationalen „Digital Hub Artificial Intelligence“ im Rahmen der de:hub-Initiative des Bundesmi-\\nnisteriums für Wirtschaft und Energie (BMWi). Träger der Initiative ist u. a. das europaweit führen de IT-Unter-\\nnehmensnetzwerk CyberForum mit mehr als 4.400 Digitalunternehmen in der Technologieregion Karlsruhe.\\x0cBEITRAG BADEN-WÜRTTEMBERGS ZUR ONLINE-KONSULTATION DER BUNDESREGIERUNG 24\\nKnotenpunkte des prosperierenden Karlsruher IT-Ökosystems und Kernpartner des de:hub für Angewandte\\nKünstliche Intelligenz sind insbesondere:\\n→ FZI (Forschungszentrum Informatik) und dem HoLL (House of Living Labs)\\n→ CyberForum und CyberLab (IT-Accelerator des Landes Baden-Württemberg)\\n→ Fraunhofer IOSB\\n→ KIT\\n→ Technologiefabrik.\\nRund 30.000 Arbeitsplätze aus der Digital-Branche und ca. 10.000 IT-Studierende runden dieses deutsch-\\nlandweit einmalige Öko-System ab. Im CyberLab werden aktuell 15 Start-ups bei der Entwicklung KI-basierter\\nGeschäftsmodelle unterstützt. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 62, 'page': 37, '_split_overlap': [{'doc_id': 'fc80d81fdafd62bad5d4741ca078d8', 'range': (0, 148)}, {'doc_id': '600587ed1ba5c204677f92329c1ceb21', 'range': (1218, 1399)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '217e0ce3737e3921d825bc9dd5ef128f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: 10.000 IT-Studierende runden dieses deutsch-\\nlandweit einmalige Öko-System ab. Im CyberLab werden aktuell 15 Start-ups bei der Entwicklung KI-basierter\\nGeschäftsmodelle unterstützt. Der Digital Hub Karlsruhe wird die zwölf de:hubs deutschlandweit vernetzen, um\\nKI-Technologien und -Anwendungen zusammenzubringen und einen schnellen Technologietransfer ins-\\nbesondere in Richtung KMU zu ermöglichen.\\nWIR BRINGEN KI ZUR ANWENDUNG2\\nWir forschen in Baden-Württemberg nicht nur auf Welt- und Spitzenniveau, sondern bringen KI-Technologie mit\\nLeuchtturmvorhaben sichtbar und erlebbar zur Anwendung. Wir wollen das Leben und die Lebensqualität der\\nMenschen in unserem Land mit den vielfältigen Möglichkeiten der KI-Technologie spürbar verbessern.\\nDabei setzen wir auf KI-Produkte und -Dienstleistungen „Made in Baden-Württemberg“, die als Gütesiegel für\\nhohen Innovationsgehalt, wirtschaftliches Potenzial, hohe Datenschutz-Standards, den Schutz der\\nPersön-lichkeitsrechte und Diskriminierungsfreiheit stehen. Wir sind der festen Überzeugung, dass darin ein grocer\\nWettbewerbsvorteil von Deutschland und Europa gegenüber den USA und Asien liegt. Denn die Bürgerinnen und\\nBürger sowie die Unternehmen werden nur dann neuen Technologien vertrauen und sie nutzen, wenn sie sicher\\nsind, dass sie die Souveränität über ihre Daten behalten und mit ihren Daten sorgsam umgegangen wird. Die\\neinzelnen Projekte können der beigefügten Anlage entnommen werden. KI-Technologie gestalten wir u. a. mit\\ndiesen Leuchtturmprojekten:\\n2Handlungsfeld Anwendungstransfer des KI-Eckpunktepapiers der Bundesregierung.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 63, 'page': 38, '_split_overlap': [{'doc_id': '217e0ce3737e3921d825bc9dd5ef128f', 'range': (0, 181)}, {'doc_id': '5556780eeb39ed5f1ebf9d99c02aaa59', 'range': (1372, 1588)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '600587ed1ba5c204677f92329c1ceb21'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Die\\neinzelnen Projekte können der beigefügten Anlage entnommen werden. KI-Technologie gestalten wir u. a. mit\\ndiesen Leuchtturmprojekten:\\n2Handlungsfeld Anwendungstransfer des KI-Eckpunktepapiers der Bundesregierung.\\x0cBEITRAG BADEN-WÜRTTEMBERGS ZUR ONLINE-KONSULTATION DER BUNDESREGIERUNG 25\\nMobilität: Testfeld autonomes Fahren\\nBaden-Württemberg wird die Innovationskraft der Fahrzeugindustrie, ihrer Zuliefererbranche sowie der Soft-\\nwareindustrie nutzen, um sich vom Automobilland Nummer 1 zum Mobilitätsland Nummer 1 weiterzuent-\\nwickeln. Digital gestützt können wir zum Wegbereiter vernetzter Mobilität der Zukunft werden – mit neuen\\nMobilitätsangeboten, die wir heute möglicherweise noch gar nicht kennen. Das ca. 250 km lange Testfeld\\nAutonomes Fahren Baden-Württemberg stellt den Grundbaustein unserer Erprobungsräume auf dem Weg zur\\nMobilitätsregion Nummer 1 dar. Auf dem Testfeld können Firmen und Forschungseinrichtungenmoderne\\nTechnologien und Dienstleistungen rund um das vernetzte und automatisierte Fahren im Straßenverkehr er -\\nproben. Die Verarbeitung von großen Datenmengen in Echtzeit und ihre KI-gestützte Analyse in Echtzeit sind\\ndabei entscheidende Innovationstreiber.\\nGesundheit: Zentren für personalisierte Medizin (PM)\\nMit der personalisierten Medizin sollen Patienten eine Therapie erhalten, die bestmöglich an die individuelle\\nErkrankung angepasst ist. Daher arbeiten wir in Baden-Württemberg mit Hochdruck an der Einrichtung eines\\nPortals für Personalisierte Medizin. Es ist ein Schlüsselprojekt für die Weiterentwicklung und Verankerung\\nder Personalisierten Medizin in der Regelversorgung. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 64, 'page': 38, '_split_overlap': [{'doc_id': '600587ed1ba5c204677f92329c1ceb21', 'range': (0, 216)}, {'doc_id': '7de2ca7d39fe4a245cd00010bf6dcba3', 'range': (1379, 1617)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5556780eeb39ed5f1ebf9d99c02aaa59'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Daher arbeiten wir in Baden-Württemberg mit Hochdruck an der Einrichtung eines\\nPortals für Personalisierte Medizin. Es ist ein Schlüsselprojekt für die Weiterentwicklung und Verankerung\\nder Personalisierten Medizin in der Regelversorgung. Die am Projekt beteiligten Zentren für Personalisierte\\nMedizin werden 2019 an den Universitätskliniken Tübingen, Heidelberg, Ulm und Freiburg eingerichtet.\\nIn engem Zusammenhang damit steht die Einrichtung einer bwHealthCloud sowie der Aufbau der bwHealth-App,\\ndurch die für eine stetige Verbesserung der Regelversorgung und die Nutzung neuester medizinischer\\nErkenntnisse eine gemeinsame Datenbank mit Patientendaten aufgebaut wird. Im Rahmen des anwendungs-\\nnahen Verbundforschungsprojekts „PRIMO“ wird u. a. untersucht, wie Machine Learning-Algorithmen die\\nindividualisierte Krebstherapie verbessern können. Im Rahmen des Strategiedialogs Gesundheitswirtschaft\\nbeziehen wir die neuen Möglichkeiten der KI in die strategische Planung des Landes ein.\\nProduktion: Industrie 4.0 und intelligente Fabrikhallen\\nKI wird zum Dreh- und Angelpunkt der Industrie 4.0. Baden-Württemberg hat als erstes Bundesland die\\nPotenziale von Industrie 4.0 erkannt und die gleichnamige Allianz ins Leben gerufen. Gemeinsam mit unseren\\nPartnerorganisationen bündeln wir die Kompetenzen aus Produktions- sowie Informations- und Kommuni-\\nkationstechnik und begleiten den industriellen Mittelstand in Richtung Industrie 4.0. Damit wollen wir Baden-\\nWürttemberg als weltweit führende Region für Industrie-4.0-Technologien etablieren. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 65, 'page': 39, '_split_overlap': [{'doc_id': '5556780eeb39ed5f1ebf9d99c02aaa59', 'range': (0, 238)}, {'doc_id': '95c432496c4522b6422187c4efa5ba0e', 'range': (1232, 1547)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7de2ca7d39fe4a245cd00010bf6dcba3'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Gemeinsam mit unseren\\nPartnerorganisationen bündeln wir die Kompetenzen aus Produktions- sowie Informations- und Kommuni-\\nkationstechnik und begleiten den industriellen Mittelstand in Richtung Industrie 4.0. Damit wollen wir Baden-\\nWürttemberg als weltweit führende Region für Industrie-4.0-Technologien etablieren. Etablierte Maschi-nen-\\nund Anlagenbauer bringen wir dabei auch mit Tech-Start-ups zusammen, um KI-basierte Prozesse und\\nGeschäftsmodelle in den Fabrikhallen unseres Landes voranzubringen.\\nDie Produktion der Zukunft ist emissionsfrei, abfallfrei, hocheffizient und dynamisch; kurz: ultraeffizient. M it\\ndem Verbundprojekt „Digitalisierung und Ultraeffizienz“ wollen wir dem Ziel, das wirtschaftliche Wachs-tum\\nvom Ressourcenverbrauch zu entkoppeln, näherkommen und Praxiserfahrungen sammeln. Den größten\\nUmfang hat dabei der Aufbau eines Zentrums für Ultraeffizienzfabriken als Kompetenzzentrum für eine\\nressourcenleichte und energieeffiziente Produktion unter ganzheitlichen Nachhaltigkeitsgesichtspunkten. Das\\nZentrum selbst soll den Ultraeffizienzkriterien entsprechen, daher wird es als „hybrides System“ – einer Kom-\\nbination aus Reallaboren mit Maschinentechnik und deren Simulation und Modellierung mit Echtzeitdaten unter\\nEinbindung von KI – realisiert.\\nIm Modellvorhaben „Die Lernende Solarfabrik“ soll durch den Einsatz von Machine Learning in der Produk-\\ntion effizientere Solarzellen in vernetzten Fertigungssystemen entwickelt werden. Damit wollen wir einen Bei -\\ntrag zur Sicherung der Weltmarktführerschaft im Solarmaschinenbau leisten. Das Projekt „Cyber Protect“ soll\\nu. a. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 66, 'page': 39, '_split_overlap': [{'doc_id': '7de2ca7d39fe4a245cd00010bf6dcba3', 'range': (0, 315)}, {'doc_id': 'be19b90ff88639bb61eadaef07d75cd5', 'range': (1463, 1605)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '95c432496c4522b6422187c4efa5ba0e'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Damit wollen wir einen Bei -\\ntrag zur Sicherung der Weltmarktführerschaft im Solarmaschinenbau leisten. Das Projekt „Cyber Protect“ soll\\nu. a. Standards für die Sicherheitsprüfung von KI-Systemen in der Produktion entwickeln und durch Sicher-\\nheitszertifizierungen Transparenz für Anwender schaffen.\\x0cBEITRAG BADEN-WÜRTTEMBERGS ZUR ONLINE-KONSULTATION DER BUNDESREGIERUNG 26\\nWIR SCHAFFEN EXPERIMENTIERRÄUME FÜR\\nINNOVATIVE LÖSUNGEN UND NEUE KI-BASIERTE\\nGESCHÄFTSIDEEN3\\nDigitalisierung und KI-Technologien brauchen Querdenker und eine Innovationskultur, die Experimente bis hin\\nzum Scheitern von Geschäftsideen zulässt, um Innovationen voranzubringen. Damit die Unternehmen in\\nunserem Land moderne Technologien erfolgreich einsetzen und die Menschen davon profitieren können, be-\\ndarf es neuer Strategien und Allianzen. Darum fördern wir auf allen Ebenen der Wirtschaft und Gesellschaft\\nein Umdenken, wie wir mit Innovationen umgehen müssen.\\nDer globale Umsatz von KI-Produkten und KI-Dienstleistungen wird bis 2025 von derzeit rund fünf Milliarden\\nEuro auf rund 100 Milliarden Euro ansteigen. Wir wollen deshalb alle Anstrengungen unternehmen, damit KI in\\nallen Bereichen unserer Wirtschaft zum Zukunftsthema gemacht wird. Den Transfer von Forschungsergeb-\\nnissen wollen wir weiter verbessern und Anwendung und Kommerzialisierung von KI massiv vorantreiben. Da -bei\\nwollen wir vor allem den Motor unserer Wirtschaft – die mittelständischen Unternehmen – im globalen\\nInnovationswettbewerb bestens positionieren.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 67, 'page': 39, '_split_overlap': [{'doc_id': '95c432496c4522b6422187c4efa5ba0e', 'range': (0, 142)}, {'doc_id': '862197af95b8ad23872f6302ecc20e50', 'range': (1356, 1508)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'be19b90ff88639bb61eadaef07d75cd5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Da -bei\\nwollen wir vor allem den Motor unserer Wirtschaft – die mittelständischen Unternehmen – im globalen\\nInnovationswettbewerb bestens positionieren.\\nDIGITAL HUBS UND WEITERE INNOVATIONSRÄUME\\nWir bringen digitale Innovationen in der gesamten Fläche unseres Landes voran und fördern dabei zehn regio-\\nnale Digital Hubs als Anlaufstelle für kleine und mittlere Unternehmen, die diese beim Einstieg in und beim\\nAusbau von Digitalisierungsvorhaben einschließlich KI-basierter Geschäftsmodelle unterstützen. Mit dem Popup\\nLabor BadenWürttemberg, der Digitalisierungsprämie, dem Aufbau eines neuen Transfer- und Ent-\\nwicklungszentrums für digitale Geschäftsmodelle „BIEC (Business Innovation Engineering Center)“ bietet\\ndie Landesregierung dem Mittelstand ein kreatives Umfeld und beste Bedingungen, um neue Wege zu erpro-ben\\nund innovative Ideen und erfolgreiche Geschäftsmodelle zu gestalten. Gründer, Start-ups und innovative,\\nkreative Köpfe können sich in den Lern- und Experimentierräumen ausprobieren.\\nDas BIEC ist ein Leuchtturmprojekt der Digitalisierungsstrategie digital@bw und wird vom Fraunhofer Institut\\nfür Arbeitswirtschaft und Organisation IAO sowie dem Institut für Arbeitswissenschaft und Technologiema -\\nnagement IAT der Universität Stuttgart umgesetzt.\\nDamit wollen wir digitale Geschäftsmodelle einschließlich KI-basierten Dienstleistungen und Produkte – ins-\\nbesondere im Mittelstand – voranbringen. Dabei spielt der rasche Wissens- und Technologietransfer von\\nDigitalisierungsansätzen und -technologien aus der Wissenschaft eine zentrale Rolle.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 68, 'page': 40, '_split_overlap': [{'doc_id': 'be19b90ff88639bb61eadaef07d75cd5', 'range': (0, 152)}, {'doc_id': '3021462e238aae18557334d7f34ff89d', 'range': (1270, 1564)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '862197af95b8ad23872f6302ecc20e50'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Damit wollen wir digitale Geschäftsmodelle einschließlich KI-basierten Dienstleistungen und Produkte – ins-\\nbesondere im Mittelstand – voranbringen. Dabei spielt der rasche Wissens- und Technologietransfer von\\nDigitalisierungsansätzen und -technologien aus der Wissenschaft eine zentrale Rolle.\\nSTART-UP-ÖKO-SYSTEME\\nStart-ups sind Treiber von Innovationen – dies gilt insbesondere bei KI als nächstem Meilenstein der digitalen\\nRevolution. Mit unserer Start-up BW-Initiative machen wir die Vielfalt unserer zehn regionalen Öko-Systeme in\\nder Fläche sichtbar und wollen so mutige Gründerinnen und Gründer dazu ermuntern, ihre Geschäftsideen in\\nBaden-Württemberg umzusetzen.\\nIn mittlerweile acht branchenspezifischen Acceleratoren unterstützen wir GründungsTeams in der Früh-\\nphase. Insbesondere in den IT-Acceleratoren CyberLab (Karlsruhe) und Up2B (Walldorf) spielen Geschäfts-\\nideen auf KI-Basis eine wichtige Rolle. Im Programm „Gründungskultur in Studium und Lehre“ werden an\\n3 Handlungsfeld Gründungen des KI-Eckpunktepapiers der Bundesregierung.\\x0cBEITRAG BADEN-WÜRTTEMBERGS ZUR ONLINE-KONSULTATION DER BUNDESREGIERUNG 27\\nHochschulen Projekte in der Lehre gefördert, um eine lebendige Gründungskultur an den Hochschulen im Land\\nzu etablieren. Das Ziel: Selbständigkeit als mögliche Berufsperspektive ins Bewusstsein rücken, die nöti -ge\\nExpertise im Bereich Entrepreneurship vermitteln und Mut geben, eigene Wege zu gehen.\\nDie „Jungen Innovatoren“ sind ein Förderprogramm, das zukunftsorientierte Unternehmensgründungen aus\\nHochschulen und Forschungseinrichtungen des Landes unterstützt. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 69, 'page': 40, '_split_overlap': [{'doc_id': '862197af95b8ad23872f6302ecc20e50', 'range': (0, 294)}, {'doc_id': 'd6b2d9425b85410d63c98f73ef5bcbc5', 'range': (1245, 1589)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3021462e238aae18557334d7f34ff89d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Das Ziel: Selbständigkeit als mögliche Berufsperspektive ins Bewusstsein rücken, die nöti -ge\\nExpertise im Bereich Entrepreneurship vermitteln und Mut geben, eigene Wege zu gehen.\\nDie „Jungen Innovatoren“ sind ein Förderprogramm, das zukunftsorientierte Unternehmensgründungen aus\\nHochschulen und Forschungseinrichtungen des Landes unterstützt. Die Förderung trägt dazu b ei, innovative\\nProdukt- oder Dienstleistungsideen aus der Wissenschaft schneller auf den Markt zu bringen. An zahlreichen\\nHochschulen wurden Innovationszentren und Inkubatoren etabliert, die Start-ups aus dem Wissenschafts-\\nbereich mit ihren Ideen unterstützen: Von der ersten Beratung bis zur Vermittlung von Investoren. Am Cyber\\nValley entsteht für Start-ups und Gründungsvorhaben ein attraktives Umfeld.\\nDurch das enge Zusammenwirken von Wissenschaft und Wirtschaft verschwimmen die Grenzen zwischen\\nGrundlagenforschung und Anwendung. So werden die Wege zwischen Entwicklung und Produkt kürzer und\\nGründungsideen können schneller fliegen.\\nWIR MACHEN DIGITALISIERUNG UND KI ZUR\\nQUERSCHNITTSKOMPETENZ IN DER BILDUNG\\nDen digitalen Wandel können wir nur dann erfolgreich gestalten, wenn wir die digitale Bildung auf allen Ebe-\\nnen unserer Gesellschaft und entlang der gesamten Bildungsbiographie vorantreiben. Denn die Potenziale\\nvon Digitalisierung und KI können wir nur dann erfolgreich heben, wenn wir die Menschen unseres Landes fit\\nfür die digitale Gegenwart und Zukunft machen.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 70, 'page': 41, '_split_overlap': [{'doc_id': '3021462e238aae18557334d7f34ff89d', 'range': (0, 344)}, {'doc_id': '9dfdba4aca7363504898da60c5cf7b11', 'range': (1281, 1454)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd6b2d9425b85410d63c98f73ef5bcbc5'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Denn die Potenziale\\nvon Digitalisierung und KI können wir nur dann erfolgreich heben, wenn wir die Menschen unseres Landes fit\\nfür die digitale Gegenwart und Zukunft machen.\\n→ Wir bilden exzellente Wissenschaftler und Nachwuchskräfte für die\\nWirtschaft an unsere Hochschulen und Forschungseinrichtungen\\naus und sind mit französischen Partnern im Gespräch wie wir hier\\nauch gemeinsam neue Formen der grenzüberschreitenden\\nKooperation gestalten können. Allein in der internationalen Max-\\nPlanck-Graduiertenschule für Intelligente Systeme sollen in den\\nkommenden Jahren 100 Doktoranden ausgebildet werden.\\nEs wurden vier Forschungsgruppen an den Universitäten Stuttgart\\nund Tübingen und fünf weitere am MPI für Intelligente Systeme\\neingerichtet. Darüber hinaus werden neue Studiengänge an den\\nHochschulen des Landes mit Schwerpunkt KI entwickelt, um gezielt\\nden digitalen Nachwuchs auszubilden.\\n→ An den Schulen unseres Landes haben wir daher den Informatik-\\nUnterricht verbindlich eingeführt. Die Schülerinnen und Schüler\\nunseres Landes lernen neben Programmier-Techniken auch, wie\\nAlgorithmen und KI funktionieren und aus ihnen neue Geschäfts-\\nmodelle entstehen. Medienkompetenz ist in unserem Land in allen\\nFächern als Querschnittsthema verbindlich integriert.\\n→ Bis zu 50.000 Lehrkräfte jährlich machen wir mit Fortbildungen fit\\nfür den digitalen Wandel.\\x0c', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 71, 'page': 41, '_split_overlap': [{'doc_id': 'd6b2d9425b85410d63c98f73ef5bcbc5', 'range': (0, 173)}, {'doc_id': '4331449750eeeb29327c86f46a26defb', 'range': (1162, 1355)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9dfdba4aca7363504898da60c5cf7b11'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Medienkompetenz ist in unserem Land in allen\\nFächern als Querschnittsthema verbindlich integriert.\\n→ Bis zu 50.000 Lehrkräfte jährlich machen wir mit Fortbildungen fit\\nfür den digitalen Wandel.\\x0cBEITRAG BADEN-WÜRTTEMBERGS ZUR ONLINE-KONSULTATION DER BUNDESREGIERUNG 28\\n→ Angehende Lehrkräfte an den Hochschulen unseres Landes\\nerwerben Medienkompetenz auf der Grundlage verbindlicher\\nLehrinhalte.\\n→ In der Landesverwaltung haben wir den Lehrgang „Digital Leader-\\nship“ eingeführt und bilden Führungskräfte zu allen Themen der\\ndigitalen Transformation einschließlich KI fort.\\n→ In den Kommunalverwaltungen werden wir in den kommenden\\nJahren über 1.600 Mitarbeiterinnen und Mitarbeiter zu so genannten\\nDigitallotsen ausbilden. Sie sollen Digitalisierungsstrategien in den\\nKommunen voranbringen und neue strategische Partnerschaften mit\\nWirtschaft und Forschung eingehen, um Innovationen – auch KI-\\nbasierte – voranzutreiben.\\n→ Mit unseren Lernfabriken 4.0 schaffen wir ein bundesweit einzig-\\nartiges Netz von Lernorten, an denen praxisnah Trainings auf\\nBasis realer Industriestandards durchgeführt werden. Es sind\\nLabore, die industriellen Automatisierungslösungen aus der\\nWirtschaft gleichen und in denen Grundlagen für\\nanwendungsnahe Technolo-gien erlernt werden können. Die\\nzunehmende Implementierung von KI in der industriellen Praxis\\nspiegelt sich so in den Lern-fabriken wider.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 72, 'page': 41, '_split_overlap': [{'doc_id': '9dfdba4aca7363504898da60c5cf7b11', 'range': (0, 193)}, {'doc_id': 'fb2c7063df102ea2d2c773046b61f959', 'range': (1102, 1379)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4331449750eeeb29327c86f46a26defb'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Es sind\\nLabore, die industriellen Automatisierungslösungen aus der\\nWirtschaft gleichen und in denen Grundlagen für\\nanwendungsnahe Technolo-gien erlernt werden können. Die\\nzunehmende Implementierung von KI in der industriellen Praxis\\nspiegelt sich so in den Lern-fabriken wider.\\n→ Im betrieblichen Kontext erproben wir digitalisierungsrelevante\\nWeiterbildungskonzepte in überbetrieblichen Berufsbildungsstätten,\\ndie Qualifizierung der Ausbilderinnen und Ausbilder sowie innovative\\nProjekte im Bereich Digitalisierung und berufliche Weiterbildung.\\nKI-Anwendungen führen zu großen Veränderungen der Arbeitswelten in verschiedenen Branchen. Deshalb\\nwollen wir von Anfang an die Transformation so begleiten, dass die Auswirkungen durch geeignete Strategien\\nund Maßnahmen abgefedert werden können. Bei entsprechenden Maßnahmen wollen wir die Verzahnung mit\\nden entsprechenden Projekten der Bundesregierung und der EU.\\nDAS LAND GEHT BEIM EINSATZ VON KI\\nSELBST VORAN: VERWALTUNG 4.0\\nIn der Landesverwaltung setzen wir schon seit langem KI-Technologien ein, um einen modernen und kom-\\nfortablen Service anzubieten und die Mitarbeiterinnen und Mitarbeiter bei Routine-Tätigkeiten zu entlasten.\\nMit automatisierten Entscheidungen wollen wir mehr Freiräume schaffen, damit sich die Bediensteten der\\nLandesverwaltung um die Bearbeitung komplexerer Sachverhalte kümmern können und mehr Zeit für die\\nindividuelle Beratung der Bürgerinnen und Bürger bleibt.\\nSo werden beispielsweise einfachere Steuerfälle automatisiert bearbeitet. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 73, 'page': 42, '_split_overlap': [{'doc_id': '4331449750eeeb29327c86f46a26defb', 'range': (0, 277)}, {'doc_id': 'b6285b70d13bd36b16ecd9de41e78419', 'range': (1184, 1515)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fb2c7063df102ea2d2c773046b61f959'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Mit automatisierten Entscheidungen wollen wir mehr Freiräume schaffen, damit sich die Bediensteten der\\nLandesverwaltung um die Bearbeitung komplexerer Sachverhalte kümmern können und mehr Zeit für die\\nindividuelle Beratung der Bürgerinnen und Bürger bleibt.\\nSo werden beispielsweise einfachere Steuerfälle automatisiert bearbeitet. In der Justiz unseres Landes wer-\\x0cBEITRAG BADEN-WÜRTTEMBERGS ZUR ONLINE-KONSULTATION DER BUNDESREGIERUNG 29\\nden maschinelle Mahnverfahren auf der Basis von Algorithmen erledigt. An den Gerichten unseres Landes\\npilotieren wir aktuell die automatisierte Übersetzung fremdsprachiger Dokumente mithilfe von hochent-\\nwickelten Computersystemen auf Basis neuronaler Netze. Unter der Federführung von Baden-Württemberg\\nkümmert sich ein bundesweiter Themenkreis zum Einsatz kognitiver Systeme in der Justiz um Potenziale von\\nKI in der Justiz. Damit wollen wir sicherstellen, dass neue erfolgsversprechende Technologien zügig bundes-\\nweit eingeführt werden können.\\nBaden-Württemberg ist bei der Einführung der elektronischen Verfahrensakte in der Justiz bundesweit füh-\\nrend. Die flächendeckende Einführung in der Arbeits- und Finanzgerichtsbarkeit steht unmittelbar bevor. Zum\\nAbschluss des 1. Quartals 2019 werden 800 Mitarbeiterinnen und Mitarbeiter mit führenden e-Akten arbeiten.\\nBaden-Württemberg verfügt daher bereits heute über den notwendigen Datenbestand zum Einsatz von KI im\\nGeschäftsbereich der Justiz.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 74, 'page': 42, '_split_overlap': [{'doc_id': 'fb2c7063df102ea2d2c773046b61f959', 'range': (0, 331)}, {'doc_id': '8913edbff314646e41ed45e3a64115a7', 'range': (1218, 1438)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b6285b70d13bd36b16ecd9de41e78419'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Quartals 2019 werden 800 Mitarbeiterinnen und Mitarbeiter mit führenden e-Akten arbeiten.\\nBaden-Württemberg verfügt daher bereits heute über den notwendigen Datenbestand zum Einsatz von KI im\\nGeschäftsbereich der Justiz.\\nChatbots kommen in der Finanzverwaltung des Landes, aber auch in den ersten kommunalen Verwaltungen zum\\nEinsatz und bieten für die Bürgerinnen und Bürger einen bequemen Informationsservice rund um die Uhr. In der\\nStadtverwaltung Ludwigsburg fördern wir den Einsatz des bundesweit ersten Verwaltungs-Roboters „L2B2“,\\nder einfache Anliegen der Bürgerinnen und Bürger KI-basiert beantworten kann und sie beispielsweise an den\\nrichtigen Schalter lotst.\\nDie Software PRECOBS wird seit 30. Oktober 2015 in den Pilotpräsidien Karlsruhe und Stuttgart für den Bereich\\nWohnungseinbruchdiebstahl (WED) unterstützend zur Lageanalyse eingesetzt.\\nDEN DIG ITALEN WAN DEL GESTALTEN WIR\\nGEMEINSAM MIT DEN BÜRGERINNEN UND\\nBÜRGERN UNSERES LANDES4\\nKI ist eine Frage des Vertrauens der Bürgerinnen und Bürger in die Innovationskraft und in den Nutzen mo -\\nderner Technologien und deren Sicherheit. Baden-Württemberg ist das Land der Bürgerbeteiligung. Für uns\\nist es klar, dass der digitale Wandel und damit auch die Chancen der KI-Technologie nur gemeinsam mit den\\nhier lebenden Menschen gestaltet werden können. Über 1600 Akteure aus Wirtschaft, Wissenschaft und\\nZivilge-sellschaft haben sich in die Konzeptionierung unserer Strategie digital@bw eingebracht. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 75, 'page': 43, '_split_overlap': [{'doc_id': 'b6285b70d13bd36b16ecd9de41e78419', 'range': (0, 220)}, {'doc_id': '3670f24f4fab3f28d5042485925673c1', 'range': (1152, 1460)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8913edbff314646e41ed45e3a64115a7'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Für uns\\nist es klar, dass der digitale Wandel und damit auch die Chancen der KI-Technologie nur gemeinsam mit den\\nhier lebenden Menschen gestaltet werden können. Über 1600 Akteure aus Wirtschaft, Wissenschaft und\\nZivilge-sellschaft haben sich in die Konzeptionierung unserer Strategie digital@bw eingebracht. Diesen\\ndialogischen Ansatz führen wir bei der Umsetzung unserer Modellvorhaben fort, die wir mit erfahrenen\\nExperten aus Wirt-schaft, Wissenschaft und Zivilgesellschaft permanent\\nrückkoppeln:\\n→ 2017 hat das Innen- und Digitalisierungsministerium einen „Think Tank digitaler\\nWandel“ zur Begleitung und zum Austausch über die Digitalisierungsstrategie\\ndigital@bw mit zahlreichen namhaften Vertretern aus der Wirtschaft,\\nWissenschaft und Zivilgesellschaft eingerichtet. Damit wollen wir eine Brücke\\nzwischen der Technologie, auch im Kontext von KI, und den Bürgerinnen und\\nBürgern schlagen, denen sie dienen soll.\\n→ Das Wirtschaftsministerium hat einen „Start-up BW Think Tank“\\n4 Handlungsfeld gesellschaftlicher Dialog des KI-Eckpunktepapiers der Bundesregierung.\\x0cBEITRAG BADEN-WÜRTTEMBERGS ZUR ONLINE-KONSULTATION DER BUNDESREGIERUNG 30\\ngestartet, mit dem die Landeskampagne Start-up BW weiterent-\\nwickelt werden soll. Dabei sollen die gründungsrelevanten Maß-\\nnahmen der Landesregierung kritisch überprüft und durch neue\\nImpulse sowie zusätzliche Ideen die Entwicklung innovativer Ansätze\\nunterstützt werden.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 76, 'page': 43, '_split_overlap': [{'doc_id': '8913edbff314646e41ed45e3a64115a7', 'range': (0, 308)}, {'doc_id': '5d261b8ada36e098ddb1c214a74b16a1', 'range': (1227, 1417)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3670f24f4fab3f28d5042485925673c1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Dabei sollen die gründungsrelevanten Maß-\\nnahmen der Landesregierung kritisch überprüft und durch neue\\nImpulse sowie zusätzliche Ideen die Entwicklung innovativer Ansätze\\nunterstützt werden.\\n→ Unter der Federführung des Verkehrsministeriums arbeitet die\\n„Ideenschmiede Digitale Mobilität“ an Fragen, wie Baden-Württem-\\nberg in eine erfolgreiche digitale Zukunft der Mobilität transformiert\\nwerden kann. Die konkreten Maßnahmen der Ideenschmiede wurden\\nbeim Schwerpunktthema „Intelligente Mobilität der Zukunft“ im\\nStrategiepapier digital@bw dargestellt.\\nWIE KI UNSERE GESELLSCHAFT VERÄNDERT\\nBei der Digitalisierung geht es nicht nur um die Vernetzung von Wirtschaft („Industrie 4.0“), sondern auch um\\ndie Vernetzung unserer Gesellschaft. Dies zeigt sich beispielsweise in intelligenten Städten und Dörfern\\nweltweit, den „Smart Cities“ und „Smart Regions“. Digitalisierung und KI können dabei helfen, die Mobilität vo r\\nOrt staufrei und sicher zu gestalten. Intelligente Laternen, die ihre Umwelt KI-gestützt analysieren, sorgen für\\nmehr Sicherheit und Komfort. Immer mehr Lebensbereiche werden dazu vernetzt, um immer mehr Daten in\\nEchtzeit auszuwerten und daraus neue innovative Dienstleistungen zu entwickeln.\\nWährend einige Menschen voller Hoffnung auf die neuen Möglichkeiten von KI schauen, erfüllt sie Andere mit Zukunftssorgen\\nund Skepsis. Viele von uns fragen sich deshalb: Werde ich durch einen Roboter ersetzt? Droht die Totalprotokollierung meines\\nLebens? ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 77, 'page': 44, '_split_overlap': [{'doc_id': '3670f24f4fab3f28d5042485925673c1', 'range': (0, 190)}, {'doc_id': '383dcf246e3770c513872d09f8e46f6b', 'range': (1212, 1466)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5d261b8ada36e098ddb1c214a74b16a1'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Während einige Menschen voller Hoffnung auf die neuen Möglichkeiten von KI schauen, erfüllt sie Andere mit Zukunftssorgen\\nund Skepsis. Viele von uns fragen sich deshalb: Werde ich durch einen Roboter ersetzt? Droht die Totalprotokollierung meines\\nLebens? Werden in Zukunft KI-Systeme anstelle von Menschen weitreichende Entscheidungen für unsere Gesellschaft treffen?\\nDie Auswertung gewaltiger Datenmengen führt zu völlig neuen Denkmustern: Statt auf Kausalität zu setzen,\\nverlassen wir uns immer häufiger auf Prognosen und Korrelationen, die von KI erzeugt und analysiert werden.\\nSo zum Beispiel in der Finanzwelt, der Medizin oder bei Sicherheitsfragen. Immer öfter vertrauen wir dabei\\nComputer-Systemen, die Experten in der Tiefe nicht immer verstehen. Diskriminierungsfreiheit ist hierbei ein\\nwesentliches Kriterium der Akzeptanz neuer KI-Technologien.\\nWir nehmen diese Sorgen in Baden-Württemberg ernst und wollen eine KI-Technologie vorantreiben, in deren\\nMittelpunkt der Mensch und unsere demokratischen Grundwerte stehen. Wir sind der Meinung, dass wir die\\nMöglichkeiten und Grenzen von KI in einem gesellschaftlichen Aushandlungsprozess beantworten müssen\\nund sie nicht allein den global agierenden Internet-Unternehmen überlassen dürfen. Hier liegt eine Stärke\\nEuropas.\\nDenn aus Sicht der Landesregierung in Baden-Württemberg ist die Digitalisierung weit mehr als nur ein Tech-\\nnikthema. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 78, 'page': 44, '_split_overlap': [{'doc_id': '5d261b8ada36e098ddb1c214a74b16a1', 'range': (0, 254)}, {'doc_id': '7d9feb663252b1fb7afa4187432f859c', 'range': (1248, 1397)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '383dcf246e3770c513872d09f8e46f6b'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Hier liegt eine Stärke\\nEuropas.\\nDenn aus Sicht der Landesregierung in Baden-Württemberg ist die Digitalisierung weit mehr als nur ein Tech-\\nnikthema. Sie sieht deswegen einen Bedarf an systematischer, wissenschaftlicher Forschung zu den gesell -\\nschaftlichen Implikationen und zu der gesellschaftlichen Einbettung des technischen Wandels. Dabei wollen\\nwir die herausfordernden ethischen, rechtlichen und sozialen Fragestellungen von KI bearbeiten.\\nDaher hat die Landesregierung im Juli 2018 bereits den Forschungsverbund „Gesellschaft im digitalen Wan-del“\\nausgeschrieben. Ziel des Forschungsverbundes ist es, die Entwicklung der Digitalisierung zum Wohle der\\x0cBEITRAG BADEN-WÜRTTEMBERGS ZUR ONLINE-KONSULTATION DER BUNDESREGIERUNG 31\\nBürgerinnen und Bürger nicht nur bewusst zu reflektieren und ethisches Orientierungswissen zu generieren,\\nsondern auch die aktive Mitgestaltung der Umsetzung zu fördern. Für die konkrete, lösungsorientierte Be -\\narbeitung der Themen ist die transdisziplinäre Kooperation der Geistes- und Sozialwissenschaften mit den\\nTechnikwissenschaften sowie den Bürgerinnen und Bürgern entscheidend.\\n2.5.\\nMIT KI ZUKUNFT GESTALTEN\\nMit der Verabschiedung der Digitalisierungsstrategie digital@bw legt die Landesregierung von Baden-Würt-\\ntemberg über alle Ressorts hinweg ein hohes Tempo bei der Umsetzung der Innovationsvorhaben und\\nLeuchtturmprojekte vor. Gleich zweimal im Jahr machen wir mit Digitalisierungsberichten transparent, wo wir\\nbei der Digitalisierung stehen und welche Wegstrecke noch vor uns liegt. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 79, 'page': 44, '_split_overlap': [{'doc_id': '383dcf246e3770c513872d09f8e46f6b', 'range': (0, 149)}, {'doc_id': 'b109a6fc2d4c020d2f28a37bfbb8a20d', 'range': (1376, 1532)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '7d9feb663252b1fb7afa4187432f859c'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Gleich zweimal im Jahr machen wir mit Digitalisierungsberichten transparent, wo wir\\nbei der Digitalisierung stehen und welche Wegstrecke noch vor uns liegt. Unsere Digitalisierungsstrategie\\nwerden wir weiterentwickeln und sind aktuell dabei, ein Verstetigungskonzept zu erarbeiten. Ein Ziel eint\\nuns dabei ressortübergreifend: Wir wollen bei der Digitalisierung Benchmarks setzen und weltweit zu den\\nBesten gehören. Dabei nimmt KI eine Schlüsselrolle ein. Auf diese Querschnittstechnologie werden wir\\ndaher auch in Zukunft setzen, um unser Land, Deutschland und Europa in eine prosperierende, nachhaltige\\nZukunft zu führen.\\x0cANLAGE\\nZUM POSITIONSPAPIER\\n3.\\n3 2\\x0cANLAGE ZUM POSITIONSPAPIER 33\\nKONKRETE ANKNÜPFUNGSPUNKTE\\nFÜR DIE KI-STRATEGIE DER BUNDESREGIERUNG IN\\nBADEN-WÜRTTEMBERG\\n3.1.\\nFORSCHUNG IN DEUTSCHLAND UND EUROPA\\nSTÄRKEN, UM INNOVATIONSTREIBER ZU SEIN\\nMAßNAHME IN BADEN-WÜRTTEMBERG POTENZIELLER ANKNÜPFUNGSPUNKT AN KI-\\nSTRATEGIE DER BUNDESREGIERUNG\\nBaden-Württemberg verfügt über exzellente Zen- tren im\\nBereich der anwendungsorientierten und\\nDas Land Baden-Württemberg ist bereit, sich in\\nbesonderem Mane mit weiteren Investitionen in den\\nzielgerichteten Ausbau des Cyber Valley und in\\nanwendungsorientierte Forschungsaktivitäten der\\nFraunhofer-Gesellschaft einzubringen. Zudem strebt\\ndas Land eine enge Kooperation mit der\\nBundesregierung an, um den weiteren Prozess der\\nEntscheidungsfindung für das geplante deutsch-\\nfranzösische Zentrum für KI voranzubringen.\\nGrundlagenforschung. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 80, 'page': 45, '_split_overlap': [{'doc_id': '7d9feb663252b1fb7afa4187432f859c', 'range': (0, 156)}, {'doc_id': 'b0a709cf3e3437731bfa61ce9fb58f81', 'range': (1278, 1489)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b109a6fc2d4c020d2f28a37bfbb8a20d'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Zudem strebt\\ndas Land eine enge Kooperation mit der\\nBundesregierung an, um den weiteren Prozess der\\nEntscheidungsfindung für das geplante deutsch-\\nfranzösische Zentrum für KI voranzubringen.\\nGrundlagenforschung. Besonders hervorzuheben\\nsind das Cyber Valley Stuttgart/Tübingen, der Stutt-\\ngarter Innovations- und Technologiecampus S-TEC\\nsowie die Technologieregion Karlsruhe, in der auch\\nder de:hub Artificial Intelligence angesiedelt ist.\\nEtablierung des Innovationscampus Cyber Valley, Förderprogramme des Bundes ausweiten, deutliche KI-\\nSchwerpunkte in EU-Förderprogrammen, insb. Horizon\\n(post 2020), setzen.\\nEinrichtung zusätzlicher Professuren und Nach-\\nwuchsgruppen; Schwerpunktbildung in den For-\\nschungsbereichen Autonomes Fahren, personali-\\nsierte Medizin/Telemedizin, Robotik.\\nNeben zukünftigen KI-Softwarelösungen ist auch die\\nKompetenzsicherung bei sicheren, hardware-\\nbasierten KI-Lösungen äunerst wichtig, um mög-\\nFür die Einrichtung von Kompetenzzentren im Be-\\nreich hardwarebasierte KI-Lösungen durch den Bund\\nwürde sich das IMS Chips gemeinsam mit weiteren\\nInstituten der Innovationsallianz Baden-Württem-berg\\nund ggf. mit Fraunhofer-Instituten des Landes\\nhervorragend eignen.\\nlichst unabhängig von Drittanbietern zu sein. Ein\\nVerbund aus Forschungsinstituten der Innovations-\\nallianz BW unter Führung des Institut für Mikro-\\nelektronik Stuttgart (IMS CHIPS) verfügt über das\\nspezialisierte Know-how bei hardwarebasierten KI-\\nLösungen (z.B. neuromorphe Chips).\\x0cANLAGE ZUM POSITIONSPAPIER 34\\nPRIMO - Personalisierte Medizin für maßgeschnei-\\nderte Krebstherapien: Im Projekt PRIMO wird u.a.\\nuntersucht, wie Machine-Learning-Algorithmen die\\nindividualisierte Krebstherapie verbessern können.\\n', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 81, 'page': 47, '_split_overlap': [{'doc_id': 'b109a6fc2d4c020d2f28a37bfbb8a20d', 'range': (0, 211)}, {'doc_id': '94d938950ba8843ae18d988a29ab7be9', 'range': (1478, 1705)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b0a709cf3e3437731bfa61ce9fb58f81'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: ANLAGE ZUM POSITIONSPAPIER 34\\nPRIMO - Personalisierte Medizin für maßgeschnei-\\nderte Krebstherapien: Im Projekt PRIMO wird u.a.\\nuntersucht, wie Machine-Learning-Algorithmen die\\nindividualisierte Krebstherapie verbessern können.\\nKI wird Prozesse, Produkte und Dienste in den Be-\\nreichen Gesundheit/Umwelt/Energie weitreichend\\nverändern.\\nDurch pilothafte, anwendungsorientierte Forschung\\nin Kooperation mit Unternehmen und begleitende\\nTransfermaßnahmen kann insb. die Wettbewerbsfä-\\nhigkeit von KMU gesichert und verbessert werden.\\nMit dem Modellvorhaben „Die Lernende Solar-\\nfabrik“ wird ein Forschungsbeitrag zur Sicherung\\nder Weltmarktführerschaft im Solarmaschinenbau\\ngeleistet. Maschinenbauer in Baden-Württemberg\\nsind auf die Herstellung von Produktionsanlagen\\nfür alle wichtigen Prozessschritte für Solarzellen\\nspezialisiert, wobei bislang die Möglichkeit zur über-\\ngreifenden Vernetzung von Industrie 4.0-tauglichen\\nAnlagen und die Qualifizierung für neue Solarzellen-\\nprozesse kaum zum Einsatz kommt. Mit der Digi-\\ntalisierung und dem Einsatz von Machine Learning\\nin der Produktion sollen effizientere Solarzellen in\\nvernetzten Fertigungssystemen entwickelt werden.\\nCyber Protect: Ein Schwerpunkt des Projekts\\nCyber Protect wird die Entwicklung von Standards\\nfür die Sicherheitsprüfung von KI-Systemen und die\\nSchaffung von Transparenz durch entsprechende\\nZertifizierungsmechanismen sein. In einem anderen\\nvom WM geförderten Projekt, Roboshield, werden\\nu.a. KI-Methoden eingesetzt, um IT-Sicherheit von\\nvernetzten Systemen in der Produktion zu über-\\nprüfen.\\nKI stellt Wirtschaft und Staat in puncto Cybersi-\\ncherheit vor neue Herausforderungen. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 82, 'page': 48, '_split_overlap': [{'doc_id': 'b0a709cf3e3437731bfa61ce9fb58f81', 'range': (0, 227)}, {'doc_id': '8435a3ea20c7385c593535b31b4587c2', 'range': (1465, 1651)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '94d938950ba8843ae18d988a29ab7be9'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: KI-Methoden eingesetzt, um IT-Sicherheit von\\nvernetzten Systemen in der Produktion zu über-\\nprüfen.\\nKI stellt Wirtschaft und Staat in puncto Cybersi-\\ncherheit vor neue Herausforderungen. Im Rahmen\\nvon Kooperationen zwischen Bund und Land könn-\\nten diese neuen Herausforderungen insbesondere für\\nmittelständische Unternehmen gemeinsam adressiert\\nwerden. Mit KASTEL ist in Karlsruhe eines von drei\\nBMBF-geförderten nationalen Cybersicher-heits-\\nKompetenzzentren angesiedelt, das neben der\\nGrundlagenforschung auch in der anwendungs-\\norientierten, wirtschaftsnahen Forschung über\\nbesondere Expertise verfügt.\\nEIP-Innovationsprojekte in der Landwirtschaft\\n(Univers. Forschung, Landesanstalten, Industrie und\\nAgrarwirtschaft) vernetzen und bauen „Kompetenz-\\nzentren“ auf.\\nStärkung entsprechender Ansätze in der Weiterent-\\nwicklung der Gemeinsamen Agrarpolitik (GAP).\\x0cANLAGE ZUM POSITIONSPAPIER 35\\n3.2.\\nTRANSFER IN DIE WIRTSCHAFT\\nMAßNAHME IN BADEN-WÜRTTEMBERG POTENZIELLER ANKNÜPFUNGSPUNKT AN KI-\\nSTRATEGIE DER BUNDESREGIERUNG\\nFörderung der Start-up Kultur im Innovationscam-pus\\nCyber Valley; Anwendungsorientierte For-\\nschungsvorhaben (z.B. ZAFH) mit Schwerpunkt auf\\nMachine Learning; de.hub für künstliche Intelligenz in\\nKarlsruhe.\\nThematisch fokussierte Transferförderprogramme für\\nPartner aus Wissenschaft und Wirtschaft (Mo-\\ndellcharakter).\\nRegionale Digital Hubs und de:hub Karlsruhe: Der\\nde:hub in Karlsruhe hat den thematischen Schwer-\\npunkt künstliche Intelligenz. Im Rahmen eines soeben\\ngestarteten Projekts ist geplant, die de:hubs\\nKarlsruhe, Stuttgart, Mannheim/Ludwigshafen mit den\\nregionalen Digital Hubs - zu vernetzen. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 83, 'page': 48, '_split_overlap': [{'doc_id': '94d938950ba8843ae18d988a29ab7be9', 'range': (0, 186)}, {'doc_id': '8ce1fc943a90f3deccb319b660cafb1f', 'range': (1468, 1628)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8435a3ea20c7385c593535b31b4587c2'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: Im Rahmen eines soeben\\ngestarteten Projekts ist geplant, die de:hubs\\nKarlsruhe, Stuttgart, Mannheim/Ludwigshafen mit den\\nregionalen Digital Hubs - zu vernetzen. Das Netzwerk\\naus de:hub KI und den regionalen Digital Hubs als\\nIdeen-, Experimentier- und Kollaborations-räumen\\nkönnte zur Plattform für einen effektiven und\\neffizienten Wissenstransfer an KMU in der Fläche des\\nLandes ausgebaut werden.\\nDer de:hub sollte als Leuchtturmprojekt des Bundes\\nauch direkt vom Bund finanziell unterstützt werden.\\nDigitalisierungsprämie: Mit der einzelbetrieb-\\nlichen Fördermaßnahme Digitalisierungsprämie\\nsind bereits aktuell Maßnahmen zur Anwendung\\nvon KI explizit förderfähig. Förderberechtigt sind\\nUnternehmen mit bis zu 100 MA. Die förderfähigen\\nMaßnahmen des am 9. Juli gestarteten zweiten\\nModellversuchs beinhalten u.a. die Vorhaben „Ein-\\nführung von Mensch-Maschinen-Interaktion in der\\nProduktion (zum Beispiel durch künstliche Intelli-\\ngenz-Anwendungen)“ und „Einführung datenbasier-\\nter Dienstleistungen (zum Beispiel durch künstliche\\nIntelligenz-Anwendungen)“.\\nEin weiterer Ausbau des Programms durch Bundes-\\nbeteiligung ist möglich.\\nBusiness Innovation Engineering Center (BIEC):\\nDas BIEC soll Unternehmen bei ihrem Transforma-\\ntionsprozess hin zu neuen digitalen Geschäftsmo-\\ndellen unterstützen. Neue technologische Entwick-\\nlungen (und damit u.a. auch KI) sollen eng begleitet\\nwerden, um diese schnellstmöglich in Richtung der\\nUnternehmen zu transportieren und für diese\\nanwendbar zu machen (Technologie- und Wissens-\\ntransfer). ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 84, 'page': 49, '_split_overlap': [{'doc_id': '8435a3ea20c7385c593535b31b4587c2', 'range': (0, 160)}, {'doc_id': '5afaaf6f76daefec6d0314be1dafb16e', 'range': (1348, 1529)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8ce1fc943a90f3deccb319b660cafb1f'}>,\n",
              "  <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: Local, stakeholder_size: nan, stakeholder_country: nan, document_date: 12-06-2020 11:39, language: German, \\n\\nPassage: auch KI) sollen eng begleitet\\nwerden, um diese schnellstmöglich in Richtung der\\nUnternehmen zu transportieren und für diese\\nanwendbar zu machen (Technologie- und Wissens-\\ntransfer). Aufgrund dieser Vorgehensweise und\\nZielsetzung ist das Thema KI bereits implizit in BIEC\\nangelegt und wird in diesem Rahmen berücksichtigt.\\nEine ergänzende Schwerpunktsetzung in Form eines\\ndezidierten Arbeitspakets zu KI durch finanzielle\\nBeteiligung des Bundes wäre möglich.\\nAls komplementäre, spezialisierte Transfereinrich-tung\\nkönnte zudem ein anwendungsorientiertes\\nKompetenzzentrum für KI-basierte Dienstleistungs-\\ninnovationen im Mittelstand errichtet werden. Eine\\nfinanzielle Unterstützung durch die Bundesregie-rung\\nwürde begrüßt.\\x0cANLAGE ZUM POSITIONSPAPIER 36\\nPopup Labor: Popup-Labore sind ein neuartiges, in\\nBW sehr erfolgreiches Transferformat. Die Labore\\nwerden temporär an verschiedenen Standorten\\naufgebaut, um KMU Impulse und Know-how für\\nInnovationen zu vermitteln. Dazu werden sie mit\\ninnovativen Technologien sowie relevanten Themen\\ndes Innovationsmanagements und der Digitalisie-\\nrung (z.B. agile Organisation, Geschäftsmodellinno-\\nvation etc.) insbesondere im Rahmen von Workshops\\nin Kontakt gebracht.\\nEine Konzeption für pilothafte Durchführung von\\nspeziellen KI-Popup-Laboren (im gesamten Bun-\\ndesgebiet) könnte aus Bundesmitteln finanziert\\nwerden.\\nDer Stuttgarter Technologie- und Innovations-\\ncampus S-TEC der Fraunhofer-Gesellschaft und der\\nUniversität Stuttgart soll insbesondere KMU den\\nZugang zu neuen Technologien ermöglichen und den\\nTechnologietransfer unterstützen. S-TEC umfasst\\nderzeit u.a. ', 'content_type': 'text', 'score': None, 'meta': {'name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': 'Local', 'document_date': '12-06-2020 11:39', 'language': 'German', 'document_reference': 'F530030', 'document_name': 'F530030-FINAL_Anlagen_-_Konsultation_KI_Wei_buch_der_EU_KOM.pdf', '_split_id': 85, 'page': 49, '_split_overlap': [{'doc_id': '8ce1fc943a90f3deccb319b660cafb1f', 'range': (0, 181)}, {'doc_id': 'de9099cb209bd86076ae22b2f567fe84', 'range': (1355, 1607)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5afaaf6f76daefec6d0314be1dafb16e'}>,\n",
              "  ...],\n",
              " 'root_node': 'File',\n",
              " 'params': {},\n",
              " 'node_id': 'DocumentStore'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# instantiate indexing pipeline\n",
        "indexing_pipeline = Pipeline()\n",
        "\n",
        "#indexing_pipeline.add_node(component=converter, name=\"TextConverter\", inputs=[\"File\"])\n",
        "indexing_pipeline.add_node(component=preprocessor, name=\"PreProcessor\", inputs=[\"File\"])\n",
        "indexing_pipeline.add_node(component=meta2text_augmenter, name=\"meta2text_augmenter\", inputs=[\"PreProcessor\"])\n",
        "indexing_pipeline.add_node(component=document_store, name=\"DocumentStore\", inputs=[\"meta2text_augmenter\"])\n",
        "\n",
        "# Run the pipeline\n",
        "indexing_pipeline.run(documents=docs)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect an example document\n",
        "# https://docs.haystack.deepset.ai/reference/document-store-api#inmemorydocumentstore\n",
        "print(document_store.get_document_count())\n",
        "print(document_store.get_document_by_id(id=\"1d1f0b8b1a976b696d106b0aa4443049\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTZNRGjLMWXd",
        "outputId": "364c0969-e040-4a3f-9a38-07b79fb5f3a4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12585\n",
            "<Document: id=1d1f0b8b1a976b696d106b0aa4443049, content='Passage meta data: stakeholder_name: Governance of AI Research Group, stakeholder_type: Academic/Res...'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hejsTovuCRFs"
      },
      "source": [
        "## RAG pipeline with open source models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8Xoir_LE8Ia"
      },
      "outputs": [],
      "source": [
        "# https://haystack.deepset.ai/tutorials/22_pipeline_with_promptnode\n",
        "from haystack.nodes import EmbeddingRetriever, BM25Retriever\n",
        "\n",
        "# the texts are in multiple languages. we therefore use a multilingual embedding model\n",
        "# the best place to find the latest embedding models is the MTEB leaderboard\n",
        "# https://huggingface.co/spaces/mteb/leaderboard\n",
        "retriever_sbert = EmbeddingRetriever(\n",
        "    document_store=document_store, embedding_model=\"intfloat/multilingual-e5-small\"\n",
        ")\n",
        "\n",
        "# we can optionally also add bm25 indexation\n",
        "#retriever_bm25 = BM25Retriever(document_store=document_store)\n",
        "\n",
        "document_store.update_embeddings(\n",
        "    retriever=retriever_sbert, filters=None,\n",
        "    update_existing_embeddings=True, batch_size=256\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import SentenceTransformersRanker\n",
        "\n",
        "ranker = SentenceTransformersRanker(model_name_or_path=\"corrius/cross-encoder-mmarco-mMiniLMv2-L12-H384-v1\")  #\"cross-encoder/ms-marco-MiniLM-L-12-v2\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264,
          "referenced_widgets": [
            "2391ddc1fe314c24add905086fbe8298",
            "c5c6818d397848e6a5bcb0e51bf01835",
            "dc5c8b03e90a4b5da7bff9004a71007d",
            "5df4fe79109b4f2fa0c16d48cdf67b36",
            "55c98f4f180c4e14a08863a8645652fd",
            "3c731dc5403a418287cd86e2a693496f",
            "d7dcf674c0f64455b3bd28d8ab5eadd9",
            "8b26ffc31d2f4ddf8309690fccc0ca4b",
            "1fa6223f78834fccb6a15735cc51dced",
            "75ad69302e994588a6e84239d6701e2b",
            "138605ab6f2f48ab96d5ab99d30ac191",
            "1f2084627e64413a81d2a926749108ad",
            "a1c96bb841a244c2831cf4eeda61b36d",
            "724b1fef03294529bdb7ff7a388a02ed",
            "7b77b491eb7b46c8a53ed4bc0d620181",
            "97afed372b52409499e11169d9fd23a3",
            "f859de6a84e74d988d1aa571f41d1065",
            "656ffc378bc745ad925c805e25646faa",
            "e92e28ccfafc40cd92034ca21f43bc80",
            "97188f61650a441397c9dee80512c90c",
            "892c358b26c340e49e5d97be3987a27b",
            "7f5fa20275234e27881bb82134763693",
            "09f1d37b527a4832af10bc3d475b915d",
            "31cc6289d03f48b38092fc6581bae1f3",
            "f9e76849e3514945b148b4696055e325",
            "a265f9dc6fcb4aa182dab0452e290cd7",
            "21753c942dc94ca39da691670d7de396",
            "dfb37629499b4f1ba04bd05ec603c0d5",
            "43b49421e5e74bbfbf96d1914b5520f4",
            "10bce7dd1071421cb9dd64f7e71c477b",
            "80cf4ef28de34929be2512c11c3e03fc",
            "0b1246cdb16846d38243c9d079c43939",
            "8d2a58f0c1ad438db8375814ee084d70",
            "c7d010677f7442f49535a2e587471559",
            "ab0d8a8139bd40049e63cde45677cb34",
            "56d3f56b93c74edc9ab9647b6e600da1",
            "ca910c771fff42e581df8398fb63765e",
            "d816a11353e5482bbf02b5f20cfd29fa",
            "3db9a8a191b34941b4615324ee0c03bd",
            "05a1c81e48794dcaa8b2ce355be9848d",
            "20892c7e4e184762b71e29d91f5b0653",
            "54305436df734908ad750facb131b9bf",
            "bdba06e808b7419a96317890781c8418",
            "43349421955f47c98d5326e4c57441a1",
            "b8cf8ba701c6468bb24ae954a509e37d",
            "c78865a8b423458bb75878a9bc5a20b0",
            "971d41964d134ab19ee78276c61b3da6",
            "945df6dfd3f54a95bc3264db56f6f37c",
            "ec9c7132f7024c11becdb504bd6e6fa2",
            "651a0a41654a4deda6e7dbd11f45e1f4",
            "6100929945ec490bbf5a9bccb3cf48ea",
            "a4ed41dc1c8a428d8fcfdefbfec50fb1",
            "e13c2bd9c56b43e398c88f243299ea3c",
            "e38037697f0d447a8601462a92fe28b6",
            "44a258b3fa2047759d34f3cec353e5b9",
            "807f20128ef94155b41626804b0037ea",
            "0635663e2650411b97e42acbe4a7ab87",
            "b3b365b4b0a64cce9d5e246f823de343",
            "b7864c26b0b14ee2996018085c3a29c2",
            "92ff61d000a84dafaf09fe0ca404e83b",
            "ed1cb2473b7e441b8ad7bc061a508fe0",
            "279b10c87f47464e88bc0de2c4229b85",
            "f4374dd68a364b2caef240e915b312e5",
            "5e7bcead34274b4891389e1d3bae2cf5",
            "79f4d75f280a4b4da531a0bad76c7c91",
            "6c9578964c084ab798c6f9e3217164db"
          ]
        },
        "id": "2tiHyablxcYd",
        "outputId": "64fdcd73-e3c0-431c-8f6f-2c9531cb00c1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/891 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2391ddc1fe314c24add905086fbe8298"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/471M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f2084627e64413a81d2a926749108ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09f1d37b527a4832af10bc3d475b915d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7d010677f7442f49535a2e587471559"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8cf8ba701c6468bb24ae954a509e37d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "807f20128ef94155b41626804b0037ea"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8uhK_Q0kESBU"
      },
      "outputs": [],
      "source": [
        "from haystack.nodes import PromptNode, PromptTemplate\n",
        "from google.colab import userdata\n",
        "\n",
        "lfqa_prompt = PromptTemplate(\n",
        "    #name=\"lfqa\",\n",
        "    prompt=\"\"\"Synthesize a comprehensive answer from the following text for the given question.\n",
        "              \\n\\n Question: {query}\n",
        "              \\n\\n Related text: {join(documents)} \\n\\n Question: {query} \\n\\n Answer:\"\"\",\n",
        ")\n",
        "\n",
        "prompt_node = PromptNode(\n",
        "    model_name_or_path = \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "    api_key = userdata.get('hf_api_key'),\n",
        "    default_prompt_template = lfqa_prompt  #\"deepset/question-generation\"\n",
        ")\n",
        "#prompt_node = PromptNode(model_name_or_path=\"google/flan-t5-base\", default_prompt_template=lfqa_prompt)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "oIjh-gI2EpDb"
      },
      "outputs": [],
      "source": [
        "from haystack import Pipeline\n",
        "\n",
        "querying_generation_pipeline = Pipeline()\n",
        "querying_generation_pipeline.add_node(component=retriever_sbert, name=\"Retriever\", inputs=[\"Query\"])\n",
        "querying_generation_pipeline.add_node(component=ranker, name=\"Ranker\", inputs=[\"Retriever\"])\n",
        "querying_generation_pipeline.add_node(component=prompt_node, name=\"PromptNode\", inputs=[\"Ranker\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "from haystack.utils import print_answers\n",
        "\n",
        "#query = \"What are the most important aspects of AI regulation for civil society?\"\n",
        "#query = \"What does business think about AI regulation?\"\n",
        "#query = \"What provisions should not be included in AI regulation according to business stakeholders?\"\n",
        "query = \"What does Microsoft think of the AI regulation?\"\n",
        "\n",
        "prediction = querying_generation_pipeline.run(\n",
        "    query=query,\n",
        "    params={\n",
        "        \"Retriever\": {\"top_k\": 10},\n",
        "        \"Ranker\": {\"top_k\": 2}\n",
        "    }\n",
        ")\n",
        "\n",
        "pprint(prediction[\"query\"])\n",
        "pprint(prediction[\"documents\"])\n",
        "pprint(prediction[\"results\"])\n",
        "#pprint(prediction[\"answers\"][0].meta[\"prompt\"])\n",
        "#print_answers(prediction, details=\"minimum\")  # Choose from `minimum`, `medium` and `all`"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpziPPpNxkMM",
        "outputId": "4fd71186-b9bd-4874-b9a7-16a02e14620c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.12 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'What does Microsoft think of the AI regulation?'\n",
            "[<Document: {'content': 'Passage meta data: stakeholder_name: Microsoft Cooperation, stakeholder_type: Company/Business organisation, stakeholder_scope: nan, stakeholder_size: Large (250 or more), stakeholder_country: United States, document_date: 13-06-2020 11:59, language: English, \\n\\nPassage: “\\n“\\nAI isn’t just another piece of technology.\\nIt could be one of the world’s most\\nfundamental pieces of technology the\\nhuman race has ever created.\\nSatya Nadella, CEO, Microsoft\\x0c3\\nWe thus offer these comments not because we oppose AI regulation, but rather to aid the Commission\\nin the difficult task of assessing where regulation might be most appropriate and how best to\\nregulate consistent with European values. As elaborated in Part I, our principal suggestions on the\\nEU’s proposed AI regulatory framework are as follows:\\nPromote trustworthy AI through governance and tools.\\nRegulatory frameworks for AI should incentivize relevant actors to adopt governance standards\\nand procedures that support their efforts to operationalize trustworthy AI, and should support the\\ndevelopment of technologies, systems, and tools to help these actors identify and mitigate relevant\\nrisks.\\nLeave space for positive uses of AI.\\nThe use of AI can help make some products and services safer and better than their non-AI\\ncounterparts. Policymakers should take care to ensure that the cost of AI regulation is not so high\\nthat it prevents these products from reaching the market.\\nDifferentiate types of harm.\\n', 'content_type': 'text', 'score': 0.9817367792129517, 'meta': {'name': 'F530212-Microsoft_Response_-_EC_White_Paper_on_AI_June_2020__small_file_.pdf', 'stakeholder_name': 'Microsoft Cooperation', 'stakeholder_type': 'Company/Business organisation', 'stakeholder_size': 'Large (250 or more)', 'stakeholder_country': 'United States', 'stakeholder_scope': nan, 'document_date': '13-06-2020 11:59', 'language': 'English', 'document_reference': 'F530212', 'document_name': 'F530212-Microsoft_Response_-_EC_White_Paper_on_AI_June_2020__small_file_.pdf', '_split_id': 3, 'page': 2, '_split_overlap': [{'doc_id': '535fcaaaf12d48c4f215e2fdcca76d08', 'range': (0, 148)}, {'doc_id': 'd3565dab736dd355ef41e08c1f940b74', 'range': (1022, 1194)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f51ab22cc8064779555ea1996f125c47'}>,\n",
            " <Document: {'content': 'Passage meta data: stakeholder_name: nan, stakeholder_type: nan, stakeholder_scope: nan, stakeholder_size: nan, stakeholder_country: nan, document_date: 29-05-2020 20:19, language: English, \\n\\nPassage: 10) In your opinion, how important are the following mandatory requirements of a possible\\nfuture regulatory framework for AI (as section 5.D of the White Paper) (1-6: 1 is not important\\nat all, 6 is very important)?\\n1-Not\\nimportant\\nat all\\n2- Not\\nimportant\\n3-\\nNeutral\\n4-\\nImportant\\n5- Very\\nimportant\\nNo\\nopinion\\nThe quality of training\\ndata sets\\n☐ ☐ ☐ ☒ ☐ ☐\\x0cThe keeping of records\\nand data\\n☐ ☐ ☒ ☐ ☐ ☐\\nInformation on the\\npurpose and the nature of\\nAI systems\\n☐ ☐ ☐ ☒ ☐ ☐\\nRobustness and accuracy\\nof AI systems\\n☐ ☐ ☐ ☒ ☐ ☐\\nHuman oversight ☐ ☐ ☐ ☒ ☐ ☐\\nClear liability and safety\\nrules\\n☐ ☐ ☐ ☒ ☐ ☐\\n11) In addition to the existing EU legislation, in particular the data protection framework,\\nincluding the General Data Protection Regulation and the Law Enforcement Directive, or,\\nwhere relevant, the new possibly mandatory requirements foreseen above (see question\\nabove), do you think that the use of remote biometric identification systems (e.g. ', 'content_type': 'text', 'score': 0.2636053264141083, 'meta': {'name': 'F528964-20200529_Response_to_the_EU_COM_AI_White_Paper_Consultation.pdf', 'stakeholder_name': nan, 'stakeholder_type': nan, 'stakeholder_size': nan, 'stakeholder_country': nan, 'stakeholder_scope': nan, 'document_date': '29-05-2020 20:19', 'language': 'English', 'document_reference': 'F528964', 'document_name': 'F528964-20200529_Response_to_the_EU_COM_AI_White_Paper_Consultation.pdf', '_split_id': 10, 'page': 6, '_split_overlap': [{'doc_id': 'a2c032d7683e41ed5d865eacdce83f60', 'range': (0, 215)}, {'doc_id': '81b4d5df849823c04f01b3fc5d2356e7', 'range': (216, 938)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f300a9f7c214b85335a62421680ca231'}>]\n",
            "[' Microsoft believes that AI regulation is important and necessary to ensure '\n",
            " 'trustworthy AI. The company suggests that regulatory frameworks for AI '\n",
            " 'should incentivize relevant actors to adopt governance standards and '\n",
            " 'procedures that support their efforts to operationalize trustworthy AI, and '\n",
            " 'should support the development of technologies, systems, and tools to help '\n",
            " 'these actors identify and mitigate relevant risks. Microsoft also believes '\n",
            " 'that the use of AI can help make some products and services safer and better '\n",
            " 'than their non-AI counterparts, and that polic']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qBPoCc4H0Sa"
      },
      "source": [
        "## Generative QA with generative LLMs (closed APIs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEQWDayHH7Nw"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/My Drive/freelance/demos/key_openai.txt', 'r') as file:\n",
        "    openai_key = file.read().replace('\\n', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNPlSDQvH3m9"
      },
      "outputs": [],
      "source": [
        "from haystack.nodes import BM25Retriever, EmbeddingRetriever\n",
        "\n",
        "retriever_bm25 = BM25Retriever(document_store=document_store)\n",
        "\n",
        "# the texts are in multiple languages. we therefore use a multilingual embedding model\n",
        "# the best place to find the latest embedding models is the MTEB leaderboard\n",
        "# https://huggingface.co/spaces/mteb/leaderboard\n",
        "retriever_sbert = EmbeddingRetriever(\n",
        "    document_store=document_store, embedding_model=\"intfloat/multilingual-e5-small\"\n",
        ")\n",
        "\n",
        "document_store.update_embeddings(\n",
        "    retriever=retriever_sbert, filters=None,\n",
        "    update_existing_embeddings=True, batch_size=256\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optional: build a multiretriever which combines two different retrievers\n",
        "# to increase performance\n",
        "from haystack.nodes import BaseRetriever\n",
        "from typing import List\n",
        "from haystack import Document\n",
        "\n",
        "class MultiRetriever(BaseRetriever):\n",
        "    def __init__(self, retrievers: List[BaseRetriever]):\n",
        "        self.retrievers = retrievers\n",
        "\n",
        "    def retrieve(self, query: str, filters: dict = None, top_k: int = 10, index: str = None, **kwargs) -> List[Document]:\n",
        "        # Use each retriever to retrieve documents\n",
        "        all_results = []\n",
        "        seen_ids = set()\n",
        "        for i, retriever in enumerate(self.retrievers):\n",
        "            results = retriever.retrieve(query, filters, top_k, index, **kwargs)\n",
        "            for doc in results:\n",
        "                if doc.id not in seen_ids:\n",
        "                    all_results.append(doc)\n",
        "                    seen_ids.add(doc.id)\n",
        "\n",
        "        return all_results\n",
        "\n",
        "    def retrieve_batch(self, query: List[str], filters: dict = None, top_k: int = 10, index: str = None, **kwargs) -> List[List[Document]]:\n",
        "        # Use each retriever to retrieve documents\n",
        "        all_results = []\n",
        "        seen_ids = set()\n",
        "        for retriever in self.retrievers:\n",
        "            results = retriever.retrieve_batch(query, filters, top_k, index, **kwargs)\n",
        "            for docs in results:\n",
        "                unique_docs = []\n",
        "                for doc in docs:\n",
        "                    if doc.id not in seen_ids:\n",
        "                        unique_docs.append(doc)\n",
        "                        seen_ids.add(doc.id)\n",
        "                all_results.append(unique_docs)\n",
        "\n",
        "        return all_results\n",
        "\n",
        "multi_retriever = MultiRetriever([retriever_bm25, retriever_sbert])"
      ],
      "metadata": {
        "id": "y3iyS_2LpdwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import SentenceTransformersRanker\n",
        "\n",
        "ranker = SentenceTransformersRanker(model_name_or_path=\"corrius/cross-encoder-mmarco-mMiniLMv2-L12-H384-v1\")  #\"cross-encoder/ms-marco-MiniLM-L-12-v2\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264,
          "referenced_widgets": [
            "a8008aaa6fad4093a1635c6571322fc9",
            "d9439f9fc239417380ecf72814c39e9b",
            "40d14832318447dda6427f48fcb86d89",
            "9594c6ae39d449f1af2d84a7dc82083b",
            "505cdb7d63dc4fc6bc34a542c7b79847",
            "6e8890ba6da740beb13f7f9f7d57f167",
            "f6f6fd07726640dba8a56cd2bb080280",
            "782360c00ba148798a8b4e183b23815c",
            "2b685a89dea84c6da280d6f0164e5397",
            "6a7861253b5641a7b18d10388b962d2e",
            "7bd80cb34c6441918731969866646ae0",
            "72b68884eea14286a8f23c37aff949d9",
            "5ccef7234aa14a388a8aba3310af131f",
            "b4e4cc786a794c5e89ce4e93d9f5b5b0",
            "99dc239adec947e8b68b69e0992b7e27",
            "5ba0d9ad46594911b8b67971db1017c4",
            "0aa4de7ea45f436bb6027fc5a509b159",
            "b7e55906994f4d7f8277bf68e5c36aa9",
            "d163a9709c004211a5950fcc8abbcb7c",
            "e28af1337c3d49f2ba484c2ebe506cbf",
            "a0a5badb86f24044b6408baade12d200",
            "b5ff58d1df594f96abfcf51eae6f3846",
            "b7d20d561e5d4c468e6140d85234098e",
            "c90ac15142d3487585e0fb5c638c76a2",
            "5ee3e5fa851844298a2f9ea53e3eee57",
            "600401b95b144e46ae97e5238a5cbe7a",
            "07c91b8b87304857843b997605754d5b",
            "d5a4e5d235b94467a5148a2939318500",
            "081ba1be30874898b90c87214e4b5338",
            "239b2963943b42cd8f8948c10f1f6c9d",
            "2f8ad866e0024414b07893f0d79b8b5b",
            "2a2c8b68fe7c40859a045970bfb7827d",
            "4cf1db1e6459403aa7a787f1775dbd36",
            "a75f8120f92f428da1261f9dc1469e66",
            "a2444c9accb74457a3bbad96fedfbc40",
            "426599ecb0b540a29e0e4e723119f833",
            "bd6ecb23eba946229cb52e7e4e4e5f12",
            "ff08697e1be6416fb1e8f6553500a271",
            "2ecf4301b030451fb15cbc8a54173428",
            "d3125a463c094b6fa685afc1b50c8f13",
            "3dec5a389cab41968ce090cfd65b2d83",
            "b9c142d312344df2a7d303d6299f569e",
            "75fe3e70dd3345259458017d1449fb66",
            "a85eeffcf0674737a14439c7f29a29b2",
            "9e54a58757364dd0b2603769d6383101",
            "f2bba6209cf542b086b50698fc07711b",
            "9989c5109e7f48baa01e4eec5c630889",
            "52361cec5f464986a90c59f7eabdb405",
            "d04a058e43d2449d8261d2b75c9f7514",
            "c16316acd4904fb08c819e23dbfd3919",
            "651d19b5d5bd4be9be2e541df9d101b4",
            "478d4f03bcc546fa923e1bfc974df34e",
            "33702be8f2cd4a828fec0a7134f2fcce",
            "bd1096ac71e945c1aa4df7ddec733e4f",
            "7ab356dd104f4d299b8aaa7f9c1402e3",
            "76e704ece194493aa31fa2b45df278fe",
            "af3f0daf59f74f22a94276ba53eb2fdc",
            "dc456c4811714a08bb143df8795940bc",
            "fcff89bed632491aad5c55e43338eac8",
            "1982d362a79540cf967c43aa84baec79",
            "225ceba5c07e402b87f98ec827a379f9",
            "eef79ce018f146bd8a782342193c166c",
            "293da2f1b3b34c488ef855ac477b24f9",
            "628556119e94436abaa2b5eab78d7ea4",
            "d57dbeab5a524726a2dec6257e26ea60",
            "2b39837250604bd28e89b085744ae989"
          ]
        },
        "id": "lZ1vfv0Pi5cA",
        "outputId": "ba43630d-934e-49a9-c3a2-152a4580017c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/891 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8008aaa6fad4093a1635c6571322fc9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/471M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72b68884eea14286a8f23c37aff949d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7d20d561e5d4c468e6140d85234098e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a75f8120f92f428da1261f9dc1469e66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e54a58757364dd0b2603769d6383101"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76e704ece194493aa31fa2b45df278fe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt79AcD7H3m-"
      },
      "outputs": [],
      "source": [
        "from haystack.nodes import PromptNode, PromptTemplate, AnswerParser\n",
        "\n",
        "# prompt hub https://haystack.deepset.ai/blog/share-and-use-prompt-with-prompthub\n",
        "# join function https://github.com/deepset-ai/haystack/blob/8920fd693965e9011084c87cee9afd565fdcecbf/haystack/nodes/prompt/shapers.py#L8C1-L8C1\n",
        "prompt_template = PromptTemplate(\n",
        "    \"\"\"Here is a list of passages that may or may not be related to a user query. Your task is to answer the query only taking into account the information in the passages. List of passages:\n",
        "    \\n{join(documents, delimiter=\"\\n\\n\")}\n",
        "    \\n\\nQuery: {query}\n",
        "    \\nAnswer:\"\"\",\n",
        "    output_parser=AnswerParser()\n",
        ")\n",
        "#prompt_template = PromptTemplate(\"deepset/question-answering\", output_parser=AnswerParser())\n",
        "\n",
        "prompt_node = PromptNode(\n",
        "    model_name_or_path=\"gpt-3.5-turbo\", api_key=openai_key,\n",
        "    default_prompt_template=prompt_template, max_length=100\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPbk7F9FMVTP"
      },
      "outputs": [],
      "source": [
        "from haystack import Pipeline\n",
        "\n",
        "querying_generation_pipeline = Pipeline()\n",
        "querying_generation_pipeline.add_node(component=multi_retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
        "querying_generation_pipeline.add_node(component=ranker, name=\"Ranker\", inputs=[\"Retriever\"])\n",
        "querying_generation_pipeline.add_node(component=prompt_node, name=\"PromptNode\", inputs=[\"Ranker\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "from haystack.utils import print_answers\n",
        "\n",
        "query = \"What are the most important aspects of AI regulation for civil society?\"\n",
        "#query = \"What does business think about AI regulation?\"\n",
        "#query = \"What provisions should not be included in AI regulation according to business stakeholders?\"\n",
        "query = \"What does Microsoft think of the AI regulation?\"\n",
        "\n",
        "prediction = querying_generation_pipeline.run(\n",
        "    query=query,\n",
        "    params={\n",
        "        \"Retriever\": {\"top_k\": 10},\n",
        "        \"Ranker\": {\"top_k\": 5}\n",
        "    }\n",
        ")\n",
        "\n",
        "pprint(prediction[\"query\"])\n",
        "pprint(prediction[\"answers\"][0].answer)\n",
        "pprint(prediction[\"documents\"])\n",
        "#pprint(prediction[\"answers\"][0].meta[\"prompt\"])\n",
        "#print_answers(prediction, details=\"minimum\")  # Choose from `minimum`, `medium` and `all`"
      ],
      "metadata": {
        "id": "HdHwMFduqdc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-iZL9voFQt5"
      },
      "source": [
        "## Passage Retriever Pipeline without generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg0BwWWmFVpN"
      },
      "outputs": [],
      "source": [
        "from haystack.nodes import BM25Retriever, EmbeddingRetriever, SentenceTransformersRanker\n",
        "\n",
        "retriever_bm25 = BM25Retriever(document_store=document_store)\n",
        "\n",
        "retriever_sbert = EmbeddingRetriever(\n",
        "    document_store=document_store, embedding_model=\"intfloat/multilingual-e5-small\"  #\"sentence-transformers/all-MiniLM-L6-v2\"  #\"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
        ")\n",
        "\n",
        "document_store.update_embeddings(retriever_sbert)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yckvy2mOGL_a"
      },
      "outputs": [],
      "source": [
        "ranker = SentenceTransformersRanker(model_name_or_path=\"cross-encoder/mmarco-mMiniLMv2-L12-H384-v1\")  #\"cross-encoder/ms-marco-MiniLM-L-12-v2\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCLQ9LmmFZLG"
      },
      "outputs": [],
      "source": [
        "from haystack import Pipeline\n",
        "\n",
        "retriever_pipeline = Pipeline()\n",
        "retriever_pipeline.add_node(component=retriever_sbert, name=\"Retriever\", inputs=[\"Query\"])\n",
        "retriever_pipeline.add_node(component=ranker, name=\"Ranker\", inputs=[\"Retriever\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8MfwZ4AFZLH"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "from haystack.utils import print_answers, print_documents\n",
        "\n",
        "query = \"Which aspects of AI regulation are most important for businesses?\"\n",
        "#query = \"Welche Aspekte der geplanten AI Regulierung sind für Unternehmen besonders wichtig?\"\n",
        "\n",
        "prediction = retriever_pipeline.run(\n",
        "    query=query,\n",
        "    params={\"Retriever\": {\"top_k\": 20}, \"Ranker\": {\"top_k\": 5}}\n",
        ")\n",
        "\n",
        "#pprint(prediction[\"query\"])\n",
        "#pprint(prediction[\"documents\"])\n",
        "#for key_document, value_document in prediction.items():\n",
        "#    pprint(value_document[\"content\"])\n",
        "#print_answers(prediction, details=\"minimum\")  # Choose from `minimum`, `medium` and `all`\n",
        "print_documents(prediction)  # Choose from `minimum`, `medium` and `all`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vIT0OZF-30s"
      },
      "source": [
        "## Extractive Q&A pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305,
          "referenced_widgets": [
            "fe0d984a5ca547e2b997c8a4e3edb497",
            "6759c782a0324170b771f39267714d1a",
            "50237f98f6c4419295a8f2e87b1073ca",
            "2f5317b570a940f2826a068dc9401d93",
            "150f36c40ec84cbf901d50a6ff776f87",
            "a0f866df67df471ca4d9a1546ac2829b",
            "fabed2631fcf4ab196037477fd68a38f",
            "fabffe7086474e6f94572fd3611b943f",
            "4ba336c727894464b94d96530385a930",
            "808236e5bef345658841d70187629d99",
            "90979d0f127846599b78729df7f2f83e",
            "7361ebe1aeb3424ca3e314d91a46f742",
            "b56383c3357946578ee734fd0d5bd6ec",
            "bb66556182734a83a0c3b26d59dbe594",
            "b8963b736ea54b6a82c54df8159ea62d",
            "adcf498a87a74be38dfdb39e03e62bba",
            "ccbf5616eec14cc098921ff8f3bf931c",
            "d2f31b11f78d4a5eb9c6a5d254177215",
            "d00eb5cfbb3c455e91274f559a7ac05a",
            "bc7a0e979c74417ab4c53fb38bfc4b43",
            "e110152ee9c5494a812d47329a190bbd",
            "c28a2f6590a54236bede1e6227dcbcb3",
            "f76cd0fa84fa4f7e82aa6fde3c1fa71e",
            "8322e66cce944105b524f18f2234b4a3",
            "45c8797f045b4f37bf504ca360435c45",
            "8952f77822174d1794ee2cb481ce428c",
            "74f5a5346c5f40a592dd60e5177a0c41",
            "cdb178fd98d14bc0aeb31925fb924828",
            "e2ec5b4738ef42cb8ee4653867087775",
            "d737756c93d0462c83b67d85171e4538",
            "0aacf6969fec4fcf807bd74a2f0c8fb3",
            "045afcc090944b33859dba49a22ef57c",
            "e91e4108c2044221ac76f4530e5fe0fd",
            "c86352745e704304a8c85fd6ef99f970",
            "18bc96464da44897acd090d21872d006",
            "4e31a82ecc124a25b7a859760a0f28ac",
            "72eb1b926e6142d9933257dad140c14d",
            "430ec644c17a4862bc51a5a16d9f7cc0",
            "4b31cfdb747a4f64b444fa57d824b5ee",
            "5b923187afdc43a1b3180248942b930b",
            "06ba428fcbd24e6691868be630e0a934",
            "8e2d1793e8d642f2bda50d9dcc3c8c5e",
            "cd4281eec994428899273c558f3f483e",
            "6b841865a47c4f01886e4ffd9f7414a1",
            "803ba8ff25e54433a0ab40fbc7e44e2a",
            "db7dcd24afe54935bbd606c0513d86d7",
            "1bea3d807d424796822b363de12d8489",
            "1cff9773ff9c45cea5673bb658f501b4",
            "9dddc44b1e794cc5839569fa8d493b79",
            "8b75028dec844bec84a46be9aba6313c",
            "4cf2b7485cc24e70bdae5aaca39699c0",
            "13f8cfbec20441e093a127beaa9be07d",
            "daf1400c271b4c9fae2314c849b60772",
            "341139b004c64320836168abcfa8d6d0",
            "b8395701f9c8444db84b775cf70e07a1",
            "8885c8eeead64888a236bd78f39bcb00",
            "4f42176257514426a384770a4198b058",
            "7a0983b0356e4c9a812556c827801930",
            "89276afe49d745629d0a3bafb4ed092b",
            "a68f1114b0514a7c9369e034eeaa71ff",
            "1ac05ca721854be7b14dd6076f798793",
            "7df33d64ffdb48b498fa110a57927d91",
            "cfe9623977af4c2ba76885de03ff3a84",
            "f270a6d7612741fd9844960e21339076",
            "a9ab0ab8426a49b4864633ed48fa32c7",
            "39bdc17f9fa64bfba5dc88df74ef1bab",
            "4803cdef6dc8420cb903586509419c6e",
            "ceaa7980edd74a0ea33d56a5135f8434",
            "992794a7c10f431ea282ff3a61173668",
            "56cf17a88e144619944e0fcabd7b8ca4",
            "1b96fe7093a24c208210637856b5557b",
            "d6d5d66e04a44054992360fc5898f2f6",
            "89d91df29639441b81b2ca634b228921",
            "d66e948bafad45a3ad333fe6118daa9e",
            "0f1c3d61b2de480b9f1c464b3d6900c2",
            "2b7cfd995288428d9e270b2cfaef9ff8",
            "c124dd2f89ef483a92560da144d59561",
            "a3df22c95efd4c5990d51b0f18358866",
            "39020c18a55f449f8f69740127f7e142",
            "8efa6a2cae2b422dbce48ac19f24d4a6",
            "c512880a850f4cc78caf5ea60a6bc6d2",
            "6751081ef1644ea7a1691f4aa47c633a",
            "46c1f4b3104a44bab02c28606fcada1b",
            "7b9ab94c780e4bc497f9b24d9e02bccd",
            "bc766388282a43c89f5d8667696bbdfc",
            "b1333060af5b4c2e9f17f8011a6bb60e",
            "8000ec3472004f50b73f1dbc73317781",
            "016d9144727d4595ac5fed02e2bc8dda",
            "849c12ed70ef40a8ad80cf7cac722a21",
            "3f01e384f3db47398029a9b90e64de10",
            "a9072d4640e642dc8ea890ae1a285201",
            "c81dc2507f61452ebc13a728569b5c18",
            "6e9cc9669a8e4a38b78563bb5cc6e375",
            "054dc7db23214a7282f42cb22221c659",
            "644c1af14312448d84fd98ecf565a5b3",
            "b6b8f95719c043ac9082aa33701b7fa3",
            "11451001782f4f56bd4f20651d3bf06d",
            "e48e21f5d1f24913b0e722f843c60b2b",
            "e8fc32b177bc4d499c79ff446af83e42"
          ]
        },
        "id": "NrknCxxq8LkG",
        "outputId": "e9d3a3a4-0324-4f34-aa46-96aee03b84df"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe0d984a5ca547e2b997c8a4e3edb497",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/655 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7361ebe1aeb3424ca3e314d91a46f742",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f76cd0fa84fa4f7e82aa6fde3c1fa71e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c86352745e704304a8c85fd6ef99f970",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "803ba8ff25e54433a0ab40fbc7e44e2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8885c8eeead64888a236bd78f39bcb00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4803cdef6dc8420cb903586509419c6e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Updating Embedding:   0%|          | 0/12483 [00:00<?, ? docs/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3df22c95efd4c5990d51b0f18358866",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Inferencing Samples:   0%|          | 0/313 [00:00<?, ? Batches/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "849c12ed70ef40a8ad80cf7cac722a21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Inferencing Samples:   0%|          | 0/78 [00:00<?, ? Batches/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from haystack.nodes import BM25Retriever, EmbeddingRetriever\n",
        "\n",
        "# example for BM25/TFIDF document representation: https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41\n",
        "retriever = BM25Retriever(document_store=document_store)\n",
        "\n",
        "retriever_sbert = EmbeddingRetriever(\n",
        "    document_store=document_store, embedding_model=\"intfloat/multilingual-e5-small\"  #\"sentence-transformers/all-MiniLM-L6-v2\"  #\"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
        ")\n",
        "document_store.update_embeddings(retriever_sbert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "3197ac9679294afe9503f4075727dc40",
            "c41ba8639ecb47138bcc4f31247dcf5f",
            "ac2f3cfc07514e03b26abb5dcd06b9d6",
            "b1310db8c9d84ffa99db83fe044204fd",
            "cfeb84eef95243fd8d5686e7228112a4",
            "59f1edfed08f479b9ccfcdacd4bbf9da",
            "7004e3061d1a45caa84ff9f933dc6a86",
            "a91b7dd7e59644f0af5801444208f4e8",
            "0782b6315ba1476db2808b38656f4c00",
            "00080af5d65c4074abddbcf498909825",
            "9db5f0ad379b4c4981d224e98a0c6d86",
            "e3a429d8f2ac4c16ac76f9accb1c63b6",
            "5333225674b54db1834baca7f6594cef",
            "ff931a92b56d4a13aa3a56b1c239d436",
            "6eff3c8e5dac495a93354e57001b8ec0",
            "dbfec6c460524d58ade0445022d95c5f",
            "25236eb04e0a4db796eb13c1c26d6b23",
            "204d2c5f9728484bb799efd6179585fb",
            "7f1f7bf202e54e4083d7be745efc65ae",
            "b2a8039a449f434480f69c05f11cf335",
            "257164866a634816aa908b10634a256a",
            "42a6e40356504c6db8fea9251907f6dd",
            "8eb4784d954040ac901d48b2ed785db7",
            "bfe9ea47c08e460dbf7082c64a71513c",
            "0cc1ee4d5a204abea748e67a826c6781",
            "4b757da1728848738ce86f1b000cb66e",
            "cbe862f277c74856b5a329c0033d61fa",
            "046be9714a4c4cccaf13cf9365c1e0b9",
            "9bd37f425b6f4aa8b6014012c94088fe",
            "0d72a7a4b4fe45fca82545389e5a26e2",
            "1af08b55be6a41fc85e32128fc2baefe",
            "84242db401544a439f84507124fb45c5",
            "5e0c3500f3294cfb8b2e6727570a823d",
            "f8098c8542f343148e749b776311dc7e",
            "ae1375a65bcb4bc08796fe6a6052ab6f",
            "53e399092b6b4e1fb358e775e81f8066",
            "8bfb4ebc235548a1ae2e4e1990c6cbdd",
            "82993715a80f4fcb92bd8b886afdce26",
            "931f2ce574a1465bbcb52e27c5c147eb",
            "6fd520a45fcf4f2ebbf5ea37051442dd",
            "446f41933a804d2a88d374f385c9d992",
            "68459a47c8574ec58d675b8ef88c0ae4",
            "3c903ff42f564b9eba17a1068c22e83b",
            "0594c3a0cfab43ee87e301a013be6b7d",
            "a34c4cf1b6c6402d95716a86f45e458d",
            "cd6fa313a8834d47961d371a4d81a930",
            "0f24c487b5d8478399663dfcf2be352d",
            "dd633b43a0e648c09c4f8722c0c96579",
            "a2958caaec4f4c4ea3208a2c8938f4b2",
            "332710b1a77b469ea1808111c41b2c4c",
            "081ac22008fe4dd98feaf2b5f4215428",
            "e8aba2f8037f49dd8f77ebda580171e6",
            "51c1c835a9a74a408a89e7ac4f252dcb",
            "bfd4b4f46ead43dab90bbd1981bcba7d",
            "fe1ece8872724485b7012c1d46bc4140",
            "ade218362da242f191d47bb33ba333c1",
            "8b2b960b4d344dbba1b9cb2178e99170",
            "6d6323031efd486194468d63253921c2",
            "b8d5cffdf02947ccb6692627d0c44943",
            "61e970d9c18842a9840e955e5f4c6c74",
            "43b6e8c84742422882f19a4e13401e91",
            "75263db51b3641f7a75dfbb66080810f",
            "ea668c86703146c3a0fff83d7b7c0501",
            "74daaa792e324cb09463d23bcb3be100",
            "237363bbce544053aca8983ba38f032f",
            "ba6f367d506b474586014aeed142321d"
          ]
        },
        "id": "biSxwaas8Nr7",
        "outputId": "66cdba5d-af6b-410b-f02a-3d0f37a3d730"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3197ac9679294afe9503f4075727dc40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3a429d8f2ac4c16ac76f9accb1c63b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8eb4784d954040ac901d48b2ed785db7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8098c8542f343148e749b776311dc7e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a34c4cf1b6c6402d95716a86f45e458d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ade218362da242f191d47bb33ba333c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from haystack.nodes import FARMReader\n",
        "\n",
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlIQmtAv8Pbc"
      },
      "outputs": [],
      "source": [
        "from haystack import Pipeline\n",
        "\n",
        "querying_pipeline = Pipeline()\n",
        "querying_pipeline.add_node(component=retriever_sbert, name=\"Retriever\", inputs=[\"Query\"])\n",
        "querying_pipeline.add_node(component=reader, name=\"Reader\", inputs=[\"Retriever\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396,
          "referenced_widgets": [
            "a4d282676ffa42e3a2b32a9a27929b89",
            "b83e685e6c8e458fbb8b6ce76294de59",
            "ff519e773bea47e5afe12f028dda141c",
            "88381ac1be2d4ca99229035d94ef4e55",
            "5d833fc5d3794db6a54824097cee20cb",
            "d11fe943c2194b789a6d150dd646aa74",
            "9cda516d0d3c49f79caec718cdc414b9",
            "fa57c414a7f846048273e7d70a17a00b",
            "98172cbe9ef3469287b24dd7540e1bb1",
            "6c75914a50394ddfbbdf93f58febbef6",
            "9ddeeec030a747f69f1e32a228c5a53f",
            "4bfb09fc877b49a98fb67cd377db6ff4",
            "60d5b3788f1d4b8a8fc6c7ec7fa3a406",
            "21511d570ebb4367833681719ffcb594",
            "9347753daff7478f86c78e05c73b2054",
            "1c3e82daca0c469ca31121189c39674a",
            "fae928f4e50b41f48ccb9be371ed0b5b",
            "ad05f3252a24462593d5d22e36ed4dbe",
            "0e9084c205ac4cc5aaba4febabba667a",
            "56af9909d80d41cdb38ec92bf9261067",
            "422d4966818b4bcf9d29bfd7e0160804",
            "acabb9ea51d647c2b4f4c23b13792a70"
          ]
        },
        "id": "bW3wbGCL8Rat",
        "outputId": "7df2e7f8-9fa3-4250-e99e-9e9fd94702bd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4d282676ffa42e3a2b32a9a27929b89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4bfb09fc877b49a98fb67cd377db6ff4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'What does business think about AI regulation?'\n",
            "[<Document: {'content': 'Policymakers should take care to ensure that the cost of AI regulation is not so high\\nthat it prevents these products from reaching the market.\\nDifferentiate types of harm.\\nRisks to safety and risks to fundamental rights are inherently distinct; any AI regulatory regime\\nshould recognize this distinction, both in the requirements it imposes and the compliance regime it\\nadopts. Both are important to address.\\nClarify roles of regulated actors.\\nAI regulation should be clear on which requirements fall on which regulated actors (developers,\\ndeployers, etc.) and should impose responsibilities on the actor that can most efficiently and\\neffectively comply with them.\\nLeverage existing laws and regulatory frameworks.\\nAbsent clear gaps, policymakers should rely on existing laws to the extent possible rather than adopt\\nwholly new regulatory frameworks and obligations on top of them. Where new laws are needed then\\nthey should be adopted.\\n', 'content_type': 'text', 'score': 0.5019347091318385, 'meta': {'_split_id': 4, '_split_overlap': [{'doc_id': 'f51ab22cc8064779555ea1996f125c47', 'range': (0, 172)}, {'doc_id': 'a6aa1ea443ff55e6d4236fae676b9769', 'range': (716, 937)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd3565dab736dd355ef41e08c1f940b74'}>,\n",
            " <Document: {'content': 'However, the Commission’s justification for introducing regulatory frameworks is that it will\\neventually lead to greater uptake of AI (“\\u200bwill give citizens the confidence to take up AI applications\\nand companies the legal certainty to innovate using AI”)\\u200b. This view of regulation as merely\\ninstrumental to increased uptake of AI is misplaced. The creation of regulatory frameworks\\nshould determine which AI applications and technological futures are worth pursuing in the first\\nplace, which are impermissible, and to and to enact modes of democratic decision making\\ncapable of steering such decisions.\\nThe White Paper puts particular emphasis on boosting small and medium-sized AI enterprises.\\nThe concentration of market power in the AI industry has negative implications for society and\\nposes a major challenge for governance. An important dynamic that should be accounted for,\\nhowever, is that control over data and computational infrastructure rests with a handful of large\\ntech companies and so, in most cases, these smaller firms have no choice but to license their\\ncomputational infrastructure from the large players. ', 'content_type': 'text', 'score': 0.5019121273522731, 'meta': {'_split_id': 8, '_split_overlap': [{'doc_id': 'dee03af38f46f103fda52fd55ae3469a', 'range': (0, 343)}, {'doc_id': 'f7c7b2c8fec3804ff16997ddc4aabc7a', 'range': (830, 1125)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'bf702cb4a81ed2d8c7cbfd6d06f8c82f'}>,\n",
            " <Document: {'content': 'Closely\\ninterconnected networks of strong centers of excellence support the development of European\\nAI much better than a single hub.\\nDo not base regulation on a definition of AI\\nFCAI agrees that regulation of AI and digital technologies is an important issue, but notes that\\nthe discussion in the White Paper goes into unnecessary levels of detail (more than half of the\\nreport is focusing on regulation), and what is more, is unfortunately partly based on misguided\\nviews on AI and its relation to software systems and digital technologies in general. In\\nparticular, we strongly disagree with statements like \"The working assumption is that the\\nregulatory framework would apply to products and services relying on AI. AI should therefore be\\nclearly defined for the purposes of this White Paper, as well as any possible future policy-\\nmaking initiative.\"[Section 5C]. Creating a regulatory framework based on ANY definition of AI\\nwould be dangerous as it would first of all offer possibilities for \"non-AI software\" to bypass the\\nregulation altogether, and moreover, regardless of the definition of AI used, circumventing this\\ntype of regulation would not be very hard.\\n', 'content_type': 'text', 'score': 0.5019095645389906, 'meta': {'_split_id': 5, '_split_overlap': [{'doc_id': '4aba29b24bdf7d1d47ed9581d76a3f29', 'range': (0, 133)}, {'doc_id': 'c900f2817474a076e24b4c7ba1e70211', 'range': (869, 1170)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '18c3fd12247739e39a6a88674672509f'}>,\n",
            " <Document: {'content': 'The Commission’s White Paper asserts that, “…lack of trust is a main factor\\nholding back a broader uptake of AI” and that a “…clear European regulatory\\nframework would build trust among consumers and businesses in AI.” The White\\nPaper, however, fails to provide sufficient evidence for these observations. While\\nconsumers may not fully comprehend the full potential of AI, consumers interface with\\nbusinesses using AI at scale every day. This suggests consumers may be more\\ncomfortable with AI than even they realize. In defining the “problem” to be addressed\\x0cby a future regulation, the White Paper outlines a series of material and immaterial\\nharms that may result from the use of AI. What remains unclear is: 1) the degree to\\nwhich the Commission has documented the prevalence of harms across a\\nsufficiently representative number of AI use cases; and 2) how the harms\\ncontemplated may be appropriately addressed through regulatory action, as\\nopposed to voluntary, multi-stakeholder initiatives already pursued by the\\nCommission and others around the world.\\nAn evidence-based approach to policymaking is essential. ', 'content_type': 'text', 'score': 0.5019068843061656, 'meta': {'_split_id': 9, '_split_overlap': [{'doc_id': '23bba1d5b8dec2d14086cf33d4c15ce8', 'range': (0, 305)}, {'doc_id': '72bd7b3d0390c2f36e54933f073771dc', 'range': (687, 1116)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '53f2ae2c22b691dcbbb2409b6d510ff0'}>,\n",
            " <Document: {'content': 'Such regulation\\ncan provide business certainty, give consumers confidence that the AI is trustworthy. However,\\nregulation can also raise barriers to the development and application of AI. This underscores the need\\nfor a balanced approach to AI regulation, one that takes into account the risks of AI and its benefits, a\\nregulatory process informed by experts and science, that is sufficiently flexible to respond and learn\\nfrom experiences with AI use-cases. Regulation also needs to be alive to the importance of competition\\nas a driver of AI uptake by business, pointing to the need for regulation to avoiding creating costs that\\nstifle competition, particularly when those costs fall most heavily on SMEs.21\\n20 David Cyranoski, “China Enters the Battle for AI talent,” Nature, January 15, 2018, https://www.nature.com/articles/d41586-\\n21 Jacques Bughin, Jeongmin Seong, James Manyika, Lari Hämäläinen, Eckart Windhagen, and Eric Hazan, “Tackling Europe’s\\nGap in Digital and AI”, McKinsey Global Institute Discussion Paper, Feb 7th, 2019\\x0c\\nThe following outlines three steps for building Transatlantic cooperation on AI regulation\\n1. Develop a common view of the goals of AI regulation\\nCommon transatlantic values can ground transatlantic cooperation on AI regulation. ', 'content_type': 'text', 'score': 0.5019028437659416, 'meta': {'_split_id': 20, '_split_overlap': [{'doc_id': '25b99ad1aaaf799227dfb07642012939', 'range': (0, 187)}, {'doc_id': 'e1413d8d92b3de1ebc86437a96b3a979', 'range': (1135, 1269)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4203dec524febaf10686b504e3a852e6'}>,\n",
            " <Document: {'content': 'The White Paper\\nneeds to state that hasty regulation runs the risk of obstructing the utilization of AI and\\nbusiness activities in society.\\nThe necessary tools cannot be maintained and social benefits may be undermined unless the\\nfollowing goals can all be achieved: rapid technological innovation, which characterizes the\\nAI fields; finding an optimal balance in human rights by both safeguarding people’s privacy\\n1 White Paper on Artificial Intelligence: a European approach to excellence and trust（released on Feb.\\x0cand ensuring people’s day-to-day livelihoods, safety, and health, an issue that has emerged\\namid the COVID-19 crisis; and ensuring the profitability of business activities. As well as\\nlooking for ways to institute balanced regulations, we hope that discussions from now on\\nwill lead to the compatibility of future standards and regulations, mutual recognition of\\nlabeling, and such other matters relating to building coherent and compatible AI\\necosystems.\\n', 'content_type': 'text', 'score': 0.501899048942073, 'meta': {'_split_id': 2, '_split_overlap': [{'doc_id': 'd8cf37293854f89f120a1973d270bb6b', 'range': (0, 139)}, {'doc_id': 'd53d67f27352617da6faa51e0cace923', 'range': (691, 973)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'cb661c26534eefd4d356d4870ac444ce'}>,\n",
            " <Document: {'content': 'Now is absolutely the right time to ensure that appropriate regulation exists within\\nEurope to tackle discriminatory AI so as to ensure that the “trust” deficit can be tackled\\nearly on before concerns become even more prominent leading to the rejection of the\\nmany beneficial ways in which AI can transform business and people’s lives.\\nImproved regulation will better enshrine the principle of non-discrimination in the\\nnewly emerging field of AI and thereby ensure that the public better embraces it.\\nAppropriate regulation will also provide confidence to business to invest in and\\ndeploy new forms of technology. Certainly, our experience has been that businesses\\nwith bases in the UK and Europe more broadly perceive the uncertainty around how\\nAI will be regulated within Europe as a significant deterrent to investment and more\\ninnovative business models. Moreover, in the absence of clear legal rules, businesses\\nmay fear that their competitors will undermine them by deploying AI in unscrupulous\\nways in the knowledge that there is no meaningful regulatory regime. This approach\\nwould again undermine the growth of the economy.\\n3. ', 'content_type': 'text', 'score': 0.5018988161892924, 'meta': {'_split_id': 15, '_split_overlap': [{'doc_id': 'fd4c09a9152e786aa81f1c13a1f9f338', 'range': (0, 335)}, {'doc_id': '839f4047b840d7e36153bb96ce91591f', 'range': (860, 1136)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '86ff7c05cc54f09467d38765ec638f26'}>,\n",
            " <Document: {'content': 'With regard to context-overarching issues in “AI”-regulation, a comprehensive policy proposal on\\n“AI” is to be welcomed, even though regulation of “AI” is, as shown, not suitable. For the purpose\\nof producing a common understanding of such a proposal’s intended scope, the Commission’s\\nWhite Paper should, therefore, be complemented by a definition of its central notion - a\\ndefinition of AI - without the necessity of it providing the legal certainty that would be required\\nfor legislation: Albeit citing the AIHLEG , the White Paper simply describes AI as “a collection of\\ntechnologies that combine data, algorithms and computing power” (p. 2) which is not sufficient\\nor even suitable to distinguish AI from any software .\\n3.2 Objects of Protection: What about Collective Goods?\\nRegulatory interventions may entail encroachments upon fundamental rights and principles\\nrecognized by the Charter of Fundamental Rights of the European Union. In particular and firstly,\\nthe freedom of sciences (Art. 13 ChFR) and the economic fundamental rights (Art. 15 ff. ChFR)\\nof those who develop, manufacture, and market AI systems should be taken into account. ', 'content_type': 'text', 'score': 0.5018853910313581, 'meta': {'_split_id': 33, '_split_overlap': [{'doc_id': '4d9d4bcb84d355bf2942ad3f50ac201d', 'range': (0, 179)}, {'doc_id': '8b840ab2a0a5e83467b24b74c992b36', 'range': (998, 1148)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6671209c0881f2da270e7025ee1bbd06'}>,\n",
            " <Document: {'content': '• The document is structured around enhancing consumer trust in AI. However, it fails to focus on\\nthe importance of also enhancing companies’ trust in implementing AI. Due to the great ambiguity\\nand uncertainty around the regulations that are currently applicable to the use of AI applications,\\nmany companies are reluctant to start using them, precisely because they do not trust that by\\ndoing so they do not expose themselves to legal infringements. A specific example here is that,\\ncurrently, some companies may not be willing to use AI in their HR processes because they fear\\nthat they might not be legally compliant, and that thereby the positive effects of using AI (when\\ndoing so in an ethical manner), such as the removal of previous human biases, are missed out on.\\nWe would therefore suggest the EC to issue specific guidance (potentially also on a sectoral basis)\\nwhat regulations already apply to AI and in which manner their compliance can be secured by\\ncompanies.\\n• While the White Paper recognizes that there are already a lot of regulations in place, there have\\nonly been limited studies on the interplay between AI and these existing regulations. ', 'content_type': 'text', 'score': 0.5018827355331271, 'meta': {'_split_id': 4, '_split_overlap': [{'doc_id': 'd7a0debf5c10872e63a058ca9a26741c', 'range': (0, 167)}, {'doc_id': 'f90d0da0498a162f21e11c39d431a2e3', 'range': (978, 1163)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2c39eefaf12b8a4e7c22e3435d13a828'}>,\n",
            " <Document: {'content': 'For instance, many current AI use-cases build on existing analytical techniques, such as using AI to\\nimprove routing and reduce fuel consumption, to improve inventory management, for predictive\\nmaintenance and services, such as in the air cargo industry, or speech recognition tools in call\\nmanagement centers. Indeed, a McKinsey report mapping 400 AI use cases across industries and\\ncompanies estimated that in 69 percent of the use cases, the gains from AI arose from improving\\nperformance beyond that provided by other analytic techniques, and only in 16 percent of cases was AI\\nbeing used in so-called “greenfield” cases.30 This underscores the importance of regulation being\\ninformed by actual AI science and experience with its use. EU engagement with the private sector as\\npart of the HLEG process shows how this process can be developed.31\\nWhere AI regulation is needed it should be based on a risk assessment and cost-benefit analysis and\\ntargeted to each high-risk category. As noted above, this should include assessment of likelihood and\\nseverity of harm compared against the status quo. ', 'content_type': 'text', 'score': 0.5018755432912432, 'meta': {'_split_id': 26, '_split_overlap': [{'doc_id': '84d7d6d40d9f23432ce63a2156a2b6a0', 'range': (0, 310)}, {'doc_id': 'e49124173ad2aa4161a428819f58258', 'range': (739, 1099)}]}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2d35fbbfffe4eb93872c15c59e3575f3'}>]\n",
            "[<Answer {'answer': 'not suitable', 'type': 'extractive', 'score': 0.6694056987762451, 'context': '“AI” is to be welcomed, even though regulation of “AI” is, as shown, not suitable. For the purpose\\nof producing a common understanding of such a propo', 'offsets_in_document': [{'start': 166, 'end': 178}], 'offsets_in_context': [{'start': 69, 'end': 81}], 'document_ids': ['6671209c0881f2da270e7025ee1bbd06'], 'meta': {'_split_id': 33, '_split_overlap': [{'doc_id': '4d9d4bcb84d355bf2942ad3f50ac201d', 'range': (0, 179)}, {'doc_id': '8b840ab2a0a5e83467b24b74c992b36', 'range': (998, 1148)}]}}>,\n",
            " <Answer {'answer': 'certainty', 'type': 'extractive', 'score': 0.4242861568927765, 'context': 'Such regulation\\ncan provide business certainty, give consumers confidence that the AI is trustworthy. However,\\nregulation can also raise barriers to t', 'offsets_in_document': [{'start': 37, 'end': 46}], 'offsets_in_context': [{'start': 37, 'end': 46}], 'document_ids': ['4203dec524febaf10686b504e3a852e6'], 'meta': {'_split_id': 20, '_split_overlap': [{'doc_id': '25b99ad1aaaf799227dfb07642012939', 'range': (0, 187)}, {'doc_id': 'e1413d8d92b3de1ebc86437a96b3a979', 'range': (1135, 1269)}]}}>,\n",
            " <Answer {'answer': 'many companies are reluctant to start using them', 'type': 'extractive', 'score': 0.4118000268936157, 'context': 'urrently applicable to the use of AI applications,\\nmany companies are reluctant to start using them, precisely because they do not trust that by\\ndoing', 'offsets_in_document': [{'start': 295, 'end': 343}], 'offsets_in_context': [{'start': 51, 'end': 99}], 'document_ids': ['2c39eefaf12b8a4e7c22e3435d13a828'], 'meta': {'_split_id': 4, '_split_overlap': [{'doc_id': 'd7a0debf5c10872e63a058ca9a26741c', 'range': (0, 167)}, {'doc_id': 'f90d0da0498a162f21e11c39d431a2e3', 'range': (978, 1163)}]}}>,\n",
            " <Answer {'answer': 'it should be based on a risk assessment and cost-benefit analysis and\\ntargeted to each high-risk category', 'type': 'extractive', 'score': 0.36713072657585144, 'context': 'I regulation is needed it should be based on a risk assessment and cost-benefit analysis and\\ntargeted to each high-risk category. As noted above, this', 'offsets_in_document': [{'start': 878, 'end': 983}], 'offsets_in_context': [{'start': 23, 'end': 128}], 'document_ids': ['2d35fbbfffe4eb93872c15c59e3575f3'], 'meta': {'_split_id': 26, '_split_overlap': [{'doc_id': '84d7d6d40d9f23432ce63a2156a2b6a0', 'range': (0, 310)}, {'doc_id': 'e49124173ad2aa4161a428819f58258', 'range': (739, 1099)}]}}>,\n",
            " <Answer {'answer': 'hasty regulation runs the risk of obstructing the utilization of AI and\\nbusiness activities in society', 'type': 'extractive', 'score': 0.3174384534358978, 'context': 'per\\nneeds to state that hasty regulation runs the risk of obstructing the utilization of AI and\\nbusiness activities in society.\\nThe necessary tools ca', 'offsets_in_document': [{'start': 36, 'end': 138}], 'offsets_in_context': [{'start': 24, 'end': 126}], 'document_ids': ['cb661c26534eefd4d356d4870ac444ce'], 'meta': {'_split_id': 2, '_split_overlap': [{'doc_id': 'd8cf37293854f89f120a1973d270bb6b', 'range': (0, 139)}, {'doc_id': 'd53d67f27352617da6faa51e0cace923', 'range': (691, 973)}]}}>]\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "from haystack.utils import print_answers\n",
        "\n",
        "query = \"What does business think about AI regulation?\"\n",
        "\n",
        "prediction = querying_pipeline.run(\n",
        "    query=query,\n",
        "    params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
        ")\n",
        "\n",
        "pprint(prediction[\"query\"])\n",
        "pprint(prediction[\"documents\"])\n",
        "pprint(prediction[\"answers\"])\n",
        "#print_answers(prediction, details=\"minimum\")  # Choose from `minimum`, `medium` and `all`"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "-qBPoCc4H0Sa",
        "z-iZL9voFQt5",
        "2vIT0OZF-30s"
      ],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00080af5d65c4074abddbcf498909825": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "016d9144727d4595ac5fed02e2bc8dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "045afcc090944b33859dba49a22ef57c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "046be9714a4c4cccaf13cf9365c1e0b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "054dc7db23214a7282f42cb22221c659": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0594c3a0cfab43ee87e301a013be6b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06ba428fcbd24e6691868be630e0a934": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0782b6315ba1476db2808b38656f4c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "081ac22008fe4dd98feaf2b5f4215428": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0aacf6969fec4fcf807bd74a2f0c8fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0cc1ee4d5a204abea748e67a826c6781": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d72a7a4b4fe45fca82545389e5a26e2",
            "max": 79,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1af08b55be6a41fc85e32128fc2baefe",
            "value": 79
          }
        },
        "0d72a7a4b4fe45fca82545389e5a26e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e9084c205ac4cc5aaba4febabba667a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f1c3d61b2de480b9f1c464b3d6900c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f24c487b5d8478399663dfcf2be352d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8aba2f8037f49dd8f77ebda580171e6",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51c1c835a9a74a408a89e7ac4f252dcb",
            "value": 456318
          }
        },
        "11451001782f4f56bd4f20651d3bf06d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13f8cfbec20441e093a127beaa9be07d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "150f36c40ec84cbf901d50a6ff776f87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18bc96464da44897acd090d21872d006": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b31cfdb747a4f64b444fa57d824b5ee",
            "placeholder": "​",
            "style": "IPY_MODEL_5b923187afdc43a1b3180248942b930b",
            "value": "Downloading (…)tencepiece.bpe.model: 100%"
          }
        },
        "1ac05ca721854be7b14dd6076f798793": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1af08b55be6a41fc85e32128fc2baefe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b96fe7093a24c208210637856b5557b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bea3d807d424796822b363de12d8489": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13f8cfbec20441e093a127beaa9be07d",
            "max": 17082730,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_daf1400c271b4c9fae2314c849b60772",
            "value": 17082730
          }
        },
        "1c3e82daca0c469ca31121189c39674a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cff9773ff9c45cea5673bb658f501b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_341139b004c64320836168abcfa8d6d0",
            "placeholder": "​",
            "style": "IPY_MODEL_b8395701f9c8444db84b775cf70e07a1",
            "value": " 17.1M/17.1M [00:00&lt;00:00, 41.5MB/s]"
          }
        },
        "204d2c5f9728484bb799efd6179585fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21511d570ebb4367833681719ffcb594": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e9084c205ac4cc5aaba4febabba667a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56af9909d80d41cdb38ec92bf9261067",
            "value": 1
          }
        },
        "237363bbce544053aca8983ba38f032f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25236eb04e0a4db796eb13c1c26d6b23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "257164866a634816aa908b10634a256a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b7cfd995288428d9e270b2cfaef9ff8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f5317b570a940f2826a068dc9401d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_808236e5bef345658841d70187629d99",
            "placeholder": "​",
            "style": "IPY_MODEL_90979d0f127846599b78729df7f2f83e",
            "value": " 655/655 [00:00&lt;00:00, 56.4kB/s]"
          }
        },
        "3197ac9679294afe9503f4075727dc40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c41ba8639ecb47138bcc4f31247dcf5f",
              "IPY_MODEL_ac2f3cfc07514e03b26abb5dcd06b9d6",
              "IPY_MODEL_b1310db8c9d84ffa99db83fe044204fd"
            ],
            "layout": "IPY_MODEL_cfeb84eef95243fd8d5686e7228112a4"
          }
        },
        "332710b1a77b469ea1808111c41b2c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "341139b004c64320836168abcfa8d6d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39020c18a55f449f8f69740127f7e142": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46c1f4b3104a44bab02c28606fcada1b",
            "placeholder": "​",
            "style": "IPY_MODEL_7b9ab94c780e4bc497f9b24d9e02bccd",
            "value": "Inferencing Samples: 100%"
          }
        },
        "39bdc17f9fa64bfba5dc88df74ef1bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c903ff42f564b9eba17a1068c22e83b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f01e384f3db47398029a9b90e64de10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_054dc7db23214a7282f42cb22221c659",
            "placeholder": "​",
            "style": "IPY_MODEL_644c1af14312448d84fd98ecf565a5b3",
            "value": "Inferencing Samples: 100%"
          }
        },
        "422d4966818b4bcf9d29bfd7e0160804": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42a6e40356504c6db8fea9251907f6dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "430ec644c17a4862bc51a5a16d9f7cc0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43b6e8c84742422882f19a4e13401e91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "446f41933a804d2a88d374f385c9d992": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45c8797f045b4f37bf504ca360435c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d737756c93d0462c83b67d85171e4538",
            "max": 443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0aacf6969fec4fcf807bd74a2f0c8fb3",
            "value": 443
          }
        },
        "46c1f4b3104a44bab02c28606fcada1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4803cdef6dc8420cb903586509419c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ceaa7980edd74a0ea33d56a5135f8434",
              "IPY_MODEL_992794a7c10f431ea282ff3a61173668",
              "IPY_MODEL_56cf17a88e144619944e0fcabd7b8ca4"
            ],
            "layout": "IPY_MODEL_1b96fe7093a24c208210637856b5557b"
          }
        },
        "4b31cfdb747a4f64b444fa57d824b5ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b757da1728848738ce86f1b000cb66e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84242db401544a439f84507124fb45c5",
            "placeholder": "​",
            "style": "IPY_MODEL_5e0c3500f3294cfb8b2e6727570a823d",
            "value": " 79.0/79.0 [00:00&lt;00:00, 4.39kB/s]"
          }
        },
        "4ba336c727894464b94d96530385a930": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4bfb09fc877b49a98fb67cd377db6ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60d5b3788f1d4b8a8fc6c7ec7fa3a406",
              "IPY_MODEL_21511d570ebb4367833681719ffcb594",
              "IPY_MODEL_9347753daff7478f86c78e05c73b2054"
            ],
            "layout": "IPY_MODEL_1c3e82daca0c469ca31121189c39674a"
          }
        },
        "4cf2b7485cc24e70bdae5aaca39699c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e31a82ecc124a25b7a859760a0f28ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06ba428fcbd24e6691868be630e0a934",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e2d1793e8d642f2bda50d9dcc3c8c5e",
            "value": 5069051
          }
        },
        "4f42176257514426a384770a4198b058": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ac05ca721854be7b14dd6076f798793",
            "placeholder": "​",
            "style": "IPY_MODEL_7df33d64ffdb48b498fa110a57927d91",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "50237f98f6c4419295a8f2e87b1073ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fabffe7086474e6f94572fd3611b943f",
            "max": 655,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ba336c727894464b94d96530385a930",
            "value": 655
          }
        },
        "51c1c835a9a74a408a89e7ac4f252dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5333225674b54db1834baca7f6594cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25236eb04e0a4db796eb13c1c26d6b23",
            "placeholder": "​",
            "style": "IPY_MODEL_204d2c5f9728484bb799efd6179585fb",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "53e399092b6b4e1fb358e775e81f8066": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_446f41933a804d2a88d374f385c9d992",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68459a47c8574ec58d675b8ef88c0ae4",
            "value": 898822
          }
        },
        "56af9909d80d41cdb38ec92bf9261067": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56cf17a88e144619944e0fcabd7b8ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b7cfd995288428d9e270b2cfaef9ff8",
            "placeholder": "​",
            "style": "IPY_MODEL_c124dd2f89ef483a92560da144d59561",
            "value": " 20000/? [03:02&lt;00:00, 122.90 docs/s]"
          }
        },
        "59f1edfed08f479b9ccfcdacd4bbf9da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b923187afdc43a1b3180248942b930b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d833fc5d3794db6a54824097cee20cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e0c3500f3294cfb8b2e6727570a823d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60d5b3788f1d4b8a8fc6c7ec7fa3a406": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fae928f4e50b41f48ccb9be371ed0b5b",
            "placeholder": "​",
            "style": "IPY_MODEL_ad05f3252a24462593d5d22e36ed4dbe",
            "value": "Inferencing Samples: 100%"
          }
        },
        "61e970d9c18842a9840e955e5f4c6c74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "644c1af14312448d84fd98ecf565a5b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6751081ef1644ea7a1691f4aa47c633a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6759c782a0324170b771f39267714d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0f866df67df471ca4d9a1546ac2829b",
            "placeholder": "​",
            "style": "IPY_MODEL_fabed2631fcf4ab196037477fd68a38f",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "68459a47c8574ec58d675b8ef88c0ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b841865a47c4f01886e4ffd9f7414a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c75914a50394ddfbbdf93f58febbef6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d6323031efd486194468d63253921c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea668c86703146c3a0fff83d7b7c0501",
            "max": 772,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74daaa792e324cb09463d23bcb3be100",
            "value": 772
          }
        },
        "6e9cc9669a8e4a38b78563bb5cc6e375": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eff3c8e5dac495a93354e57001b8ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_257164866a634816aa908b10634a256a",
            "placeholder": "​",
            "style": "IPY_MODEL_42a6e40356504c6db8fea9251907f6dd",
            "value": " 496M/496M [00:02&lt;00:00, 241MB/s]"
          }
        },
        "6fd520a45fcf4f2ebbf5ea37051442dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7004e3061d1a45caa84ff9f933dc6a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72eb1b926e6142d9933257dad140c14d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd4281eec994428899273c558f3f483e",
            "placeholder": "​",
            "style": "IPY_MODEL_6b841865a47c4f01886e4ffd9f7414a1",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 16.1MB/s]"
          }
        },
        "7361ebe1aeb3424ca3e314d91a46f742": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b56383c3357946578ee734fd0d5bd6ec",
              "IPY_MODEL_bb66556182734a83a0c3b26d59dbe594",
              "IPY_MODEL_b8963b736ea54b6a82c54df8159ea62d"
            ],
            "layout": "IPY_MODEL_adcf498a87a74be38dfdb39e03e62bba"
          }
        },
        "74daaa792e324cb09463d23bcb3be100": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74f5a5346c5f40a592dd60e5177a0c41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75263db51b3641f7a75dfbb66080810f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a0983b0356e4c9a812556c827801930": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfe9623977af4c2ba76885de03ff3a84",
            "max": 167,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f270a6d7612741fd9844960e21339076",
            "value": 167
          }
        },
        "7b9ab94c780e4bc497f9b24d9e02bccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7df33d64ffdb48b498fa110a57927d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f1f7bf202e54e4083d7be745efc65ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8000ec3472004f50b73f1dbc73317781": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "803ba8ff25e54433a0ab40fbc7e44e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db7dcd24afe54935bbd606c0513d86d7",
              "IPY_MODEL_1bea3d807d424796822b363de12d8489",
              "IPY_MODEL_1cff9773ff9c45cea5673bb658f501b4"
            ],
            "layout": "IPY_MODEL_9dddc44b1e794cc5839569fa8d493b79"
          }
        },
        "808236e5bef345658841d70187629d99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82993715a80f4fcb92bd8b886afdce26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8322e66cce944105b524f18f2234b4a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdb178fd98d14bc0aeb31925fb924828",
            "placeholder": "​",
            "style": "IPY_MODEL_e2ec5b4738ef42cb8ee4653867087775",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "84242db401544a439f84507124fb45c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "849c12ed70ef40a8ad80cf7cac722a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f01e384f3db47398029a9b90e64de10",
              "IPY_MODEL_a9072d4640e642dc8ea890ae1a285201",
              "IPY_MODEL_c81dc2507f61452ebc13a728569b5c18"
            ],
            "layout": "IPY_MODEL_6e9cc9669a8e4a38b78563bb5cc6e375"
          }
        },
        "88381ac1be2d4ca99229035d94ef4e55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c75914a50394ddfbbdf93f58febbef6",
            "placeholder": "​",
            "style": "IPY_MODEL_9ddeeec030a747f69f1e32a228c5a53f",
            "value": " 1/1 [00:00&lt;00:00, 30.27it/s]"
          }
        },
        "8885c8eeead64888a236bd78f39bcb00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f42176257514426a384770a4198b058",
              "IPY_MODEL_7a0983b0356e4c9a812556c827801930",
              "IPY_MODEL_89276afe49d745629d0a3bafb4ed092b"
            ],
            "layout": "IPY_MODEL_a68f1114b0514a7c9369e034eeaa71ff"
          }
        },
        "89276afe49d745629d0a3bafb4ed092b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9ab0ab8426a49b4864633ed48fa32c7",
            "placeholder": "​",
            "style": "IPY_MODEL_39bdc17f9fa64bfba5dc88df74ef1bab",
            "value": " 167/167 [00:00&lt;00:00, 14.5kB/s]"
          }
        },
        "8952f77822174d1794ee2cb481ce428c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_045afcc090944b33859dba49a22ef57c",
            "placeholder": "​",
            "style": "IPY_MODEL_e91e4108c2044221ac76f4530e5fe0fd",
            "value": " 443/443 [00:00&lt;00:00, 33.4kB/s]"
          }
        },
        "89d91df29639441b81b2ca634b228921": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b2b960b4d344dbba1b9cb2178e99170": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43b6e8c84742422882f19a4e13401e91",
            "placeholder": "​",
            "style": "IPY_MODEL_75263db51b3641f7a75dfbb66080810f",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "8b75028dec844bec84a46be9aba6313c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bfb4ebc235548a1ae2e4e1990c6cbdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c903ff42f564b9eba17a1068c22e83b",
            "placeholder": "​",
            "style": "IPY_MODEL_0594c3a0cfab43ee87e301a013be6b7d",
            "value": " 899k/899k [00:00&lt;00:00, 4.65MB/s]"
          }
        },
        "8e2d1793e8d642f2bda50d9dcc3c8c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8eb4784d954040ac901d48b2ed785db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bfe9ea47c08e460dbf7082c64a71513c",
              "IPY_MODEL_0cc1ee4d5a204abea748e67a826c6781",
              "IPY_MODEL_4b757da1728848738ce86f1b000cb66e"
            ],
            "layout": "IPY_MODEL_cbe862f277c74856b5a329c0033d61fa"
          }
        },
        "8efa6a2cae2b422dbce48ac19f24d4a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc766388282a43c89f5d8667696bbdfc",
            "max": 313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1333060af5b4c2e9f17f8011a6bb60e",
            "value": 313
          }
        },
        "90979d0f127846599b78729df7f2f83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "931f2ce574a1465bbcb52e27c5c147eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9347753daff7478f86c78e05c73b2054": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_422d4966818b4bcf9d29bfd7e0160804",
            "placeholder": "​",
            "style": "IPY_MODEL_acabb9ea51d647c2b4f4c23b13792a70",
            "value": " 1/1 [00:00&lt;00:00,  3.56 Batches/s]"
          }
        },
        "98172cbe9ef3469287b24dd7540e1bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "992794a7c10f431ea282ff3a61173668": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d66e948bafad45a3ad333fe6118daa9e",
            "max": 12483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f1c3d61b2de480b9f1c464b3d6900c2",
            "value": 12483
          }
        },
        "9bd37f425b6f4aa8b6014012c94088fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cda516d0d3c49f79caec718cdc414b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9db5f0ad379b4c4981d224e98a0c6d86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9dddc44b1e794cc5839569fa8d493b79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ddeeec030a747f69f1e32a228c5a53f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0f866df67df471ca4d9a1546ac2829b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2958caaec4f4c4ea3208a2c8938f4b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a34c4cf1b6c6402d95716a86f45e458d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd6fa313a8834d47961d371a4d81a930",
              "IPY_MODEL_0f24c487b5d8478399663dfcf2be352d",
              "IPY_MODEL_dd633b43a0e648c09c4f8722c0c96579"
            ],
            "layout": "IPY_MODEL_a2958caaec4f4c4ea3208a2c8938f4b2"
          }
        },
        "a3df22c95efd4c5990d51b0f18358866": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39020c18a55f449f8f69740127f7e142",
              "IPY_MODEL_8efa6a2cae2b422dbce48ac19f24d4a6",
              "IPY_MODEL_c512880a850f4cc78caf5ea60a6bc6d2"
            ],
            "layout": "IPY_MODEL_6751081ef1644ea7a1691f4aa47c633a"
          }
        },
        "a4d282676ffa42e3a2b32a9a27929b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b83e685e6c8e458fbb8b6ce76294de59",
              "IPY_MODEL_ff519e773bea47e5afe12f028dda141c",
              "IPY_MODEL_88381ac1be2d4ca99229035d94ef4e55"
            ],
            "layout": "IPY_MODEL_5d833fc5d3794db6a54824097cee20cb"
          }
        },
        "a68f1114b0514a7c9369e034eeaa71ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9072d4640e642dc8ea890ae1a285201": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6b8f95719c043ac9082aa33701b7fa3",
            "max": 78,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11451001782f4f56bd4f20651d3bf06d",
            "value": 78
          }
        },
        "a91b7dd7e59644f0af5801444208f4e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9ab0ab8426a49b4864633ed48fa32c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac2f3cfc07514e03b26abb5dcd06b9d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a91b7dd7e59644f0af5801444208f4e8",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0782b6315ba1476db2808b38656f4c00",
            "value": 571
          }
        },
        "acabb9ea51d647c2b4f4c23b13792a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad05f3252a24462593d5d22e36ed4dbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adcf498a87a74be38dfdb39e03e62bba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ade218362da242f191d47bb33ba333c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b2b960b4d344dbba1b9cb2178e99170",
              "IPY_MODEL_6d6323031efd486194468d63253921c2",
              "IPY_MODEL_b8d5cffdf02947ccb6692627d0c44943"
            ],
            "layout": "IPY_MODEL_61e970d9c18842a9840e955e5f4c6c74"
          }
        },
        "ae1375a65bcb4bc08796fe6a6052ab6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_931f2ce574a1465bbcb52e27c5c147eb",
            "placeholder": "​",
            "style": "IPY_MODEL_6fd520a45fcf4f2ebbf5ea37051442dd",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "b1310db8c9d84ffa99db83fe044204fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00080af5d65c4074abddbcf498909825",
            "placeholder": "​",
            "style": "IPY_MODEL_9db5f0ad379b4c4981d224e98a0c6d86",
            "value": " 571/571 [00:00&lt;00:00, 12.1kB/s]"
          }
        },
        "b1333060af5b4c2e9f17f8011a6bb60e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2a8039a449f434480f69c05f11cf335": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b56383c3357946578ee734fd0d5bd6ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccbf5616eec14cc098921ff8f3bf931c",
            "placeholder": "​",
            "style": "IPY_MODEL_d2f31b11f78d4a5eb9c6a5d254177215",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "b6b8f95719c043ac9082aa33701b7fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8395701f9c8444db84b775cf70e07a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b83e685e6c8e458fbb8b6ce76294de59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d11fe943c2194b789a6d150dd646aa74",
            "placeholder": "​",
            "style": "IPY_MODEL_9cda516d0d3c49f79caec718cdc414b9",
            "value": "Batches: 100%"
          }
        },
        "b8963b736ea54b6a82c54df8159ea62d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e110152ee9c5494a812d47329a190bbd",
            "placeholder": "​",
            "style": "IPY_MODEL_c28a2f6590a54236bede1e6227dcbcb3",
            "value": " 471M/471M [00:09&lt;00:00, 50.4MB/s]"
          }
        },
        "b8d5cffdf02947ccb6692627d0c44943": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_237363bbce544053aca8983ba38f032f",
            "placeholder": "​",
            "style": "IPY_MODEL_ba6f367d506b474586014aeed142321d",
            "value": " 772/772 [00:00&lt;00:00, 47.3kB/s]"
          }
        },
        "ba6f367d506b474586014aeed142321d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb66556182734a83a0c3b26d59dbe594": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d00eb5cfbb3c455e91274f559a7ac05a",
            "max": 470641600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc7a0e979c74417ab4c53fb38bfc4b43",
            "value": 470641600
          }
        },
        "bc766388282a43c89f5d8667696bbdfc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc7a0e979c74417ab4c53fb38bfc4b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfd4b4f46ead43dab90bbd1981bcba7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfe9ea47c08e460dbf7082c64a71513c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_046be9714a4c4cccaf13cf9365c1e0b9",
            "placeholder": "​",
            "style": "IPY_MODEL_9bd37f425b6f4aa8b6014012c94088fe",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "c124dd2f89ef483a92560da144d59561": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c28a2f6590a54236bede1e6227dcbcb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c41ba8639ecb47138bcc4f31247dcf5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59f1edfed08f479b9ccfcdacd4bbf9da",
            "placeholder": "​",
            "style": "IPY_MODEL_7004e3061d1a45caa84ff9f933dc6a86",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "c512880a850f4cc78caf5ea60a6bc6d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8000ec3472004f50b73f1dbc73317781",
            "placeholder": "​",
            "style": "IPY_MODEL_016d9144727d4595ac5fed02e2bc8dda",
            "value": " 313/313 [02:18&lt;00:00,  2.63 Batches/s]"
          }
        },
        "c81dc2507f61452ebc13a728569b5c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e48e21f5d1f24913b0e722f843c60b2b",
            "placeholder": "​",
            "style": "IPY_MODEL_e8fc32b177bc4d499c79ff446af83e42",
            "value": " 78/78 [00:33&lt;00:00,  2.60 Batches/s]"
          }
        },
        "c86352745e704304a8c85fd6ef99f970": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18bc96464da44897acd090d21872d006",
              "IPY_MODEL_4e31a82ecc124a25b7a859760a0f28ac",
              "IPY_MODEL_72eb1b926e6142d9933257dad140c14d"
            ],
            "layout": "IPY_MODEL_430ec644c17a4862bc51a5a16d9f7cc0"
          }
        },
        "cbe862f277c74856b5a329c0033d61fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccbf5616eec14cc098921ff8f3bf931c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd4281eec994428899273c558f3f483e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd6fa313a8834d47961d371a4d81a930": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_332710b1a77b469ea1808111c41b2c4c",
            "placeholder": "​",
            "style": "IPY_MODEL_081ac22008fe4dd98feaf2b5f4215428",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "cdb178fd98d14bc0aeb31925fb924828": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceaa7980edd74a0ea33d56a5135f8434": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6d5d66e04a44054992360fc5898f2f6",
            "placeholder": "​",
            "style": "IPY_MODEL_89d91df29639441b81b2ca634b228921",
            "value": "Documents Processed: "
          }
        },
        "cfe9623977af4c2ba76885de03ff3a84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfeb84eef95243fd8d5686e7228112a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d00eb5cfbb3c455e91274f559a7ac05a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d11fe943c2194b789a6d150dd646aa74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2f31b11f78d4a5eb9c6a5d254177215": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d66e948bafad45a3ad333fe6118daa9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6d5d66e04a44054992360fc5898f2f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d737756c93d0462c83b67d85171e4538": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daf1400c271b4c9fae2314c849b60772": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db7dcd24afe54935bbd606c0513d86d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b75028dec844bec84a46be9aba6313c",
            "placeholder": "​",
            "style": "IPY_MODEL_4cf2b7485cc24e70bdae5aaca39699c0",
            "value": "Downloading tokenizer.json: 100%"
          }
        },
        "dbfec6c460524d58ade0445022d95c5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd633b43a0e648c09c4f8722c0c96579": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfd4b4f46ead43dab90bbd1981bcba7d",
            "placeholder": "​",
            "style": "IPY_MODEL_fe1ece8872724485b7012c1d46bc4140",
            "value": " 456k/456k [00:00&lt;00:00, 7.53MB/s]"
          }
        },
        "e110152ee9c5494a812d47329a190bbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2ec5b4738ef42cb8ee4653867087775": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3a429d8f2ac4c16ac76f9accb1c63b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5333225674b54db1834baca7f6594cef",
              "IPY_MODEL_ff931a92b56d4a13aa3a56b1c239d436",
              "IPY_MODEL_6eff3c8e5dac495a93354e57001b8ec0"
            ],
            "layout": "IPY_MODEL_dbfec6c460524d58ade0445022d95c5f"
          }
        },
        "e48e21f5d1f24913b0e722f843c60b2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8aba2f8037f49dd8f77ebda580171e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8fc32b177bc4d499c79ff446af83e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e91e4108c2044221ac76f4530e5fe0fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea668c86703146c3a0fff83d7b7c0501": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f270a6d7612741fd9844960e21339076": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f76cd0fa84fa4f7e82aa6fde3c1fa71e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8322e66cce944105b524f18f2234b4a3",
              "IPY_MODEL_45c8797f045b4f37bf504ca360435c45",
              "IPY_MODEL_8952f77822174d1794ee2cb481ce428c"
            ],
            "layout": "IPY_MODEL_74f5a5346c5f40a592dd60e5177a0c41"
          }
        },
        "f8098c8542f343148e749b776311dc7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae1375a65bcb4bc08796fe6a6052ab6f",
              "IPY_MODEL_53e399092b6b4e1fb358e775e81f8066",
              "IPY_MODEL_8bfb4ebc235548a1ae2e4e1990c6cbdd"
            ],
            "layout": "IPY_MODEL_82993715a80f4fcb92bd8b886afdce26"
          }
        },
        "fa57c414a7f846048273e7d70a17a00b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fabed2631fcf4ab196037477fd68a38f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fabffe7086474e6f94572fd3611b943f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fae928f4e50b41f48ccb9be371ed0b5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe0d984a5ca547e2b997c8a4e3edb497": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6759c782a0324170b771f39267714d1a",
              "IPY_MODEL_50237f98f6c4419295a8f2e87b1073ca",
              "IPY_MODEL_2f5317b570a940f2826a068dc9401d93"
            ],
            "layout": "IPY_MODEL_150f36c40ec84cbf901d50a6ff776f87"
          }
        },
        "fe1ece8872724485b7012c1d46bc4140": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff519e773bea47e5afe12f028dda141c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa57c414a7f846048273e7d70a17a00b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98172cbe9ef3469287b24dd7540e1bb1",
            "value": 1
          }
        },
        "ff931a92b56d4a13aa3a56b1c239d436": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f1f7bf202e54e4083d7be745efc65ae",
            "max": 496254442,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2a8039a449f434480f69c05f11cf335",
            "value": 496254442
          }
        },
        "a8008aaa6fad4093a1635c6571322fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9439f9fc239417380ecf72814c39e9b",
              "IPY_MODEL_40d14832318447dda6427f48fcb86d89",
              "IPY_MODEL_9594c6ae39d449f1af2d84a7dc82083b"
            ],
            "layout": "IPY_MODEL_505cdb7d63dc4fc6bc34a542c7b79847"
          }
        },
        "d9439f9fc239417380ecf72814c39e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e8890ba6da740beb13f7f9f7d57f167",
            "placeholder": "​",
            "style": "IPY_MODEL_f6f6fd07726640dba8a56cd2bb080280",
            "value": "config.json: 100%"
          }
        },
        "40d14832318447dda6427f48fcb86d89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_782360c00ba148798a8b4e183b23815c",
            "max": 891,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b685a89dea84c6da280d6f0164e5397",
            "value": 891
          }
        },
        "9594c6ae39d449f1af2d84a7dc82083b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a7861253b5641a7b18d10388b962d2e",
            "placeholder": "​",
            "style": "IPY_MODEL_7bd80cb34c6441918731969866646ae0",
            "value": " 891/891 [00:00&lt;00:00, 43.0kB/s]"
          }
        },
        "505cdb7d63dc4fc6bc34a542c7b79847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e8890ba6da740beb13f7f9f7d57f167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6f6fd07726640dba8a56cd2bb080280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "782360c00ba148798a8b4e183b23815c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b685a89dea84c6da280d6f0164e5397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a7861253b5641a7b18d10388b962d2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bd80cb34c6441918731969866646ae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72b68884eea14286a8f23c37aff949d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ccef7234aa14a388a8aba3310af131f",
              "IPY_MODEL_b4e4cc786a794c5e89ce4e93d9f5b5b0",
              "IPY_MODEL_99dc239adec947e8b68b69e0992b7e27"
            ],
            "layout": "IPY_MODEL_5ba0d9ad46594911b8b67971db1017c4"
          }
        },
        "5ccef7234aa14a388a8aba3310af131f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aa4de7ea45f436bb6027fc5a509b159",
            "placeholder": "​",
            "style": "IPY_MODEL_b7e55906994f4d7f8277bf68e5c36aa9",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "b4e4cc786a794c5e89ce4e93d9f5b5b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d163a9709c004211a5950fcc8abbcb7c",
            "max": 470633197,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e28af1337c3d49f2ba484c2ebe506cbf",
            "value": 470633197
          }
        },
        "99dc239adec947e8b68b69e0992b7e27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0a5badb86f24044b6408baade12d200",
            "placeholder": "​",
            "style": "IPY_MODEL_b5ff58d1df594f96abfcf51eae6f3846",
            "value": " 471M/471M [00:22&lt;00:00, 21.3MB/s]"
          }
        },
        "5ba0d9ad46594911b8b67971db1017c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aa4de7ea45f436bb6027fc5a509b159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7e55906994f4d7f8277bf68e5c36aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d163a9709c004211a5950fcc8abbcb7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e28af1337c3d49f2ba484c2ebe506cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0a5badb86f24044b6408baade12d200": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5ff58d1df594f96abfcf51eae6f3846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7d20d561e5d4c468e6140d85234098e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c90ac15142d3487585e0fb5c638c76a2",
              "IPY_MODEL_5ee3e5fa851844298a2f9ea53e3eee57",
              "IPY_MODEL_600401b95b144e46ae97e5238a5cbe7a"
            ],
            "layout": "IPY_MODEL_07c91b8b87304857843b997605754d5b"
          }
        },
        "c90ac15142d3487585e0fb5c638c76a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5a4e5d235b94467a5148a2939318500",
            "placeholder": "​",
            "style": "IPY_MODEL_081ba1be30874898b90c87214e4b5338",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "5ee3e5fa851844298a2f9ea53e3eee57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_239b2963943b42cd8f8948c10f1f6c9d",
            "max": 435,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f8ad866e0024414b07893f0d79b8b5b",
            "value": 435
          }
        },
        "600401b95b144e46ae97e5238a5cbe7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a2c8b68fe7c40859a045970bfb7827d",
            "placeholder": "​",
            "style": "IPY_MODEL_4cf1db1e6459403aa7a787f1775dbd36",
            "value": " 435/435 [00:00&lt;00:00, 17.6kB/s]"
          }
        },
        "07c91b8b87304857843b997605754d5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5a4e5d235b94467a5148a2939318500": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "081ba1be30874898b90c87214e4b5338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "239b2963943b42cd8f8948c10f1f6c9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f8ad866e0024414b07893f0d79b8b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a2c8b68fe7c40859a045970bfb7827d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cf1db1e6459403aa7a787f1775dbd36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a75f8120f92f428da1261f9dc1469e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2444c9accb74457a3bbad96fedfbc40",
              "IPY_MODEL_426599ecb0b540a29e0e4e723119f833",
              "IPY_MODEL_bd6ecb23eba946229cb52e7e4e4e5f12"
            ],
            "layout": "IPY_MODEL_ff08697e1be6416fb1e8f6553500a271"
          }
        },
        "a2444c9accb74457a3bbad96fedfbc40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ecf4301b030451fb15cbc8a54173428",
            "placeholder": "​",
            "style": "IPY_MODEL_d3125a463c094b6fa685afc1b50c8f13",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "426599ecb0b540a29e0e4e723119f833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dec5a389cab41968ce090cfd65b2d83",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9c142d312344df2a7d303d6299f569e",
            "value": 5069051
          }
        },
        "bd6ecb23eba946229cb52e7e4e4e5f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75fe3e70dd3345259458017d1449fb66",
            "placeholder": "​",
            "style": "IPY_MODEL_a85eeffcf0674737a14439c7f29a29b2",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 7.69MB/s]"
          }
        },
        "ff08697e1be6416fb1e8f6553500a271": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ecf4301b030451fb15cbc8a54173428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3125a463c094b6fa685afc1b50c8f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dec5a389cab41968ce090cfd65b2d83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9c142d312344df2a7d303d6299f569e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75fe3e70dd3345259458017d1449fb66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a85eeffcf0674737a14439c7f29a29b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e54a58757364dd0b2603769d6383101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2bba6209cf542b086b50698fc07711b",
              "IPY_MODEL_9989c5109e7f48baa01e4eec5c630889",
              "IPY_MODEL_52361cec5f464986a90c59f7eabdb405"
            ],
            "layout": "IPY_MODEL_d04a058e43d2449d8261d2b75c9f7514"
          }
        },
        "f2bba6209cf542b086b50698fc07711b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c16316acd4904fb08c819e23dbfd3919",
            "placeholder": "​",
            "style": "IPY_MODEL_651d19b5d5bd4be9be2e541df9d101b4",
            "value": "tokenizer.json: 100%"
          }
        },
        "9989c5109e7f48baa01e4eec5c630889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_478d4f03bcc546fa923e1bfc974df34e",
            "max": 17082660,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33702be8f2cd4a828fec0a7134f2fcce",
            "value": 17082660
          }
        },
        "52361cec5f464986a90c59f7eabdb405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd1096ac71e945c1aa4df7ddec733e4f",
            "placeholder": "​",
            "style": "IPY_MODEL_7ab356dd104f4d299b8aaa7f9c1402e3",
            "value": " 17.1M/17.1M [00:00&lt;00:00, 20.2MB/s]"
          }
        },
        "d04a058e43d2449d8261d2b75c9f7514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c16316acd4904fb08c819e23dbfd3919": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "651d19b5d5bd4be9be2e541df9d101b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "478d4f03bcc546fa923e1bfc974df34e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33702be8f2cd4a828fec0a7134f2fcce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd1096ac71e945c1aa4df7ddec733e4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ab356dd104f4d299b8aaa7f9c1402e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76e704ece194493aa31fa2b45df278fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af3f0daf59f74f22a94276ba53eb2fdc",
              "IPY_MODEL_dc456c4811714a08bb143df8795940bc",
              "IPY_MODEL_fcff89bed632491aad5c55e43338eac8"
            ],
            "layout": "IPY_MODEL_1982d362a79540cf967c43aa84baec79"
          }
        },
        "af3f0daf59f74f22a94276ba53eb2fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_225ceba5c07e402b87f98ec827a379f9",
            "placeholder": "​",
            "style": "IPY_MODEL_eef79ce018f146bd8a782342193c166c",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "dc456c4811714a08bb143df8795940bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_293da2f1b3b34c488ef855ac477b24f9",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_628556119e94436abaa2b5eab78d7ea4",
            "value": 239
          }
        },
        "fcff89bed632491aad5c55e43338eac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d57dbeab5a524726a2dec6257e26ea60",
            "placeholder": "​",
            "style": "IPY_MODEL_2b39837250604bd28e89b085744ae989",
            "value": " 239/239 [00:00&lt;00:00, 15.2kB/s]"
          }
        },
        "1982d362a79540cf967c43aa84baec79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "225ceba5c07e402b87f98ec827a379f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eef79ce018f146bd8a782342193c166c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "293da2f1b3b34c488ef855ac477b24f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "628556119e94436abaa2b5eab78d7ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d57dbeab5a524726a2dec6257e26ea60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b39837250604bd28e89b085744ae989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2391ddc1fe314c24add905086fbe8298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5c6818d397848e6a5bcb0e51bf01835",
              "IPY_MODEL_dc5c8b03e90a4b5da7bff9004a71007d",
              "IPY_MODEL_5df4fe79109b4f2fa0c16d48cdf67b36"
            ],
            "layout": "IPY_MODEL_55c98f4f180c4e14a08863a8645652fd"
          }
        },
        "c5c6818d397848e6a5bcb0e51bf01835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c731dc5403a418287cd86e2a693496f",
            "placeholder": "​",
            "style": "IPY_MODEL_d7dcf674c0f64455b3bd28d8ab5eadd9",
            "value": "config.json: 100%"
          }
        },
        "dc5c8b03e90a4b5da7bff9004a71007d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b26ffc31d2f4ddf8309690fccc0ca4b",
            "max": 891,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fa6223f78834fccb6a15735cc51dced",
            "value": 891
          }
        },
        "5df4fe79109b4f2fa0c16d48cdf67b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75ad69302e994588a6e84239d6701e2b",
            "placeholder": "​",
            "style": "IPY_MODEL_138605ab6f2f48ab96d5ab99d30ac191",
            "value": " 891/891 [00:00&lt;00:00, 34.7kB/s]"
          }
        },
        "55c98f4f180c4e14a08863a8645652fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c731dc5403a418287cd86e2a693496f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7dcf674c0f64455b3bd28d8ab5eadd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b26ffc31d2f4ddf8309690fccc0ca4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fa6223f78834fccb6a15735cc51dced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75ad69302e994588a6e84239d6701e2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "138605ab6f2f48ab96d5ab99d30ac191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f2084627e64413a81d2a926749108ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1c96bb841a244c2831cf4eeda61b36d",
              "IPY_MODEL_724b1fef03294529bdb7ff7a388a02ed",
              "IPY_MODEL_7b77b491eb7b46c8a53ed4bc0d620181"
            ],
            "layout": "IPY_MODEL_97afed372b52409499e11169d9fd23a3"
          }
        },
        "a1c96bb841a244c2831cf4eeda61b36d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f859de6a84e74d988d1aa571f41d1065",
            "placeholder": "​",
            "style": "IPY_MODEL_656ffc378bc745ad925c805e25646faa",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "724b1fef03294529bdb7ff7a388a02ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e92e28ccfafc40cd92034ca21f43bc80",
            "max": 470633197,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97188f61650a441397c9dee80512c90c",
            "value": 470633197
          }
        },
        "7b77b491eb7b46c8a53ed4bc0d620181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_892c358b26c340e49e5d97be3987a27b",
            "placeholder": "​",
            "style": "IPY_MODEL_7f5fa20275234e27881bb82134763693",
            "value": " 471M/471M [00:30&lt;00:00, 16.3MB/s]"
          }
        },
        "97afed372b52409499e11169d9fd23a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f859de6a84e74d988d1aa571f41d1065": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "656ffc378bc745ad925c805e25646faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e92e28ccfafc40cd92034ca21f43bc80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97188f61650a441397c9dee80512c90c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "892c358b26c340e49e5d97be3987a27b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f5fa20275234e27881bb82134763693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09f1d37b527a4832af10bc3d475b915d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31cc6289d03f48b38092fc6581bae1f3",
              "IPY_MODEL_f9e76849e3514945b148b4696055e325",
              "IPY_MODEL_a265f9dc6fcb4aa182dab0452e290cd7"
            ],
            "layout": "IPY_MODEL_21753c942dc94ca39da691670d7de396"
          }
        },
        "31cc6289d03f48b38092fc6581bae1f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfb37629499b4f1ba04bd05ec603c0d5",
            "placeholder": "​",
            "style": "IPY_MODEL_43b49421e5e74bbfbf96d1914b5520f4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f9e76849e3514945b148b4696055e325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10bce7dd1071421cb9dd64f7e71c477b",
            "max": 435,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80cf4ef28de34929be2512c11c3e03fc",
            "value": 435
          }
        },
        "a265f9dc6fcb4aa182dab0452e290cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b1246cdb16846d38243c9d079c43939",
            "placeholder": "​",
            "style": "IPY_MODEL_8d2a58f0c1ad438db8375814ee084d70",
            "value": " 435/435 [00:00&lt;00:00, 30.9kB/s]"
          }
        },
        "21753c942dc94ca39da691670d7de396": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfb37629499b4f1ba04bd05ec603c0d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43b49421e5e74bbfbf96d1914b5520f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10bce7dd1071421cb9dd64f7e71c477b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80cf4ef28de34929be2512c11c3e03fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b1246cdb16846d38243c9d079c43939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d2a58f0c1ad438db8375814ee084d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7d010677f7442f49535a2e587471559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab0d8a8139bd40049e63cde45677cb34",
              "IPY_MODEL_56d3f56b93c74edc9ab9647b6e600da1",
              "IPY_MODEL_ca910c771fff42e581df8398fb63765e"
            ],
            "layout": "IPY_MODEL_d816a11353e5482bbf02b5f20cfd29fa"
          }
        },
        "ab0d8a8139bd40049e63cde45677cb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3db9a8a191b34941b4615324ee0c03bd",
            "placeholder": "​",
            "style": "IPY_MODEL_05a1c81e48794dcaa8b2ce355be9848d",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "56d3f56b93c74edc9ab9647b6e600da1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20892c7e4e184762b71e29d91f5b0653",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54305436df734908ad750facb131b9bf",
            "value": 5069051
          }
        },
        "ca910c771fff42e581df8398fb63765e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdba06e808b7419a96317890781c8418",
            "placeholder": "​",
            "style": "IPY_MODEL_43349421955f47c98d5326e4c57441a1",
            "value": " 5.07M/5.07M [00:01&lt;00:00, 3.20MB/s]"
          }
        },
        "d816a11353e5482bbf02b5f20cfd29fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3db9a8a191b34941b4615324ee0c03bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05a1c81e48794dcaa8b2ce355be9848d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20892c7e4e184762b71e29d91f5b0653": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54305436df734908ad750facb131b9bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdba06e808b7419a96317890781c8418": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43349421955f47c98d5326e4c57441a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8cf8ba701c6468bb24ae954a509e37d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c78865a8b423458bb75878a9bc5a20b0",
              "IPY_MODEL_971d41964d134ab19ee78276c61b3da6",
              "IPY_MODEL_945df6dfd3f54a95bc3264db56f6f37c"
            ],
            "layout": "IPY_MODEL_ec9c7132f7024c11becdb504bd6e6fa2"
          }
        },
        "c78865a8b423458bb75878a9bc5a20b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_651a0a41654a4deda6e7dbd11f45e1f4",
            "placeholder": "​",
            "style": "IPY_MODEL_6100929945ec490bbf5a9bccb3cf48ea",
            "value": "tokenizer.json: 100%"
          }
        },
        "971d41964d134ab19ee78276c61b3da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4ed41dc1c8a428d8fcfdefbfec50fb1",
            "max": 17082660,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e13c2bd9c56b43e398c88f243299ea3c",
            "value": 17082660
          }
        },
        "945df6dfd3f54a95bc3264db56f6f37c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e38037697f0d447a8601462a92fe28b6",
            "placeholder": "​",
            "style": "IPY_MODEL_44a258b3fa2047759d34f3cec353e5b9",
            "value": " 17.1M/17.1M [00:02&lt;00:00, 6.80MB/s]"
          }
        },
        "ec9c7132f7024c11becdb504bd6e6fa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "651a0a41654a4deda6e7dbd11f45e1f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6100929945ec490bbf5a9bccb3cf48ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4ed41dc1c8a428d8fcfdefbfec50fb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e13c2bd9c56b43e398c88f243299ea3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e38037697f0d447a8601462a92fe28b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44a258b3fa2047759d34f3cec353e5b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "807f20128ef94155b41626804b0037ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0635663e2650411b97e42acbe4a7ab87",
              "IPY_MODEL_b3b365b4b0a64cce9d5e246f823de343",
              "IPY_MODEL_b7864c26b0b14ee2996018085c3a29c2"
            ],
            "layout": "IPY_MODEL_92ff61d000a84dafaf09fe0ca404e83b"
          }
        },
        "0635663e2650411b97e42acbe4a7ab87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed1cb2473b7e441b8ad7bc061a508fe0",
            "placeholder": "​",
            "style": "IPY_MODEL_279b10c87f47464e88bc0de2c4229b85",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b3b365b4b0a64cce9d5e246f823de343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4374dd68a364b2caef240e915b312e5",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e7bcead34274b4891389e1d3bae2cf5",
            "value": 239
          }
        },
        "b7864c26b0b14ee2996018085c3a29c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79f4d75f280a4b4da531a0bad76c7c91",
            "placeholder": "​",
            "style": "IPY_MODEL_6c9578964c084ab798c6f9e3217164db",
            "value": " 239/239 [00:00&lt;00:00, 15.6kB/s]"
          }
        },
        "92ff61d000a84dafaf09fe0ca404e83b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed1cb2473b7e441b8ad7bc061a508fe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "279b10c87f47464e88bc0de2c4229b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4374dd68a364b2caef240e915b312e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e7bcead34274b4891389e1d3bae2cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79f4d75f280a4b4da531a0bad76c7c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c9578964c084ab798c6f9e3217164db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}